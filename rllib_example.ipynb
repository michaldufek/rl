{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config['num_gpus'] = 0\n",
    "config['num_workers'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 10:58:59,100\tINFO trainer.py:2295 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2022-07-21 10:58:59,102\tINFO ppo.py:268 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-07-21 10:58:59,103\tINFO trainer.py:864 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=544502)\u001b[0m 2022-07-21 10:59:02,378\tWARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).\n",
      "2022-07-21 10:59:04,207\tWARNING util.py:60 -- Install gputil for GPU system monitoring.\n",
      "2022-07-21 10:59:07,473\tWARNING deprecation.py:46 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 4000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_10-59-10\n",
      "done: false\n",
      "episode_len_mean: 24.81366459627329\n",
      "episode_media: {}\n",
      "episode_reward_max: 109.0\n",
      "episode_reward_mean: 24.81366459627329\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 161\n",
      "episodes_total: 161\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.20000000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6680648326873779\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.026196440681815147\n",
      "        model: {}\n",
      "        policy_loss: -0.03886919096112251\n",
      "        total_loss: 9.027015686035156\n",
      "        vf_explained_var: -0.06597967445850372\n",
      "        vf_loss: 9.060644149780273\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 4000\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 4000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 1\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.266666666666666\n",
      "  ram_util_percent: 88.28888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.05166299996808659\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.05871520820661535\n",
      "  mean_inference_ms: 0.6026281353474497\n",
      "  mean_raw_obs_processing_ms: 0.0860453903362233\n",
      "time_since_restore: 5.80277681350708\n",
      "time_this_iter_s: 5.80277681350708\n",
      "time_total_s: 5.80277681350708\n",
      "timers:\n",
      "  learn_throughput: 1584.35\n",
      "  learn_time_ms: 2524.695\n",
      "  load_throughput: 31418007.491\n",
      "  load_time_ms: 0.127\n",
      "  sample_throughput: 1224.489\n",
      "  sample_time_ms: 3266.668\n",
      "  update_time_ms: 1.984\n",
      "timestamp: 1658393950\n",
      "timesteps_since_restore: 4000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000001/checkpoint-1\n",
      "agent_timesteps_total: 8000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_10-59-17\n",
      "done: false\n",
      "episode_len_mean: 46.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 155.0\n",
      "episode_reward_mean: 46.85\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 75\n",
      "episodes_total: 236\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.6119816899299622\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.016611145809292793\n",
      "        model: {}\n",
      "        policy_loss: -0.030397726222872734\n",
      "        total_loss: 9.433724403381348\n",
      "        vf_explained_var: -0.02905583567917347\n",
      "        vf_loss: 9.459138870239258\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 8000\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 8000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 2\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.88\n",
      "  ram_util_percent: 88.21000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.058181823645904684\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0666051974950899\n",
      "  mean_inference_ms: 0.6616122974602778\n",
      "  mean_raw_obs_processing_ms: 0.09097516379878996\n",
      "time_since_restore: 13.275986433029175\n",
      "time_this_iter_s: 7.473209619522095\n",
      "time_total_s: 13.275986433029175\n",
      "timers:\n",
      "  learn_throughput: 1355.324\n",
      "  learn_time_ms: 2951.323\n",
      "  load_throughput: 24192092.286\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 805.714\n",
      "  sample_time_ms: 4964.539\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658393957\n",
      "timesteps_since_restore: 8000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 8000\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 12000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_10-59-25\n",
      "done: false\n",
      "episode_len_mean: 72.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 72.09\n",
      "episode_reward_min: 11.0\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 276\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5720645785331726\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0082619683817029\n",
      "        model: {}\n",
      "        policy_loss: -0.02037632092833519\n",
      "        total_loss: 9.596806526184082\n",
      "        vf_explained_var: 0.011656667105853558\n",
      "        vf_loss: 9.614705085754395\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 12000\n",
      "  num_agent_steps_trained: 12000\n",
      "  num_steps_sampled: 12000\n",
      "  num_steps_trained: 12000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 3\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.49166666666667\n",
      "  ram_util_percent: 88.05000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06254483906550828\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0716740619969333\n",
      "  mean_inference_ms: 0.7000000724437581\n",
      "  mean_raw_obs_processing_ms: 0.09390900683665489\n",
      "time_since_restore: 21.005697011947632\n",
      "time_this_iter_s: 7.729710578918457\n",
      "time_total_s: 21.005697011947632\n",
      "timers:\n",
      "  learn_throughput: 1302.832\n",
      "  learn_time_ms: 3070.235\n",
      "  load_throughput: 22846867.0\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 675.971\n",
      "  sample_time_ms: 5917.416\n",
      "  update_time_ms: 2.213\n",
      "timestamp: 1658393965\n",
      "timesteps_since_restore: 12000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 12000\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 16000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_10-59-33\n",
      "done: false\n",
      "episode_len_mean: 95.47\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 95.47\n",
      "episode_reward_min: 13.0\n",
      "episodes_this_iter: 27\n",
      "episodes_total: 303\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5505146980285645\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006656712386757135\n",
      "        model: {}\n",
      "        policy_loss: -0.016865279525518417\n",
      "        total_loss: 9.548752784729004\n",
      "        vf_explained_var: 0.04090454801917076\n",
      "        vf_loss: 9.563620567321777\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 16000\n",
      "  num_agent_steps_trained: 16000\n",
      "  num_steps_sampled: 16000\n",
      "  num_steps_trained: 16000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 4\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.96666666666667\n",
      "  ram_util_percent: 88.08333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06512252012869199\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07466618381802684\n",
      "  mean_inference_ms: 0.7231271697008007\n",
      "  mean_raw_obs_processing_ms: 0.09564059901539287\n",
      "time_since_restore: 29.418038606643677\n",
      "time_this_iter_s: 8.412341594696045\n",
      "time_total_s: 29.418038606643677\n",
      "timers:\n",
      "  learn_throughput: 1242.813\n",
      "  learn_time_ms: 3218.505\n",
      "  load_throughput: 22258329.685\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 619.317\n",
      "  sample_time_ms: 6458.729\n",
      "  update_time_ms: 2.175\n",
      "timestamp: 1658393973\n",
      "timesteps_since_restore: 16000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 16000\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 20000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_10-59-42\n",
      "done: false\n",
      "episode_len_mean: 123.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 123.91\n",
      "episode_reward_min: 13.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 325\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.30000001192092896\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5575863122940063\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0014695426216349006\n",
      "        model: {}\n",
      "        policy_loss: -0.009603514336049557\n",
      "        total_loss: 9.525096893310547\n",
      "        vf_explained_var: 0.0196625255048275\n",
      "        vf_loss: 9.534259796142578\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 20000\n",
      "  num_agent_steps_trained: 20000\n",
      "  num_steps_sampled: 20000\n",
      "  num_steps_trained: 20000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 5\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.31666666666666\n",
      "  ram_util_percent: 88.03333333333332\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06811691048371898\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07811114751896196\n",
      "  mean_inference_ms: 0.750969715623186\n",
      "  mean_raw_obs_processing_ms: 0.09788073980165812\n",
      "time_since_restore: 38.20182704925537\n",
      "time_this_iter_s: 8.783788442611694\n",
      "time_total_s: 38.20182704925537\n",
      "timers:\n",
      "  learn_throughput: 1215.59\n",
      "  learn_time_ms: 3290.583\n",
      "  load_throughput: 19682327.546\n",
      "  load_time_ms: 0.203\n",
      "  sample_throughput: 576.001\n",
      "  sample_time_ms: 6944.428\n",
      "  update_time_ms: 2.268\n",
      "timestamp: 1658393982\n",
      "timesteps_since_restore: 20000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 20000\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 24000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_10-59-52\n",
      "done: false\n",
      "episode_len_mean: 153.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 153.46\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 346\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.15000000596046448\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5284289717674255\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037731099873781204\n",
      "        model: {}\n",
      "        policy_loss: -0.016402604058384895\n",
      "        total_loss: 9.537238121032715\n",
      "        vf_explained_var: 0.011269724927842617\n",
      "        vf_loss: 9.553074836730957\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 24000\n",
      "  num_agent_steps_trained: 24000\n",
      "  num_steps_sampled: 24000\n",
      "  num_steps_trained: 24000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 6\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 53.67857142857143\n",
      "  ram_util_percent: 87.97857142857143\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07055813607215132\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08095131103530057\n",
      "  mean_inference_ms: 0.7740783031033832\n",
      "  mean_raw_obs_processing_ms: 0.09970468815939917\n",
      "time_since_restore: 47.71397280693054\n",
      "time_this_iter_s: 9.512145757675171\n",
      "time_total_s: 47.71397280693054\n",
      "timers:\n",
      "  learn_throughput: 1119.033\n",
      "  learn_time_ms: 3574.514\n",
      "  load_throughput: 19630127.925\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 560.07\n",
      "  sample_time_ms: 7141.959\n",
      "  update_time_ms: 2.236\n",
      "timestamp: 1658393992\n",
      "timesteps_since_restore: 24000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 24000\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 28000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_10-59-59\n",
      "done: false\n",
      "episode_len_mean: 170.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 170.04\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 367\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.07500000298023224\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5159353017807007\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00407487154006958\n",
      "        model: {}\n",
      "        policy_loss: -0.010988730005919933\n",
      "        total_loss: 9.455941200256348\n",
      "        vf_explained_var: 0.044390298426151276\n",
      "        vf_loss: 9.46662425994873\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 28000\n",
      "  num_agent_steps_trained: 28000\n",
      "  num_steps_sampled: 28000\n",
      "  num_steps_trained: 28000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 7\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.92727272727273\n",
      "  ram_util_percent: 88.19090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07246342314785433\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08317847817587008\n",
      "  mean_inference_ms: 0.7923255087004593\n",
      "  mean_raw_obs_processing_ms: 0.10110336133840205\n",
      "time_since_restore: 55.446038007736206\n",
      "time_this_iter_s: 7.732065200805664\n",
      "time_total_s: 55.446038007736206\n",
      "timers:\n",
      "  learn_throughput: 1130.819\n",
      "  learn_time_ms: 3537.258\n",
      "  load_throughput: 19901798.339\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 535.525\n",
      "  sample_time_ms: 7469.303\n",
      "  update_time_ms: 2.218\n",
      "timestamp: 1658393999\n",
      "timesteps_since_restore: 28000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 28000\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 32000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-00-07\n",
      "done: false\n",
      "episode_len_mean: 183.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 183.06\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 387\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.5049304962158203\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0063830167055130005\n",
      "        model: {}\n",
      "        policy_loss: -0.010320240631699562\n",
      "        total_loss: 9.481812477111816\n",
      "        vf_explained_var: -0.009222819469869137\n",
      "        vf_loss: 9.491893768310547\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 32000\n",
      "  num_agent_steps_trained: 32000\n",
      "  num_steps_sampled: 32000\n",
      "  num_steps_trained: 32000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 8\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.11818181818182\n",
      "  ram_util_percent: 88.11818181818182\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07385680244250097\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08477286877571341\n",
      "  mean_inference_ms: 0.8056048420966337\n",
      "  mean_raw_obs_processing_ms: 0.10203518997599435\n",
      "time_since_restore: 63.243457555770874\n",
      "time_this_iter_s: 7.797419548034668\n",
      "time_total_s: 63.243457555770874\n",
      "timers:\n",
      "  learn_throughput: 1136.749\n",
      "  learn_time_ms: 3518.806\n",
      "  load_throughput: 20323701.999\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 533.057\n",
      "  sample_time_ms: 7503.883\n",
      "  update_time_ms: 2.19\n",
      "timestamp: 1658394007\n",
      "timesteps_since_restore: 32000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 32000\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 36000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-00-15\n",
      "done: false\n",
      "episode_len_mean: 190.81\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.81\n",
      "episode_reward_min: 51.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 408\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.03750000149011612\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.49135348200798035\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004050138872116804\n",
      "        model: {}\n",
      "        policy_loss: -0.009920591488480568\n",
      "        total_loss: 9.414885520935059\n",
      "        vf_explained_var: 0.04267837479710579\n",
      "        vf_loss: 9.424654960632324\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 36000\n",
      "  num_agent_steps_trained: 36000\n",
      "  num_steps_sampled: 36000\n",
      "  num_steps_trained: 36000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 9\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.72727272727272\n",
      "  ram_util_percent: 88.05454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07468837485149957\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08567537497071281\n",
      "  mean_inference_ms: 0.8130732221241499\n",
      "  mean_raw_obs_processing_ms: 0.10238954743498065\n",
      "time_since_restore: 70.80301713943481\n",
      "time_this_iter_s: 7.55955958366394\n",
      "time_total_s: 70.80301713943481\n",
      "timers:\n",
      "  learn_throughput: 1142.776\n",
      "  learn_time_ms: 3500.247\n",
      "  load_throughput: 20571518.256\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 532.151\n",
      "  sample_time_ms: 7516.659\n",
      "  update_time_ms: 2.156\n",
      "timestamp: 1658394015\n",
      "timesteps_since_restore: 36000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 36000\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 40000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-00-23\n",
      "done: false\n",
      "episode_len_mean: 193.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.79\n",
      "episode_reward_min: 51.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 428\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.01875000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4686257839202881\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005174227058887482\n",
      "        model: {}\n",
      "        policy_loss: -0.0076318965293467045\n",
      "        total_loss: 9.400371551513672\n",
      "        vf_explained_var: 0.02345193363726139\n",
      "        vf_loss: 9.407906532287598\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 40000\n",
      "  num_agent_steps_trained: 40000\n",
      "  num_steps_sampled: 40000\n",
      "  num_steps_trained: 40000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 10\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.36363636363637\n",
      "  ram_util_percent: 87.92727272727272\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07495314110430529\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08596289598847937\n",
      "  mean_inference_ms: 0.8149537553528963\n",
      "  mean_raw_obs_processing_ms: 0.10223450781122548\n",
      "time_since_restore: 78.74540138244629\n",
      "time_this_iter_s: 7.942384243011475\n",
      "time_total_s: 78.74540138244629\n",
      "timers:\n",
      "  learn_throughput: 1150.263\n",
      "  learn_time_ms: 3477.465\n",
      "  load_throughput: 19652355.628\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 528.466\n",
      "  sample_time_ms: 7569.079\n",
      "  update_time_ms: 2.179\n",
      "timestamp: 1658394023\n",
      "timesteps_since_restore: 40000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 40000\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 44000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-00-31\n",
      "done: false\n",
      "episode_len_mean: 194.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.79\n",
      "episode_reward_min: 51.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 448\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.01875000074505806\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.42515993118286133\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038502286188304424\n",
      "        model: {}\n",
      "        policy_loss: -0.0067917825654149055\n",
      "        total_loss: 9.384655952453613\n",
      "        vf_explained_var: 0.12565213441848755\n",
      "        vf_loss: 9.391374588012695\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 44000\n",
      "  num_agent_steps_trained: 44000\n",
      "  num_steps_sampled: 44000\n",
      "  num_steps_trained: 44000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 11\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.90833333333334\n",
      "  ram_util_percent: 87.89999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07517411717163473\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08618278346217029\n",
      "  mean_inference_ms: 0.8164670068122021\n",
      "  mean_raw_obs_processing_ms: 0.10209158679687322\n",
      "time_since_restore: 86.861323595047\n",
      "time_this_iter_s: 8.115922212600708\n",
      "time_total_s: 86.861323595047\n",
      "timers:\n",
      "  learn_throughput: 1117.374\n",
      "  learn_time_ms: 3579.822\n",
      "  load_throughput: 18914561.443\n",
      "  load_time_ms: 0.211\n",
      "  sample_throughput: 498.215\n",
      "  sample_time_ms: 8028.664\n",
      "  update_time_ms: 2.19\n",
      "timestamp: 1658394031\n",
      "timesteps_since_restore: 44000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 44000\n",
      "training_iteration: 11\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 48000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-00-38\n",
      "done: false\n",
      "episode_len_mean: 196.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.9\n",
      "episode_reward_min: 156.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 468\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.00937500037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4578096568584442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006342123728245497\n",
      "        model: {}\n",
      "        policy_loss: -0.012570231221616268\n",
      "        total_loss: 9.526710510253906\n",
      "        vf_explained_var: 0.10245196521282196\n",
      "        vf_loss: 9.539220809936523\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 48000\n",
      "  num_agent_steps_trained: 48000\n",
      "  num_steps_sampled: 48000\n",
      "  num_steps_trained: 48000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 12\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.14\n",
      "  ram_util_percent: 88.05\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0752910357690253\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0862915877600231\n",
      "  mean_inference_ms: 0.8171350486657775\n",
      "  mean_raw_obs_processing_ms: 0.1019285176177145\n",
      "time_since_restore: 94.23976683616638\n",
      "time_this_iter_s: 7.378443241119385\n",
      "time_total_s: 94.23976683616638\n",
      "timers:\n",
      "  learn_throughput: 1124.296\n",
      "  learn_time_ms: 3557.781\n",
      "  load_throughput: 19015319.052\n",
      "  load_time_ms: 0.21\n",
      "  sample_throughput: 491.306\n",
      "  sample_time_ms: 8141.57\n",
      "  update_time_ms: 2.153\n",
      "timestamp: 1658394038\n",
      "timesteps_since_restore: 48000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 48000\n",
      "training_iteration: 12\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 52000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-00-46\n",
      "done: false\n",
      "episode_len_mean: 196.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.0\n",
      "episode_reward_min: 156.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 489\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.00937500037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4523819386959076\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007508034817874432\n",
      "        model: {}\n",
      "        policy_loss: -0.0071322317235171795\n",
      "        total_loss: 9.439677238464355\n",
      "        vf_explained_var: 0.09757329523563385\n",
      "        vf_loss: 9.446738243103027\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 52000\n",
      "  num_agent_steps_trained: 52000\n",
      "  num_steps_sampled: 52000\n",
      "  num_steps_trained: 52000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 13\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.699999999999996\n",
      "  ram_util_percent: 88.04545454545455\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07533551858391464\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0863152042740714\n",
      "  mean_inference_ms: 0.8170293727630533\n",
      "  mean_raw_obs_processing_ms: 0.10171038720770507\n",
      "time_since_restore: 101.79046988487244\n",
      "time_this_iter_s: 7.550703048706055\n",
      "time_total_s: 101.79046988487244\n",
      "timers:\n",
      "  learn_throughput: 1121.617\n",
      "  learn_time_ms: 3566.279\n",
      "  load_throughput: 19180537.327\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 494.261\n",
      "  sample_time_ms: 8092.898\n",
      "  update_time_ms: 2.147\n",
      "timestamp: 1658394046\n",
      "timesteps_since_restore: 52000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 52000\n",
      "training_iteration: 13\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 56000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-00-54\n",
      "done: false\n",
      "episode_len_mean: 197.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.27\n",
      "episode_reward_min: 157.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 509\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.00937500037252903\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.445165753364563\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00419461028650403\n",
      "        model: {}\n",
      "        policy_loss: -0.0025844855699688196\n",
      "        total_loss: 9.220388412475586\n",
      "        vf_explained_var: -0.005647455342113972\n",
      "        vf_loss: 9.222933769226074\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 56000\n",
      "  num_agent_steps_trained: 56000\n",
      "  num_steps_sampled: 56000\n",
      "  num_steps_trained: 56000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 14\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.574999999999996\n",
      "  ram_util_percent: 88.09166666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07554311465201444\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08654284037077126\n",
      "  mean_inference_ms: 0.8189148895647258\n",
      "  mean_raw_obs_processing_ms: 0.10176568301620717\n",
      "time_since_restore: 109.93202090263367\n",
      "time_this_iter_s: 8.14155101776123\n",
      "time_total_s: 109.93202090263367\n",
      "timers:\n",
      "  learn_throughput: 1135.318\n",
      "  learn_time_ms: 3523.242\n",
      "  load_throughput: 19364284.395\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 492.813\n",
      "  sample_time_ms: 8116.661\n",
      "  update_time_ms: 2.221\n",
      "timestamp: 1658394054\n",
      "timesteps_since_restore: 56000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 56000\n",
      "training_iteration: 14\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 60000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-01-01\n",
      "done: false\n",
      "episode_len_mean: 197.84\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.84\n",
      "episode_reward_min: 157.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 529\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.004687500186264515\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4390934705734253\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030028491746634245\n",
      "        model: {}\n",
      "        policy_loss: -0.002299628220498562\n",
      "        total_loss: 9.044898986816406\n",
      "        vf_explained_var: 0.10401671379804611\n",
      "        vf_loss: 9.047184944152832\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 60000\n",
      "  num_agent_steps_trained: 60000\n",
      "  num_steps_sampled: 60000\n",
      "  num_steps_trained: 60000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 15\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.89\n",
      "  ram_util_percent: 88.11\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07557164020097845\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08654455817244708\n",
      "  mean_inference_ms: 0.8188473163034514\n",
      "  mean_raw_obs_processing_ms: 0.10163687714958014\n",
      "time_since_restore: 117.15502691268921\n",
      "time_this_iter_s: 7.223006010055542\n",
      "time_total_s: 117.15502691268921\n",
      "timers:\n",
      "  learn_throughput: 1149.937\n",
      "  learn_time_ms: 3478.45\n",
      "  load_throughput: 20520078.278\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 502.339\n",
      "  sample_time_ms: 7962.746\n",
      "  update_time_ms: 2.174\n",
      "timestamp: 1658394061\n",
      "timesteps_since_restore: 60000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 60000\n",
      "training_iteration: 15\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 64000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-01-09\n",
      "done: false\n",
      "episode_len_mean: 197.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.45\n",
      "episode_reward_min: 144.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 550\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0023437500931322575\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4171767234802246\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031170696020126343\n",
      "        model: {}\n",
      "        policy_loss: -0.01779438927769661\n",
      "        total_loss: 9.27519702911377\n",
      "        vf_explained_var: 0.07769042253494263\n",
      "        vf_loss: 9.292983055114746\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 64000\n",
      "  num_agent_steps_trained: 64000\n",
      "  num_steps_sampled: 64000\n",
      "  num_steps_trained: 64000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 16\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.50909090909091\n",
      "  ram_util_percent: 88.06363636363636\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07552620211727072\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08646424856969336\n",
      "  mean_inference_ms: 0.8179108990816966\n",
      "  mean_raw_obs_processing_ms: 0.10144210835649936\n",
      "time_since_restore: 124.77725553512573\n",
      "time_this_iter_s: 7.622228622436523\n",
      "time_total_s: 124.77725553512573\n",
      "timers:\n",
      "  learn_throughput: 1207.136\n",
      "  learn_time_ms: 3313.63\n",
      "  load_throughput: 20631106.739\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 506.771\n",
      "  sample_time_ms: 7893.111\n",
      "  update_time_ms: 2.196\n",
      "timestamp: 1658394069\n",
      "timesteps_since_restore: 64000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 64000\n",
      "training_iteration: 16\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 68000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-01-16\n",
      "done: false\n",
      "episode_len_mean: 195.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.48\n",
      "episode_reward_min: 143.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 571\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0011718750465661287\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4342869222164154\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008100146427750587\n",
      "        model: {}\n",
      "        policy_loss: -0.0016696631209924817\n",
      "        total_loss: 8.890067100524902\n",
      "        vf_explained_var: 0.3222624659538269\n",
      "        vf_loss: 8.891727447509766\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 68000\n",
      "  num_agent_steps_trained: 68000\n",
      "  num_steps_sampled: 68000\n",
      "  num_steps_trained: 68000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 17\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.52727272727273\n",
      "  ram_util_percent: 87.91818181818184\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07552527404680347\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08644542744974765\n",
      "  mean_inference_ms: 0.817483602386164\n",
      "  mean_raw_obs_processing_ms: 0.10130781234683932\n",
      "time_since_restore: 132.3892958164215\n",
      "time_this_iter_s: 7.612040281295776\n",
      "time_total_s: 132.3892958164215\n",
      "timers:\n",
      "  learn_throughput: 1207.897\n",
      "  learn_time_ms: 3311.541\n",
      "  load_throughput: 20694728.013\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 518.237\n",
      "  sample_time_ms: 7718.483\n",
      "  update_time_ms: 2.267\n",
      "timestamp: 1658394076\n",
      "timesteps_since_restore: 68000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 68000\n",
      "training_iteration: 17\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 72000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-01-24\n",
      "done: false\n",
      "episode_len_mean: 188.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.62\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 595\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0011718750465661287\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.43551477789878845\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0123841417953372\n",
      "        model: {}\n",
      "        policy_loss: -0.002890506759285927\n",
      "        total_loss: 8.625423431396484\n",
      "        vf_explained_var: 0.4404771327972412\n",
      "        vf_loss: 8.628299713134766\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 72000\n",
      "  num_agent_steps_trained: 72000\n",
      "  num_steps_sampled: 72000\n",
      "  num_steps_trained: 72000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 18\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.35454545454545\n",
      "  ram_util_percent: 87.9909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07555005522495976\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08646765124906011\n",
      "  mean_inference_ms: 0.8174274094759097\n",
      "  mean_raw_obs_processing_ms: 0.1012222986560756\n",
      "time_since_restore: 140.28186058998108\n",
      "time_this_iter_s: 7.89256477355957\n",
      "time_total_s: 140.28186058998108\n",
      "timers:\n",
      "  learn_throughput: 1205.499\n",
      "  learn_time_ms: 3318.127\n",
      "  load_throughput: 20626033.932\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 518.209\n",
      "  sample_time_ms: 7718.892\n",
      "  update_time_ms: 2.279\n",
      "timestamp: 1658394084\n",
      "timesteps_since_restore: 72000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 72000\n",
      "training_iteration: 18\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 76000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-01-32\n",
      "done: false\n",
      "episode_len_mean: 188.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.19\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 615\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0011718750465661287\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.45759329199790955\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024424700532108545\n",
      "        model: {}\n",
      "        policy_loss: 0.00164004135876894\n",
      "        total_loss: 8.47361946105957\n",
      "        vf_explained_var: 0.27465417981147766\n",
      "        vf_loss: 8.471976280212402\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 76000\n",
      "  num_agent_steps_trained: 76000\n",
      "  num_steps_sampled: 76000\n",
      "  num_steps_trained: 76000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 19\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.7\n",
      "  ram_util_percent: 88.02727272727272\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07546344157346443\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08636534913134562\n",
      "  mean_inference_ms: 0.816265064276887\n",
      "  mean_raw_obs_processing_ms: 0.10103243307770224\n",
      "time_since_restore: 147.78296446800232\n",
      "time_this_iter_s: 7.50110387802124\n",
      "time_total_s: 147.78296446800232\n",
      "timers:\n",
      "  learn_throughput: 1208.268\n",
      "  learn_time_ms: 3310.525\n",
      "  load_throughput: 19784452.83\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 517.651\n",
      "  sample_time_ms: 7727.218\n",
      "  update_time_ms: 2.287\n",
      "timestamp: 1658394092\n",
      "timesteps_since_restore: 76000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 76000\n",
      "training_iteration: 19\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 80000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-01-40\n",
      "done: false\n",
      "episode_len_mean: 187.72\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.72\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 636\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0005859375232830644\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.45534464716911316\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005723016802221537\n",
      "        model: {}\n",
      "        policy_loss: -0.0034410711377859116\n",
      "        total_loss: 8.895940780639648\n",
      "        vf_explained_var: 0.35563063621520996\n",
      "        vf_loss: 8.89937686920166\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 80000\n",
      "  num_agent_steps_trained: 80000\n",
      "  num_steps_sampled: 80000\n",
      "  num_steps_trained: 80000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 20\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.699999999999996\n",
      "  ram_util_percent: 88.02500000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0754169127259549\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08631264225740784\n",
      "  mean_inference_ms: 0.8155676558581157\n",
      "  mean_raw_obs_processing_ms: 0.1008865134897734\n",
      "time_since_restore: 156.14208889007568\n",
      "time_this_iter_s: 8.359124422073364\n",
      "time_total_s: 156.14208889007568\n",
      "timers:\n",
      "  learn_throughput: 1180.181\n",
      "  learn_time_ms: 3389.31\n",
      "  load_throughput: 20776738.08\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 520.746\n",
      "  sample_time_ms: 7681.287\n",
      "  update_time_ms: 2.69\n",
      "timestamp: 1658394100\n",
      "timesteps_since_restore: 80000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 80000\n",
      "training_iteration: 20\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 84000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-01-49\n",
      "done: false\n",
      "episode_len_mean: 186.54\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.54\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 657\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0005859375232830644\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4726215898990631\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005090025719255209\n",
      "        model: {}\n",
      "        policy_loss: 0.0009290339075960219\n",
      "        total_loss: 8.690808296203613\n",
      "        vf_explained_var: 0.30929604172706604\n",
      "        vf_loss: 8.689876556396484\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 84000\n",
      "  num_agent_steps_trained: 84000\n",
      "  num_steps_sampled: 84000\n",
      "  num_steps_trained: 84000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 21\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.48333333333334\n",
      "  ram_util_percent: 88.21666666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07546406044319749\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08636886606747379\n",
      "  mean_inference_ms: 0.8159752047498284\n",
      "  mean_raw_obs_processing_ms: 0.10086884811760549\n",
      "time_since_restore: 164.38208627700806\n",
      "time_this_iter_s: 8.239997386932373\n",
      "time_total_s: 164.38208627700806\n",
      "timers:\n",
      "  learn_throughput: 1184.82\n",
      "  learn_time_ms: 3376.04\n",
      "  load_throughput: 21119355.488\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 513.435\n",
      "  sample_time_ms: 7790.672\n",
      "  update_time_ms: 2.761\n",
      "timestamp: 1658394109\n",
      "timesteps_since_restore: 84000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 84000\n",
      "training_iteration: 21\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 88000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-01-56\n",
      "done: false\n",
      "episode_len_mean: 186.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.98\n",
      "episode_reward_min: 119.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 679\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0005859375232830644\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.44946765899658203\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006370415911078453\n",
      "        model: {}\n",
      "        policy_loss: -0.0016299214912578464\n",
      "        total_loss: 8.602631568908691\n",
      "        vf_explained_var: 0.4586154520511627\n",
      "        vf_loss: 8.604257583618164\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 88000\n",
      "  num_agent_steps_trained: 88000\n",
      "  num_steps_sampled: 88000\n",
      "  num_steps_trained: 88000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 22\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.24999999999999\n",
      "  ram_util_percent: 87.75999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07546125130265018\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08636603914396769\n",
      "  mean_inference_ms: 0.8159245871428285\n",
      "  mean_raw_obs_processing_ms: 0.10079716822164403\n",
      "time_since_restore: 171.66386127471924\n",
      "time_this_iter_s: 7.281774997711182\n",
      "time_total_s: 171.66386127471924\n",
      "timers:\n",
      "  learn_throughput: 1184.103\n",
      "  learn_time_ms: 3378.085\n",
      "  load_throughput: 20542691.319\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 515.071\n",
      "  sample_time_ms: 7765.925\n",
      "  update_time_ms: 2.758\n",
      "timestamp: 1658394116\n",
      "timesteps_since_restore: 88000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 88000\n",
      "training_iteration: 22\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 92000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-02-03\n",
      "done: false\n",
      "episode_len_mean: 189.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.02\n",
      "episode_reward_min: 137.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 700\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0005859375232830644\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4503684937953949\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005715790204703808\n",
      "        model: {}\n",
      "        policy_loss: 0.0018861701246351004\n",
      "        total_loss: 8.700359344482422\n",
      "        vf_explained_var: 0.25336289405822754\n",
      "        vf_loss: 8.698470115661621\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 92000\n",
      "  num_agent_steps_trained: 92000\n",
      "  num_steps_sampled: 92000\n",
      "  num_steps_trained: 92000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 23\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.269999999999996\n",
      "  ram_util_percent: 87.62\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07540655635209183\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0863053103794377\n",
      "  mean_inference_ms: 0.8152840665711036\n",
      "  mean_raw_obs_processing_ms: 0.10066274200923982\n",
      "time_since_restore: 178.78840947151184\n",
      "time_this_iter_s: 7.1245481967926025\n",
      "time_total_s: 178.78840947151184\n",
      "timers:\n",
      "  learn_throughput: 1194.998\n",
      "  learn_time_ms: 3347.287\n",
      "  load_throughput: 20623498.463\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 515.705\n",
      "  sample_time_ms: 7756.373\n",
      "  update_time_ms: 2.713\n",
      "timestamp: 1658394123\n",
      "timesteps_since_restore: 92000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 92000\n",
      "training_iteration: 23\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 96000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-02-10\n",
      "done: false\n",
      "episode_len_mean: 187.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.93\n",
      "episode_reward_min: 107.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 721\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0005859375232830644\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4215172231197357\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004954018630087376\n",
      "        model: {}\n",
      "        policy_loss: 0.0014925409341230989\n",
      "        total_loss: 8.813214302062988\n",
      "        vf_explained_var: 0.13240952789783478\n",
      "        vf_loss: 8.811718940734863\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 96000\n",
      "  num_agent_steps_trained: 96000\n",
      "  num_steps_sampled: 96000\n",
      "  num_steps_trained: 96000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 24\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.04\n",
      "  ram_util_percent: 87.64000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07532552159403796\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.086215483031927\n",
      "  mean_inference_ms: 0.8143573350891011\n",
      "  mean_raw_obs_processing_ms: 0.10050529636868984\n",
      "time_since_restore: 185.9384331703186\n",
      "time_this_iter_s: 7.150023698806763\n",
      "time_total_s: 185.9384331703186\n",
      "timers:\n",
      "  learn_throughput: 1198.567\n",
      "  learn_time_ms: 3337.318\n",
      "  load_throughput: 20659051.841\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 523.809\n",
      "  sample_time_ms: 7636.378\n",
      "  update_time_ms: 2.649\n",
      "timestamp: 1658394130\n",
      "timesteps_since_restore: 96000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 96000\n",
      "training_iteration: 24\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 100000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-02-19\n",
      "done: false\n",
      "episode_len_mean: 188.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.51\n",
      "episode_reward_min: 107.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 742\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0002929687616415322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4158383011817932\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006168511230498552\n",
      "        model: {}\n",
      "        policy_loss: -0.001321776187978685\n",
      "        total_loss: 8.423680305480957\n",
      "        vf_explained_var: 0.05737250670790672\n",
      "        vf_loss: 8.425000190734863\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 100000\n",
      "  num_agent_steps_trained: 100000\n",
      "  num_steps_sampled: 100000\n",
      "  num_steps_trained: 100000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 25\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.36666666666667\n",
      "  ram_util_percent: 87.925\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07530862717220105\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08619917530246796\n",
      "  mean_inference_ms: 0.8141080992133375\n",
      "  mean_raw_obs_processing_ms: 0.10045225177099237\n",
      "time_since_restore: 194.23408317565918\n",
      "time_this_iter_s: 8.295650005340576\n",
      "time_total_s: 194.23408317565918\n",
      "timers:\n",
      "  learn_throughput: 1188.276\n",
      "  learn_time_ms: 3366.222\n",
      "  load_throughput: 19782120.033\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 519.146\n",
      "  sample_time_ms: 7704.968\n",
      "  update_time_ms: 2.996\n",
      "timestamp: 1658394139\n",
      "timesteps_since_restore: 100000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 100000\n",
      "training_iteration: 25\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 104000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-02-26\n",
      "done: false\n",
      "episode_len_mean: 190.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.09\n",
      "episode_reward_min: 107.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 762\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0002929687616415322\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4324781596660614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004470769315958023\n",
      "        model: {}\n",
      "        policy_loss: 0.0013962917728349566\n",
      "        total_loss: 7.420628070831299\n",
      "        vf_explained_var: 0.02032117173075676\n",
      "        vf_loss: 7.419229984283447\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 104000\n",
      "  num_agent_steps_trained: 104000\n",
      "  num_steps_sampled: 104000\n",
      "  num_steps_trained: 104000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 26\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.00909090909091\n",
      "  ram_util_percent: 87.70909090909092\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07523603753691074\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08611965660167656\n",
      "  mean_inference_ms: 0.8132403392579122\n",
      "  mean_raw_obs_processing_ms: 0.10033589978579634\n",
      "time_since_restore: 201.5081911087036\n",
      "time_this_iter_s: 7.274107933044434\n",
      "time_total_s: 201.5081911087036\n",
      "timers:\n",
      "  learn_throughput: 1200.089\n",
      "  learn_time_ms: 3333.087\n",
      "  load_throughput: 20034888.942\n",
      "  load_time_ms: 0.2\n",
      "  sample_throughput: 517.27\n",
      "  sample_time_ms: 7732.909\n",
      "  update_time_ms: 3.038\n",
      "timestamp: 1658394146\n",
      "timesteps_since_restore: 104000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 104000\n",
      "training_iteration: 26\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 108000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-02-33\n",
      "done: false\n",
      "episode_len_mean: 193.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.7\n",
      "episode_reward_min: 107.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 782\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0001464843808207661\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.43426513671875\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006491971667855978\n",
      "        model: {}\n",
      "        policy_loss: -0.003717157058417797\n",
      "        total_loss: 3.787590265274048\n",
      "        vf_explained_var: 0.0746997818350792\n",
      "        vf_loss: 3.791306495666504\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 108000\n",
      "  num_agent_steps_trained: 108000\n",
      "  num_steps_sampled: 108000\n",
      "  num_steps_trained: 108000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 27\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.18\n",
      "  ram_util_percent: 87.6\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0751485825276916\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08602582624506341\n",
      "  mean_inference_ms: 0.8122937638491012\n",
      "  mean_raw_obs_processing_ms: 0.10020456369251082\n",
      "time_since_restore: 208.50289750099182\n",
      "time_this_iter_s: 6.994706392288208\n",
      "time_total_s: 208.50289750099182\n",
      "timers:\n",
      "  learn_throughput: 1209.864\n",
      "  learn_time_ms: 3306.158\n",
      "  load_throughput: 20097287.973\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 521.863\n",
      "  sample_time_ms: 7664.843\n",
      "  update_time_ms: 3.019\n",
      "timestamp: 1658394153\n",
      "timesteps_since_restore: 108000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 108000\n",
      "training_iteration: 27\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 112000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-02-41\n",
      "done: false\n",
      "episode_len_mean: 193.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.42\n",
      "episode_reward_min: 107.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 804\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0001464843808207661\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4523552358150482\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00552472285926342\n",
      "        model: {}\n",
      "        policy_loss: -0.017209645360708237\n",
      "        total_loss: 6.757637023925781\n",
      "        vf_explained_var: 0.1572253257036209\n",
      "        vf_loss: 6.774846076965332\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 112000\n",
      "  num_agent_steps_trained: 112000\n",
      "  num_steps_sampled: 112000\n",
      "  num_steps_trained: 112000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 28\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.099999999999994\n",
      "  ram_util_percent: 87.91818181818182\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07509598226953247\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08597171826975819\n",
      "  mean_inference_ms: 0.8118112739680119\n",
      "  mean_raw_obs_processing_ms: 0.10011448693511457\n",
      "time_since_restore: 216.56040334701538\n",
      "time_this_iter_s: 8.05750584602356\n",
      "time_total_s: 216.56040334701538\n",
      "timers:\n",
      "  learn_throughput: 1198.538\n",
      "  learn_time_ms: 3337.399\n",
      "  load_throughput: 19798461.175\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 524.723\n",
      "  sample_time_ms: 7623.07\n",
      "  update_time_ms: 3.001\n",
      "timestamp: 1658394161\n",
      "timesteps_since_restore: 112000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 112000\n",
      "training_iteration: 28\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 116000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-02-48\n",
      "done: false\n",
      "episode_len_mean: 194.29\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.29\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 824\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0001464843808207661\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.43456947803497314\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0051089390181005\n",
      "        model: {}\n",
      "        policy_loss: 0.005302228033542633\n",
      "        total_loss: 7.0594916343688965\n",
      "        vf_explained_var: 0.08297474682331085\n",
      "        vf_loss: 7.0541887283325195\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 116000\n",
      "  num_agent_steps_trained: 116000\n",
      "  num_steps_sampled: 116000\n",
      "  num_steps_trained: 116000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 29\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.59090909090909\n",
      "  ram_util_percent: 88.08181818181819\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07504668909936148\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08592134064787875\n",
      "  mean_inference_ms: 0.8113912401102524\n",
      "  mean_raw_obs_processing_ms: 0.10002342230623355\n",
      "time_since_restore: 223.86344599723816\n",
      "time_this_iter_s: 7.303042650222778\n",
      "time_total_s: 223.86344599723816\n",
      "timers:\n",
      "  learn_throughput: 1201.002\n",
      "  learn_time_ms: 3330.552\n",
      "  load_throughput: 20692175.629\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 523.479\n",
      "  sample_time_ms: 7641.191\n",
      "  update_time_ms: 3.001\n",
      "timestamp: 1658394168\n",
      "timesteps_since_restore: 116000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 116000\n",
      "training_iteration: 29\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 120000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-02-55\n",
      "done: false\n",
      "episode_len_mean: 195.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.31\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 844\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0001464843808207661\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4189665615558624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007913700304925442\n",
      "        model: {}\n",
      "        policy_loss: 0.0014244638150557876\n",
      "        total_loss: 4.802736282348633\n",
      "        vf_explained_var: 0.06660561263561249\n",
      "        vf_loss: 4.8013105392456055\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 120000\n",
      "  num_agent_steps_trained: 120000\n",
      "  num_steps_sampled: 120000\n",
      "  num_steps_trained: 120000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 30\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.1\n",
      "  ram_util_percent: 87.99\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07487243889080519\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08572565837806806\n",
      "  mean_inference_ms: 0.8096718400449793\n",
      "  mean_raw_obs_processing_ms: 0.09977471295569224\n",
      "time_since_restore: 230.85614609718323\n",
      "time_this_iter_s: 6.992700099945068\n",
      "time_total_s: 230.85614609718323\n",
      "timers:\n",
      "  learn_throughput: 1233.457\n",
      "  learn_time_ms: 3242.919\n",
      "  load_throughput: 20664140.904\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 527.222\n",
      "  sample_time_ms: 7586.937\n",
      "  update_time_ms: 2.573\n",
      "timestamp: 1658394175\n",
      "timesteps_since_restore: 120000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 120000\n",
      "training_iteration: 30\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 124000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-02\n",
      "done: false\n",
      "episode_len_mean: 196.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.02\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 864\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0001464843808207661\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4317019283771515\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036351040471345186\n",
      "        model: {}\n",
      "        policy_loss: 0.0017495824722573161\n",
      "        total_loss: 3.6070170402526855\n",
      "        vf_explained_var: 0.18273434042930603\n",
      "        vf_loss: 3.605266809463501\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 124000\n",
      "  num_agent_steps_trained: 124000\n",
      "  num_steps_sampled: 124000\n",
      "  num_steps_trained: 124000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 31\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.879999999999995\n",
      "  ram_util_percent: 87.84\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0746546807447924\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08548371461912005\n",
      "  mean_inference_ms: 0.8075534662716015\n",
      "  mean_raw_obs_processing_ms: 0.09947969386838239\n",
      "time_since_restore: 237.75346493721008\n",
      "time_this_iter_s: 6.8973188400268555\n",
      "time_total_s: 237.75346493721008\n",
      "timers:\n",
      "  learn_throughput: 1246.512\n",
      "  learn_time_ms: 3208.955\n",
      "  load_throughput: 19645451.991\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 541.018\n",
      "  sample_time_ms: 7393.467\n",
      "  update_time_ms: 2.523\n",
      "timestamp: 1658394182\n",
      "timesteps_since_restore: 124000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 124000\n",
      "training_iteration: 31\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 128000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-09\n",
      "done: false\n",
      "episode_len_mean: 195.24\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.24\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 885\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.324219041038305e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.42697641253471375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007883463986217976\n",
      "        model: {}\n",
      "        policy_loss: 0.0021643880754709244\n",
      "        total_loss: 5.5616936683654785\n",
      "        vf_explained_var: 0.17057529091835022\n",
      "        vf_loss: 5.559528350830078\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 128000\n",
      "  num_agent_steps_trained: 128000\n",
      "  num_steps_sampled: 128000\n",
      "  num_steps_trained: 128000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 32\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.089999999999996\n",
      "  ram_util_percent: 88.01999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07444355182607565\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08524619879707801\n",
      "  mean_inference_ms: 0.8053965997244532\n",
      "  mean_raw_obs_processing_ms: 0.0991794876807079\n",
      "time_since_restore: 244.82885074615479\n",
      "time_this_iter_s: 7.075385808944702\n",
      "time_total_s: 244.82885074615479\n",
      "timers:\n",
      "  learn_throughput: 1248.382\n",
      "  learn_time_ms: 3204.147\n",
      "  load_throughput: 20063640.277\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 544.72\n",
      "  sample_time_ms: 7343.224\n",
      "  update_time_ms: 2.593\n",
      "timestamp: 1658394189\n",
      "timesteps_since_restore: 128000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 128000\n",
      "training_iteration: 32\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 132000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-16\n",
      "done: false\n",
      "episode_len_mean: 197.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.06\n",
      "episode_reward_min: 145.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 905\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.324219041038305e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4254629611968994\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005124659277498722\n",
      "        model: {}\n",
      "        policy_loss: 0.006008415017277002\n",
      "        total_loss: 6.252365589141846\n",
      "        vf_explained_var: 0.08215529471635818\n",
      "        vf_loss: 6.246357440948486\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 132000\n",
      "  num_agent_steps_trained: 132000\n",
      "  num_steps_sampled: 132000\n",
      "  num_steps_trained: 132000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 33\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.17\n",
      "  ram_util_percent: 87.94000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07421622933768825\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08499038779679859\n",
      "  mean_inference_ms: 0.8030347182558589\n",
      "  mean_raw_obs_processing_ms: 0.09886321537329565\n",
      "time_since_restore: 252.01476430892944\n",
      "time_this_iter_s: 7.185913562774658\n",
      "time_total_s: 252.01476430892944\n",
      "timers:\n",
      "  learn_throughput: 1242.907\n",
      "  learn_time_ms: 3218.261\n",
      "  load_throughput: 20078046.912\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 545.71\n",
      "  sample_time_ms: 7329.899\n",
      "  update_time_ms: 2.672\n",
      "timestamp: 1658394196\n",
      "timesteps_since_restore: 132000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 132000\n",
      "training_iteration: 33\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 136000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-23\n",
      "done: false\n",
      "episode_len_mean: 197.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.38\n",
      "episode_reward_min: 149.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 925\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.324219041038305e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.43826723098754883\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00704931141808629\n",
      "        model: {}\n",
      "        policy_loss: 0.00016239997057709843\n",
      "        total_loss: 2.5889689922332764\n",
      "        vf_explained_var: 0.17063969373703003\n",
      "        vf_loss: 2.588806390762329\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 136000\n",
      "  num_agent_steps_trained: 136000\n",
      "  num_steps_sampled: 136000\n",
      "  num_steps_trained: 136000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 34\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.82\n",
      "  ram_util_percent: 87.95\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07395386096236636\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08469239751516333\n",
      "  mean_inference_ms: 0.8003257939705831\n",
      "  mean_raw_obs_processing_ms: 0.09850702690644265\n",
      "time_since_restore: 258.7737925052643\n",
      "time_this_iter_s: 6.759028196334839\n",
      "time_total_s: 258.7737925052643\n",
      "timers:\n",
      "  learn_throughput: 1244.051\n",
      "  learn_time_ms: 3215.302\n",
      "  load_throughput: 20008605.844\n",
      "  load_time_ms: 0.2\n",
      "  sample_throughput: 547.344\n",
      "  sample_time_ms: 7308.021\n",
      "  update_time_ms: 2.666\n",
      "timestamp: 1658394203\n",
      "timesteps_since_restore: 136000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 136000\n",
      "training_iteration: 34\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 140000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-30\n",
      "done: false\n",
      "episode_len_mean: 196.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.51\n",
      "episode_reward_min: 146.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 946\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.324219041038305e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4046591520309448\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0050452700816094875\n",
      "        model: {}\n",
      "        policy_loss: -0.0005892292247153819\n",
      "        total_loss: 4.92332124710083\n",
      "        vf_explained_var: 0.11422291398048401\n",
      "        vf_loss: 4.923910140991211\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 140000\n",
      "  num_agent_steps_trained: 140000\n",
      "  num_steps_sampled: 140000\n",
      "  num_steps_trained: 140000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 35\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.31\n",
      "  ram_util_percent: 87.96000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07369275074849181\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0843977123820125\n",
      "  mean_inference_ms: 0.7976857331579145\n",
      "  mean_raw_obs_processing_ms: 0.09815559978208216\n",
      "time_since_restore: 265.8004491329193\n",
      "time_this_iter_s: 7.026656627655029\n",
      "time_total_s: 265.8004491329193\n",
      "timers:\n",
      "  learn_throughput: 1251.43\n",
      "  learn_time_ms: 3196.345\n",
      "  load_throughput: 21159308.866\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 555.759\n",
      "  sample_time_ms: 7197.365\n",
      "  update_time_ms: 2.258\n",
      "timestamp: 1658394210\n",
      "timesteps_since_restore: 140000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 140000\n",
      "training_iteration: 35\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 144000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-38\n",
      "done: false\n",
      "episode_len_mean: 195.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.39\n",
      "episode_reward_min: 126.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 967\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.324219041038305e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3943810760974884\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005013212561607361\n",
      "        model: {}\n",
      "        policy_loss: 0.0021138314623385668\n",
      "        total_loss: 6.233506679534912\n",
      "        vf_explained_var: 0.13501718640327454\n",
      "        vf_loss: 6.231392860412598\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 144000\n",
      "  num_agent_steps_trained: 144000\n",
      "  num_steps_sampled: 144000\n",
      "  num_steps_trained: 144000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 36\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.88\n",
      "  ram_util_percent: 87.89999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07345195587340654\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0841259110429405\n",
      "  mean_inference_ms: 0.79527185849175\n",
      "  mean_raw_obs_processing_ms: 0.09783526108162781\n",
      "time_since_restore: 273.0222473144531\n",
      "time_this_iter_s: 7.2217981815338135\n",
      "time_total_s: 273.0222473144531\n",
      "timers:\n",
      "  learn_throughput: 1238.552\n",
      "  learn_time_ms: 3229.577\n",
      "  load_throughput: 20963658.628\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 560.395\n",
      "  sample_time_ms: 7137.818\n",
      "  update_time_ms: 2.161\n",
      "timestamp: 1658394218\n",
      "timesteps_since_restore: 144000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 144000\n",
      "training_iteration: 36\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 148000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-45\n",
      "done: false\n",
      "episode_len_mean: 195.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.21\n",
      "episode_reward_min: 126.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 987\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.324219041038305e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3914968967437744\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009224842302501202\n",
      "        model: {}\n",
      "        policy_loss: 0.0012458566343411803\n",
      "        total_loss: 5.474359035491943\n",
      "        vf_explained_var: 0.03652481734752655\n",
      "        vf_loss: 5.4731125831604\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 148000\n",
      "  num_agent_steps_trained: 148000\n",
      "  num_steps_sampled: 148000\n",
      "  num_steps_trained: 148000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 37\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.11\n",
      "  ram_util_percent: 87.93999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07323008212137683\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0838722121503476\n",
      "  mean_inference_ms: 0.7930838968486786\n",
      "  mean_raw_obs_processing_ms: 0.09754812121613277\n",
      "time_since_restore: 280.1321225166321\n",
      "time_this_iter_s: 7.109875202178955\n",
      "time_total_s: 280.1321225166321\n",
      "timers:\n",
      "  learn_throughput: 1233.339\n",
      "  learn_time_ms: 3243.227\n",
      "  load_throughput: 21063673.572\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 557.983\n",
      "  sample_time_ms: 7168.673\n",
      "  update_time_ms: 2.08\n",
      "timestamp: 1658394225\n",
      "timesteps_since_restore: 148000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 148000\n",
      "training_iteration: 37\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 152000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-52\n",
      "done: false\n",
      "episode_len_mean: 195.82\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.82\n",
      "episode_reward_min: 126.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1007\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.324219041038305e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.42173364758491516\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030443482100963593\n",
      "        model: {}\n",
      "        policy_loss: 0.0023708129301667213\n",
      "        total_loss: 3.5037808418273926\n",
      "        vf_explained_var: 0.07436118274927139\n",
      "        vf_loss: 3.5014100074768066\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 152000\n",
      "  num_agent_steps_trained: 152000\n",
      "  num_steps_sampled: 152000\n",
      "  num_steps_trained: 152000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 38\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.58181818181817\n",
      "  ram_util_percent: 87.68181818181819\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07305697777202727\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08367529040579474\n",
      "  mean_inference_ms: 0.7914729996406326\n",
      "  mean_raw_obs_processing_ms: 0.09732477286777862\n",
      "time_since_restore: 287.6692316532135\n",
      "time_this_iter_s: 7.537109136581421\n",
      "time_total_s: 287.6692316532135\n",
      "timers:\n",
      "  learn_throughput: 1257.295\n",
      "  learn_time_ms: 3181.434\n",
      "  load_throughput: 21236982.278\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 556.196\n",
      "  sample_time_ms: 7191.703\n",
      "  update_time_ms: 2.176\n",
      "timestamp: 1658394232\n",
      "timesteps_since_restore: 152000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 152000\n",
      "training_iteration: 38\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 156000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-03-59\n",
      "done: false\n",
      "episode_len_mean: 195.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.65\n",
      "episode_reward_min: 126.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1027\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.662109520519152e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4266243875026703\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009443607181310654\n",
      "        model: {}\n",
      "        policy_loss: -0.0053763603791594505\n",
      "        total_loss: 2.3052115440368652\n",
      "        vf_explained_var: 0.20374779403209686\n",
      "        vf_loss: 2.3105876445770264\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 156000\n",
      "  num_agent_steps_trained: 156000\n",
      "  num_steps_sampled: 156000\n",
      "  num_steps_trained: 156000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 39\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.300000000000004\n",
      "  ram_util_percent: 87.48888888888888\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07288712485980595\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0834880771099067\n",
      "  mean_inference_ms: 0.7898798293866812\n",
      "  mean_raw_obs_processing_ms: 0.09710610164135795\n",
      "time_since_restore: 294.24712204933167\n",
      "time_this_iter_s: 6.577890396118164\n",
      "time_total_s: 294.24712204933167\n",
      "timers:\n",
      "  learn_throughput: 1265.195\n",
      "  learn_time_ms: 3161.567\n",
      "  load_throughput: 21304401.27\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 565.118\n",
      "  sample_time_ms: 7078.17\n",
      "  update_time_ms: 2.376\n",
      "timestamp: 1658394239\n",
      "timesteps_since_restore: 156000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 156000\n",
      "training_iteration: 39\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 160000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-04-06\n",
      "done: false\n",
      "episode_len_mean: 192.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.21\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 1050\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.662109520519152e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3821064531803131\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007458163890987635\n",
      "        model: {}\n",
      "        policy_loss: -0.0006322286208160222\n",
      "        total_loss: 6.359685897827148\n",
      "        vf_explained_var: 0.08858419209718704\n",
      "        vf_loss: 6.360318183898926\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 160000\n",
      "  num_agent_steps_trained: 160000\n",
      "  num_steps_sampled: 160000\n",
      "  num_steps_trained: 160000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 40\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.41\n",
      "  ram_util_percent: 87.52\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07269502011096622\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08327911090003305\n",
      "  mean_inference_ms: 0.7880738409404034\n",
      "  mean_raw_obs_processing_ms: 0.09686810411792329\n",
      "time_since_restore: 301.09193420410156\n",
      "time_this_iter_s: 6.8448121547698975\n",
      "time_total_s: 301.09193420410156\n",
      "timers:\n",
      "  learn_throughput: 1266.835\n",
      "  learn_time_ms: 3157.474\n",
      "  load_throughput: 21575637.86\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 567.553\n",
      "  sample_time_ms: 7047.8\n",
      "  update_time_ms: 2.373\n",
      "timestamp: 1658394246\n",
      "timesteps_since_restore: 160000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 160000\n",
      "training_iteration: 40\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 164000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-04-12\n",
      "done: false\n",
      "episode_len_mean: 194.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.32\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1070\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.662109520519152e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4018031656742096\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010032271966338158\n",
      "        model: {}\n",
      "        policy_loss: 0.005415560677647591\n",
      "        total_loss: 7.419589042663574\n",
      "        vf_explained_var: 0.044301360845565796\n",
      "        vf_loss: 7.414172649383545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 164000\n",
      "  num_agent_steps_trained: 164000\n",
      "  num_steps_sampled: 164000\n",
      "  num_steps_trained: 164000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 41\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.57\n",
      "  ram_util_percent: 87.53999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07252772699329052\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0830963896090975\n",
      "  mean_inference_ms: 0.7864987076359375\n",
      "  mean_raw_obs_processing_ms: 0.0966608105773556\n",
      "time_since_restore: 307.77371525764465\n",
      "time_this_iter_s: 6.681781053543091\n",
      "time_total_s: 307.77371525764465\n",
      "timers:\n",
      "  learn_throughput: 1274.655\n",
      "  learn_time_ms: 3138.104\n",
      "  load_throughput: 22733355.014\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 568.028\n",
      "  sample_time_ms: 7041.901\n",
      "  update_time_ms: 2.333\n",
      "timestamp: 1658394252\n",
      "timesteps_since_restore: 164000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 164000\n",
      "training_iteration: 41\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 168000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-04-19\n",
      "done: false\n",
      "episode_len_mean: 194.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.48\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1090\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.662109520519152e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.41727298498153687\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00853262934833765\n",
      "        model: {}\n",
      "        policy_loss: 0.005561951547861099\n",
      "        total_loss: 6.321953773498535\n",
      "        vf_explained_var: 0.06298660486936569\n",
      "        vf_loss: 6.316391468048096\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 168000\n",
      "  num_agent_steps_trained: 168000\n",
      "  num_steps_sampled: 168000\n",
      "  num_steps_trained: 168000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 42\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.333333333333336\n",
      "  ram_util_percent: 87.53333333333335\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07234969085454385\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08290589304818878\n",
      "  mean_inference_ms: 0.7848139062652166\n",
      "  mean_raw_obs_processing_ms: 0.09644342182160809\n",
      "time_since_restore: 314.4638078212738\n",
      "time_this_iter_s: 6.69009256362915\n",
      "time_total_s: 314.4638078212738\n",
      "timers:\n",
      "  learn_throughput: 1285.606\n",
      "  learn_time_ms: 3111.374\n",
      "  load_throughput: 23128227.185\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 570.59\n",
      "  sample_time_ms: 7010.284\n",
      "  update_time_ms: 2.342\n",
      "timestamp: 1658394259\n",
      "timesteps_since_restore: 168000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 168000\n",
      "training_iteration: 42\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 172000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-04-28\n",
      "done: false\n",
      "episode_len_mean: 192.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.99\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1111\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.662109520519152e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4066753387451172\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007924285717308521\n",
      "        model: {}\n",
      "        policy_loss: 0.0012746899155899882\n",
      "        total_loss: 3.8003785610198975\n",
      "        vf_explained_var: 0.16849738359451294\n",
      "        vf_loss: 3.799103260040283\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 172000\n",
      "  num_agent_steps_trained: 172000\n",
      "  num_steps_sampled: 172000\n",
      "  num_steps_trained: 172000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 43\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.75384615384615\n",
      "  ram_util_percent: 87.89230769230768\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07226460568125849\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08282562791214199\n",
      "  mean_inference_ms: 0.7840887685933899\n",
      "  mean_raw_obs_processing_ms: 0.09634177039221281\n",
      "time_since_restore: 323.0443935394287\n",
      "time_this_iter_s: 8.580585718154907\n",
      "time_total_s: 323.0443935394287\n",
      "timers:\n",
      "  learn_throughput: 1285.093\n",
      "  learn_time_ms: 3112.615\n",
      "  load_throughput: 22659665.046\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 561.521\n",
      "  sample_time_ms: 7123.512\n",
      "  update_time_ms: 2.278\n",
      "timestamp: 1658394268\n",
      "timesteps_since_restore: 172000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 172000\n",
      "training_iteration: 43\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 176000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-04-36\n",
      "done: false\n",
      "episode_len_mean: 192.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.85\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1131\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.662109520519152e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3978642225265503\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034193757455796003\n",
      "        model: {}\n",
      "        policy_loss: 0.00505440728738904\n",
      "        total_loss: 5.649496078491211\n",
      "        vf_explained_var: 0.05161827430129051\n",
      "        vf_loss: 5.644442081451416\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 176000\n",
      "  num_agent_steps_trained: 176000\n",
      "  num_steps_sampled: 176000\n",
      "  num_steps_trained: 176000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 44\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.07500000000001\n",
      "  ram_util_percent: 87.71666666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07225939556600663\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08283482741329444\n",
      "  mean_inference_ms: 0.7842207504464034\n",
      "  mean_raw_obs_processing_ms: 0.09634704651218254\n",
      "time_since_restore: 331.53169870376587\n",
      "time_this_iter_s: 8.487305164337158\n",
      "time_total_s: 331.53169870376587\n",
      "timers:\n",
      "  learn_throughput: 1247.633\n",
      "  learn_time_ms: 3206.071\n",
      "  load_throughput: 22513709.071\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 555.206\n",
      "  sample_time_ms: 7204.533\n",
      "  update_time_ms: 2.23\n",
      "timestamp: 1658394276\n",
      "timesteps_since_restore: 176000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 176000\n",
      "training_iteration: 44\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 180000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-04-45\n",
      "done: false\n",
      "episode_len_mean: 197.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.39\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1151\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.831054760259576e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38728469610214233\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006965119857341051\n",
      "        model: {}\n",
      "        policy_loss: 0.0017378916963934898\n",
      "        total_loss: 4.345990180969238\n",
      "        vf_explained_var: 0.04481896758079529\n",
      "        vf_loss: 4.344252109527588\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 180000\n",
      "  num_agent_steps_trained: 180000\n",
      "  num_steps_sampled: 180000\n",
      "  num_steps_trained: 180000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 45\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.11666666666667\n",
      "  ram_util_percent: 88.0\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0723138098711672\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08290827446779188\n",
      "  mean_inference_ms: 0.7849856216346671\n",
      "  mean_raw_obs_processing_ms: 0.0964209429101387\n",
      "time_since_restore: 339.7870543003082\n",
      "time_this_iter_s: 8.255355596542358\n",
      "time_total_s: 339.7870543003082\n",
      "timers:\n",
      "  learn_throughput: 1226.869\n",
      "  learn_time_ms: 3260.331\n",
      "  load_throughput: 20490004.885\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 543.108\n",
      "  sample_time_ms: 7365.024\n",
      "  update_time_ms: 2.312\n",
      "timestamp: 1658394285\n",
      "timesteps_since_restore: 180000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 180000\n",
      "training_iteration: 45\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 184000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-04-52\n",
      "done: false\n",
      "episode_len_mean: 197.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.4\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1171\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.831054760259576e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3889275789260864\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007825840264558792\n",
      "        model: {}\n",
      "        policy_loss: 0.0008499757386744022\n",
      "        total_loss: 3.640204906463623\n",
      "        vf_explained_var: 0.06282421946525574\n",
      "        vf_loss: 3.639354944229126\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 184000\n",
      "  num_agent_steps_trained: 184000\n",
      "  num_steps_sampled: 184000\n",
      "  num_steps_trained: 184000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 46\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.34\n",
      "  ram_util_percent: 87.88000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0723951723835487\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08301296929774243\n",
      "  mean_inference_ms: 0.7860245709031076\n",
      "  mean_raw_obs_processing_ms: 0.09652883008782999\n",
      "time_since_restore: 346.89789485931396\n",
      "time_this_iter_s: 7.110840559005737\n",
      "time_total_s: 346.89789485931396\n",
      "timers:\n",
      "  learn_throughput: 1240.029\n",
      "  learn_time_ms: 3225.732\n",
      "  load_throughput: 20512551.657\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 537.32\n",
      "  sample_time_ms: 7444.347\n",
      "  update_time_ms: 2.352\n",
      "timestamp: 1658394292\n",
      "timesteps_since_restore: 184000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 184000\n",
      "training_iteration: 46\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 188000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-04-58\n",
      "done: false\n",
      "episode_len_mean: 197.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.12\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1191\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.831054760259576e-05\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37418830394744873\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00454410957172513\n",
      "        model: {}\n",
      "        policy_loss: -0.0016638876404613256\n",
      "        total_loss: 2.2622475624084473\n",
      "        vf_explained_var: 0.19360151886940002\n",
      "        vf_loss: 2.263911247253418\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 188000\n",
      "  num_agent_steps_trained: 188000\n",
      "  num_steps_sampled: 188000\n",
      "  num_steps_trained: 188000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 47\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.76666666666667\n",
      "  ram_util_percent: 87.60000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07246064847977757\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08309939957310908\n",
      "  mean_inference_ms: 0.7868922147723261\n",
      "  mean_raw_obs_processing_ms: 0.09661781534312608\n",
      "time_since_restore: 353.562664270401\n",
      "time_this_iter_s: 6.664769411087036\n",
      "time_total_s: 353.562664270401\n",
      "timers:\n",
      "  learn_throughput: 1246.755\n",
      "  learn_time_ms: 3208.329\n",
      "  load_throughput: 20547723.209\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 541.799\n",
      "  sample_time_ms: 7382.817\n",
      "  update_time_ms: 2.392\n",
      "timestamp: 1658394298\n",
      "timesteps_since_restore: 188000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 188000\n",
      "training_iteration: 47\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 192000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-05-06\n",
      "done: false\n",
      "episode_len_mean: 196.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.75\n",
      "episode_reward_min: 152.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1212\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 9.15527380129788e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38232696056365967\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0049399943090975285\n",
      "        model: {}\n",
      "        policy_loss: 0.004372569732367992\n",
      "        total_loss: 6.479661464691162\n",
      "        vf_explained_var: 0.07618381828069687\n",
      "        vf_loss: 6.4752888679504395\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 192000\n",
      "  num_agent_steps_trained: 192000\n",
      "  num_steps_sampled: 192000\n",
      "  num_steps_trained: 192000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 48\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.627272727272725\n",
      "  ram_util_percent: 87.86363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07245686271236684\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08310184651682251\n",
      "  mean_inference_ms: 0.7870130720981672\n",
      "  mean_raw_obs_processing_ms: 0.09662130358965335\n",
      "time_since_restore: 361.02913784980774\n",
      "time_this_iter_s: 7.466473579406738\n",
      "time_total_s: 361.02913784980774\n",
      "timers:\n",
      "  learn_throughput: 1253.54\n",
      "  learn_time_ms: 3190.964\n",
      "  load_throughput: 20656508.249\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 542.283\n",
      "  sample_time_ms: 7376.22\n",
      "  update_time_ms: 2.318\n",
      "timestamp: 1658394306\n",
      "timesteps_since_restore: 192000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 192000\n",
      "training_iteration: 48\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 196000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-05-13\n",
      "done: false\n",
      "episode_len_mean: 196.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.79\n",
      "episode_reward_min: 153.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1233\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.57763690064894e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.41508179903030396\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011245829984545708\n",
      "        model: {}\n",
      "        policy_loss: 0.002861699787899852\n",
      "        total_loss: 6.970859527587891\n",
      "        vf_explained_var: 0.12300363928079605\n",
      "        vf_loss: 6.9679975509643555\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 196000\n",
      "  num_agent_steps_trained: 196000\n",
      "  num_steps_sampled: 196000\n",
      "  num_steps_trained: 196000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 49\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.95\n",
      "  ram_util_percent: 87.92\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07241932282191671\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08306149227036581\n",
      "  mean_inference_ms: 0.7867321591791009\n",
      "  mean_raw_obs_processing_ms: 0.09657239258852708\n",
      "time_since_restore: 368.0656940937042\n",
      "time_this_iter_s: 7.036556243896484\n",
      "time_total_s: 368.0656940937042\n",
      "timers:\n",
      "  learn_throughput: 1252.227\n",
      "  learn_time_ms: 3194.308\n",
      "  load_throughput: 20477500.305\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 540.433\n",
      "  sample_time_ms: 7401.478\n",
      "  update_time_ms: 2.166\n",
      "timestamp: 1658394313\n",
      "timesteps_since_restore: 196000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 196000\n",
      "training_iteration: 49\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 200000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-05-20\n",
      "done: false\n",
      "episode_len_mean: 196.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.52\n",
      "episode_reward_min: 153.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1253\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.57763690064894e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.40499234199523926\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01615597866475582\n",
      "        model: {}\n",
      "        policy_loss: 0.0018123147310689092\n",
      "        total_loss: 7.75596809387207\n",
      "        vf_explained_var: 0.08793596178293228\n",
      "        vf_loss: 7.754156112670898\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 200000\n",
      "  num_agent_steps_trained: 200000\n",
      "  num_steps_sampled: 200000\n",
      "  num_steps_trained: 200000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 50\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.410000000000004\n",
      "  ram_util_percent: 87.89\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0723581483099189\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08299449900782845\n",
      "  mean_inference_ms: 0.7861527313511119\n",
      "  mean_raw_obs_processing_ms: 0.09649086636080562\n",
      "time_since_restore: 375.34213519096375\n",
      "time_this_iter_s: 7.2764410972595215\n",
      "time_total_s: 375.34213519096375\n",
      "timers:\n",
      "  learn_throughput: 1249.296\n",
      "  learn_time_ms: 3201.804\n",
      "  load_throughput: 20250109.837\n",
      "  load_time_ms: 0.198\n",
      "  sample_throughput: 537.655\n",
      "  sample_time_ms: 7439.712\n",
      "  update_time_ms: 2.183\n",
      "timestamp: 1658394320\n",
      "timesteps_since_restore: 200000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 200000\n",
      "training_iteration: 50\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 204000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-05-28\n",
      "done: false\n",
      "episode_len_mean: 195.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.17\n",
      "episode_reward_min: 153.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1274\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.57763690064894e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3901194632053375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005394835956394672\n",
      "        model: {}\n",
      "        policy_loss: -0.01065040286630392\n",
      "        total_loss: 4.699204921722412\n",
      "        vf_explained_var: 0.1582399159669876\n",
      "        vf_loss: 4.709855556488037\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 204000\n",
      "  num_agent_steps_trained: 204000\n",
      "  num_steps_sampled: 204000\n",
      "  num_steps_trained: 204000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 51\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.09090909090909\n",
      "  ram_util_percent: 87.83636363636363\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07230884831730867\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.082937267857891\n",
      "  mean_inference_ms: 0.785668101175522\n",
      "  mean_raw_obs_processing_ms: 0.0964198587297188\n",
      "time_since_restore: 382.8644108772278\n",
      "time_this_iter_s: 7.522275686264038\n",
      "time_total_s: 382.8644108772278\n",
      "timers:\n",
      "  learn_throughput: 1231.342\n",
      "  learn_time_ms: 3248.488\n",
      "  load_throughput: 20392872.25\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 534.442\n",
      "  sample_time_ms: 7484.449\n",
      "  update_time_ms: 2.208\n",
      "timestamp: 1658394328\n",
      "timesteps_since_restore: 204000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 204000\n",
      "training_iteration: 51\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 208000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-05-36\n",
      "done: false\n",
      "episode_len_mean: 194.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.66\n",
      "episode_reward_min: 153.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1294\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.57763690064894e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39377033710479736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006369297858327627\n",
      "        model: {}\n",
      "        policy_loss: 0.0012234051246196032\n",
      "        total_loss: 4.0515971183776855\n",
      "        vf_explained_var: 0.1976223886013031\n",
      "        vf_loss: 4.0503740310668945\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 208000\n",
      "  num_agent_steps_trained: 208000\n",
      "  num_steps_sampled: 208000\n",
      "  num_steps_trained: 208000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 52\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.11666666666667\n",
      "  ram_util_percent: 88.10000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0723225772775065\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08294909920059448\n",
      "  mean_inference_ms: 0.7858475901797819\n",
      "  mean_raw_obs_processing_ms: 0.09642424946553857\n",
      "time_since_restore: 391.15204191207886\n",
      "time_this_iter_s: 8.287631034851074\n",
      "time_total_s: 391.15204191207886\n",
      "timers:\n",
      "  learn_throughput: 1201.638\n",
      "  learn_time_ms: 3328.79\n",
      "  load_throughput: 20447551.493\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 525.56\n",
      "  sample_time_ms: 7610.928\n",
      "  update_time_ms: 2.224\n",
      "timestamp: 1658394336\n",
      "timesteps_since_restore: 208000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 208000\n",
      "training_iteration: 52\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 212000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-05-45\n",
      "done: false\n",
      "episode_len_mean: 193.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.68\n",
      "episode_reward_min: 148.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1315\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.57763690064894e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3888305127620697\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008655508048832417\n",
      "        model: {}\n",
      "        policy_loss: 0.00010179357923334464\n",
      "        total_loss: 4.639211654663086\n",
      "        vf_explained_var: 0.1971127688884735\n",
      "        vf_loss: 4.639110088348389\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 212000\n",
      "  num_agent_steps_trained: 212000\n",
      "  num_steps_sampled: 212000\n",
      "  num_steps_trained: 212000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 53\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.599999999999994\n",
      "  ram_util_percent: 88.19999999999997\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07240840087281308\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08303925058090499\n",
      "  mean_inference_ms: 0.7867612758585749\n",
      "  mean_raw_obs_processing_ms: 0.0965136036766241\n",
      "time_since_restore: 400.47542452812195\n",
      "time_this_iter_s: 9.32338261604309\n",
      "time_total_s: 400.47542452812195\n",
      "timers:\n",
      "  learn_throughput: 1178.202\n",
      "  learn_time_ms: 3395.004\n",
      "  load_throughput: 19946755.439\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 519.536\n",
      "  sample_time_ms: 7699.184\n",
      "  update_time_ms: 2.257\n",
      "timestamp: 1658394345\n",
      "timesteps_since_restore: 212000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 212000\n",
      "training_iteration: 53\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 216000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-05-54\n",
      "done: false\n",
      "episode_len_mean: 193.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.76\n",
      "episode_reward_min: 148.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1336\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.57763690064894e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.4015044867992401\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004230997525155544\n",
      "        model: {}\n",
      "        policy_loss: 0.003958964720368385\n",
      "        total_loss: 5.470795154571533\n",
      "        vf_explained_var: 0.14827284216880798\n",
      "        vf_loss: 5.4668354988098145\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 216000\n",
      "  num_agent_steps_trained: 216000\n",
      "  num_steps_sampled: 216000\n",
      "  num_steps_trained: 216000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 54\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.723076923076924\n",
      "  ram_util_percent: 88.13076923076923\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07258958849194028\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08323465187903345\n",
      "  mean_inference_ms: 0.7886576807835786\n",
      "  mean_raw_obs_processing_ms: 0.09672122182027357\n",
      "time_since_restore: 409.4219524860382\n",
      "time_this_iter_s: 8.94652795791626\n",
      "time_total_s: 409.4219524860382\n",
      "timers:\n",
      "  learn_throughput: 1193.995\n",
      "  learn_time_ms: 3350.098\n",
      "  load_throughput: 20001449.69\n",
      "  load_time_ms: 0.2\n",
      "  sample_throughput: 509.106\n",
      "  sample_time_ms: 7856.908\n",
      "  update_time_ms: 2.312\n",
      "timestamp: 1658394354\n",
      "timesteps_since_restore: 216000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 216000\n",
      "training_iteration: 54\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 220000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-03\n",
      "done: false\n",
      "episode_len_mean: 194.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.09\n",
      "episode_reward_min: 148.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1356\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.28881845032447e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38203611969947815\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006471727043390274\n",
      "        model: {}\n",
      "        policy_loss: 0.0038358760066330433\n",
      "        total_loss: 5.35279655456543\n",
      "        vf_explained_var: 0.06302095949649811\n",
      "        vf_loss: 5.348959922790527\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 220000\n",
      "  num_agent_steps_trained: 220000\n",
      "  num_steps_sampled: 220000\n",
      "  num_steps_trained: 220000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 55\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.26666666666666\n",
      "  ram_util_percent: 87.97500000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07280182287696718\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.083466895194654\n",
      "  mean_inference_ms: 0.7908818112322143\n",
      "  mean_raw_obs_processing_ms: 0.09697030897043053\n",
      "time_since_restore: 417.87767148017883\n",
      "time_this_iter_s: 8.455718994140625\n",
      "time_total_s: 417.87767148017883\n",
      "timers:\n",
      "  learn_throughput: 1195.479\n",
      "  learn_time_ms: 3345.939\n",
      "  load_throughput: 21636853.237\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 510.398\n",
      "  sample_time_ms: 7837.021\n",
      "  update_time_ms: 2.337\n",
      "timestamp: 1658394363\n",
      "timesteps_since_restore: 220000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 220000\n",
      "training_iteration: 55\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 224000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-10\n",
      "done: false\n",
      "episode_len_mean: 195.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.15\n",
      "episode_reward_min: 148.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1376\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.28881845032447e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.40233394503593445\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004204544238746166\n",
      "        model: {}\n",
      "        policy_loss: 0.004157166462391615\n",
      "        total_loss: 5.263210773468018\n",
      "        vf_explained_var: 0.07890813797712326\n",
      "        vf_loss: 5.259053707122803\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 224000\n",
      "  num_agent_steps_trained: 224000\n",
      "  num_steps_sampled: 224000\n",
      "  num_steps_trained: 224000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 56\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.629999999999995\n",
      "  ram_util_percent: 87.86\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07296988064384152\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.083652805370894\n",
      "  mean_inference_ms: 0.7927611927623494\n",
      "  mean_raw_obs_processing_ms: 0.09717028916135895\n",
      "time_since_restore: 424.7545573711395\n",
      "time_this_iter_s: 6.876885890960693\n",
      "time_total_s: 424.7545573711395\n",
      "timers:\n",
      "  learn_throughput: 1190.478\n",
      "  learn_time_ms: 3359.995\n",
      "  load_throughput: 21945344.67\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 513.101\n",
      "  sample_time_ms: 7795.733\n",
      "  update_time_ms: 2.331\n",
      "timestamp: 1658394370\n",
      "timesteps_since_restore: 224000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 224000\n",
      "training_iteration: 56\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 228000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-16\n",
      "done: false\n",
      "episode_len_mean: 196.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.01\n",
      "episode_reward_min: 148.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1396\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.144409225162235e-06\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3896925449371338\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004704785067588091\n",
      "        model: {}\n",
      "        policy_loss: -0.002344984095543623\n",
      "        total_loss: 2.6619889736175537\n",
      "        vf_explained_var: 0.18595479428768158\n",
      "        vf_loss: 2.6643340587615967\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 228000\n",
      "  num_agent_steps_trained: 228000\n",
      "  num_steps_sampled: 228000\n",
      "  num_steps_trained: 228000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 57\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.52\n",
      "  ram_util_percent: 87.52000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07307289493166504\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08376735376309678\n",
      "  mean_inference_ms: 0.7939806792095482\n",
      "  mean_raw_obs_processing_ms: 0.09729301290212672\n",
      "time_since_restore: 431.4682879447937\n",
      "time_this_iter_s: 6.713730573654175\n",
      "time_total_s: 431.4682879447937\n",
      "timers:\n",
      "  learn_throughput: 1192.535\n",
      "  learn_time_ms: 3354.199\n",
      "  load_throughput: 21794253.053\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 511.453\n",
      "  sample_time_ms: 7820.862\n",
      "  update_time_ms: 2.305\n",
      "timestamp: 1658394376\n",
      "timesteps_since_restore: 228000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 228000\n",
      "training_iteration: 57\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 232000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-23\n",
      "done: false\n",
      "episode_len_mean: 197.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.06\n",
      "episode_reward_min: 152.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1417\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.722046125811175e-07\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.365395724773407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004190101288259029\n",
      "        model: {}\n",
      "        policy_loss: 0.003968591336160898\n",
      "        total_loss: 6.590320110321045\n",
      "        vf_explained_var: 0.12272803485393524\n",
      "        vf_loss: 6.58635139465332\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 232000\n",
      "  num_agent_steps_trained: 232000\n",
      "  num_steps_sampled: 232000\n",
      "  num_steps_trained: 232000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 58\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.86\n",
      "  ram_util_percent: 87.73999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07305796368507\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08374938834532525\n",
      "  mean_inference_ms: 0.7939649855631905\n",
      "  mean_raw_obs_processing_ms: 0.09726997638025242\n",
      "time_since_restore: 438.39279103279114\n",
      "time_this_iter_s: 6.9245030879974365\n",
      "time_total_s: 438.39279103279114\n",
      "timers:\n",
      "  learn_throughput: 1181.743\n",
      "  learn_time_ms: 3384.831\n",
      "  load_throughput: 21388597.654\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 517.445\n",
      "  sample_time_ms: 7730.29\n",
      "  update_time_ms: 2.284\n",
      "timestamp: 1658394383\n",
      "timesteps_since_restore: 232000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 232000\n",
      "training_iteration: 58\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 236000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-30\n",
      "done: false\n",
      "episode_len_mean: 197.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.49\n",
      "episode_reward_min: 171.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1437\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.8610230629055877e-07\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39976149797439575\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00385588058270514\n",
      "        model: {}\n",
      "        policy_loss: 0.0027944131288677454\n",
      "        total_loss: 4.355897903442383\n",
      "        vf_explained_var: 0.10065358132123947\n",
      "        vf_loss: 4.353103160858154\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 236000\n",
      "  num_agent_steps_trained: 236000\n",
      "  num_steps_sampled: 236000\n",
      "  num_steps_trained: 236000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 59\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.31111111111111\n",
      "  ram_util_percent: 87.77777777777777\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07294597075784112\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08362446770514952\n",
      "  mean_inference_ms: 0.7929541616024127\n",
      "  mean_raw_obs_processing_ms: 0.09712800187910219\n",
      "time_since_restore: 445.18427753448486\n",
      "time_this_iter_s: 6.791486501693726\n",
      "time_total_s: 445.18427753448486\n",
      "timers:\n",
      "  learn_throughput: 1183.421\n",
      "  learn_time_ms: 3380.03\n",
      "  load_throughput: 21347774.526\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 516.806\n",
      "  sample_time_ms: 7739.851\n",
      "  update_time_ms: 2.276\n",
      "timestamp: 1658394390\n",
      "timesteps_since_restore: 236000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 236000\n",
      "training_iteration: 59\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 240000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-38\n",
      "done: false\n",
      "episode_len_mean: 196.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.69\n",
      "episode_reward_min: 149.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1458\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.4305115314527939e-07\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3967098891735077\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005113678053021431\n",
      "        model: {}\n",
      "        policy_loss: -0.002902811858803034\n",
      "        total_loss: 5.35768985748291\n",
      "        vf_explained_var: 0.1525396704673767\n",
      "        vf_loss: 5.360591888427734\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 240000\n",
      "  num_agent_steps_trained: 240000\n",
      "  num_steps_sampled: 240000\n",
      "  num_steps_trained: 240000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 60\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.824999999999996\n",
      "  ram_util_percent: 87.84166666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07281351651816269\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.083475231195515\n",
      "  mean_inference_ms: 0.7917696523232074\n",
      "  mean_raw_obs_processing_ms: 0.09695680425142399\n",
      "time_since_restore: 453.1363174915314\n",
      "time_this_iter_s: 7.952039957046509\n",
      "time_total_s: 453.1363174915314\n",
      "timers:\n",
      "  learn_throughput: 1173.746\n",
      "  learn_time_ms: 3407.893\n",
      "  load_throughput: 21451497.251\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 514.42\n",
      "  sample_time_ms: 7775.746\n",
      "  update_time_ms: 2.249\n",
      "timestamp: 1658394398\n",
      "timesteps_since_restore: 240000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 240000\n",
      "training_iteration: 60\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 244000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-45\n",
      "done: false\n",
      "episode_len_mean: 194.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.4\n",
      "episode_reward_min: 132.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1479\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.4305115314527939e-07\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39804425835609436\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009346816688776016\n",
      "        model: {}\n",
      "        policy_loss: 0.0025872134137898684\n",
      "        total_loss: 6.012572765350342\n",
      "        vf_explained_var: 0.07393494248390198\n",
      "        vf_loss: 6.00998592376709\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 244000\n",
      "  num_agent_steps_trained: 244000\n",
      "  num_steps_sampled: 244000\n",
      "  num_steps_trained: 244000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 61\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.44\n",
      "  ram_util_percent: 87.34\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07271369170854147\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0833623160749582\n",
      "  mean_inference_ms: 0.7908042820966493\n",
      "  mean_raw_obs_processing_ms: 0.09682330216416207\n",
      "time_since_restore: 460.060711145401\n",
      "time_this_iter_s: 6.924393653869629\n",
      "time_total_s: 460.060711145401\n",
      "timers:\n",
      "  learn_throughput: 1189.134\n",
      "  learn_time_ms: 3363.792\n",
      "  load_throughput: 21380420.543\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 513.605\n",
      "  sample_time_ms: 7788.092\n",
      "  update_time_ms: 2.234\n",
      "timestamp: 1658394405\n",
      "timesteps_since_restore: 244000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 244000\n",
      "training_iteration: 61\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 248000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-52\n",
      "done: false\n",
      "episode_len_mean: 192.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.31\n",
      "episode_reward_min: 132.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1500\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.4305115314527939e-07\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.37224340438842773\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034125871025025845\n",
      "        model: {}\n",
      "        policy_loss: 0.0028013570699840784\n",
      "        total_loss: 3.6110665798187256\n",
      "        vf_explained_var: 0.2184162735939026\n",
      "        vf_loss: 3.6082651615142822\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 248000\n",
      "  num_agent_steps_trained: 248000\n",
      "  num_steps_sampled: 248000\n",
      "  num_steps_trained: 248000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 62\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.0\n",
      "  ram_util_percent: 87.47777777777779\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07262167380117099\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08325877509280759\n",
      "  mean_inference_ms: 0.789874601153128\n",
      "  mean_raw_obs_processing_ms: 0.0966986954875052\n",
      "time_since_restore: 466.6472589969635\n",
      "time_this_iter_s: 6.5865478515625\n",
      "time_total_s: 466.6472589969635\n",
      "timers:\n",
      "  learn_throughput: 1218.896\n",
      "  learn_time_ms: 3281.659\n",
      "  load_throughput: 21151306.102\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 522.467\n",
      "  sample_time_ms: 7655.985\n",
      "  update_time_ms: 2.171\n",
      "timestamp: 1658394412\n",
      "timesteps_since_restore: 248000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 248000\n",
      "training_iteration: 62\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 252000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-06-58\n",
      "done: false\n",
      "episode_len_mean: 191.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.5\n",
      "episode_reward_min: 132.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1521\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.152557657263969e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38130345940589905\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00574495317414403\n",
      "        model: {}\n",
      "        policy_loss: 0.003000738564878702\n",
      "        total_loss: 4.111894607543945\n",
      "        vf_explained_var: 0.13290099799633026\n",
      "        vf_loss: 4.108893871307373\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 252000\n",
      "  num_agent_steps_trained: 252000\n",
      "  num_steps_sampled: 252000\n",
      "  num_steps_trained: 252000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 63\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 30.544444444444448\n",
      "  ram_util_percent: 87.43333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07252729570328953\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08315394353142962\n",
      "  mean_inference_ms: 0.788935688337666\n",
      "  mean_raw_obs_processing_ms: 0.09657413190185682\n",
      "time_since_restore: 473.07244515419006\n",
      "time_this_iter_s: 6.4251861572265625\n",
      "time_total_s: 473.07244515419006\n",
      "timers:\n",
      "  learn_throughput: 1259.743\n",
      "  learn_time_ms: 3175.251\n",
      "  load_throughput: 22203832.716\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 541.369\n",
      "  sample_time_ms: 7388.678\n",
      "  update_time_ms: 2.197\n",
      "timestamp: 1658394418\n",
      "timesteps_since_restore: 252000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 252000\n",
      "training_iteration: 63\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 256000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-07-06\n",
      "done: false\n",
      "episode_len_mean: 191.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.05\n",
      "episode_reward_min: 132.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1542\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.152557657263969e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3863268196582794\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009611230343580246\n",
      "        model: {}\n",
      "        policy_loss: 0.0053734309040009975\n",
      "        total_loss: 9.529119491577148\n",
      "        vf_explained_var: 0.09743742644786835\n",
      "        vf_loss: 9.523746490478516\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 256000\n",
      "  num_agent_steps_trained: 256000\n",
      "  num_steps_sampled: 256000\n",
      "  num_steps_trained: 256000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 64\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.86363636363637\n",
      "  ram_util_percent: 87.55454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07245974261190216\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08308081016530691\n",
      "  mean_inference_ms: 0.7882560911740941\n",
      "  mean_raw_obs_processing_ms: 0.09648240117755023\n",
      "time_since_restore: 480.3810963630676\n",
      "time_this_iter_s: 7.3086512088775635\n",
      "time_total_s: 480.3810963630676\n",
      "timers:\n",
      "  learn_throughput: 1283.651\n",
      "  learn_time_ms: 3116.112\n",
      "  load_throughput: 22192084.656\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 557.237\n",
      "  sample_time_ms: 7178.27\n",
      "  update_time_ms: 2.209\n",
      "timestamp: 1658394426\n",
      "timesteps_since_restore: 256000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 256000\n",
      "training_iteration: 64\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 260000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-07-13\n",
      "done: false\n",
      "episode_len_mean: 191.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.27\n",
      "episode_reward_min: 132.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1562\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.152557657263969e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.39566007256507874\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008666842244565487\n",
      "        model: {}\n",
      "        policy_loss: 0.004096164368093014\n",
      "        total_loss: 5.208830833435059\n",
      "        vf_explained_var: 0.07492117583751678\n",
      "        vf_loss: 5.204734802246094\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 260000\n",
      "  num_agent_steps_trained: 260000\n",
      "  num_steps_sampled: 260000\n",
      "  num_steps_trained: 260000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 65\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.220000000000006\n",
      "  ram_util_percent: 87.4\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07238051714948415\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0829948627820315\n",
      "  mean_inference_ms: 0.7874266840251093\n",
      "  mean_raw_obs_processing_ms: 0.09637757654691521\n",
      "time_since_restore: 487.86661291122437\n",
      "time_this_iter_s: 7.485516548156738\n",
      "time_total_s: 487.86661291122437\n",
      "timers:\n",
      "  learn_throughput: 1295.805\n",
      "  learn_time_ms: 3086.884\n",
      "  load_throughput: 22180349.022\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 567.269\n",
      "  sample_time_ms: 7051.333\n",
      "  update_time_ms: 2.164\n",
      "timestamp: 1658394433\n",
      "timesteps_since_restore: 260000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 260000\n",
      "training_iteration: 65\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 264000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-07-20\n",
      "done: false\n",
      "episode_len_mean: 191.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.6\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 1584\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.152557657263969e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3798588514328003\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004965591244399548\n",
      "        model: {}\n",
      "        policy_loss: 0.0003276306961197406\n",
      "        total_loss: 5.290218830108643\n",
      "        vf_explained_var: 0.13779860734939575\n",
      "        vf_loss: 5.289892196655273\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 264000\n",
      "  num_agent_steps_trained: 264000\n",
      "  num_steps_sampled: 264000\n",
      "  num_steps_trained: 264000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 66\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.67272727272727\n",
      "  ram_util_percent: 87.37272727272727\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07230296527444567\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08291055457631001\n",
      "  mean_inference_ms: 0.7866168393337787\n",
      "  mean_raw_obs_processing_ms: 0.09627549706183774\n",
      "time_since_restore: 495.0101046562195\n",
      "time_this_iter_s: 7.143491744995117\n",
      "time_total_s: 495.0101046562195\n",
      "timers:\n",
      "  learn_throughput: 1298.563\n",
      "  learn_time_ms: 3080.327\n",
      "  load_throughput: 22072379.95\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 567.05\n",
      "  sample_time_ms: 7054.053\n",
      "  update_time_ms: 2.199\n",
      "timestamp: 1658394440\n",
      "timesteps_since_restore: 264000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 264000\n",
      "training_iteration: 66\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 268000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-07-27\n",
      "done: false\n",
      "episode_len_mean: 192.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.71\n",
      "episode_reward_min: 150.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1605\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.5762788286319847e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.38670647144317627\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007101945113390684\n",
      "        model: {}\n",
      "        policy_loss: -0.004436970222741365\n",
      "        total_loss: 5.830011367797852\n",
      "        vf_explained_var: 0.1119234636425972\n",
      "        vf_loss: 5.834448337554932\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 268000\n",
      "  num_agent_steps_trained: 268000\n",
      "  num_steps_sampled: 268000\n",
      "  num_steps_trained: 268000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 67\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.86666666666667\n",
      "  ram_util_percent: 87.34444444444445\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07222566529440229\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08282683769510892\n",
      "  mean_inference_ms: 0.7858159279851158\n",
      "  mean_raw_obs_processing_ms: 0.0961729641540622\n",
      "time_since_restore: 501.54212474823\n",
      "time_this_iter_s: 6.532020092010498\n",
      "time_total_s: 501.54212474823\n",
      "timers:\n",
      "  learn_throughput: 1297.921\n",
      "  learn_time_ms: 3081.853\n",
      "  load_throughput: 22139371.866\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 569.191\n",
      "  sample_time_ms: 7027.515\n",
      "  update_time_ms: 2.2\n",
      "timestamp: 1658394447\n",
      "timesteps_since_restore: 268000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 268000\n",
      "training_iteration: 67\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 272000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-07-34\n",
      "done: false\n",
      "episode_len_mean: 192.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.92\n",
      "episode_reward_min: 150.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1625\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.5762788286319847e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3898024559020996\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006562265567481518\n",
      "        model: {}\n",
      "        policy_loss: 0.002467142650857568\n",
      "        total_loss: 6.367224216461182\n",
      "        vf_explained_var: 0.06581548601388931\n",
      "        vf_loss: 6.364757537841797\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 272000\n",
      "  num_agent_steps_trained: 272000\n",
      "  num_steps_sampled: 272000\n",
      "  num_steps_trained: 272000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 68\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.989999999999995\n",
      "  ram_util_percent: 87.37\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07215407625743091\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08274987087291853\n",
      "  mean_inference_ms: 0.7851083751533465\n",
      "  mean_raw_obs_processing_ms: 0.09607808722888328\n",
      "time_since_restore: 508.33663606643677\n",
      "time_this_iter_s: 6.794511318206787\n",
      "time_total_s: 508.33663606643677\n",
      "timers:\n",
      "  learn_throughput: 1309.394\n",
      "  learn_time_ms: 3054.848\n",
      "  load_throughput: 21399510.204\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 567.946\n",
      "  sample_time_ms: 7042.923\n",
      "  update_time_ms: 2.19\n",
      "timestamp: 1658394454\n",
      "timesteps_since_restore: 272000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 272000\n",
      "training_iteration: 68\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 276000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-07-40\n",
      "done: false\n",
      "episode_len_mean: 191.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.91\n",
      "episode_reward_min: 146.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1646\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.5762788286319847e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3716217279434204\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0048661008477211\n",
      "        model: {}\n",
      "        policy_loss: 0.0015129911480471492\n",
      "        total_loss: 4.661448001861572\n",
      "        vf_explained_var: 0.17910565435886383\n",
      "        vf_loss: 4.6599345207214355\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 276000\n",
      "  num_agent_steps_trained: 276000\n",
      "  num_steps_sampled: 276000\n",
      "  num_steps_trained: 276000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 69\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.966666666666665\n",
      "  ram_util_percent: 87.30000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07204337632213506\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08262947564278812\n",
      "  mean_inference_ms: 0.7840107386307125\n",
      "  mean_raw_obs_processing_ms: 0.09593708449135796\n",
      "time_since_restore: 514.9681148529053\n",
      "time_this_iter_s: 6.631478786468506\n",
      "time_total_s: 514.9681148529053\n",
      "timers:\n",
      "  learn_throughput: 1308.564\n",
      "  learn_time_ms: 3056.786\n",
      "  load_throughput: 21670390.08\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 571.557\n",
      "  sample_time_ms: 6998.423\n",
      "  update_time_ms: 2.136\n",
      "timestamp: 1658394460\n",
      "timesteps_since_restore: 276000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 276000\n",
      "training_iteration: 69\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 280000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-07-47\n",
      "done: false\n",
      "episode_len_mean: 193.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.09\n",
      "episode_reward_min: 146.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1666\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.7881394143159923e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36932262778282166\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009356868453323841\n",
      "        model: {}\n",
      "        policy_loss: 0.0050091976299881935\n",
      "        total_loss: 6.388481616973877\n",
      "        vf_explained_var: 0.058598220348358154\n",
      "        vf_loss: 6.383472919464111\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 280000\n",
      "  num_agent_steps_trained: 280000\n",
      "  num_steps_sampled: 280000\n",
      "  num_steps_trained: 280000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 70\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.37777777777778\n",
      "  ram_util_percent: 87.31111111111112\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07191846515359444\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08249346463089749\n",
      "  mean_inference_ms: 0.7827594103871885\n",
      "  mean_raw_obs_processing_ms: 0.09578054909485623\n",
      "time_since_restore: 521.4444804191589\n",
      "time_this_iter_s: 6.476365566253662\n",
      "time_total_s: 521.4444804191589\n",
      "timers:\n",
      "  learn_throughput: 1337.039\n",
      "  learn_time_ms: 2991.685\n",
      "  load_throughput: 21743411.094\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 578.31\n",
      "  sample_time_ms: 6916.701\n",
      "  update_time_ms: 2.142\n",
      "timestamp: 1658394467\n",
      "timesteps_since_restore: 280000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 280000\n",
      "training_iteration: 70\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 284000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-07-53\n",
      "done: false\n",
      "episode_len_mean: 195.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.25\n",
      "episode_reward_min: 146.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1686\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.7881394143159923e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.42146191000938416\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005768162664026022\n",
      "        model: {}\n",
      "        policy_loss: -0.00018493142852094024\n",
      "        total_loss: 4.404540538787842\n",
      "        vf_explained_var: 0.07527836412191391\n",
      "        vf_loss: 4.404725074768066\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 284000\n",
      "  num_agent_steps_trained: 284000\n",
      "  num_steps_sampled: 284000\n",
      "  num_steps_trained: 284000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 71\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.96\n",
      "  ram_util_percent: 87.33000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0717726512019071\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08233334283265137\n",
      "  mean_inference_ms: 0.7812922306641465\n",
      "  mean_raw_obs_processing_ms: 0.09559751757623879\n",
      "time_since_restore: 527.9398846626282\n",
      "time_this_iter_s: 6.495404243469238\n",
      "time_total_s: 527.9398846626282\n",
      "timers:\n",
      "  learn_throughput: 1336.667\n",
      "  learn_time_ms: 2992.518\n",
      "  load_throughput: 21734960.487\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 587.603\n",
      "  sample_time_ms: 6807.321\n",
      "  update_time_ms: 2.359\n",
      "timestamp: 1658394473\n",
      "timesteps_since_restore: 284000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 284000\n",
      "training_iteration: 71\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 288000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-00\n",
      "done: false\n",
      "episode_len_mean: 195.13\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.13\n",
      "episode_reward_min: 146.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1707\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.7881394143159923e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3763200640678406\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00795699842274189\n",
      "        model: {}\n",
      "        policy_loss: 0.004035773687064648\n",
      "        total_loss: 6.643314361572266\n",
      "        vf_explained_var: 0.10371823608875275\n",
      "        vf_loss: 6.639278888702393\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 288000\n",
      "  num_agent_steps_trained: 288000\n",
      "  num_steps_sampled: 288000\n",
      "  num_steps_trained: 288000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 72\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.67\n",
      "  ram_util_percent: 87.35\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0716254971559682\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08217143750362618\n",
      "  mean_inference_ms: 0.779804985274152\n",
      "  mean_raw_obs_processing_ms: 0.09540981108909664\n",
      "time_since_restore: 535.0081241130829\n",
      "time_this_iter_s: 7.068239450454712\n",
      "time_total_s: 535.0081241130829\n",
      "timers:\n",
      "  learn_throughput: 1310.228\n",
      "  learn_time_ms: 3052.903\n",
      "  load_throughput: 22078189.235\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 588.356\n",
      "  sample_time_ms: 6798.61\n",
      "  update_time_ms: 2.26\n",
      "timestamp: 1658394480\n",
      "timesteps_since_restore: 288000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 288000\n",
      "training_iteration: 72\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 292000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-06\n",
      "done: false\n",
      "episode_len_mean: 195.24\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.24\n",
      "episode_reward_min: 146.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1728\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.7881394143159923e-08\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36299577355384827\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003148711519315839\n",
      "        model: {}\n",
      "        policy_loss: -0.0025231956969946623\n",
      "        total_loss: 5.637722492218018\n",
      "        vf_explained_var: 0.1646001935005188\n",
      "        vf_loss: 5.6402459144592285\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 292000\n",
      "  num_agent_steps_trained: 292000\n",
      "  num_steps_sampled: 292000\n",
      "  num_steps_trained: 292000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 73\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.3375\n",
      "  ram_util_percent: 87.32500000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07145885295481609\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08198719663389356\n",
      "  mean_inference_ms: 0.7780925683051501\n",
      "  mean_raw_obs_processing_ms: 0.09520148564791935\n",
      "time_since_restore: 541.0791277885437\n",
      "time_this_iter_s: 6.071003675460815\n",
      "time_total_s: 541.0791277885437\n",
      "timers:\n",
      "  learn_throughput: 1311.537\n",
      "  learn_time_ms: 3049.856\n",
      "  load_throughput: 22159841.5\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 586.027\n",
      "  sample_time_ms: 6825.622\n",
      "  update_time_ms: 2.231\n",
      "timestamp: 1658394486\n",
      "timesteps_since_restore: 292000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 292000\n",
      "training_iteration: 73\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 296000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-13\n",
      "done: false\n",
      "episode_len_mean: 194.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.78\n",
      "episode_reward_min: 152.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1748\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.940697071579962e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35511651635169983\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008513880893588066\n",
      "        model: {}\n",
      "        policy_loss: 0.0026512735057622194\n",
      "        total_loss: 5.791093349456787\n",
      "        vf_explained_var: 0.11642017960548401\n",
      "        vf_loss: 5.788442134857178\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 296000\n",
      "  num_agent_steps_trained: 296000\n",
      "  num_steps_sampled: 296000\n",
      "  num_steps_trained: 296000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 74\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.06\n",
      "  ram_util_percent: 87.34\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07130050289840785\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08181175161059953\n",
      "  mean_inference_ms: 0.7764546499574123\n",
      "  mean_raw_obs_processing_ms: 0.09500423513785165\n",
      "time_since_restore: 547.7866353988647\n",
      "time_this_iter_s: 6.707507610321045\n",
      "time_total_s: 547.7866353988647\n",
      "timers:\n",
      "  learn_throughput: 1304.781\n",
      "  learn_time_ms: 3065.648\n",
      "  load_throughput: 22420441.0\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 593.0\n",
      "  sample_time_ms: 6745.366\n",
      "  update_time_ms: 2.181\n",
      "timestamp: 1658394493\n",
      "timesteps_since_restore: 296000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 296000\n",
      "training_iteration: 74\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 300000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-20\n",
      "done: false\n",
      "episode_len_mean: 192.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.36\n",
      "episode_reward_min: 152.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 1770\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.940697071579962e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35217559337615967\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007057798560708761\n",
      "        model: {}\n",
      "        policy_loss: -0.0024549905210733414\n",
      "        total_loss: 3.938783884048462\n",
      "        vf_explained_var: 0.18188683688640594\n",
      "        vf_loss: 3.94123911857605\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 300000\n",
      "  num_agent_steps_trained: 300000\n",
      "  num_steps_sampled: 300000\n",
      "  num_steps_trained: 300000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 75\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.700000000000003\n",
      "  ram_util_percent: 87.46666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07113610677917566\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08162923400445703\n",
      "  mean_inference_ms: 0.7747481204091691\n",
      "  mean_raw_obs_processing_ms: 0.0947987964754991\n",
      "time_since_restore: 554.3228418827057\n",
      "time_this_iter_s: 6.536206483840942\n",
      "time_total_s: 554.3228418827057\n",
      "timers:\n",
      "  learn_throughput: 1329.345\n",
      "  learn_time_ms: 3009.0\n",
      "  load_throughput: 22733355.014\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 595.024\n",
      "  sample_time_ms: 6722.412\n",
      "  update_time_ms: 2.188\n",
      "timestamp: 1658394500\n",
      "timesteps_since_restore: 300000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 300000\n",
      "training_iteration: 75\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 304000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-26\n",
      "done: false\n",
      "episode_len_mean: 190.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.44\n",
      "episode_reward_min: 133.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1791\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.940697071579962e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35479551553726196\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007975880056619644\n",
      "        model: {}\n",
      "        policy_loss: 0.0010596959618851542\n",
      "        total_loss: 4.474516868591309\n",
      "        vf_explained_var: 0.11454837024211884\n",
      "        vf_loss: 4.473456859588623\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 304000\n",
      "  num_agent_steps_trained: 304000\n",
      "  num_steps_sampled: 304000\n",
      "  num_steps_trained: 304000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 76\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.88000000000001\n",
      "  ram_util_percent: 87.44000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07099097945366481\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08147062241769315\n",
      "  mean_inference_ms: 0.7732599765615978\n",
      "  mean_raw_obs_processing_ms: 0.09461912141141132\n",
      "time_since_restore: 560.8943405151367\n",
      "time_this_iter_s: 6.57149863243103\n",
      "time_total_s: 560.8943405151367\n",
      "timers:\n",
      "  learn_throughput: 1340.204\n",
      "  learn_time_ms: 2984.619\n",
      "  load_throughput: 22897797.188\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 603.034\n",
      "  sample_time_ms: 6633.127\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658394506\n",
      "timesteps_since_restore: 304000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 304000\n",
      "training_iteration: 76\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 308000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-33\n",
      "done: false\n",
      "episode_len_mean: 190.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.4\n",
      "episode_reward_min: 133.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1812\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.940697071579962e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3616197109222412\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008532845415174961\n",
      "        model: {}\n",
      "        policy_loss: 0.0020510072354227304\n",
      "        total_loss: 6.054436683654785\n",
      "        vf_explained_var: 0.11437924206256866\n",
      "        vf_loss: 6.0523858070373535\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 308000\n",
      "  num_agent_steps_trained: 308000\n",
      "  num_steps_sampled: 308000\n",
      "  num_steps_trained: 308000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 77\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.94444444444444\n",
      "  ram_util_percent: 87.45555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07085111124343502\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08131762316741664\n",
      "  mean_inference_ms: 0.7718268546481758\n",
      "  mean_raw_obs_processing_ms: 0.09444850203309077\n",
      "time_since_restore: 567.5358397960663\n",
      "time_this_iter_s: 6.641499280929565\n",
      "time_total_s: 567.5358397960663\n",
      "timers:\n",
      "  learn_throughput: 1334.383\n",
      "  learn_time_ms: 2997.641\n",
      "  load_throughput: 22973046.693\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 605.469\n",
      "  sample_time_ms: 6606.453\n",
      "  update_time_ms: 2.097\n",
      "timestamp: 1658394513\n",
      "timesteps_since_restore: 308000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 308000\n",
      "training_iteration: 77\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 312000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-40\n",
      "done: false\n",
      "episode_len_mean: 187.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.37\n",
      "episode_reward_min: 104.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 1834\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.940697071579962e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3569459915161133\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003956702072173357\n",
      "        model: {}\n",
      "        policy_loss: 0.00466229347512126\n",
      "        total_loss: 5.948702812194824\n",
      "        vf_explained_var: 0.09667740762233734\n",
      "        vf_loss: 5.944040298461914\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 312000\n",
      "  num_agent_steps_trained: 312000\n",
      "  num_steps_sampled: 312000\n",
      "  num_steps_trained: 312000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 78\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.94\n",
      "  ram_util_percent: 87.42999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07072721667726613\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08118045980117715\n",
      "  mean_inference_ms: 0.7705538563528589\n",
      "  mean_raw_obs_processing_ms: 0.09429477769667274\n",
      "time_since_restore: 574.2934246063232\n",
      "time_this_iter_s: 6.757584810256958\n",
      "time_total_s: 574.2934246063232\n",
      "timers:\n",
      "  learn_throughput: 1330.09\n",
      "  learn_time_ms: 3007.316\n",
      "  load_throughput: 24410324.458\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 605.549\n",
      "  sample_time_ms: 6605.572\n",
      "  update_time_ms: 2.093\n",
      "timestamp: 1658394520\n",
      "timesteps_since_restore: 312000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 312000\n",
      "training_iteration: 78\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 316000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-46\n",
      "done: false\n",
      "episode_len_mean: 186.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.21\n",
      "episode_reward_min: 104.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 1856\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.470348535789981e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33806756138801575\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00788049679249525\n",
      "        model: {}\n",
      "        policy_loss: -0.012140302918851376\n",
      "        total_loss: 4.417250633239746\n",
      "        vf_explained_var: 0.11010570079088211\n",
      "        vf_loss: 4.429391384124756\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 316000\n",
      "  num_agent_steps_trained: 316000\n",
      "  num_steps_sampled: 316000\n",
      "  num_steps_trained: 316000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 79\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.077777777777776\n",
      "  ram_util_percent: 87.30000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07061462284810198\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08105465210893652\n",
      "  mean_inference_ms: 0.7694099888461478\n",
      "  mean_raw_obs_processing_ms: 0.09415768579756964\n",
      "time_since_restore: 580.8942487239838\n",
      "time_this_iter_s: 6.6008241176605225\n",
      "time_total_s: 580.8942487239838\n",
      "timers:\n",
      "  learn_throughput: 1335.683\n",
      "  learn_time_ms: 2994.722\n",
      "  load_throughput: 24367779.23\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 603.823\n",
      "  sample_time_ms: 6624.458\n",
      "  update_time_ms: 2.108\n",
      "timestamp: 1658394526\n",
      "timesteps_since_restore: 316000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 316000\n",
      "training_iteration: 79\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 320000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-53\n",
      "done: false\n",
      "episode_len_mean: 185.81\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.81\n",
      "episode_reward_min: 104.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1877\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.470348535789981e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3199005424976349\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003975891973823309\n",
      "        model: {}\n",
      "        policy_loss: 0.004468977451324463\n",
      "        total_loss: 6.027529716491699\n",
      "        vf_explained_var: 0.09789007902145386\n",
      "        vf_loss: 6.023060321807861\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 320000\n",
      "  num_agent_steps_trained: 320000\n",
      "  num_steps_sampled: 320000\n",
      "  num_steps_trained: 320000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 80\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.540000000000006\n",
      "  ram_util_percent: 87.34\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07050125590927277\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0809275336753472\n",
      "  mean_inference_ms: 0.7682594819852953\n",
      "  mean_raw_obs_processing_ms: 0.09402011803879966\n",
      "time_since_restore: 587.3362398147583\n",
      "time_this_iter_s: 6.441991090774536\n",
      "time_total_s: 587.3362398147583\n",
      "timers:\n",
      "  learn_throughput: 1332.722\n",
      "  learn_time_ms: 3001.376\n",
      "  load_throughput: 24262062.184\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 605.861\n",
      "  sample_time_ms: 6602.174\n",
      "  update_time_ms: 2.097\n",
      "timestamp: 1658394533\n",
      "timesteps_since_restore: 320000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 320000\n",
      "training_iteration: 80\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 324000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-08-59\n",
      "done: false\n",
      "episode_len_mean: 185.84\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.84\n",
      "episode_reward_min: 104.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 1899\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.2351742678949904e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32011890411376953\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0039606401696801186\n",
      "        model: {}\n",
      "        policy_loss: 0.004197004716843367\n",
      "        total_loss: 4.886244297027588\n",
      "        vf_explained_var: 0.1210402175784111\n",
      "        vf_loss: 4.882047176361084\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 324000\n",
      "  num_agent_steps_trained: 324000\n",
      "  num_steps_sampled: 324000\n",
      "  num_steps_trained: 324000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 81\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.599999999999998\n",
      "  ram_util_percent: 87.44444444444444\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07038119337494927\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0807922262296873\n",
      "  mean_inference_ms: 0.7670408553283342\n",
      "  mean_raw_obs_processing_ms: 0.09387448456677007\n",
      "time_since_restore: 593.8352971076965\n",
      "time_this_iter_s: 6.499057292938232\n",
      "time_total_s: 593.8352971076965\n",
      "timers:\n",
      "  learn_throughput: 1332.649\n",
      "  learn_time_ms: 3001.54\n",
      "  load_throughput: 24488711.137\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 605.204\n",
      "  sample_time_ms: 6609.338\n",
      "  update_time_ms: 1.868\n",
      "timestamp: 1658394539\n",
      "timesteps_since_restore: 324000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 324000\n",
      "training_iteration: 81\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 328000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-06\n",
      "done: false\n",
      "episode_len_mean: 183.58\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 183.58\n",
      "episode_reward_min: 122.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 1922\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.1175871339474952e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30646854639053345\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005189485382288694\n",
      "        model: {}\n",
      "        policy_loss: -0.01875726878643036\n",
      "        total_loss: 6.118819236755371\n",
      "        vf_explained_var: 0.0884728878736496\n",
      "        vf_loss: 6.137576580047607\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 328000\n",
      "  num_agent_steps_trained: 328000\n",
      "  num_steps_sampled: 328000\n",
      "  num_steps_trained: 328000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 82\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 30.933333333333337\n",
      "  ram_util_percent: 87.35555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07026100459180819\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0806561326990573\n",
      "  mean_inference_ms: 0.7658082019536553\n",
      "  mean_raw_obs_processing_ms: 0.09372592105308102\n",
      "time_since_restore: 600.2254302501678\n",
      "time_this_iter_s: 6.3901331424713135\n",
      "time_total_s: 600.2254302501678\n",
      "timers:\n",
      "  learn_throughput: 1361.635\n",
      "  learn_time_ms: 2937.644\n",
      "  load_throughput: 24549628.329\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 605.796\n",
      "  sample_time_ms: 6602.884\n",
      "  update_time_ms: 1.926\n",
      "timestamp: 1658394546\n",
      "timesteps_since_restore: 328000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 328000\n",
      "training_iteration: 82\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 332000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-13\n",
      "done: false\n",
      "episode_len_mean: 182.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 182.8\n",
      "episode_reward_min: 122.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 1944\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.1175871339474952e-09\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31575652956962585\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037302221171557903\n",
      "        model: {}\n",
      "        policy_loss: 0.004103794693946838\n",
      "        total_loss: 5.533581256866455\n",
      "        vf_explained_var: 0.1458560675382614\n",
      "        vf_loss: 5.529477596282959\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 332000\n",
      "  num_agent_steps_trained: 332000\n",
      "  num_steps_sampled: 332000\n",
      "  num_steps_trained: 332000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 83\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.24\n",
      "  ram_util_percent: 87.45\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07014920191744885\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08053156705960524\n",
      "  mean_inference_ms: 0.7646563679707272\n",
      "  mean_raw_obs_processing_ms: 0.09358513160872357\n",
      "time_since_restore: 607.0176994800568\n",
      "time_this_iter_s: 6.792269229888916\n",
      "time_total_s: 607.0176994800568\n",
      "timers:\n",
      "  learn_throughput: 1347.293\n",
      "  learn_time_ms: 2968.917\n",
      "  load_throughput: 24018920.544\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 607.836\n",
      "  sample_time_ms: 6580.723\n",
      "  update_time_ms: 1.97\n",
      "timestamp: 1658394553\n",
      "timesteps_since_restore: 332000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 332000\n",
      "training_iteration: 83\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 336000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-19\n",
      "done: false\n",
      "episode_len_mean: 182.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 182.33\n",
      "episode_reward_min: 122.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 1965\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.587935669737476e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3343794643878937\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003324460471048951\n",
      "        model: {}\n",
      "        policy_loss: 0.0043925815261900425\n",
      "        total_loss: 5.972754955291748\n",
      "        vf_explained_var: 0.09181235730648041\n",
      "        vf_loss: 5.968362331390381\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 336000\n",
      "  num_agent_steps_trained: 336000\n",
      "  num_steps_sampled: 336000\n",
      "  num_steps_trained: 336000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 84\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.733333333333334\n",
      "  ram_util_percent: 87.44444444444444\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0700444327353183\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08041533925066219\n",
      "  mean_inference_ms: 0.7635754068322992\n",
      "  mean_raw_obs_processing_ms: 0.09345234301488003\n",
      "time_since_restore: 613.5130045413971\n",
      "time_this_iter_s: 6.495305061340332\n",
      "time_total_s: 613.5130045413971\n",
      "timers:\n",
      "  learn_throughput: 1360.611\n",
      "  learn_time_ms: 2939.855\n",
      "  load_throughput: 24108659.29\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 604.206\n",
      "  sample_time_ms: 6620.255\n",
      "  update_time_ms: 2.038\n",
      "timestamp: 1658394559\n",
      "timesteps_since_restore: 336000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 336000\n",
      "training_iteration: 84\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 340000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-26\n",
      "done: false\n",
      "episode_len_mean: 185.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.83\n",
      "episode_reward_min: 122.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 1985\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.793967834868738e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.312905877828598\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008939605206251144\n",
      "        model: {}\n",
      "        policy_loss: 0.000751363520976156\n",
      "        total_loss: 5.900613307952881\n",
      "        vf_explained_var: 0.04946521669626236\n",
      "        vf_loss: 5.899861812591553\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 340000\n",
      "  num_agent_steps_trained: 340000\n",
      "  num_steps_sampled: 340000\n",
      "  num_steps_trained: 340000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 85\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.55555555555556\n",
      "  ram_util_percent: 87.44444444444444\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06995107984803008\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08031212735044166\n",
      "  mean_inference_ms: 0.7626130577445968\n",
      "  mean_raw_obs_processing_ms: 0.09333321804280223\n",
      "time_since_restore: 620.0571093559265\n",
      "time_this_iter_s: 6.544104814529419\n",
      "time_total_s: 620.0571093559265\n",
      "timers:\n",
      "  learn_throughput: 1360.055\n",
      "  learn_time_ms: 2941.059\n",
      "  load_throughput: 24070611.191\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 606.88\n",
      "  sample_time_ms: 6591.091\n",
      "  update_time_ms: 2.057\n",
      "timestamp: 1658394566\n",
      "timesteps_since_restore: 340000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 340000\n",
      "training_iteration: 85\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 344000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-32\n",
      "done: false\n",
      "episode_len_mean: 186.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.85\n",
      "episode_reward_min: 122.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2006\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.793967834868738e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.308536559343338\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0040571182034909725\n",
      "        model: {}\n",
      "        policy_loss: 0.003780870698392391\n",
      "        total_loss: 4.91632080078125\n",
      "        vf_explained_var: 0.1041041910648346\n",
      "        vf_loss: 4.912539958953857\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 344000\n",
      "  num_agent_steps_trained: 344000\n",
      "  num_steps_sampled: 344000\n",
      "  num_steps_trained: 344000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 86\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.949999999999996\n",
      "  ram_util_percent: 87.39000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06985908916184445\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0802119505129673\n",
      "  mean_inference_ms: 0.7616693413008\n",
      "  mean_raw_obs_processing_ms: 0.0932175640002486\n",
      "time_since_restore: 626.6806967258453\n",
      "time_this_iter_s: 6.623587369918823\n",
      "time_total_s: 626.6806967258453\n",
      "timers:\n",
      "  learn_throughput: 1356.447\n",
      "  learn_time_ms: 2948.88\n",
      "  load_throughput: 23576750.984\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 607.022\n",
      "  sample_time_ms: 6589.55\n",
      "  update_time_ms: 2.093\n",
      "timestamp: 1658394572\n",
      "timesteps_since_restore: 344000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 344000\n",
      "training_iteration: 86\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 348000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-39\n",
      "done: false\n",
      "episode_len_mean: 186.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.69\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2028\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.396983917434369e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2832036316394806\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005097029265016317\n",
      "        model: {}\n",
      "        policy_loss: 0.0009856184478849173\n",
      "        total_loss: 5.070563316345215\n",
      "        vf_explained_var: 0.05942216143012047\n",
      "        vf_loss: 5.069578170776367\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 348000\n",
      "  num_agent_steps_trained: 348000\n",
      "  num_steps_sampled: 348000\n",
      "  num_steps_trained: 348000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 87\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.46666666666667\n",
      "  ram_util_percent: 87.38888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06976428447260012\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08010951373119607\n",
      "  mean_inference_ms: 0.7607102122322165\n",
      "  mean_raw_obs_processing_ms: 0.09310079140236364\n",
      "time_since_restore: 633.3202421665192\n",
      "time_this_iter_s: 6.639545440673828\n",
      "time_total_s: 633.3202421665192\n",
      "timers:\n",
      "  learn_throughput: 1360.156\n",
      "  learn_time_ms: 2940.84\n",
      "  load_throughput: 23659873.079\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 605.563\n",
      "  sample_time_ms: 6605.421\n",
      "  update_time_ms: 2.151\n",
      "timestamp: 1658394579\n",
      "timesteps_since_restore: 348000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 348000\n",
      "training_iteration: 87\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 352000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-45\n",
      "done: false\n",
      "episode_len_mean: 190.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.12\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2049\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.396983917434369e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3309609889984131\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008439421653747559\n",
      "        model: {}\n",
      "        policy_loss: 0.00041527170105837286\n",
      "        total_loss: 5.368156909942627\n",
      "        vf_explained_var: 0.1083933487534523\n",
      "        vf_loss: 5.36774206161499\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 352000\n",
      "  num_agent_steps_trained: 352000\n",
      "  num_steps_sampled: 352000\n",
      "  num_steps_trained: 352000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 88\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.18\n",
      "  ram_util_percent: 87.23\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06967462180738375\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08001262108257289\n",
      "  mean_inference_ms: 0.7598167820949171\n",
      "  mean_raw_obs_processing_ms: 0.09299211655005447\n",
      "time_since_restore: 639.8190224170685\n",
      "time_this_iter_s: 6.498780250549316\n",
      "time_total_s: 639.8190224170685\n",
      "timers:\n",
      "  learn_throughput: 1373.502\n",
      "  learn_time_ms: 2912.265\n",
      "  load_throughput: 23061465.292\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 606.03\n",
      "  sample_time_ms: 6600.338\n",
      "  update_time_ms: 2.224\n",
      "timestamp: 1658394585\n",
      "timesteps_since_restore: 352000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 352000\n",
      "training_iteration: 88\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 356000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-52\n",
      "done: false\n",
      "episode_len_mean: 188.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.4\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2071\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.396983917434369e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3183107376098633\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0051860748790204525\n",
      "        model: {}\n",
      "        policy_loss: 0.001023306860588491\n",
      "        total_loss: 5.97066593170166\n",
      "        vf_explained_var: 0.05757103115320206\n",
      "        vf_loss: 5.969642639160156\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 356000\n",
      "  num_agent_steps_trained: 356000\n",
      "  num_steps_sampled: 356000\n",
      "  num_steps_trained: 356000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 89\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.811111111111114\n",
      "  ram_util_percent: 87.25555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06958251998651552\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07991271930903274\n",
      "  mean_inference_ms: 0.7588934447683192\n",
      "  mean_raw_obs_processing_ms: 0.09288177342311002\n",
      "time_since_restore: 646.2103357315063\n",
      "time_this_iter_s: 6.391313314437866\n",
      "time_total_s: 646.2103357315063\n",
      "timers:\n",
      "  learn_throughput: 1378.242\n",
      "  learn_time_ms: 2902.248\n",
      "  load_throughput: 23020329.308\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 609.611\n",
      "  sample_time_ms: 6561.557\n",
      "  update_time_ms: 2.245\n",
      "timestamp: 1658394592\n",
      "timesteps_since_restore: 356000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 356000\n",
      "training_iteration: 89\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 360000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-09-58\n",
      "done: false\n",
      "episode_len_mean: 186.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.28\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2092\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.396983917434369e-10\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3381906747817993\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004464901052415371\n",
      "        model: {}\n",
      "        policy_loss: 0.0016302334843203425\n",
      "        total_loss: 5.488896369934082\n",
      "        vf_explained_var: 0.13672086596488953\n",
      "        vf_loss: 5.487267017364502\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 360000\n",
      "  num_agent_steps_trained: 360000\n",
      "  num_steps_sampled: 360000\n",
      "  num_steps_trained: 360000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 90\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.555555555555557\n",
      "  ram_util_percent: 87.22222222222221\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06949232815394589\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07981472858537753\n",
      "  mean_inference_ms: 0.7579868103259332\n",
      "  mean_raw_obs_processing_ms: 0.0927747687837896\n",
      "time_since_restore: 652.6398816108704\n",
      "time_this_iter_s: 6.429545879364014\n",
      "time_total_s: 652.6398816108704\n",
      "timers:\n",
      "  learn_throughput: 1379.77\n",
      "  learn_time_ms: 2899.035\n",
      "  load_throughput: 23172950.276\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 610.367\n",
      "  sample_time_ms: 6553.431\n",
      "  update_time_ms: 2.245\n",
      "timestamp: 1658394598\n",
      "timesteps_since_restore: 360000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 360000\n",
      "training_iteration: 90\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 364000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-05\n",
      "done: false\n",
      "episode_len_mean: 187.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.44\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2114\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.984919587171845e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.354981392621994\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0070375413633883\n",
      "        model: {}\n",
      "        policy_loss: 0.0017952423077076674\n",
      "        total_loss: 5.030973434448242\n",
      "        vf_explained_var: 0.1939520388841629\n",
      "        vf_loss: 5.029177665710449\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 364000\n",
      "  num_agent_steps_trained: 364000\n",
      "  num_steps_sampled: 364000\n",
      "  num_steps_trained: 364000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 91\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.84444444444444\n",
      "  ram_util_percent: 87.30000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06939287983517632\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07970571465296432\n",
      "  mean_inference_ms: 0.756987752760757\n",
      "  mean_raw_obs_processing_ms: 0.092655932746185\n",
      "time_since_restore: 659.0851283073425\n",
      "time_this_iter_s: 6.445246696472168\n",
      "time_total_s: 659.0851283073425\n",
      "timers:\n",
      "  learn_throughput: 1379.388\n",
      "  learn_time_ms: 2899.837\n",
      "  load_throughput: 22613850.923\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 611.243\n",
      "  sample_time_ms: 6544.045\n",
      "  update_time_ms: 2.25\n",
      "timestamp: 1658394605\n",
      "timesteps_since_restore: 364000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 364000\n",
      "training_iteration: 91\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 368000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-11\n",
      "done: false\n",
      "episode_len_mean: 187.82\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.82\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2135\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.984919587171845e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30102577805519104\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004050887655466795\n",
      "        model: {}\n",
      "        policy_loss: 0.005079198628664017\n",
      "        total_loss: 6.834738254547119\n",
      "        vf_explained_var: 0.12522341310977936\n",
      "        vf_loss: 6.8296589851379395\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 368000\n",
      "  num_agent_steps_trained: 368000\n",
      "  num_steps_sampled: 368000\n",
      "  num_steps_trained: 368000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 92\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.455555555555552\n",
      "  ram_util_percent: 87.25555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06929558841800551\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07959887247352433\n",
      "  mean_inference_ms: 0.7560007189650808\n",
      "  mean_raw_obs_processing_ms: 0.09253921239644047\n",
      "time_since_restore: 665.437536239624\n",
      "time_this_iter_s: 6.352407932281494\n",
      "time_total_s: 665.437536239624\n",
      "timers:\n",
      "  learn_throughput: 1379.609\n",
      "  learn_time_ms: 2899.372\n",
      "  load_throughput: 22562151.694\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 611.476\n",
      "  sample_time_ms: 6541.549\n",
      "  update_time_ms: 2.275\n",
      "timestamp: 1658394611\n",
      "timesteps_since_restore: 368000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 368000\n",
      "training_iteration: 92\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 372000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-18\n",
      "done: false\n",
      "episode_len_mean: 185.07\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.07\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2157\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4924597935859225e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31705042719841003\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005959066562354565\n",
      "        model: {}\n",
      "        policy_loss: 0.005213398020714521\n",
      "        total_loss: 6.500944137573242\n",
      "        vf_explained_var: 0.16301222145557404\n",
      "        vf_loss: 6.495730400085449\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 372000\n",
      "  num_agent_steps_trained: 372000\n",
      "  num_steps_sampled: 372000\n",
      "  num_steps_trained: 372000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 93\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.989999999999995\n",
      "  ram_util_percent: 87.3\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06919500301376341\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0794885709709277\n",
      "  mean_inference_ms: 0.7549840707719736\n",
      "  mean_raw_obs_processing_ms: 0.09241688306201201\n",
      "time_since_restore: 671.8777611255646\n",
      "time_this_iter_s: 6.440224885940552\n",
      "time_total_s: 671.8777611255646\n",
      "timers:\n",
      "  learn_throughput: 1394.071\n",
      "  learn_time_ms: 2869.294\n",
      "  load_throughput: 22875942.187\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 611.96\n",
      "  sample_time_ms: 6536.377\n",
      "  update_time_ms: 2.187\n",
      "timestamp: 1658394618\n",
      "timesteps_since_restore: 372000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 372000\n",
      "training_iteration: 93\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 376000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-24\n",
      "done: false\n",
      "episode_len_mean: 183.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 183.66\n",
      "episode_reward_min: 115.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 2180\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4924597935859225e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3206169605255127\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005707798060029745\n",
      "        model: {}\n",
      "        policy_loss: -0.0143283661454916\n",
      "        total_loss: 6.7225260734558105\n",
      "        vf_explained_var: 0.18812131881713867\n",
      "        vf_loss: 6.7368550300598145\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 376000\n",
      "  num_agent_steps_trained: 376000\n",
      "  num_steps_sampled: 376000\n",
      "  num_steps_trained: 376000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 94\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.455555555555556\n",
      "  ram_util_percent: 87.3111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06908937603043441\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0793732383422906\n",
      "  mean_inference_ms: 0.7539191964987054\n",
      "  mean_raw_obs_processing_ms: 0.09228788481217073\n",
      "time_since_restore: 678.3733870983124\n",
      "time_this_iter_s: 6.495625972747803\n",
      "time_total_s: 678.3733870983124\n",
      "timers:\n",
      "  learn_throughput: 1388.451\n",
      "  learn_time_ms: 2880.909\n",
      "  load_throughput: 22816831.225\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 615.996\n",
      "  sample_time_ms: 6493.549\n",
      "  update_time_ms: 2.165\n",
      "timestamp: 1658394624\n",
      "timesteps_since_restore: 376000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 376000\n",
      "training_iteration: 94\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 380000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-31\n",
      "done: false\n",
      "episode_len_mean: 182.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 182.39\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2202\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4924597935859225e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32345056533813477\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0050267805345356464\n",
      "        model: {}\n",
      "        policy_loss: -0.008815741166472435\n",
      "        total_loss: 6.16108512878418\n",
      "        vf_explained_var: 0.14654317498207092\n",
      "        vf_loss: 6.169900894165039\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 380000\n",
      "  num_agent_steps_trained: 380000\n",
      "  num_steps_sampled: 380000\n",
      "  num_steps_trained: 380000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 95\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.38\n",
      "  ram_util_percent: 87.30000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06901400302342407\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07929170431091598\n",
      "  mean_inference_ms: 0.7531712533495858\n",
      "  mean_raw_obs_processing_ms: 0.09219539514779501\n",
      "time_since_restore: 685.3632252216339\n",
      "time_this_iter_s: 6.989838123321533\n",
      "time_total_s: 685.3632252216339\n",
      "timers:\n",
      "  learn_throughput: 1386.826\n",
      "  learn_time_ms: 2884.284\n",
      "  load_throughput: 22767289.999\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 611.02\n",
      "  sample_time_ms: 6546.428\n",
      "  update_time_ms: 2.127\n",
      "timestamp: 1658394631\n",
      "timesteps_since_restore: 380000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 380000\n",
      "training_iteration: 95\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 384000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-38\n",
      "done: false\n",
      "episode_len_mean: 180.43\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 180.43\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2224\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4924597935859225e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3535558581352234\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00535158533602953\n",
      "        model: {}\n",
      "        policy_loss: 0.002537691965699196\n",
      "        total_loss: 5.359012603759766\n",
      "        vf_explained_var: 0.1940869837999344\n",
      "        vf_loss: 5.356474876403809\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 384000\n",
      "  num_agent_steps_trained: 384000\n",
      "  num_steps_sampled: 384000\n",
      "  num_steps_trained: 384000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 96\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.05\n",
      "  ram_util_percent: 87.12\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0689487089486343\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07922143471190264\n",
      "  mean_inference_ms: 0.7525212343319362\n",
      "  mean_raw_obs_processing_ms: 0.092113227786995\n",
      "time_since_restore: 692.0899362564087\n",
      "time_this_iter_s: 6.72671103477478\n",
      "time_total_s: 692.0899362564087\n",
      "timers:\n",
      "  learn_throughput: 1382.18\n",
      "  learn_time_ms: 2893.979\n",
      "  load_throughput: 22798228.02\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 610.674\n",
      "  sample_time_ms: 6550.145\n",
      "  update_time_ms: 2.185\n",
      "timestamp: 1658394638\n",
      "timesteps_since_restore: 384000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 384000\n",
      "training_iteration: 96\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 388000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-45\n",
      "done: false\n",
      "episode_len_mean: 180.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 180.14\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2246\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4924597935859225e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3769936263561249\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008594157174229622\n",
      "        model: {}\n",
      "        policy_loss: 0.0017001221422106028\n",
      "        total_loss: 5.8481059074401855\n",
      "        vf_explained_var: 0.19723287224769592\n",
      "        vf_loss: 5.846405029296875\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 388000\n",
      "  num_agent_steps_trained: 388000\n",
      "  num_steps_sampled: 388000\n",
      "  num_steps_trained: 388000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 97\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.800000000000004\n",
      "  ram_util_percent: 87.13333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06888679511716142\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07915397073731607\n",
      "  mean_inference_ms: 0.751909504363175\n",
      "  mean_raw_obs_processing_ms: 0.0920360470956452\n",
      "time_since_restore: 698.7439987659454\n",
      "time_this_iter_s: 6.654062509536743\n",
      "time_total_s: 698.7439987659454\n",
      "timers:\n",
      "  learn_throughput: 1379.916\n",
      "  learn_time_ms: 2898.728\n",
      "  load_throughput: 22492580.775\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 610.046\n",
      "  sample_time_ms: 6556.883\n",
      "  update_time_ms: 2.212\n",
      "timestamp: 1658394645\n",
      "timesteps_since_restore: 388000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 388000\n",
      "training_iteration: 97\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 392000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-51\n",
      "done: false\n",
      "episode_len_mean: 176.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 176.86\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 2270\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4924597935859225e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30138862133026123\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005542859900742769\n",
      "        model: {}\n",
      "        policy_loss: 0.0024563835468143225\n",
      "        total_loss: 6.347428321838379\n",
      "        vf_explained_var: 0.1334255039691925\n",
      "        vf_loss: 6.344972133636475\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 392000\n",
      "  num_agent_steps_trained: 392000\n",
      "  num_steps_sampled: 392000\n",
      "  num_steps_trained: 392000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 98\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.400000000000006\n",
      "  ram_util_percent: 87.21111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06882611540899068\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07908484384658687\n",
      "  mean_inference_ms: 0.7512895069674148\n",
      "  mean_raw_obs_processing_ms: 0.09195906709541907\n",
      "time_since_restore: 705.2191772460938\n",
      "time_this_iter_s: 6.475178480148315\n",
      "time_total_s: 705.2191772460938\n",
      "timers:\n",
      "  learn_throughput: 1378.237\n",
      "  learn_time_ms: 2902.259\n",
      "  load_throughput: 23373106.715\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 610.143\n",
      "  sample_time_ms: 6555.845\n",
      "  update_time_ms: 2.145\n",
      "timestamp: 1658394651\n",
      "timesteps_since_restore: 392000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 392000\n",
      "training_iteration: 98\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 396000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-10-58\n",
      "done: false\n",
      "episode_len_mean: 177.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 177.35\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2291\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4924597935859225e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3293769657611847\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008097171783447266\n",
      "        model: {}\n",
      "        policy_loss: -0.0023039858788251877\n",
      "        total_loss: 4.152160167694092\n",
      "        vf_explained_var: 0.17338024079799652\n",
      "        vf_loss: 4.154464244842529\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 396000\n",
      "  num_agent_steps_trained: 396000\n",
      "  num_steps_sampled: 396000\n",
      "  num_steps_trained: 396000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 99\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.11\n",
      "  ram_util_percent: 87.14000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06876913778121889\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0790193623821107\n",
      "  mean_inference_ms: 0.7507032405169105\n",
      "  mean_raw_obs_processing_ms: 0.0918859505053757\n",
      "time_since_restore: 711.845644235611\n",
      "time_this_iter_s: 6.626466989517212\n",
      "time_total_s: 711.845644235611\n",
      "timers:\n",
      "  learn_throughput: 1370.592\n",
      "  learn_time_ms: 2918.446\n",
      "  load_throughput: 23517263.807\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 609.183\n",
      "  sample_time_ms: 6566.174\n",
      "  update_time_ms: 2.118\n",
      "timestamp: 1658394658\n",
      "timesteps_since_restore: 396000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 396000\n",
      "training_iteration: 99\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 400000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-11-04\n",
      "done: false\n",
      "episode_len_mean: 179.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 179.71\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2313\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4924597935859225e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3392018973827362\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0048434012569487095\n",
      "        model: {}\n",
      "        policy_loss: 0.004791561048477888\n",
      "        total_loss: 5.895613670349121\n",
      "        vf_explained_var: 0.13899782299995422\n",
      "        vf_loss: 5.890822410583496\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 400000\n",
      "  num_agent_steps_trained: 400000\n",
      "  num_steps_sampled: 400000\n",
      "  num_steps_trained: 400000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 100\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.211111111111116\n",
      "  ram_util_percent: 87.1888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06870150823822378\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07894134261404216\n",
      "  mean_inference_ms: 0.7500128329703258\n",
      "  mean_raw_obs_processing_ms: 0.09179966984449515\n",
      "time_since_restore: 718.592942237854\n",
      "time_this_iter_s: 6.747298002243042\n",
      "time_total_s: 718.592942237854\n",
      "timers:\n",
      "  learn_throughput: 1362.054\n",
      "  learn_time_ms: 2936.741\n",
      "  load_throughput: 23636539.87\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 606.455\n",
      "  sample_time_ms: 6595.712\n",
      "  update_time_ms: 2.192\n",
      "timestamp: 1658394664\n",
      "timesteps_since_restore: 400000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 400000\n",
      "training_iteration: 100\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 404000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-11-12\n",
      "done: false\n",
      "episode_len_mean: 180.47\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 180.47\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2335\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.7462298967929613e-11\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31205686926841736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004766067489981651\n",
      "        model: {}\n",
      "        policy_loss: -0.001458573853597045\n",
      "        total_loss: 5.332815170288086\n",
      "        vf_explained_var: 0.14102338254451752\n",
      "        vf_loss: 5.334273815155029\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 404000\n",
      "  num_agent_steps_trained: 404000\n",
      "  num_steps_sampled: 404000\n",
      "  num_steps_trained: 404000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 101\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.37272727272727\n",
      "  ram_util_percent: 87.14545454545456\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06865055227034947\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07888034162458822\n",
      "  mean_inference_ms: 0.7494696809880981\n",
      "  mean_raw_obs_processing_ms: 0.09173224184443249\n",
      "time_since_restore: 725.7409529685974\n",
      "time_this_iter_s: 7.148010730743408\n",
      "time_total_s: 725.7409529685974\n",
      "timers:\n",
      "  learn_throughput: 1351.869\n",
      "  learn_time_ms: 2958.867\n",
      "  load_throughput: 23916202.423\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 600.37\n",
      "  sample_time_ms: 6662.554\n",
      "  update_time_ms: 2.178\n",
      "timestamp: 1658394672\n",
      "timesteps_since_restore: 404000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 404000\n",
      "training_iteration: 101\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000101/checkpoint-101\n",
      "agent_timesteps_total: 408000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-11-19\n",
      "done: false\n",
      "episode_len_mean: 184.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.86\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2355\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.731149483964806e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.320978045463562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005208123009651899\n",
      "        model: {}\n",
      "        policy_loss: 0.0007658489048480988\n",
      "        total_loss: 3.8916995525360107\n",
      "        vf_explained_var: 0.1401512175798416\n",
      "        vf_loss: 3.8909337520599365\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 408000\n",
      "  num_agent_steps_trained: 408000\n",
      "  num_steps_sampled: 408000\n",
      "  num_steps_trained: 408000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 102\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.279999999999994\n",
      "  ram_util_percent: 87.15\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06861183229682169\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07883476570804843\n",
      "  mean_inference_ms: 0.7490554190168729\n",
      "  mean_raw_obs_processing_ms: 0.09167901143076254\n",
      "time_since_restore: 732.6741230487823\n",
      "time_this_iter_s: 6.9331700801849365\n",
      "time_total_s: 732.6741230487823\n",
      "timers:\n",
      "  learn_throughput: 1337.916\n",
      "  learn_time_ms: 2989.725\n",
      "  load_throughput: 23773864.248\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 595.886\n",
      "  sample_time_ms: 6712.688\n",
      "  update_time_ms: 2.185\n",
      "timestamp: 1658394679\n",
      "timesteps_since_restore: 408000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 408000\n",
      "training_iteration: 102\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 412000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-11-26\n",
      "done: false\n",
      "episode_len_mean: 186.22\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.22\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 2378\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.731149483964806e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3591316342353821\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007066367659717798\n",
      "        model: {}\n",
      "        policy_loss: 0.001596519723534584\n",
      "        total_loss: 6.33486795425415\n",
      "        vf_explained_var: 0.1379896104335785\n",
      "        vf_loss: 6.333271503448486\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 412000\n",
      "  num_agent_steps_trained: 412000\n",
      "  num_steps_sampled: 412000\n",
      "  num_steps_trained: 412000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 103\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.59\n",
      "  ram_util_percent: 87.20000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06858267735838015\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07880154753138836\n",
      "  mean_inference_ms: 0.7487654092237029\n",
      "  mean_raw_obs_processing_ms: 0.09163842183436\n",
      "time_since_restore: 739.7670533657074\n",
      "time_this_iter_s: 7.092930316925049\n",
      "time_total_s: 739.7670533657074\n",
      "timers:\n",
      "  learn_throughput: 1329.56\n",
      "  learn_time_ms: 3008.515\n",
      "  load_throughput: 23909385.777\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 589.095\n",
      "  sample_time_ms: 6790.079\n",
      "  update_time_ms: 2.177\n",
      "timestamp: 1658394686\n",
      "timesteps_since_restore: 412000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 412000\n",
      "training_iteration: 103\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 416000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-11-32\n",
      "done: false\n",
      "episode_len_mean: 187.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.12\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2398\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.731149483964806e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3188088834285736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004207075107842684\n",
      "        model: {}\n",
      "        policy_loss: 0.0026786471717059612\n",
      "        total_loss: 5.240174293518066\n",
      "        vf_explained_var: 0.1752815842628479\n",
      "        vf_loss: 5.2374958992004395\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 416000\n",
      "  num_agent_steps_trained: 416000\n",
      "  num_steps_sampled: 416000\n",
      "  num_steps_trained: 416000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 104\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.233333333333334\n",
      "  ram_util_percent: 87.25555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06855935736724486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877470847958709\n",
      "  mean_inference_ms: 0.7485333905388458\n",
      "  mean_raw_obs_processing_ms: 0.09160519773760716\n",
      "time_since_restore: 746.4315049648285\n",
      "time_this_iter_s: 6.664451599121094\n",
      "time_total_s: 746.4315049648285\n",
      "timers:\n",
      "  learn_throughput: 1330.732\n",
      "  learn_time_ms: 3005.864\n",
      "  load_throughput: 23800845.51\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 585.778\n",
      "  sample_time_ms: 6828.529\n",
      "  update_time_ms: 2.132\n",
      "timestamp: 1658394692\n",
      "timesteps_since_restore: 416000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 416000\n",
      "training_iteration: 104\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 420000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-11-39\n",
      "done: false\n",
      "episode_len_mean: 190.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.49\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2419\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.365574741982403e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33165690302848816\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033847035374492407\n",
      "        model: {}\n",
      "        policy_loss: -0.02071464993059635\n",
      "        total_loss: 6.290074825286865\n",
      "        vf_explained_var: 0.14907938241958618\n",
      "        vf_loss: 6.310789585113525\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 420000\n",
      "  num_agent_steps_trained: 420000\n",
      "  num_steps_sampled: 420000\n",
      "  num_steps_trained: 420000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 105\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.78\n",
      "  ram_util_percent: 87.29999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06853439436221662\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07874773280711649\n",
      "  mean_inference_ms: 0.7482769765964814\n",
      "  mean_raw_obs_processing_ms: 0.09156470220925432\n",
      "time_since_restore: 753.389972448349\n",
      "time_this_iter_s: 6.958467483520508\n",
      "time_total_s: 753.389972448349\n",
      "timers:\n",
      "  learn_throughput: 1317.634\n",
      "  learn_time_ms: 3035.745\n",
      "  load_throughput: 23543665.45\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 588.85\n",
      "  sample_time_ms: 6792.906\n",
      "  update_time_ms: 2.096\n",
      "timestamp: 1658394699\n",
      "timesteps_since_restore: 420000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 420000\n",
      "training_iteration: 105\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 424000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-11-46\n",
      "done: false\n",
      "episode_len_mean: 191.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.98\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2439\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.1827873709912016e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31956085562705994\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005029358901083469\n",
      "        model: {}\n",
      "        policy_loss: 0.004659904167056084\n",
      "        total_loss: 5.977753639221191\n",
      "        vf_explained_var: 0.08525776118040085\n",
      "        vf_loss: 5.9730939865112305\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 424000\n",
      "  num_agent_steps_trained: 424000\n",
      "  num_steps_sampled: 424000\n",
      "  num_steps_trained: 424000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 106\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.35\n",
      "  ram_util_percent: 87.27\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06850444384424403\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07871709604580099\n",
      "  mean_inference_ms: 0.747983404471674\n",
      "  mean_raw_obs_processing_ms: 0.09151765602845054\n",
      "time_since_restore: 760.1802299022675\n",
      "time_this_iter_s: 6.790257453918457\n",
      "time_total_s: 760.1802299022675\n",
      "timers:\n",
      "  learn_throughput: 1318.803\n",
      "  learn_time_ms: 3033.054\n",
      "  load_throughput: 23957184.064\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 585.494\n",
      "  sample_time_ms: 6831.837\n",
      "  update_time_ms: 2.038\n",
      "timestamp: 1658394706\n",
      "timesteps_since_restore: 424000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 424000\n",
      "training_iteration: 106\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 428000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-11-53\n",
      "done: false\n",
      "episode_len_mean: 191.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.36\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2460\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.1827873709912016e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.334362655878067\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0043824114836752415\n",
      "        model: {}\n",
      "        policy_loss: 0.002422527875751257\n",
      "        total_loss: 4.251553058624268\n",
      "        vf_explained_var: 0.08529040217399597\n",
      "        vf_loss: 4.249130725860596\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 428000\n",
      "  num_agent_steps_trained: 428000\n",
      "  num_steps_sampled: 428000\n",
      "  num_steps_trained: 428000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 107\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.23333333333333\n",
      "  ram_util_percent: 87.30000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06846889427678833\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07867943905596482\n",
      "  mean_inference_ms: 0.7476183276392692\n",
      "  mean_raw_obs_processing_ms: 0.09146392277215963\n",
      "time_since_restore: 766.7578563690186\n",
      "time_this_iter_s: 6.577626466751099\n",
      "time_total_s: 766.7578563690186\n",
      "timers:\n",
      "  learn_throughput: 1326.702\n",
      "  learn_time_ms: 3014.995\n",
      "  load_throughput: 23967451.429\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 584.897\n",
      "  sample_time_ms: 6838.811\n",
      "  update_time_ms: 2.046\n",
      "timestamp: 1658394713\n",
      "timesteps_since_restore: 428000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 428000\n",
      "training_iteration: 107\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 432000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-00\n",
      "done: false\n",
      "episode_len_mean: 195.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.32\n",
      "episode_reward_min: 130.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2480\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.0913936854956008e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31100621819496155\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005949756596237421\n",
      "        model: {}\n",
      "        policy_loss: 0.004411206115037203\n",
      "        total_loss: 6.465145587921143\n",
      "        vf_explained_var: 0.04216517508029938\n",
      "        vf_loss: 6.460734844207764\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 432000\n",
      "  num_agent_steps_trained: 432000\n",
      "  num_steps_sampled: 432000\n",
      "  num_steps_trained: 432000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 108\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.49999999999999\n",
      "  ram_util_percent: 87.23999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06842795214856309\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07863585032275741\n",
      "  mean_inference_ms: 0.7471921514563773\n",
      "  mean_raw_obs_processing_ms: 0.09140269073883182\n",
      "time_since_restore: 773.5268843173981\n",
      "time_this_iter_s: 6.769027948379517\n",
      "time_total_s: 773.5268843173981\n",
      "timers:\n",
      "  learn_throughput: 1322.187\n",
      "  learn_time_ms: 3025.291\n",
      "  load_throughput: 23804222.474\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 584.754\n",
      "  sample_time_ms: 6840.485\n",
      "  update_time_ms: 2.047\n",
      "timestamp: 1658394720\n",
      "timesteps_since_restore: 432000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 432000\n",
      "training_iteration: 108\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 436000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-06\n",
      "done: false\n",
      "episode_len_mean: 194.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.36\n",
      "episode_reward_min: 130.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2501\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.0913936854956008e-12\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3103102147579193\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003063305513933301\n",
      "        model: {}\n",
      "        policy_loss: 0.0036285733804106712\n",
      "        total_loss: 5.441074371337891\n",
      "        vf_explained_var: 0.052743397653102875\n",
      "        vf_loss: 5.437446117401123\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 436000\n",
      "  num_agent_steps_trained: 436000\n",
      "  num_steps_sampled: 436000\n",
      "  num_steps_trained: 436000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 109\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.22222222222222\n",
      "  ram_util_percent: 87.25555555555556\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06838302298199161\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0785895883967666\n",
      "  mean_inference_ms: 0.7467186381606811\n",
      "  mean_raw_obs_processing_ms: 0.09133810201949245\n",
      "time_since_restore: 780.1196630001068\n",
      "time_this_iter_s: 6.59277868270874\n",
      "time_total_s: 780.1196630001068\n",
      "timers:\n",
      "  learn_throughput: 1320.999\n",
      "  learn_time_ms: 3028.012\n",
      "  load_throughput: 23659873.079\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 584.388\n",
      "  sample_time_ms: 6844.773\n",
      "  update_time_ms: 2.049\n",
      "timestamp: 1658394726\n",
      "timesteps_since_restore: 436000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 436000\n",
      "training_iteration: 109\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 440000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-13\n",
      "done: false\n",
      "episode_len_mean: 192.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.89\n",
      "episode_reward_min: 130.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2522\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.456968427478004e-13\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3575029969215393\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005277202930301428\n",
      "        model: {}\n",
      "        policy_loss: -3.060531889786944e-05\n",
      "        total_loss: 4.704087257385254\n",
      "        vf_explained_var: 0.12026792764663696\n",
      "        vf_loss: 4.704118251800537\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 440000\n",
      "  num_agent_steps_trained: 440000\n",
      "  num_steps_sampled: 440000\n",
      "  num_steps_trained: 440000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 110\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.690000000000005\n",
      "  ram_util_percent: 87.29999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06833284268151864\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07853614012972927\n",
      "  mean_inference_ms: 0.7461971671326049\n",
      "  mean_raw_obs_processing_ms: 0.09127199462129272\n",
      "time_since_restore: 786.8425269126892\n",
      "time_this_iter_s: 6.7228639125823975\n",
      "time_total_s: 786.8425269126892\n",
      "timers:\n",
      "  learn_throughput: 1318.264\n",
      "  learn_time_ms: 3034.293\n",
      "  load_throughput: 23804222.474\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 584.893\n",
      "  sample_time_ms: 6838.852\n",
      "  update_time_ms: 1.98\n",
      "timestamp: 1658394733\n",
      "timesteps_since_restore: 440000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 440000\n",
      "training_iteration: 110\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 444000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-19\n",
      "done: false\n",
      "episode_len_mean: 191.63\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.63\n",
      "episode_reward_min: 133.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2544\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.456968427478004e-13\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33495521545410156\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003267341759055853\n",
      "        model: {}\n",
      "        policy_loss: -0.013886925764381886\n",
      "        total_loss: 5.123562335968018\n",
      "        vf_explained_var: 0.06124012544751167\n",
      "        vf_loss: 5.137449264526367\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 444000\n",
      "  num_agent_steps_trained: 444000\n",
      "  num_steps_sampled: 444000\n",
      "  num_steps_trained: 444000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 111\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.47777777777778\n",
      "  ram_util_percent: 87.3\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0682750810409728\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07847453641693071\n",
      "  mean_inference_ms: 0.7456088938949874\n",
      "  mean_raw_obs_processing_ms: 0.0911995695698311\n",
      "time_since_restore: 793.4032809734344\n",
      "time_this_iter_s: 6.560754060745239\n",
      "time_total_s: 793.4032809734344\n",
      "timers:\n",
      "  learn_throughput: 1327.949\n",
      "  learn_time_ms: 3012.164\n",
      "  load_throughput: 24056805.277\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 587.559\n",
      "  sample_time_ms: 6807.829\n",
      "  update_time_ms: 2.092\n",
      "timestamp: 1658394739\n",
      "timesteps_since_restore: 444000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 444000\n",
      "training_iteration: 111\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 448000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-26\n",
      "done: false\n",
      "episode_len_mean: 189.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.61\n",
      "episode_reward_min: 114.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2565\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.728484213739002e-13\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30918100476264954\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004664041567593813\n",
      "        model: {}\n",
      "        policy_loss: -0.0008466312428936362\n",
      "        total_loss: 5.124330997467041\n",
      "        vf_explained_var: 0.15787070989608765\n",
      "        vf_loss: 5.125176906585693\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 448000\n",
      "  num_agent_steps_trained: 448000\n",
      "  num_steps_sampled: 448000\n",
      "  num_steps_trained: 448000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 112\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.19\n",
      "  ram_util_percent: 87.26\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06822083980583966\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07841654049817778\n",
      "  mean_inference_ms: 0.7450665474618237\n",
      "  mean_raw_obs_processing_ms: 0.09113002247568164\n",
      "time_since_restore: 800.3403782844543\n",
      "time_this_iter_s: 6.9370973110198975\n",
      "time_total_s: 800.3403782844543\n",
      "timers:\n",
      "  learn_throughput: 1324.902\n",
      "  learn_time_ms: 3019.091\n",
      "  load_throughput: 24188604.383\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 590.091\n",
      "  sample_time_ms: 6778.616\n",
      "  update_time_ms: 2.162\n",
      "timestamp: 1658394746\n",
      "timesteps_since_restore: 448000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 448000\n",
      "training_iteration: 112\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 452000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-34\n",
      "done: false\n",
      "episode_len_mean: 189.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.2\n",
      "episode_reward_min: 114.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2586\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.364242106869501e-13\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31968221068382263\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004091902170330286\n",
      "        model: {}\n",
      "        policy_loss: -0.00874941423535347\n",
      "        total_loss: 4.613948345184326\n",
      "        vf_explained_var: 0.10495658218860626\n",
      "        vf_loss: 4.6226983070373535\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 452000\n",
      "  num_agent_steps_trained: 452000\n",
      "  num_steps_sampled: 452000\n",
      "  num_steps_trained: 452000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 113\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.5\n",
      "  ram_util_percent: 87.33000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06817123452740428\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07836266303736596\n",
      "  mean_inference_ms: 0.7445714041125581\n",
      "  mean_raw_obs_processing_ms: 0.09106640846422731\n",
      "time_since_restore: 807.4093086719513\n",
      "time_this_iter_s: 7.068930387496948\n",
      "time_total_s: 807.4093086719513\n",
      "timers:\n",
      "  learn_throughput: 1315.696\n",
      "  learn_time_ms: 3040.216\n",
      "  load_throughput: 24105195.402\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 591.495\n",
      "  sample_time_ms: 6762.53\n",
      "  update_time_ms: 2.132\n",
      "timestamp: 1658394754\n",
      "timesteps_since_restore: 452000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 452000\n",
      "training_iteration: 113\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 456000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-40\n",
      "done: false\n",
      "episode_len_mean: 190.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.8\n",
      "episode_reward_min: 114.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2606\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.821210534347505e-14\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3307349681854248\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006911308970302343\n",
      "        model: {}\n",
      "        policy_loss: 0.004309316631406546\n",
      "        total_loss: 7.148191452026367\n",
      "        vf_explained_var: 0.08447819948196411\n",
      "        vf_loss: 7.1438822746276855\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 456000\n",
      "  num_agent_steps_trained: 456000\n",
      "  num_steps_sampled: 456000\n",
      "  num_steps_trained: 456000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 114\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.760000000000005\n",
      "  ram_util_percent: 87.29999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06812888658469853\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07831535201668965\n",
      "  mean_inference_ms: 0.7441658780943198\n",
      "  mean_raw_obs_processing_ms: 0.09101131049530281\n",
      "time_since_restore: 814.2175395488739\n",
      "time_this_iter_s: 6.808230876922607\n",
      "time_total_s: 814.2175395488739\n",
      "timers:\n",
      "  learn_throughput: 1312.544\n",
      "  learn_time_ms: 3047.518\n",
      "  load_throughput: 23868567.364\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 589.091\n",
      "  sample_time_ms: 6790.117\n",
      "  update_time_ms: 2.133\n",
      "timestamp: 1658394760\n",
      "timesteps_since_restore: 456000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 456000\n",
      "training_iteration: 114\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 460000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-47\n",
      "done: false\n",
      "episode_len_mean: 191.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.55\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2626\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.821210534347505e-14\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3080664873123169\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027780993841588497\n",
      "        model: {}\n",
      "        policy_loss: 0.0015710018342360854\n",
      "        total_loss: 3.6582651138305664\n",
      "        vf_explained_var: 0.125667005777359\n",
      "        vf_loss: 3.656694173812866\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 460000\n",
      "  num_agent_steps_trained: 460000\n",
      "  num_steps_sampled: 460000\n",
      "  num_steps_trained: 460000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 115\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.480000000000004\n",
      "  ram_util_percent: 87.30999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06808774699586677\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07826934223294779\n",
      "  mean_inference_ms: 0.7437678088106314\n",
      "  mean_raw_obs_processing_ms: 0.09095795264175552\n",
      "time_since_restore: 820.7578091621399\n",
      "time_this_iter_s: 6.540269613265991\n",
      "time_total_s: 820.7578091621399\n",
      "timers:\n",
      "  learn_throughput: 1325.561\n",
      "  learn_time_ms: 3017.591\n",
      "  load_throughput: 24272592.593\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 589.496\n",
      "  sample_time_ms: 6785.455\n",
      "  update_time_ms: 2.163\n",
      "timestamp: 1658394767\n",
      "timesteps_since_restore: 460000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 460000\n",
      "training_iteration: 115\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 464000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-12-54\n",
      "done: false\n",
      "episode_len_mean: 194.24\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.24\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2647\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.4106052671737525e-14\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25904807448387146\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003368957433849573\n",
      "        model: {}\n",
      "        policy_loss: -0.0027429149486124516\n",
      "        total_loss: 4.581113815307617\n",
      "        vf_explained_var: 0.03351990506052971\n",
      "        vf_loss: 4.583856582641602\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 464000\n",
      "  num_agent_steps_trained: 464000\n",
      "  num_steps_sampled: 464000\n",
      "  num_steps_trained: 464000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 116\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.0\n",
      "  ram_util_percent: 87.35555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06804684984253356\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07822306776372127\n",
      "  mean_inference_ms: 0.7433701969063877\n",
      "  mean_raw_obs_processing_ms: 0.09090392874035733\n",
      "time_since_restore: 827.3192355632782\n",
      "time_this_iter_s: 6.561426401138306\n",
      "time_total_s: 827.3192355632782\n",
      "timers:\n",
      "  learn_throughput: 1331.106\n",
      "  learn_time_ms: 3005.02\n",
      "  load_throughput: 24251540.908\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 593.002\n",
      "  sample_time_ms: 6745.344\n",
      "  update_time_ms: 2.176\n",
      "timestamp: 1658394774\n",
      "timesteps_since_restore: 464000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 464000\n",
      "training_iteration: 116\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 468000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-01\n",
      "done: false\n",
      "episode_len_mean: 196.58\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.58\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2667\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.7053026335868762e-14\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2539840340614319\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0021307889837771654\n",
      "        model: {}\n",
      "        policy_loss: 0.005788376554846764\n",
      "        total_loss: 8.762618064880371\n",
      "        vf_explained_var: 0.021535102277994156\n",
      "        vf_loss: 8.756829261779785\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 468000\n",
      "  num_agent_steps_trained: 468000\n",
      "  num_steps_sampled: 468000\n",
      "  num_steps_trained: 468000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 117\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.879999999999995\n",
      "  ram_util_percent: 87.37\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06801175847743825\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07818295838309147\n",
      "  mean_inference_ms: 0.743025458474166\n",
      "  mean_raw_obs_processing_ms: 0.09085765954246089\n",
      "time_since_restore: 834.6611680984497\n",
      "time_this_iter_s: 7.341932535171509\n",
      "time_total_s: 834.6611680984497\n",
      "timers:\n",
      "  learn_throughput: 1304.432\n",
      "  learn_time_ms: 3066.47\n",
      "  load_throughput: 24546036.576\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 592.792\n",
      "  sample_time_ms: 6747.73\n",
      "  update_time_ms: 2.182\n",
      "timestamp: 1658394781\n",
      "timesteps_since_restore: 468000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 468000\n",
      "training_iteration: 117\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 472000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-07\n",
      "done: false\n",
      "episode_len_mean: 197.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.89\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2687\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.526513167934381e-15\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2634904980659485\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032258701976388693\n",
      "        model: {}\n",
      "        policy_loss: 0.0045652142725884914\n",
      "        total_loss: 8.762873649597168\n",
      "        vf_explained_var: 0.023524746298789978\n",
      "        vf_loss: 8.758308410644531\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 472000\n",
      "  num_agent_steps_trained: 472000\n",
      "  num_steps_sampled: 472000\n",
      "  num_steps_trained: 472000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 118\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.488888888888894\n",
      "  ram_util_percent: 87.35555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06796014237153339\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07812426983388039\n",
      "  mean_inference_ms: 0.7425085925774694\n",
      "  mean_raw_obs_processing_ms: 0.0907920341311015\n",
      "time_since_restore: 840.9742798805237\n",
      "time_this_iter_s: 6.313111782073975\n",
      "time_total_s: 840.9742798805237\n",
      "timers:\n",
      "  learn_throughput: 1302.329\n",
      "  learn_time_ms: 3071.42\n",
      "  load_throughput: 24571200.937\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 591.812\n",
      "  sample_time_ms: 6758.903\n",
      "  update_time_ms: 2.205\n",
      "timestamp: 1658394787\n",
      "timesteps_since_restore: 472000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 472000\n",
      "training_iteration: 118\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 476000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-14\n",
      "done: false\n",
      "episode_len_mean: 198.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.51\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2707\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.2632565839671906e-15\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.273314505815506\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004576602950692177\n",
      "        model: {}\n",
      "        policy_loss: 0.004731313791126013\n",
      "        total_loss: 8.761918067932129\n",
      "        vf_explained_var: 0.03556189313530922\n",
      "        vf_loss: 8.757186889648438\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 476000\n",
      "  num_agent_steps_trained: 476000\n",
      "  num_steps_sampled: 476000\n",
      "  num_steps_trained: 476000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 119\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.75\n",
      "  ram_util_percent: 87.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06790560686179446\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07806314431040874\n",
      "  mean_inference_ms: 0.7419436029446551\n",
      "  mean_raw_obs_processing_ms: 0.09072132705888887\n",
      "time_since_restore: 847.6406300067902\n",
      "time_this_iter_s: 6.6663501262664795\n",
      "time_total_s: 847.6406300067902\n",
      "timers:\n",
      "  learn_throughput: 1298.938\n",
      "  learn_time_ms: 3079.438\n",
      "  load_throughput: 24723277.336\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 591.449\n",
      "  sample_time_ms: 6763.048\n",
      "  update_time_ms: 2.203\n",
      "timestamp: 1658394794\n",
      "timesteps_since_restore: 476000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 476000\n",
      "training_iteration: 119\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 480000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-21\n",
      "done: false\n",
      "episode_len_mean: 198.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.92\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2727\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.1316282919835953e-15\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2542451024055481\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004327434115111828\n",
      "        model: {}\n",
      "        policy_loss: 0.005819971673190594\n",
      "        total_loss: 7.4395623207092285\n",
      "        vf_explained_var: 0.02700778655707836\n",
      "        vf_loss: 7.433742523193359\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 480000\n",
      "  num_agent_steps_trained: 480000\n",
      "  num_steps_sampled: 480000\n",
      "  num_steps_trained: 480000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 120\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.620000000000005\n",
      "  ram_util_percent: 87.38999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0678519376992624\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07800330179448829\n",
      "  mean_inference_ms: 0.7413855139503157\n",
      "  mean_raw_obs_processing_ms: 0.09065101293717254\n",
      "time_since_restore: 854.3848786354065\n",
      "time_this_iter_s: 6.744248628616333\n",
      "time_total_s: 854.3848786354065\n",
      "timers:\n",
      "  learn_throughput: 1299.041\n",
      "  learn_time_ms: 3079.196\n",
      "  load_throughput: 24098270.612\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 590.472\n",
      "  sample_time_ms: 6774.245\n",
      "  update_time_ms: 2.211\n",
      "timestamp: 1658394801\n",
      "timesteps_since_restore: 480000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 480000\n",
      "training_iteration: 120\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 484000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-27\n",
      "done: false\n",
      "episode_len_mean: 199.23\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.23\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2747\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.0658141459917976e-15\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22347582876682281\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003548764158040285\n",
      "        model: {}\n",
      "        policy_loss: 0.005238891113549471\n",
      "        total_loss: 4.918460369110107\n",
      "        vf_explained_var: 0.01705067791044712\n",
      "        vf_loss: 4.91322135925293\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 484000\n",
      "  num_agent_steps_trained: 484000\n",
      "  num_steps_sampled: 484000\n",
      "  num_steps_trained: 484000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 121\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.677777777777774\n",
      "  ram_util_percent: 87.25555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06779787768504089\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07794320212848337\n",
      "  mean_inference_ms: 0.7408242044322464\n",
      "  mean_raw_obs_processing_ms: 0.090580652946126\n",
      "time_since_restore: 860.9095275402069\n",
      "time_this_iter_s: 6.524648904800415\n",
      "time_total_s: 860.9095275402069\n",
      "timers:\n",
      "  learn_throughput: 1302.64\n",
      "  learn_time_ms: 3070.687\n",
      "  load_throughput: 24244531.792\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 590.043\n",
      "  sample_time_ms: 6779.168\n",
      "  update_time_ms: 2.105\n",
      "timestamp: 1658394807\n",
      "timesteps_since_restore: 484000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 484000\n",
      "training_iteration: 121\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 488000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-34\n",
      "done: false\n",
      "episode_len_mean: 198.58\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.58\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2767\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.329070729958988e-16\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25177615880966187\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003231605514883995\n",
      "        model: {}\n",
      "        policy_loss: 0.002462007338181138\n",
      "        total_loss: 3.6516060829162598\n",
      "        vf_explained_var: 0.09360704571008682\n",
      "        vf_loss: 3.649144172668457\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 488000\n",
      "  num_agent_steps_trained: 488000\n",
      "  num_steps_sampled: 488000\n",
      "  num_steps_trained: 488000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 122\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 30.466666666666665\n",
      "  ram_util_percent: 87.27777777777777\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06773586391442717\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07787576390290726\n",
      "  mean_inference_ms: 0.74018906714819\n",
      "  mean_raw_obs_processing_ms: 0.09050111639593514\n",
      "time_since_restore: 867.4353837966919\n",
      "time_this_iter_s: 6.525856256484985\n",
      "time_total_s: 867.4353837966919\n",
      "timers:\n",
      "  learn_throughput: 1313.758\n",
      "  learn_time_ms: 3044.702\n",
      "  load_throughput: 24230525.708\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 592.156\n",
      "  sample_time_ms: 6754.977\n",
      "  update_time_ms: 2.076\n",
      "timestamp: 1658394814\n",
      "timesteps_since_restore: 488000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 488000\n",
      "training_iteration: 122\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 492000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-41\n",
      "done: false\n",
      "episode_len_mean: 198.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.36\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2787\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.664535364979494e-16\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29040732979774475\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008428344503045082\n",
      "        model: {}\n",
      "        policy_loss: -0.007479671388864517\n",
      "        total_loss: 0.7962725162506104\n",
      "        vf_explained_var: 0.10072936862707138\n",
      "        vf_loss: 0.8037521243095398\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 492000\n",
      "  num_agent_steps_trained: 492000\n",
      "  num_steps_sampled: 492000\n",
      "  num_steps_trained: 492000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 123\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.160000000000004\n",
      "  ram_util_percent: 87.26\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06768437348811882\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07781997891917529\n",
      "  mean_inference_ms: 0.7396588010841879\n",
      "  mean_raw_obs_processing_ms: 0.0904331836713753\n",
      "time_since_restore: 874.3401439189911\n",
      "time_this_iter_s: 6.904760122299194\n",
      "time_total_s: 874.3401439189911\n",
      "timers:\n",
      "  learn_throughput: 1309.932\n",
      "  learn_time_ms: 3053.594\n",
      "  load_throughput: 23998306.394\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 596.702\n",
      "  sample_time_ms: 6703.516\n",
      "  update_time_ms: 2.103\n",
      "timestamp: 1658394821\n",
      "timesteps_since_restore: 492000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 492000\n",
      "training_iteration: 123\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 496000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-47\n",
      "done: false\n",
      "episode_len_mean: 195.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.59\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2809\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.664535364979494e-16\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2749928832054138\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003953966777771711\n",
      "        model: {}\n",
      "        policy_loss: 0.0064849769696593285\n",
      "        total_loss: 6.944470405578613\n",
      "        vf_explained_var: 0.018425898626446724\n",
      "        vf_loss: 6.937984943389893\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 496000\n",
      "  num_agent_steps_trained: 496000\n",
      "  num_steps_sampled: 496000\n",
      "  num_steps_trained: 496000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 124\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.38\n",
      "  ram_util_percent: 87.41999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0676319692368023\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07776324024532981\n",
      "  mean_inference_ms: 0.7391277636243495\n",
      "  mean_raw_obs_processing_ms: 0.09036621252456563\n",
      "time_since_restore: 881.0189180374146\n",
      "time_this_iter_s: 6.678774118423462\n",
      "time_total_s: 881.0189180374146\n",
      "timers:\n",
      "  learn_throughput: 1312.193\n",
      "  learn_time_ms: 3048.332\n",
      "  load_throughput: 24223528.732\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 596.539\n",
      "  sample_time_ms: 6705.345\n",
      "  update_time_ms: 2.121\n",
      "timestamp: 1658394827\n",
      "timesteps_since_restore: 496000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 496000\n",
      "training_iteration: 124\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 500000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-13-54\n",
      "done: false\n",
      "episode_len_mean: 192.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.01\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 2831\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.332267682489747e-16\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2550801634788513\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033562795724719763\n",
      "        model: {}\n",
      "        policy_loss: 0.004904475063085556\n",
      "        total_loss: 6.116948127746582\n",
      "        vf_explained_var: 0.01773747242987156\n",
      "        vf_loss: 6.112043857574463\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 500000\n",
      "  num_agent_steps_trained: 500000\n",
      "  num_steps_sampled: 500000\n",
      "  num_steps_trained: 500000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 125\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.233333333333334\n",
      "  ram_util_percent: 87.28888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06758272255916385\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0777096840792722\n",
      "  mean_inference_ms: 0.7386404167856198\n",
      "  mean_raw_obs_processing_ms: 0.09030494262835884\n",
      "time_since_restore: 887.6128950119019\n",
      "time_this_iter_s: 6.593976974487305\n",
      "time_total_s: 887.6128950119019\n",
      "timers:\n",
      "  learn_throughput: 1313.255\n",
      "  learn_time_ms: 3045.868\n",
      "  load_throughput: 23609929.637\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 596.316\n",
      "  sample_time_ms: 6707.849\n",
      "  update_time_ms: 2.132\n",
      "timestamp: 1658394834\n",
      "timesteps_since_restore: 500000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 500000\n",
      "training_iteration: 125\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 504000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-00\n",
      "done: false\n",
      "episode_len_mean: 190.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.59\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2852\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.661338412448735e-17\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26953256130218506\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005691003054380417\n",
      "        model: {}\n",
      "        policy_loss: 0.0021104500629007816\n",
      "        total_loss: 5.412407398223877\n",
      "        vf_explained_var: -0.0165767390280962\n",
      "        vf_loss: 5.41029691696167\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 504000\n",
      "  num_agent_steps_trained: 504000\n",
      "  num_steps_sampled: 504000\n",
      "  num_steps_trained: 504000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 126\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.077777777777783\n",
      "  ram_util_percent: 87.23333333333332\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06753513303408218\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07765851532920784\n",
      "  mean_inference_ms: 0.7381675355523828\n",
      "  mean_raw_obs_processing_ms: 0.09024579861243233\n",
      "time_since_restore: 894.0217440128326\n",
      "time_this_iter_s: 6.408849000930786\n",
      "time_total_s: 894.0217440128326\n",
      "timers:\n",
      "  learn_throughput: 1315.241\n",
      "  learn_time_ms: 3041.268\n",
      "  load_throughput: 23613252.639\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 597.429\n",
      "  sample_time_ms: 6695.355\n",
      "  update_time_ms: 2.092\n",
      "timestamp: 1658394840\n",
      "timesteps_since_restore: 504000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 504000\n",
      "training_iteration: 126\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 508000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-07\n",
      "done: false\n",
      "episode_len_mean: 189.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.85\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2873\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.661338412448735e-17\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29075494408607483\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0049147470854222775\n",
      "        model: {}\n",
      "        policy_loss: -0.014077150262892246\n",
      "        total_loss: 5.711515426635742\n",
      "        vf_explained_var: 0.01794467307627201\n",
      "        vf_loss: 5.725592613220215\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 508000\n",
      "  num_agent_steps_trained: 508000\n",
      "  num_steps_sampled: 508000\n",
      "  num_steps_trained: 508000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 127\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.53\n",
      "  ram_util_percent: 87.25999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06748849122281268\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0776070042269171\n",
      "  mean_inference_ms: 0.7376950953643469\n",
      "  mean_raw_obs_processing_ms: 0.09018870077609556\n",
      "time_since_restore: 900.6285543441772\n",
      "time_this_iter_s: 6.6068103313446045\n",
      "time_total_s: 900.6285543441772\n",
      "timers:\n",
      "  learn_throughput: 1334.235\n",
      "  learn_time_ms: 2997.973\n",
      "  load_throughput: 23266143.392\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 600.548\n",
      "  sample_time_ms: 6660.582\n",
      "  update_time_ms: 2.059\n",
      "timestamp: 1658394847\n",
      "timesteps_since_restore: 508000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 508000\n",
      "training_iteration: 127\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 512000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-14\n",
      "done: false\n",
      "episode_len_mean: 190.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.39\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2893\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.3306692062243676e-17\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3083677291870117\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008161510340869427\n",
      "        model: {}\n",
      "        policy_loss: -0.016911705955863\n",
      "        total_loss: 9.743692398071289\n",
      "        vf_explained_var: 0.023941200226545334\n",
      "        vf_loss: 9.760603904724121\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 512000\n",
      "  num_agent_steps_trained: 512000\n",
      "  num_steps_sampled: 512000\n",
      "  num_steps_trained: 512000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 128\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.26666666666667\n",
      "  ram_util_percent: 87.26666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06744907499727439\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07756331207900918\n",
      "  mean_inference_ms: 0.7372941636995776\n",
      "  mean_raw_obs_processing_ms: 0.09014045650001673\n",
      "time_since_restore: 907.3271429538727\n",
      "time_this_iter_s: 6.698588609695435\n",
      "time_total_s: 907.3271429538727\n",
      "timers:\n",
      "  learn_throughput: 1338.026\n",
      "  learn_time_ms: 2989.479\n",
      "  load_throughput: 23237141.274\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 600.314\n",
      "  sample_time_ms: 6663.18\n",
      "  update_time_ms: 2.133\n",
      "timestamp: 1658394854\n",
      "timesteps_since_restore: 512000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 512000\n",
      "training_iteration: 128\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 516000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-21\n",
      "done: false\n",
      "episode_len_mean: 192.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.65\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2913\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.3306692062243676e-17\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2804490327835083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004184367135167122\n",
      "        model: {}\n",
      "        policy_loss: 0.00618278281763196\n",
      "        total_loss: 6.719325542449951\n",
      "        vf_explained_var: 0.02708621695637703\n",
      "        vf_loss: 6.7131428718566895\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 516000\n",
      "  num_agent_steps_trained: 516000\n",
      "  num_steps_sampled: 516000\n",
      "  num_steps_trained: 516000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 129\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.910000000000004\n",
      "  ram_util_percent: 87.35999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06740569626466555\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07751567952346192\n",
      "  mean_inference_ms: 0.7368548930465585\n",
      "  mean_raw_obs_processing_ms: 0.09008779346915965\n",
      "time_since_restore: 914.0851156711578\n",
      "time_this_iter_s: 6.757972717285156\n",
      "time_total_s: 914.0851156711578\n",
      "timers:\n",
      "  learn_throughput: 1332.271\n",
      "  learn_time_ms: 3002.392\n",
      "  load_throughput: 22982487.671\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 601.376\n",
      "  sample_time_ms: 6651.41\n",
      "  update_time_ms: 2.091\n",
      "timestamp: 1658394861\n",
      "timesteps_since_restore: 516000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 516000\n",
      "training_iteration: 129\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 520000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-27\n",
      "done: false\n",
      "episode_len_mean: 194.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.49\n",
      "episode_reward_min: 133.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 2934\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.6653346031121838e-17\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26472654938697815\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033921999856829643\n",
      "        model: {}\n",
      "        policy_loss: 0.005680134054273367\n",
      "        total_loss: 6.574686050415039\n",
      "        vf_explained_var: 0.015524103306233883\n",
      "        vf_loss: 6.569006443023682\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 520000\n",
      "  num_agent_steps_trained: 520000\n",
      "  num_steps_sampled: 520000\n",
      "  num_steps_trained: 520000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 130\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.166666666666664\n",
      "  ram_util_percent: 87.1888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06735279019930168\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0774572157207872\n",
      "  mean_inference_ms: 0.7363108256610118\n",
      "  mean_raw_obs_processing_ms: 0.09002304625344566\n",
      "time_since_restore: 920.3042697906494\n",
      "time_this_iter_s: 6.219154119491577\n",
      "time_total_s: 920.3042697906494\n",
      "timers:\n",
      "  learn_throughput: 1346.307\n",
      "  learn_time_ms: 2971.091\n",
      "  load_throughput: 23543665.45\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 602.278\n",
      "  sample_time_ms: 6641.456\n",
      "  update_time_ms: 2.056\n",
      "timestamp: 1658394867\n",
      "timesteps_since_restore: 520000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 520000\n",
      "training_iteration: 130\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 524000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-33\n",
      "done: false\n",
      "episode_len_mean: 195.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.09\n",
      "episode_reward_min: 132.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 2954\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.326673015560919e-18\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29157406091690063\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006229148246347904\n",
      "        model: {}\n",
      "        policy_loss: 0.003542937571182847\n",
      "        total_loss: 5.3582000732421875\n",
      "        vf_explained_var: 0.02086181566119194\n",
      "        vf_loss: 5.354657173156738\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 524000\n",
      "  num_agent_steps_trained: 524000\n",
      "  num_steps_sampled: 524000\n",
      "  num_steps_trained: 524000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 131\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.77777777777778\n",
      "  ram_util_percent: 87.37777777777778\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06730741281077254\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0774060534088006\n",
      "  mean_inference_ms: 0.7358412417345425\n",
      "  mean_raw_obs_processing_ms: 0.08996628046559976\n",
      "time_since_restore: 926.888519525528\n",
      "time_this_iter_s: 6.58424973487854\n",
      "time_total_s: 926.888519525528\n",
      "timers:\n",
      "  learn_throughput: 1346.695\n",
      "  learn_time_ms: 2970.235\n",
      "  load_throughput: 23520560.774\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 604.512\n",
      "  sample_time_ms: 6616.906\n",
      "  update_time_ms: 2.053\n",
      "timestamp: 1658394873\n",
      "timesteps_since_restore: 524000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 524000\n",
      "training_iteration: 131\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 528000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-40\n",
      "done: false\n",
      "episode_len_mean: 191.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.35\n",
      "episode_reward_min: 116.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 2977\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.326673015560919e-18\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2636878192424774\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036242834758013487\n",
      "        model: {}\n",
      "        policy_loss: 0.002922814805060625\n",
      "        total_loss: 5.124866962432861\n",
      "        vf_explained_var: 0.04758458957076073\n",
      "        vf_loss: 5.121944427490234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 528000\n",
      "  num_agent_steps_trained: 528000\n",
      "  num_steps_sampled: 528000\n",
      "  num_steps_trained: 528000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 132\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.970000000000006\n",
      "  ram_util_percent: 87.32\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06725966279158622\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07735295220531845\n",
      "  mean_inference_ms: 0.735365432190383\n",
      "  mean_raw_obs_processing_ms: 0.08990601406214005\n",
      "time_since_restore: 933.4272134304047\n",
      "time_this_iter_s: 6.538693904876709\n",
      "time_total_s: 933.4272134304047\n",
      "timers:\n",
      "  learn_throughput: 1351.775\n",
      "  learn_time_ms: 2959.072\n",
      "  load_throughput: 23520560.774\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 603.41\n",
      "  sample_time_ms: 6628.988\n",
      "  update_time_ms: 1.983\n",
      "timestamp: 1658394880\n",
      "timesteps_since_restore: 528000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 528000\n",
      "training_iteration: 132\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 532000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-47\n",
      "done: false\n",
      "episode_len_mean: 184.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.59\n",
      "episode_reward_min: 71.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 3001\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.1633365077804595e-18\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2764753997325897\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004659087862819433\n",
      "        model: {}\n",
      "        policy_loss: -0.0028893721755594015\n",
      "        total_loss: 6.346035480499268\n",
      "        vf_explained_var: 0.014148227870464325\n",
      "        vf_loss: 6.34892463684082\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 532000\n",
      "  num_agent_steps_trained: 532000\n",
      "  num_steps_sampled: 532000\n",
      "  num_steps_trained: 532000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 133\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.839999999999996\n",
      "  ram_util_percent: 87.31999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06720470504332311\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07729130648523869\n",
      "  mean_inference_ms: 0.7348141624704053\n",
      "  mean_raw_obs_processing_ms: 0.08983792896345193\n",
      "time_since_restore: 940.2831881046295\n",
      "time_this_iter_s: 6.8559746742248535\n",
      "time_total_s: 940.2831881046295\n",
      "timers:\n",
      "  learn_throughput: 1349.508\n",
      "  learn_time_ms: 2964.042\n",
      "  load_throughput: 23780603.827\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 605.383\n",
      "  sample_time_ms: 6607.388\n",
      "  update_time_ms: 2.08\n",
      "timestamp: 1658394887\n",
      "timesteps_since_restore: 532000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 532000\n",
      "training_iteration: 133\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 536000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-14-53\n",
      "done: false\n",
      "episode_len_mean: 183.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 183.66\n",
      "episode_reward_min: 71.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3022\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.0816682538902298e-18\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27839013934135437\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004401249811053276\n",
      "        model: {}\n",
      "        policy_loss: 0.005020760465413332\n",
      "        total_loss: 7.004086971282959\n",
      "        vf_explained_var: 0.011849338188767433\n",
      "        vf_loss: 6.999066352844238\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 536000\n",
      "  num_agent_steps_trained: 536000\n",
      "  num_steps_sampled: 536000\n",
      "  num_steps_trained: 536000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 134\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 30.799999999999997\n",
      "  ram_util_percent: 87.3375\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06715298651599547\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07723185132376409\n",
      "  mean_inference_ms: 0.7342889152947878\n",
      "  mean_raw_obs_processing_ms: 0.08977321528908426\n",
      "time_since_restore: 946.4167726039886\n",
      "time_this_iter_s: 6.133584499359131\n",
      "time_total_s: 946.4167726039886\n",
      "timers:\n",
      "  learn_throughput: 1355.72\n",
      "  learn_time_ms: 2950.462\n",
      "  load_throughput: 23713379.505\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 608.691\n",
      "  sample_time_ms: 6571.484\n",
      "  update_time_ms: 2.074\n",
      "timestamp: 1658394893\n",
      "timesteps_since_restore: 536000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 536000\n",
      "training_iteration: 134\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 540000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-00\n",
      "done: false\n",
      "episode_len_mean: 182.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 182.94\n",
      "episode_reward_min: 71.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3042\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.0408341269451149e-18\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27761486172676086\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005210835486650467\n",
      "        model: {}\n",
      "        policy_loss: 0.0023736993316560984\n",
      "        total_loss: 4.043058395385742\n",
      "        vf_explained_var: 0.022816412150859833\n",
      "        vf_loss: 4.040684700012207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 540000\n",
      "  num_agent_steps_trained: 540000\n",
      "  num_steps_sampled: 540000\n",
      "  num_steps_trained: 540000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 135\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.769999999999996\n",
      "  ram_util_percent: 87.29999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06710580169864169\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07717800742528651\n",
      "  mean_inference_ms: 0.7338110409065643\n",
      "  mean_raw_obs_processing_ms: 0.08971448197860386\n",
      "time_since_restore: 952.9772508144379\n",
      "time_this_iter_s: 6.560478210449219\n",
      "time_total_s: 952.9772508144379\n",
      "timers:\n",
      "  learn_throughput: 1353.33\n",
      "  learn_time_ms: 2955.673\n",
      "  load_throughput: 24276104.761\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 610.738\n",
      "  sample_time_ms: 6549.448\n",
      "  update_time_ms: 2.05\n",
      "timestamp: 1658394900\n",
      "timesteps_since_restore: 540000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 540000\n",
      "training_iteration: 135\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 544000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-06\n",
      "done: false\n",
      "episode_len_mean: 183.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 183.86\n",
      "episode_reward_min: 71.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 3064\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.0408341269451149e-18\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2992627024650574\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004576737992465496\n",
      "        model: {}\n",
      "        policy_loss: 0.0032746486831456423\n",
      "        total_loss: 5.152082920074463\n",
      "        vf_explained_var: 0.03336730971932411\n",
      "        vf_loss: 5.148808002471924\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 544000\n",
      "  num_agent_steps_trained: 544000\n",
      "  num_steps_sampled: 544000\n",
      "  num_steps_trained: 544000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 136\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.577777777777776\n",
      "  ram_util_percent: 87.32222222222221\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06705297077742037\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07711783743240204\n",
      "  mean_inference_ms: 0.7332683353933531\n",
      "  mean_raw_obs_processing_ms: 0.08964876004304148\n",
      "time_since_restore: 959.4322040081024\n",
      "time_this_iter_s: 6.454953193664551\n",
      "time_total_s: 959.4322040081024\n",
      "timers:\n",
      "  learn_throughput: 1353.946\n",
      "  learn_time_ms: 2954.327\n",
      "  load_throughput: 24300718.424\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 609.753\n",
      "  sample_time_ms: 6560.029\n",
      "  update_time_ms: 2.03\n",
      "timestamp: 1658394906\n",
      "timesteps_since_restore: 544000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 544000\n",
      "training_iteration: 136\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 548000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-12\n",
      "done: false\n",
      "episode_len_mean: 185.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.52\n",
      "episode_reward_min: 107.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 3086\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.204170634725574e-19\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28657299280166626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00419293949380517\n",
      "        model: {}\n",
      "        policy_loss: 0.0045741223730146885\n",
      "        total_loss: 6.952308177947998\n",
      "        vf_explained_var: 0.002244005212560296\n",
      "        vf_loss: 6.9477338790893555\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 548000\n",
      "  num_agent_steps_trained: 548000\n",
      "  num_steps_sampled: 548000\n",
      "  num_steps_trained: 548000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 137\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 30.555555555555557\n",
      "  ram_util_percent: 87.3\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06699926220552982\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07705762021545523\n",
      "  mean_inference_ms: 0.7327127555776332\n",
      "  mean_raw_obs_processing_ms: 0.08958238619857116\n",
      "time_since_restore: 965.827183008194\n",
      "time_this_iter_s: 6.394979000091553\n",
      "time_total_s: 965.827183008194\n",
      "timers:\n",
      "  learn_throughput: 1364.612\n",
      "  learn_time_ms: 2931.236\n",
      "  load_throughput: 24676005.295\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 609.685\n",
      "  sample_time_ms: 6560.763\n",
      "  update_time_ms: 1.98\n",
      "timestamp: 1658394912\n",
      "timesteps_since_restore: 548000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 548000\n",
      "training_iteration: 137\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 552000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-19\n",
      "done: false\n",
      "episode_len_mean: 190.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.08\n",
      "episode_reward_min: 107.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3106\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.602085317362787e-19\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27867555618286133\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002784447278827429\n",
      "        model: {}\n",
      "        policy_loss: 0.007706305477768183\n",
      "        total_loss: 7.757632255554199\n",
      "        vf_explained_var: 0.005506639368832111\n",
      "        vf_loss: 7.74992561340332\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 552000\n",
      "  num_agent_steps_trained: 552000\n",
      "  num_steps_sampled: 552000\n",
      "  num_steps_trained: 552000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 138\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.72222222222222\n",
      "  ram_util_percent: 87.36666666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06695209136084034\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0770045970173729\n",
      "  mean_inference_ms: 0.7322269016087009\n",
      "  mean_raw_obs_processing_ms: 0.0895234912109996\n",
      "time_since_restore: 972.259171962738\n",
      "time_this_iter_s: 6.431988954544067\n",
      "time_total_s: 972.259171962738\n",
      "timers:\n",
      "  learn_throughput: 1366.878\n",
      "  learn_time_ms: 2926.378\n",
      "  load_throughput: 24607239.66\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 613.858\n",
      "  sample_time_ms: 6516.162\n",
      "  update_time_ms: 1.875\n",
      "timestamp: 1658394919\n",
      "timesteps_since_restore: 552000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 552000\n",
      "training_iteration: 138\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 556000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-25\n",
      "done: false\n",
      "episode_len_mean: 191.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.52\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3126\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.3010426586813936e-19\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2770431935787201\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037445875350385904\n",
      "        model: {}\n",
      "        policy_loss: 0.003985939081758261\n",
      "        total_loss: 4.983809471130371\n",
      "        vf_explained_var: 0.024393048137426376\n",
      "        vf_loss: 4.979823589324951\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 556000\n",
      "  num_agent_steps_trained: 556000\n",
      "  num_steps_sampled: 556000\n",
      "  num_steps_trained: 556000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 139\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 30.95555555555556\n",
      "  ram_util_percent: 87.33333333333331\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06690890489089792\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07695698651340525\n",
      "  mean_inference_ms: 0.7317836354814824\n",
      "  mean_raw_obs_processing_ms: 0.08946940781315466\n",
      "time_since_restore: 978.544016122818\n",
      "time_this_iter_s: 6.284844160079956\n",
      "time_total_s: 978.544016122818\n",
      "timers:\n",
      "  learn_throughput: 1386.76\n",
      "  learn_time_ms: 2884.422\n",
      "  load_throughput: 24712352.335\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 614.878\n",
      "  sample_time_ms: 6505.356\n",
      "  update_time_ms: 2.053\n",
      "timestamp: 1658394925\n",
      "timesteps_since_restore: 556000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 556000\n",
      "training_iteration: 139\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 560000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-32\n",
      "done: false\n",
      "episode_len_mean: 192.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.36\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3146\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.505213293406968e-20\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23295724391937256\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0020039076916873455\n",
      "        model: {}\n",
      "        policy_loss: 0.002360882004722953\n",
      "        total_loss: 2.4203062057495117\n",
      "        vf_explained_var: 0.08434179425239563\n",
      "        vf_loss: 2.417945623397827\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 560000\n",
      "  num_agent_steps_trained: 560000\n",
      "  num_steps_sampled: 560000\n",
      "  num_steps_trained: 560000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 140\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.959999999999994\n",
      "  ram_util_percent: 87.38\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06686797932707293\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0769118261539393\n",
      "  mean_inference_ms: 0.7313690188015426\n",
      "  mean_raw_obs_processing_ms: 0.08941786526611634\n",
      "time_since_restore: 985.2200212478638\n",
      "time_this_iter_s: 6.676005125045776\n",
      "time_total_s: 985.2200212478638\n",
      "timers:\n",
      "  learn_throughput: 1379.0\n",
      "  learn_time_ms: 2900.653\n",
      "  load_throughput: 24353630.425\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 615.941\n",
      "  sample_time_ms: 6494.126\n",
      "  update_time_ms: 2.103\n",
      "timestamp: 1658394932\n",
      "timesteps_since_restore: 560000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 560000\n",
      "training_iteration: 140\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 564000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-39\n",
      "done: false\n",
      "episode_len_mean: 196.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.11\n",
      "episode_reward_min: 125.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3166\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.252606646703484e-20\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21362420916557312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0016018617898225784\n",
      "        model: {}\n",
      "        policy_loss: 0.0024979235604405403\n",
      "        total_loss: 2.32155442237854\n",
      "        vf_explained_var: -0.016619553789496422\n",
      "        vf_loss: 2.319056510925293\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 564000\n",
      "  num_agent_steps_trained: 564000\n",
      "  num_steps_sampled: 564000\n",
      "  num_steps_trained: 564000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 141\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.85555555555556\n",
      "  ram_util_percent: 87.28888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0668253989884072\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07686463792900361\n",
      "  mean_inference_ms: 0.7309395680167359\n",
      "  mean_raw_obs_processing_ms: 0.08936452042944222\n",
      "time_since_restore: 991.89928150177\n",
      "time_this_iter_s: 6.67926025390625\n",
      "time_total_s: 991.89928150177\n",
      "timers:\n",
      "  learn_throughput: 1367.642\n",
      "  learn_time_ms: 2924.742\n",
      "  load_throughput: 24279617.945\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 615.795\n",
      "  sample_time_ms: 6495.664\n",
      "  update_time_ms: 2.19\n",
      "timestamp: 1658394939\n",
      "timesteps_since_restore: 564000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 564000\n",
      "training_iteration: 141\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 568000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-46\n",
      "done: false\n",
      "episode_len_mean: 198.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.28\n",
      "episode_reward_min: 125.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3187\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.626303323351742e-20\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25980934500694275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00213716272264719\n",
      "        model: {}\n",
      "        policy_loss: -0.012492368929088116\n",
      "        total_loss: 5.164534091949463\n",
      "        vf_explained_var: 0.02948637120425701\n",
      "        vf_loss: 5.177026748657227\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 568000\n",
      "  num_agent_steps_trained: 568000\n",
      "  num_steps_sampled: 568000\n",
      "  num_steps_trained: 568000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 142\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.629999999999995\n",
      "  ram_util_percent: 87.28999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06678982705307077\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07682471508998413\n",
      "  mean_inference_ms: 0.7305891344514589\n",
      "  mean_raw_obs_processing_ms: 0.08931951503763153\n",
      "time_since_restore: 998.8806998729706\n",
      "time_this_iter_s: 6.9814183712005615\n",
      "time_total_s: 998.8806998729706\n",
      "timers:\n",
      "  learn_throughput: 1356.58\n",
      "  learn_time_ms: 2948.592\n",
      "  load_throughput: 24036126.074\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 611.557\n",
      "  sample_time_ms: 6540.683\n",
      "  update_time_ms: 2.219\n",
      "timestamp: 1658394946\n",
      "timesteps_since_restore: 568000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 568000\n",
      "training_iteration: 142\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 572000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-52\n",
      "done: false\n",
      "episode_len_mean: 198.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.31\n",
      "episode_reward_min: 125.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3207\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 8.13151661675871e-21\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2502886652946472\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0045126318000257015\n",
      "        model: {}\n",
      "        policy_loss: 0.005773330572992563\n",
      "        total_loss: 9.171616554260254\n",
      "        vf_explained_var: 0.002917901147156954\n",
      "        vf_loss: 9.165842056274414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 572000\n",
      "  num_agent_steps_trained: 572000\n",
      "  num_steps_sampled: 572000\n",
      "  num_steps_trained: 572000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 143\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.32\n",
      "  ram_util_percent: 87.37\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06676331170473518\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07679551373460301\n",
      "  mean_inference_ms: 0.7303321436035182\n",
      "  mean_raw_obs_processing_ms: 0.08928497499055958\n",
      "time_since_restore: 1005.7839813232422\n",
      "time_this_iter_s: 6.9032814502716064\n",
      "time_total_s: 1005.7839813232422\n",
      "timers:\n",
      "  learn_throughput: 1369.283\n",
      "  learn_time_ms: 2921.237\n",
      "  load_throughput: 23369850.954\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 606.35\n",
      "  sample_time_ms: 6596.85\n",
      "  update_time_ms: 2.147\n",
      "timestamp: 1658394952\n",
      "timesteps_since_restore: 572000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 572000\n",
      "training_iteration: 143\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 576000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-15-59\n",
      "done: false\n",
      "episode_len_mean: 197.96\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.96\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3227\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.065758308379355e-21\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24865509569644928\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005121882539242506\n",
      "        model: {}\n",
      "        policy_loss: 0.0033942125737667084\n",
      "        total_loss: 5.580848217010498\n",
      "        vf_explained_var: -0.025805961340665817\n",
      "        vf_loss: 5.577454090118408\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 576000\n",
      "  num_agent_steps_trained: 576000\n",
      "  num_steps_sampled: 576000\n",
      "  num_steps_trained: 576000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 144\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.42\n",
      "  ram_util_percent: 87.36999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06674435983637043\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07677398047253756\n",
      "  mean_inference_ms: 0.730154906530928\n",
      "  mean_raw_obs_processing_ms: 0.08925963790437975\n",
      "time_since_restore: 1012.4316341876984\n",
      "time_this_iter_s: 6.647652864456177\n",
      "time_total_s: 1012.4316341876984\n",
      "timers:\n",
      "  learn_throughput: 1369.267\n",
      "  learn_time_ms: 2921.271\n",
      "  load_throughput: 23330852.454\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 604.165\n",
      "  sample_time_ms: 6620.711\n",
      "  update_time_ms: 2.162\n",
      "timestamp: 1658394959\n",
      "timesteps_since_restore: 576000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 576000\n",
      "training_iteration: 144\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 580000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-16-06\n",
      "done: false\n",
      "episode_len_mean: 198.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.15\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3247\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.065758308379355e-21\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2750062644481659\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003892093664035201\n",
      "        model: {}\n",
      "        policy_loss: -0.0007567571010440588\n",
      "        total_loss: 3.074573516845703\n",
      "        vf_explained_var: -0.006988555192947388\n",
      "        vf_loss: 3.0753302574157715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 580000\n",
      "  num_agent_steps_trained: 580000\n",
      "  num_steps_sampled: 580000\n",
      "  num_steps_trained: 580000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 145\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.144444444444446\n",
      "  ram_util_percent: 87.35555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06672281512724396\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07674923265080952\n",
      "  mean_inference_ms: 0.7299420768748868\n",
      "  mean_raw_obs_processing_ms: 0.08923107358915203\n",
      "time_since_restore: 1018.8971931934357\n",
      "time_this_iter_s: 6.465559005737305\n",
      "time_total_s: 1018.8971931934357\n",
      "timers:\n",
      "  learn_throughput: 1370.973\n",
      "  learn_time_ms: 2917.636\n",
      "  load_throughput: 23350335.421\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 604.701\n",
      "  sample_time_ms: 6614.834\n",
      "  update_time_ms: 2.181\n",
      "timestamp: 1658394966\n",
      "timesteps_since_restore: 580000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 580000\n",
      "training_iteration: 145\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 584000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-16-13\n",
      "done: false\n",
      "episode_len_mean: 198.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.15\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3267\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.0328791541896775e-21\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2700011730194092\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002676136326044798\n",
      "        model: {}\n",
      "        policy_loss: 0.0009218232589773834\n",
      "        total_loss: 3.0759739875793457\n",
      "        vf_explained_var: -0.010680039413273335\n",
      "        vf_loss: 3.07505202293396\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 584000\n",
      "  num_agent_steps_trained: 584000\n",
      "  num_steps_sampled: 584000\n",
      "  num_steps_trained: 584000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 146\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.269999999999996\n",
      "  ram_util_percent: 87.38\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06670629040752321\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07673093261584056\n",
      "  mean_inference_ms: 0.7298282143388063\n",
      "  mean_raw_obs_processing_ms: 0.08920993131205282\n",
      "time_since_restore: 1025.8755929470062\n",
      "time_this_iter_s: 6.978399753570557\n",
      "time_total_s: 1025.8755929470062\n",
      "timers:\n",
      "  learn_throughput: 1360.162\n",
      "  learn_time_ms: 2940.827\n",
      "  load_throughput: 23221060.208\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 602.389\n",
      "  sample_time_ms: 6640.222\n",
      "  update_time_ms: 2.353\n",
      "timestamp: 1658394973\n",
      "timesteps_since_restore: 584000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 584000\n",
      "training_iteration: 146\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 588000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-16-19\n",
      "done: false\n",
      "episode_len_mean: 198.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.68\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3287\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.0164395770948388e-21\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23978231847286224\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030087437480688095\n",
      "        model: {}\n",
      "        policy_loss: 0.0023985770530998707\n",
      "        total_loss: 3.07710599899292\n",
      "        vf_explained_var: 0.015723824501037598\n",
      "        vf_loss: 3.074707269668579\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 588000\n",
      "  num_agent_steps_trained: 588000\n",
      "  num_steps_sampled: 588000\n",
      "  num_steps_trained: 588000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 147\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.5\n",
      "  ram_util_percent: 87.34444444444445\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06668622630677469\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0767084745233831\n",
      "  mean_inference_ms: 0.7296714985054698\n",
      "  mean_raw_obs_processing_ms: 0.0891841093622811\n",
      "time_since_restore: 1032.468430519104\n",
      "time_this_iter_s: 6.592837572097778\n",
      "time_total_s: 1032.468430519104\n",
      "timers:\n",
      "  learn_throughput: 1359.334\n",
      "  learn_time_ms: 2942.617\n",
      "  load_throughput: 23224274.64\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 598.567\n",
      "  sample_time_ms: 6682.622\n",
      "  update_time_ms: 2.372\n",
      "timestamp: 1658394979\n",
      "timesteps_since_restore: 588000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 588000\n",
      "training_iteration: 147\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 592000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-16-28\n",
      "done: false\n",
      "episode_len_mean: 198.3\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.3\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3307\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.082197885474194e-22\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29248568415641785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003547575091943145\n",
      "        model: {}\n",
      "        policy_loss: 0.0011656254064291716\n",
      "        total_loss: 2.9253361225128174\n",
      "        vf_explained_var: -0.02708578296005726\n",
      "        vf_loss: 2.9241702556610107\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 592000\n",
      "  num_agent_steps_trained: 592000\n",
      "  num_steps_sampled: 592000\n",
      "  num_steps_trained: 592000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 148\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.35833333333333\n",
      "  ram_util_percent: 87.61666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0666933023155229\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07671545001117906\n",
      "  mean_inference_ms: 0.7297993836327911\n",
      "  mean_raw_obs_processing_ms: 0.08918973585862516\n",
      "time_since_restore: 1040.8095281124115\n",
      "time_this_iter_s: 8.341097593307495\n",
      "time_total_s: 1040.8095281124115\n",
      "timers:\n",
      "  learn_throughput: 1334.931\n",
      "  learn_time_ms: 2996.409\n",
      "  load_throughput: 23014013.717\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 586.371\n",
      "  sample_time_ms: 6821.625\n",
      "  update_time_ms: 2.38\n",
      "timestamp: 1658394988\n",
      "timesteps_since_restore: 592000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 592000\n",
      "training_iteration: 148\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 596000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-16-35\n",
      "done: false\n",
      "episode_len_mean: 199.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.06\n",
      "episode_reward_min: 140.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3328\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.541098942737097e-22\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2653413414955139\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031494139693677425\n",
      "        model: {}\n",
      "        policy_loss: 0.0015896938275545835\n",
      "        total_loss: 4.322126865386963\n",
      "        vf_explained_var: 0.0005889789899811149\n",
      "        vf_loss: 4.320537567138672\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 596000\n",
      "  num_agent_steps_trained: 596000\n",
      "  num_steps_sampled: 596000\n",
      "  num_steps_trained: 596000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 149\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.31818181818182\n",
      "  ram_util_percent: 87.59090909090911\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06670477827170739\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07672729971440034\n",
      "  mean_inference_ms: 0.7299684672579148\n",
      "  mean_raw_obs_processing_ms: 0.08920019463960525\n",
      "time_since_restore: 1048.1248226165771\n",
      "time_this_iter_s: 7.315294504165649\n",
      "time_total_s: 1048.1248226165771\n",
      "timers:\n",
      "  learn_throughput: 1307.751\n",
      "  learn_time_ms: 3058.687\n",
      "  load_throughput: 22316062.783\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 578.348\n",
      "  sample_time_ms: 6916.251\n",
      "  update_time_ms: 2.246\n",
      "timestamp: 1658394995\n",
      "timesteps_since_restore: 596000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 596000\n",
      "training_iteration: 149\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 600000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-16-43\n",
      "done: false\n",
      "episode_len_mean: 198.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.15\n",
      "episode_reward_min: 131.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3348\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.2705494713685484e-22\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2817499041557312\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029908758588135242\n",
      "        model: {}\n",
      "        policy_loss: 0.005824684631079435\n",
      "        total_loss: 6.1828155517578125\n",
      "        vf_explained_var: 0.002553744940087199\n",
      "        vf_loss: 6.1769914627075195\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 600000\n",
      "  num_agent_steps_trained: 600000\n",
      "  num_steps_sampled: 600000\n",
      "  num_steps_trained: 600000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 150\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.845454545454544\n",
      "  ram_util_percent: 87.80909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06673496256188542\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07675995822281809\n",
      "  mean_inference_ms: 0.7303346433796842\n",
      "  mean_raw_obs_processing_ms: 0.08923358692816662\n",
      "time_since_restore: 1056.0308015346527\n",
      "time_this_iter_s: 7.9059789180755615\n",
      "time_total_s: 1056.0308015346527\n",
      "timers:\n",
      "  learn_throughput: 1284.644\n",
      "  learn_time_ms: 3113.703\n",
      "  load_throughput: 21768802.387\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 567.696\n",
      "  sample_time_ms: 7046.027\n",
      "  update_time_ms: 2.281\n",
      "timestamp: 1658395003\n",
      "timesteps_since_restore: 600000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 600000\n",
      "training_iteration: 150\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 604000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-16-51\n",
      "done: false\n",
      "episode_len_mean: 197.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.78\n",
      "episode_reward_min: 131.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3368\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.352747356842742e-23\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23847195506095886\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024916462134569883\n",
      "        model: {}\n",
      "        policy_loss: 0.00176783197093755\n",
      "        total_loss: 2.5799829959869385\n",
      "        vf_explained_var: -0.06735501438379288\n",
      "        vf_loss: 2.5782153606414795\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 604000\n",
      "  num_agent_steps_trained: 604000\n",
      "  num_steps_sampled: 604000\n",
      "  num_steps_trained: 604000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 151\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.11818181818182\n",
      "  ram_util_percent: 87.58181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06678737913808865\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07681669895214117\n",
      "  mean_inference_ms: 0.7308893195554481\n",
      "  mean_raw_obs_processing_ms: 0.08929354074991565\n",
      "time_since_restore: 1063.9701900482178\n",
      "time_this_iter_s: 7.9393885135650635\n",
      "time_total_s: 1063.9701900482178\n",
      "timers:\n",
      "  learn_throughput: 1279.783\n",
      "  learn_time_ms: 3125.53\n",
      "  load_throughput: 21828279.99\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 554.302\n",
      "  sample_time_ms: 7216.279\n",
      "  update_time_ms: 2.206\n",
      "timestamp: 1658395011\n",
      "timesteps_since_restore: 604000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 604000\n",
      "training_iteration: 151\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 608000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-16-58\n",
      "done: false\n",
      "episode_len_mean: 196.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.98\n",
      "episode_reward_min: 131.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3389\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.176373678421371e-23\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2773551344871521\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0040460312739014626\n",
      "        model: {}\n",
      "        policy_loss: 0.003207074012607336\n",
      "        total_loss: 5.424271106719971\n",
      "        vf_explained_var: -0.03455117344856262\n",
      "        vf_loss: 5.4210638999938965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 608000\n",
      "  num_agent_steps_trained: 608000\n",
      "  num_steps_sampled: 608000\n",
      "  num_steps_trained: 608000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 152\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.96999999999999\n",
      "  ram_util_percent: 87.45\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06684046622793624\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07687411533514636\n",
      "  mean_inference_ms: 0.7314544515043175\n",
      "  mean_raw_obs_processing_ms: 0.08935498791012104\n",
      "time_since_restore: 1070.7036266326904\n",
      "time_this_iter_s: 6.733436584472656\n",
      "time_total_s: 1070.7036266326904\n",
      "timers:\n",
      "  learn_throughput: 1285.131\n",
      "  learn_time_ms: 3112.523\n",
      "  load_throughput: 21988487.549\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 554.335\n",
      "  sample_time_ms: 7215.852\n",
      "  update_time_ms: 2.191\n",
      "timestamp: 1658395018\n",
      "timesteps_since_restore: 608000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 608000\n",
      "training_iteration: 152\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 612000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-17-04\n",
      "done: false\n",
      "episode_len_mean: 196.96\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.96\n",
      "episode_reward_min: 131.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3409\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.5881868392106856e-23\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2644957900047302\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005184370558708906\n",
      "        model: {}\n",
      "        policy_loss: 0.005328271072357893\n",
      "        total_loss: 7.013906955718994\n",
      "        vf_explained_var: 0.0017911829054355621\n",
      "        vf_loss: 7.008579254150391\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 612000\n",
      "  num_agent_steps_trained: 612000\n",
      "  num_steps_sampled: 612000\n",
      "  num_steps_trained: 612000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 153\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.3\n",
      "  ram_util_percent: 87.53\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0668596651298555\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07689505443474949\n",
      "  mean_inference_ms: 0.7316674538552184\n",
      "  mean_raw_obs_processing_ms: 0.08937745723106971\n",
      "time_since_restore: 1077.5694727897644\n",
      "time_this_iter_s: 6.865846157073975\n",
      "time_total_s: 1077.5694727897644\n",
      "timers:\n",
      "  learn_throughput: 1275.999\n",
      "  learn_time_ms: 3134.799\n",
      "  load_throughput: 22354718.188\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 557.359\n",
      "  sample_time_ms: 7176.708\n",
      "  update_time_ms: 2.214\n",
      "timestamp: 1658395024\n",
      "timesteps_since_restore: 612000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 612000\n",
      "training_iteration: 153\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 616000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-17-12\n",
      "done: false\n",
      "episode_len_mean: 196.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.14\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3430\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.5881868392106856e-23\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.272487998008728\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004027446266263723\n",
      "        model: {}\n",
      "        policy_loss: -0.005678700748831034\n",
      "        total_loss: 6.126266002655029\n",
      "        vf_explained_var: -0.027074242010712624\n",
      "        vf_loss: 6.1319451332092285\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 616000\n",
      "  num_agent_steps_trained: 616000\n",
      "  num_steps_sampled: 616000\n",
      "  num_steps_trained: 616000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 154\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.79090909090909\n",
      "  ram_util_percent: 87.66363636363636\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0668943189581715\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07693493135444075\n",
      "  mean_inference_ms: 0.7320787887012737\n",
      "  mean_raw_obs_processing_ms: 0.08942421836899982\n",
      "time_since_restore: 1085.1794760227203\n",
      "time_this_iter_s: 7.610003232955933\n",
      "time_total_s: 1085.1794760227203\n",
      "timers:\n",
      "  learn_throughput: 1273.063\n",
      "  learn_time_ms: 3142.028\n",
      "  load_throughput: 22598620.69\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 548.777\n",
      "  sample_time_ms: 7288.929\n",
      "  update_time_ms: 2.191\n",
      "timestamp: 1658395032\n",
      "timesteps_since_restore: 616000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 616000\n",
      "training_iteration: 154\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 620000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-17-20\n",
      "done: false\n",
      "episode_len_mean: 193.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.36\n",
      "episode_reward_min: 108.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 3452\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.940934196053428e-24\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2791576087474823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003324728924781084\n",
      "        model: {}\n",
      "        policy_loss: -0.010243676602840424\n",
      "        total_loss: 6.801549911499023\n",
      "        vf_explained_var: -0.02379327267408371\n",
      "        vf_loss: 6.811793327331543\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 620000\n",
      "  num_agent_steps_trained: 620000\n",
      "  num_steps_sampled: 620000\n",
      "  num_steps_trained: 620000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 155\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.940000000000005\n",
      "  ram_util_percent: 87.35\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06691775105589638\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0769623674512555\n",
      "  mean_inference_ms: 0.7323756329133008\n",
      "  mean_raw_obs_processing_ms: 0.0894586425101926\n",
      "time_since_restore: 1092.5781292915344\n",
      "time_this_iter_s: 7.398653268814087\n",
      "time_total_s: 1092.5781292915344\n",
      "timers:\n",
      "  learn_throughput: 1254.228\n",
      "  learn_time_ms: 3189.213\n",
      "  load_throughput: 22519753.02\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 544.786\n",
      "  sample_time_ms: 7342.337\n",
      "  update_time_ms: 2.195\n",
      "timestamp: 1658395040\n",
      "timesteps_since_restore: 620000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 620000\n",
      "training_iteration: 155\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 624000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-17-27\n",
      "done: false\n",
      "episode_len_mean: 192.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.06\n",
      "episode_reward_min: 108.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3472\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.970467098026714e-24\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2824673652648926\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005790336523205042\n",
      "        model: {}\n",
      "        policy_loss: 0.002545966999605298\n",
      "        total_loss: 7.078657150268555\n",
      "        vf_explained_var: 0.00810313317924738\n",
      "        vf_loss: 7.076111793518066\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 624000\n",
      "  num_agent_steps_trained: 624000\n",
      "  num_steps_sampled: 624000\n",
      "  num_steps_trained: 624000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 156\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.54545454545455\n",
      "  ram_util_percent: 86.36363636363636\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06691971861239548\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0769657766634341\n",
      "  mean_inference_ms: 0.7324461279892582\n",
      "  mean_raw_obs_processing_ms: 0.08946518029862215\n",
      "time_since_restore: 1099.71915102005\n",
      "time_this_iter_s: 7.141021728515625\n",
      "time_total_s: 1099.71915102005\n",
      "timers:\n",
      "  learn_throughput: 1240.92\n",
      "  learn_time_ms: 3223.416\n",
      "  load_throughput: 22647429.806\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 542.544\n",
      "  sample_time_ms: 7372.67\n",
      "  update_time_ms: 2.071\n",
      "timestamp: 1658395047\n",
      "timesteps_since_restore: 624000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 624000\n",
      "training_iteration: 156\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 628000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-17-34\n",
      "done: false\n",
      "episode_len_mean: 187.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.99\n",
      "episode_reward_min: 96.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 3495\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.970467098026714e-24\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2847302556037903\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037861561868339777\n",
      "        model: {}\n",
      "        policy_loss: 0.004951954819262028\n",
      "        total_loss: 6.3265461921691895\n",
      "        vf_explained_var: 0.008520099334418774\n",
      "        vf_loss: 6.321594715118408\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 628000\n",
      "  num_agent_steps_trained: 628000\n",
      "  num_steps_sampled: 628000\n",
      "  num_steps_trained: 628000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 157\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.54\n",
      "  ram_util_percent: 86.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06693631235089312\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07698501345536911\n",
      "  mean_inference_ms: 0.7326728593058776\n",
      "  mean_raw_obs_processing_ms: 0.08949119173192072\n",
      "time_since_restore: 1106.8200702667236\n",
      "time_this_iter_s: 7.100919246673584\n",
      "time_total_s: 1106.8200702667236\n",
      "timers:\n",
      "  learn_throughput: 1240.886\n",
      "  learn_time_ms: 3223.503\n",
      "  load_throughput: 22525800.215\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 536.426\n",
      "  sample_time_ms: 7456.759\n",
      "  update_time_ms: 2.077\n",
      "timestamp: 1658395054\n",
      "timesteps_since_restore: 628000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 628000\n",
      "training_iteration: 157\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 632000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-17-41\n",
      "done: false\n",
      "episode_len_mean: 184.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.69\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 3517\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.985233549013357e-24\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24636423587799072\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005263646133244038\n",
      "        model: {}\n",
      "        policy_loss: -0.0029811833519488573\n",
      "        total_loss: 3.47237229347229\n",
      "        vf_explained_var: -0.006734843831509352\n",
      "        vf_loss: 3.475353240966797\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 632000\n",
      "  num_agent_steps_trained: 632000\n",
      "  num_steps_sampled: 632000\n",
      "  num_steps_trained: 632000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 158\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.89\n",
      "  ram_util_percent: 86.47999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06695386756521607\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07700372491240975\n",
      "  mean_inference_ms: 0.7328895508406887\n",
      "  mean_raw_obs_processing_ms: 0.08951646887439985\n",
      "time_since_restore: 1114.0601825714111\n",
      "time_this_iter_s: 7.2401123046875\n",
      "time_total_s: 1114.0601825714111\n",
      "timers:\n",
      "  learn_throughput: 1245.748\n",
      "  learn_time_ms: 3210.923\n",
      "  load_throughput: 22776562.585\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 543.524\n",
      "  sample_time_ms: 7359.377\n",
      "  update_time_ms: 2.241\n",
      "timestamp: 1658395061\n",
      "timesteps_since_restore: 632000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 632000\n",
      "training_iteration: 158\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 636000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-17-48\n",
      "done: false\n",
      "episode_len_mean: 184.43\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.43\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3537\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.985233549013357e-24\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2619762420654297\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003732917131856084\n",
      "        model: {}\n",
      "        policy_loss: 0.004088225308805704\n",
      "        total_loss: 5.821387767791748\n",
      "        vf_explained_var: -0.06115374341607094\n",
      "        vf_loss: 5.817299842834473\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 636000\n",
      "  num_agent_steps_trained: 636000\n",
      "  num_steps_sampled: 636000\n",
      "  num_steps_trained: 636000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 159\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.44\n",
      "  ram_util_percent: 86.53\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06696012505923807\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07700900727248731\n",
      "  mean_inference_ms: 0.7329668507142424\n",
      "  mean_raw_obs_processing_ms: 0.08952531772293798\n",
      "time_since_restore: 1120.9879403114319\n",
      "time_this_iter_s: 6.927757740020752\n",
      "time_total_s: 1120.9879403114319\n",
      "timers:\n",
      "  learn_throughput: 1262.747\n",
      "  learn_time_ms: 3167.698\n",
      "  load_throughput: 23590011.249\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 544.075\n",
      "  sample_time_ms: 7351.933\n",
      "  update_time_ms: 2.255\n",
      "timestamp: 1658395068\n",
      "timesteps_since_restore: 636000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 636000\n",
      "training_iteration: 159\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 640000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-17-56\n",
      "done: false\n",
      "episode_len_mean: 185.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.25\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 3559\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 9.926167745066785e-25\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25860539078712463\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0018559448653832078\n",
      "        model: {}\n",
      "        policy_loss: 0.0055104149505496025\n",
      "        total_loss: 5.8306145668029785\n",
      "        vf_explained_var: -0.029686689376831055\n",
      "        vf_loss: 5.825103759765625\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 640000\n",
      "  num_agent_steps_trained: 640000\n",
      "  num_steps_sampled: 640000\n",
      "  num_steps_trained: 640000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 160\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.35454545454545\n",
      "  ram_util_percent: 86.46363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06697236340760755\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07702015024525098\n",
      "  mean_inference_ms: 0.7331039625190363\n",
      "  mean_raw_obs_processing_ms: 0.0895403705244706\n",
      "time_since_restore: 1128.5239825248718\n",
      "time_this_iter_s: 7.536042213439941\n",
      "time_total_s: 1128.5239825248718\n",
      "timers:\n",
      "  learn_throughput: 1267.602\n",
      "  learn_time_ms: 3155.565\n",
      "  load_throughput: 23794094.455\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 549.118\n",
      "  sample_time_ms: 7284.415\n",
      "  update_time_ms: 2.133\n",
      "timestamp: 1658395076\n",
      "timesteps_since_restore: 640000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 640000\n",
      "training_iteration: 160\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 644000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-04\n",
      "done: false\n",
      "episode_len_mean: 184.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.59\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 3581\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.963083872533392e-25\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25848281383514404\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032290350645780563\n",
      "        model: {}\n",
      "        policy_loss: 0.001544171362183988\n",
      "        total_loss: 4.969202518463135\n",
      "        vf_explained_var: 0.017492741346359253\n",
      "        vf_loss: 4.967658519744873\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 644000\n",
      "  num_agent_steps_trained: 644000\n",
      "  num_steps_sampled: 644000\n",
      "  num_steps_trained: 644000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 161\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.07272727272727\n",
      "  ram_util_percent: 86.60909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06700130382184115\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07705002693909903\n",
      "  mean_inference_ms: 0.7334026457045535\n",
      "  mean_raw_obs_processing_ms: 0.0895754115068681\n",
      "time_since_restore: 1136.5532660484314\n",
      "time_this_iter_s: 8.02928352355957\n",
      "time_total_s: 1136.5532660484314\n",
      "timers:\n",
      "  learn_throughput: 1258.338\n",
      "  learn_time_ms: 3178.797\n",
      "  load_throughput: 21228920.663\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 551.254\n",
      "  sample_time_ms: 7256.189\n",
      "  update_time_ms: 2.142\n",
      "timestamp: 1658395084\n",
      "timesteps_since_restore: 644000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 644000\n",
      "training_iteration: 161\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 648000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-10\n",
      "done: false\n",
      "episode_len_mean: 183.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 183.06\n",
      "episode_reward_min: 63.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 3604\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.481541936266696e-25\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3194209933280945\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006813246291130781\n",
      "        model: {}\n",
      "        policy_loss: 0.004104360472410917\n",
      "        total_loss: 7.47455358505249\n",
      "        vf_explained_var: 0.03650185465812683\n",
      "        vf_loss: 7.470448970794678\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 648000\n",
      "  num_agent_steps_trained: 648000\n",
      "  num_steps_sampled: 648000\n",
      "  num_steps_trained: 648000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 162\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.64\n",
      "  ram_util_percent: 86.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06702714111132786\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0770764782437517\n",
      "  mean_inference_ms: 0.7336755327975374\n",
      "  mean_raw_obs_processing_ms: 0.08960543616235686\n",
      "time_since_restore: 1143.354786157608\n",
      "time_this_iter_s: 6.801520109176636\n",
      "time_total_s: 1143.354786157608\n",
      "timers:\n",
      "  learn_throughput: 1262.862\n",
      "  learn_time_ms: 3167.408\n",
      "  load_throughput: 21258509.883\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 548.12\n",
      "  sample_time_ms: 7297.676\n",
      "  update_time_ms: 2.168\n",
      "timestamp: 1658395090\n",
      "timesteps_since_restore: 648000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 648000\n",
      "training_iteration: 162\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 652000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-17\n",
      "done: false\n",
      "episode_len_mean: 184.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.03\n",
      "episode_reward_min: 63.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3625\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.481541936266696e-25\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2583279311656952\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004129549954086542\n",
      "        model: {}\n",
      "        policy_loss: 0.0013649624306708574\n",
      "        total_loss: 5.340020656585693\n",
      "        vf_explained_var: 0.03167327120900154\n",
      "        vf_loss: 5.3386549949646\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 652000\n",
      "  num_agent_steps_trained: 652000\n",
      "  num_steps_sampled: 652000\n",
      "  num_steps_trained: 652000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 163\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.24444444444444\n",
      "  ram_util_percent: 86.37777777777778\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06704031461255487\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0770892339810723\n",
      "  mean_inference_ms: 0.7338169197956814\n",
      "  mean_raw_obs_processing_ms: 0.08961964209294754\n",
      "time_since_restore: 1149.7361252307892\n",
      "time_this_iter_s: 6.381339073181152\n",
      "time_total_s: 1149.7361252307892\n",
      "timers:\n",
      "  learn_throughput: 1280.637\n",
      "  learn_time_ms: 3123.446\n",
      "  load_throughput: 21559002.827\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 549.311\n",
      "  sample_time_ms: 7281.846\n",
      "  update_time_ms: 2.14\n",
      "timestamp: 1658395097\n",
      "timesteps_since_restore: 652000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 652000\n",
      "training_iteration: 163\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 656000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-23\n",
      "done: false\n",
      "episode_len_mean: 185.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.02\n",
      "episode_reward_min: 63.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3645\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.240770968133348e-25\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24528460204601288\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0050809551030397415\n",
      "        model: {}\n",
      "        policy_loss: 0.005467948038130999\n",
      "        total_loss: 7.399718761444092\n",
      "        vf_explained_var: 0.003819111967459321\n",
      "        vf_loss: 7.394250392913818\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 656000\n",
      "  num_agent_steps_trained: 656000\n",
      "  num_steps_sampled: 656000\n",
      "  num_steps_trained: 656000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 164\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.511111111111106\n",
      "  ram_util_percent: 86.33333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06704303650257008\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0770909476475936\n",
      "  mean_inference_ms: 0.7338443847159035\n",
      "  mean_raw_obs_processing_ms: 0.08962005412276834\n",
      "time_since_restore: 1156.137939453125\n",
      "time_this_iter_s: 6.401814222335815\n",
      "time_total_s: 1156.137939453125\n",
      "timers:\n",
      "  learn_throughput: 1284.422\n",
      "  learn_time_ms: 3114.242\n",
      "  load_throughput: 21545159.882\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 561.353\n",
      "  sample_time_ms: 7125.637\n",
      "  update_time_ms: 2.167\n",
      "timestamp: 1658395103\n",
      "timesteps_since_restore: 656000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 656000\n",
      "training_iteration: 164\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 660000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-30\n",
      "done: false\n",
      "episode_len_mean: 186.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.94\n",
      "episode_reward_min: 63.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3666\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.240770968133348e-25\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25057846307754517\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029528376180678606\n",
      "        model: {}\n",
      "        policy_loss: 0.0040534911677241325\n",
      "        total_loss: 5.307399272918701\n",
      "        vf_explained_var: 0.0059926752001047134\n",
      "        vf_loss: 5.303346157073975\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 660000\n",
      "  num_agent_steps_trained: 660000\n",
      "  num_steps_sampled: 660000\n",
      "  num_steps_trained: 660000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 165\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.37\n",
      "  ram_util_percent: 86.60999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06703578332440781\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07708169234864246\n",
      "  mean_inference_ms: 0.7337701823195993\n",
      "  mean_raw_obs_processing_ms: 0.08960903667798333\n",
      "time_since_restore: 1162.9734921455383\n",
      "time_this_iter_s: 6.83555269241333\n",
      "time_total_s: 1162.9734921455383\n",
      "timers:\n",
      "  learn_throughput: 1301.299\n",
      "  learn_time_ms: 3073.852\n",
      "  load_throughput: 21443271.984\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 563.345\n",
      "  sample_time_ms: 7100.441\n",
      "  update_time_ms: 2.131\n",
      "timestamp: 1658395110\n",
      "timesteps_since_restore: 660000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 660000\n",
      "training_iteration: 165\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 664000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-37\n",
      "done: false\n",
      "episode_len_mean: 189.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.51\n",
      "episode_reward_min: 63.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3686\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.20385484066674e-26\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2277771383523941\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029353629797697067\n",
      "        model: {}\n",
      "        policy_loss: 0.006181489210575819\n",
      "        total_loss: 6.358150959014893\n",
      "        vf_explained_var: -0.03086606226861477\n",
      "        vf_loss: 6.3519697189331055\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 664000\n",
      "  num_agent_steps_trained: 664000\n",
      "  num_steps_sampled: 664000\n",
      "  num_steps_trained: 664000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 166\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.55555555555556\n",
      "  ram_util_percent: 86.26666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0670098376585889\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0770518157504673\n",
      "  mean_inference_ms: 0.7335025751070381\n",
      "  mean_raw_obs_processing_ms: 0.08957524630981353\n",
      "time_since_restore: 1169.3772451877594\n",
      "time_this_iter_s: 6.403753042221069\n",
      "time_total_s: 1169.3772451877594\n",
      "timers:\n",
      "  learn_throughput: 1322.924\n",
      "  learn_time_ms: 3023.604\n",
      "  load_throughput: 21492718.422\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 568.527\n",
      "  sample_time_ms: 7035.723\n",
      "  update_time_ms: 2.119\n",
      "timestamp: 1658395117\n",
      "timesteps_since_restore: 664000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 664000\n",
      "training_iteration: 166\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 668000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-43\n",
      "done: false\n",
      "episode_len_mean: 191.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.16\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 3709\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.10192742033337e-26\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23075629770755768\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003453287063166499\n",
      "        model: {}\n",
      "        policy_loss: 0.0022693430073559284\n",
      "        total_loss: 5.9291605949401855\n",
      "        vf_explained_var: -0.020848575979471207\n",
      "        vf_loss: 5.926890850067139\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 668000\n",
      "  num_agent_steps_trained: 668000\n",
      "  num_steps_sampled: 668000\n",
      "  num_steps_trained: 668000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 167\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.822222222222226\n",
      "  ram_util_percent: 86.14444444444445\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06697386545087568\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07701094521011724\n",
      "  mean_inference_ms: 0.7331322809395999\n",
      "  mean_raw_obs_processing_ms: 0.08952954524216405\n",
      "time_since_restore: 1175.826261997223\n",
      "time_this_iter_s: 6.449016809463501\n",
      "time_total_s: 1175.826261997223\n",
      "timers:\n",
      "  learn_throughput: 1323.854\n",
      "  learn_time_ms: 3021.481\n",
      "  load_throughput: 21567317.136\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 577.863\n",
      "  sample_time_ms: 6922.051\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658395123\n",
      "timesteps_since_restore: 668000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 668000\n",
      "training_iteration: 167\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 672000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-50\n",
      "done: false\n",
      "episode_len_mean: 191.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.15\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3729\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.550963710166685e-26\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22071969509124756\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027289462741464376\n",
      "        model: {}\n",
      "        policy_loss: 0.004279223270714283\n",
      "        total_loss: 5.814597129821777\n",
      "        vf_explained_var: 0.004530421458184719\n",
      "        vf_loss: 5.8103179931640625\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 672000\n",
      "  num_agent_steps_trained: 672000\n",
      "  num_steps_sampled: 672000\n",
      "  num_steps_trained: 672000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 168\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.981818181818184\n",
      "  ram_util_percent: 86.15454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06696052436275396\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07699601289181883\n",
      "  mean_inference_ms: 0.7329934810459053\n",
      "  mean_raw_obs_processing_ms: 0.08951196780803437\n",
      "time_since_restore: 1183.2581903934479\n",
      "time_this_iter_s: 7.431928396224976\n",
      "time_total_s: 1183.2581903934479\n",
      "timers:\n",
      "  learn_throughput: 1332.759\n",
      "  learn_time_ms: 3001.292\n",
      "  load_throughput: 21606202.189\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 574.791\n",
      "  sample_time_ms: 6959.055\n",
      "  update_time_ms: 2.025\n",
      "timestamp: 1658395130\n",
      "timesteps_since_restore: 672000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 672000\n",
      "training_iteration: 168\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 676000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-18-57\n",
      "done: false\n",
      "episode_len_mean: 190.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.62\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3750\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.754818550833426e-27\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20414747297763824\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029324530623853207\n",
      "        model: {}\n",
      "        policy_loss: 0.003908887505531311\n",
      "        total_loss: 5.974084854125977\n",
      "        vf_explained_var: 0.006671372335404158\n",
      "        vf_loss: 5.9701762199401855\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 676000\n",
      "  num_agent_steps_trained: 676000\n",
      "  num_steps_sampled: 676000\n",
      "  num_steps_trained: 676000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 169\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.92222222222222\n",
      "  ram_util_percent: 86.1\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06694737550464955\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07698091146285561\n",
      "  mean_inference_ms: 0.7328670208561782\n",
      "  mean_raw_obs_processing_ms: 0.08949510731387936\n",
      "time_since_restore: 1189.8477900028229\n",
      "time_this_iter_s: 6.589599609375\n",
      "time_total_s: 1189.8477900028229\n",
      "timers:\n",
      "  learn_throughput: 1335.445\n",
      "  learn_time_ms: 2995.257\n",
      "  load_throughput: 21737776.626\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 578.806\n",
      "  sample_time_ms: 6910.781\n",
      "  update_time_ms: 2.031\n",
      "timestamp: 1658395137\n",
      "timesteps_since_restore: 676000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 676000\n",
      "training_iteration: 169\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 680000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-19-05\n",
      "done: false\n",
      "episode_len_mean: 192.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.08\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3770\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.877409275416713e-27\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.196328803896904\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003042621770873666\n",
      "        model: {}\n",
      "        policy_loss: 0.008098081685602665\n",
      "        total_loss: 7.820925712585449\n",
      "        vf_explained_var: 0.002479923889040947\n",
      "        vf_loss: 7.812827110290527\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 680000\n",
      "  num_agent_steps_trained: 680000\n",
      "  num_steps_sampled: 680000\n",
      "  num_steps_trained: 680000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 170\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.72727272727273\n",
      "  ram_util_percent: 86.28181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06694022101023506\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07697246307623087\n",
      "  mean_inference_ms: 0.7328002408219105\n",
      "  mean_raw_obs_processing_ms: 0.08948437073966682\n",
      "time_since_restore: 1197.3497083187103\n",
      "time_this_iter_s: 7.501918315887451\n",
      "time_total_s: 1197.3497083187103\n",
      "timers:\n",
      "  learn_throughput: 1332.403\n",
      "  learn_time_ms: 3002.094\n",
      "  load_throughput: 21968333.115\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 580.222\n",
      "  sample_time_ms: 6893.917\n",
      "  update_time_ms: 2.117\n",
      "timestamp: 1658395145\n",
      "timesteps_since_restore: 680000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 680000\n",
      "training_iteration: 170\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 684000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-19-14\n",
      "done: false\n",
      "episode_len_mean: 194.13\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.13\n",
      "episode_reward_min: 83.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3790\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.9387046377083564e-27\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1944998800754547\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030174413695931435\n",
      "        model: {}\n",
      "        policy_loss: 0.0076108030043542385\n",
      "        total_loss: 7.820679187774658\n",
      "        vf_explained_var: 0.00459570437669754\n",
      "        vf_loss: 7.813068389892578\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 684000\n",
      "  num_agent_steps_trained: 684000\n",
      "  num_steps_sampled: 684000\n",
      "  num_steps_trained: 684000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 171\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.60769230769232\n",
      "  ram_util_percent: 86.77692307692307\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.066966970158003\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07700251009918141\n",
      "  mean_inference_ms: 0.7330917074972194\n",
      "  mean_raw_obs_processing_ms: 0.08951407977567159\n",
      "time_since_restore: 1206.4071459770203\n",
      "time_this_iter_s: 9.057437658309937\n",
      "time_total_s: 1206.4071459770203\n",
      "timers:\n",
      "  learn_throughput: 1312.142\n",
      "  learn_time_ms: 3048.451\n",
      "  load_throughput: 24325382.05\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 574.824\n",
      "  sample_time_ms: 6958.657\n",
      "  update_time_ms: 2.148\n",
      "timestamp: 1658395154\n",
      "timesteps_since_restore: 684000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 684000\n",
      "training_iteration: 171\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 688000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-19-20\n",
      "done: false\n",
      "episode_len_mean: 195.24\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.24\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3811\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 9.693523188541782e-28\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17380249500274658\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0021916371770203114\n",
      "        model: {}\n",
      "        policy_loss: 0.0032750784885138273\n",
      "        total_loss: 4.828582763671875\n",
      "        vf_explained_var: -0.08783165365457535\n",
      "        vf_loss: 4.825307846069336\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 688000\n",
      "  num_agent_steps_trained: 688000\n",
      "  num_steps_sampled: 688000\n",
      "  num_steps_trained: 688000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 172\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.730000000000004\n",
      "  ram_util_percent: 86.61\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06699592235103963\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07703471912486635\n",
      "  mean_inference_ms: 0.7333957373429507\n",
      "  mean_raw_obs_processing_ms: 0.08954539116008642\n",
      "time_since_restore: 1212.9837234020233\n",
      "time_this_iter_s: 6.576577425003052\n",
      "time_total_s: 1212.9837234020233\n",
      "timers:\n",
      "  learn_throughput: 1310.678\n",
      "  learn_time_ms: 3051.856\n",
      "  load_throughput: 24371319.001\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 573.162\n",
      "  sample_time_ms: 6978.832\n",
      "  update_time_ms: 2.122\n",
      "timestamp: 1658395160\n",
      "timesteps_since_restore: 688000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 688000\n",
      "training_iteration: 172\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 692000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-19-27\n",
      "done: false\n",
      "episode_len_mean: 195.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.19\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3832\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.846761594270891e-28\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22673970460891724\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004454853944480419\n",
      "        model: {}\n",
      "        policy_loss: -0.015083763748407364\n",
      "        total_loss: 3.9082207679748535\n",
      "        vf_explained_var: -0.022956913337111473\n",
      "        vf_loss: 3.923304319381714\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 692000\n",
      "  num_agent_steps_trained: 692000\n",
      "  num_steps_sampled: 692000\n",
      "  num_steps_trained: 692000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 173\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.77777777777778\n",
      "  ram_util_percent: 86.3\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06701121549987779\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07705106273758294\n",
      "  mean_inference_ms: 0.733556789313677\n",
      "  mean_raw_obs_processing_ms: 0.08955926204156003\n",
      "time_since_restore: 1219.6027340888977\n",
      "time_this_iter_s: 6.61901068687439\n",
      "time_total_s: 1219.6027340888977\n",
      "timers:\n",
      "  learn_throughput: 1306.538\n",
      "  learn_time_ms: 3061.525\n",
      "  load_throughput: 24314805.797\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 571.721\n",
      "  sample_time_ms: 6996.421\n",
      "  update_time_ms: 2.158\n",
      "timestamp: 1658395167\n",
      "timesteps_since_restore: 692000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 692000\n",
      "training_iteration: 173\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 696000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-19-34\n",
      "done: false\n",
      "episode_len_mean: 196.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.42\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3852\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.4233807971354455e-28\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19861532747745514\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00373071595095098\n",
      "        model: {}\n",
      "        policy_loss: -0.014892001636326313\n",
      "        total_loss: 9.841466903686523\n",
      "        vf_explained_var: 0.006162651814520359\n",
      "        vf_loss: 9.856358528137207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 696000\n",
      "  num_agent_steps_trained: 696000\n",
      "  num_steps_sampled: 696000\n",
      "  num_steps_trained: 696000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 174\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.06666666666666\n",
      "  ram_util_percent: 86.26666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06702446177354995\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07706533771854895\n",
      "  mean_inference_ms: 0.7337004054027528\n",
      "  mean_raw_obs_processing_ms: 0.08957168188169998\n",
      "time_since_restore: 1226.1698367595673\n",
      "time_this_iter_s: 6.567102670669556\n",
      "time_total_s: 1226.1698367595673\n",
      "timers:\n",
      "  learn_throughput: 1304.093\n",
      "  learn_time_ms: 3067.267\n",
      "  load_throughput: 24213040.843\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 570.059\n",
      "  sample_time_ms: 7016.82\n",
      "  update_time_ms: 2.167\n",
      "timestamp: 1658395174\n",
      "timesteps_since_restore: 696000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 696000\n",
      "training_iteration: 174\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 700000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-19-40\n",
      "done: false\n",
      "episode_len_mean: 194.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.51\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3872\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.2116903985677227e-28\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20883259177207947\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002701780293136835\n",
      "        model: {}\n",
      "        policy_loss: 0.0063535114750266075\n",
      "        total_loss: 7.275986194610596\n",
      "        vf_explained_var: -0.05768391862511635\n",
      "        vf_loss: 7.269631862640381\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 700000\n",
      "  num_agent_steps_trained: 700000\n",
      "  num_steps_sampled: 700000\n",
      "  num_steps_trained: 700000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 175\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.239999999999995\n",
      "  ram_util_percent: 86.55000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06702913221957126\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07707071616063363\n",
      "  mean_inference_ms: 0.7337550139601177\n",
      "  mean_raw_obs_processing_ms: 0.08957436955213001\n",
      "time_since_restore: 1232.7443335056305\n",
      "time_this_iter_s: 6.574496746063232\n",
      "time_total_s: 1232.7443335056305\n",
      "timers:\n",
      "  learn_throughput: 1310.52\n",
      "  learn_time_ms: 3052.224\n",
      "  load_throughput: 24008609.044\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 570.517\n",
      "  sample_time_ms: 7011.187\n",
      "  update_time_ms: 2.303\n",
      "timestamp: 1658395180\n",
      "timesteps_since_restore: 700000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 700000\n",
      "training_iteration: 175\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 704000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-19-47\n",
      "done: false\n",
      "episode_len_mean: 193.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.2\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3893\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 6.058451992838614e-29\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23672199249267578\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001026586745865643\n",
      "        model: {}\n",
      "        policy_loss: 0.002933218376711011\n",
      "        total_loss: 3.044105291366577\n",
      "        vf_explained_var: 0.0477876178920269\n",
      "        vf_loss: 3.0411720275878906\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 704000\n",
      "  num_agent_steps_trained: 704000\n",
      "  num_steps_sampled: 704000\n",
      "  num_steps_trained: 704000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 176\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.02222222222222\n",
      "  ram_util_percent: 86.3\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06700702708531514\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0770457134715889\n",
      "  mean_inference_ms: 0.7335334690238348\n",
      "  mean_raw_obs_processing_ms: 0.08954687632876171\n",
      "time_since_restore: 1239.3815672397614\n",
      "time_this_iter_s: 6.637233734130859\n",
      "time_total_s: 1239.3815672397614\n",
      "timers:\n",
      "  learn_throughput: 1312.307\n",
      "  learn_time_ms: 3048.068\n",
      "  load_throughput: 23885558.087\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 569.425\n",
      "  sample_time_ms: 7024.635\n",
      "  update_time_ms: 2.312\n",
      "timestamp: 1658395187\n",
      "timesteps_since_restore: 704000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 704000\n",
      "training_iteration: 176\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 708000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-19-53\n",
      "done: false\n",
      "episode_len_mean: 194.22\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.22\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3914\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.029225996419307e-29\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24790817499160767\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004614681005477905\n",
      "        model: {}\n",
      "        policy_loss: 0.00181859009899199\n",
      "        total_loss: 5.579734802246094\n",
      "        vf_explained_var: 0.013694094493985176\n",
      "        vf_loss: 5.577916622161865\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 708000\n",
      "  num_agent_steps_trained: 708000\n",
      "  num_steps_sampled: 708000\n",
      "  num_steps_trained: 708000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 177\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.41\n",
      "  ram_util_percent: 86.28999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06698370091214248\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07701989314194896\n",
      "  mean_inference_ms: 0.7333013099451139\n",
      "  mean_raw_obs_processing_ms: 0.08951831657011652\n",
      "time_since_restore: 1245.8589541912079\n",
      "time_this_iter_s: 6.477386951446533\n",
      "time_total_s: 1245.8589541912079\n",
      "timers:\n",
      "  learn_throughput: 1312.277\n",
      "  learn_time_ms: 3048.138\n",
      "  load_throughput: 23957184.064\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 569.529\n",
      "  sample_time_ms: 7023.35\n",
      "  update_time_ms: 2.292\n",
      "timestamp: 1658395193\n",
      "timesteps_since_restore: 708000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 708000\n",
      "training_iteration: 177\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 712000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-00\n",
      "done: false\n",
      "episode_len_mean: 194.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.4\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3934\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.5146129982096534e-29\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2513836920261383\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004549605306237936\n",
      "        model: {}\n",
      "        policy_loss: 0.0027392797637730837\n",
      "        total_loss: 4.534401893615723\n",
      "        vf_explained_var: -0.09279755502939224\n",
      "        vf_loss: 4.5316619873046875\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 712000\n",
      "  num_agent_steps_trained: 712000\n",
      "  num_steps_sampled: 712000\n",
      "  num_steps_trained: 712000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 178\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.888888888888886\n",
      "  ram_util_percent: 86.28888888888888\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06696108086418745\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07699466603336275\n",
      "  mean_inference_ms: 0.7330736286593417\n",
      "  mean_raw_obs_processing_ms: 0.0894902888366671\n",
      "time_since_restore: 1252.6463205814362\n",
      "time_this_iter_s: 6.7873663902282715\n",
      "time_total_s: 1252.6463205814362\n",
      "timers:\n",
      "  learn_throughput: 1309.296\n",
      "  learn_time_ms: 3055.077\n",
      "  load_throughput: 24049908.257\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 575.391\n",
      "  sample_time_ms: 6951.789\n",
      "  update_time_ms: 2.307\n",
      "timestamp: 1658395200\n",
      "timesteps_since_restore: 712000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 712000\n",
      "training_iteration: 178\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 716000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-08\n",
      "done: false\n",
      "episode_len_mean: 189.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.6\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 3957\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.573064991048267e-30\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24591822922229767\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002982886042445898\n",
      "        model: {}\n",
      "        policy_loss: 0.0035588715691119432\n",
      "        total_loss: 4.76109504699707\n",
      "        vf_explained_var: -0.10470572859048843\n",
      "        vf_loss: 4.7575364112854\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 716000\n",
      "  num_agent_steps_trained: 716000\n",
      "  num_steps_sampled: 716000\n",
      "  num_steps_trained: 716000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 179\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.199999999999996\n",
      "  ram_util_percent: 86.575\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0669549192735178\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0769860380198994\n",
      "  mean_inference_ms: 0.732989537913185\n",
      "  mean_raw_obs_processing_ms: 0.08947972277778156\n",
      "time_since_restore: 1260.5151481628418\n",
      "time_this_iter_s: 7.86882758140564\n",
      "time_total_s: 1260.5151481628418\n",
      "timers:\n",
      "  learn_throughput: 1285.748\n",
      "  learn_time_ms: 3111.029\n",
      "  load_throughput: 23699980.223\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 568.859\n",
      "  sample_time_ms: 7031.614\n",
      "  update_time_ms: 2.339\n",
      "timestamp: 1658395208\n",
      "timesteps_since_restore: 716000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 716000\n",
      "training_iteration: 179\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 720000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-15\n",
      "done: false\n",
      "episode_len_mean: 190.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.1\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 3977\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.7865324955241336e-30\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22564832866191864\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002965663792565465\n",
      "        model: {}\n",
      "        policy_loss: 0.0013569059083238244\n",
      "        total_loss: 2.7689406871795654\n",
      "        vf_explained_var: -0.12601865828037262\n",
      "        vf_loss: 2.7675833702087402\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 720000\n",
      "  num_agent_steps_trained: 720000\n",
      "  num_steps_sampled: 720000\n",
      "  num_steps_trained: 720000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 180\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.41\n",
      "  ram_util_percent: 86.53\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06695827952187605\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.076986646152309\n",
      "  mean_inference_ms: 0.7330059438517721\n",
      "  mean_raw_obs_processing_ms: 0.08947950438600408\n",
      "time_since_restore: 1267.7980365753174\n",
      "time_this_iter_s: 7.282888412475586\n",
      "time_total_s: 1267.7980365753174\n",
      "timers:\n",
      "  learn_throughput: 1300.554\n",
      "  learn_time_ms: 3075.612\n",
      "  load_throughput: 24043015.191\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 563.252\n",
      "  sample_time_ms: 7101.622\n",
      "  update_time_ms: 2.356\n",
      "timestamp: 1658395215\n",
      "timesteps_since_restore: 720000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 720000\n",
      "training_iteration: 180\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 724000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-22\n",
      "done: false\n",
      "episode_len_mean: 190.47\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.47\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 3998\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.8932662477620668e-30\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2223750352859497\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004526678938418627\n",
      "        model: {}\n",
      "        policy_loss: -0.0013569939183071256\n",
      "        total_loss: 3.5536229610443115\n",
      "        vf_explained_var: -0.012713524512946606\n",
      "        vf_loss: 3.5549800395965576\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 724000\n",
      "  num_agent_steps_trained: 724000\n",
      "  num_steps_sampled: 724000\n",
      "  num_steps_trained: 724000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 181\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.67\n",
      "  ram_util_percent: 86.58000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0669662327882984\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07699269080619882\n",
      "  mean_inference_ms: 0.7330607556987936\n",
      "  mean_raw_obs_processing_ms: 0.0894832099202802\n",
      "time_since_restore: 1274.908395767212\n",
      "time_this_iter_s: 7.110359191894531\n",
      "time_total_s: 1274.908395767212\n",
      "timers:\n",
      "  learn_throughput: 1332.219\n",
      "  learn_time_ms: 3002.509\n",
      "  load_throughput: 24039570.139\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 575.964\n",
      "  sample_time_ms: 6944.877\n",
      "  update_time_ms: 2.328\n",
      "timestamp: 1658395222\n",
      "timesteps_since_restore: 724000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 724000\n",
      "training_iteration: 181\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 728000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-31\n",
      "done: false\n",
      "episode_len_mean: 191.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.21\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4018\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 9.466331238810334e-31\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21930086612701416\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035532487090677023\n",
      "        model: {}\n",
      "        policy_loss: -0.0010707746259868145\n",
      "        total_loss: 1.6617457866668701\n",
      "        vf_explained_var: -0.16889245808124542\n",
      "        vf_loss: 1.6628164052963257\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 728000\n",
      "  num_agent_steps_trained: 728000\n",
      "  num_steps_sampled: 728000\n",
      "  num_steps_trained: 728000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 182\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.6\n",
      "  ram_util_percent: 87.0\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06700975669648972\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07703974174527199\n",
      "  mean_inference_ms: 0.7335260239307831\n",
      "  mean_raw_obs_processing_ms: 0.08953245779215266\n",
      "time_since_restore: 1283.5003974437714\n",
      "time_this_iter_s: 8.592001676559448\n",
      "time_total_s: 1283.5003974437714\n",
      "timers:\n",
      "  learn_throughput: 1327.224\n",
      "  learn_time_ms: 3013.809\n",
      "  load_throughput: 23875360.751\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 566.399\n",
      "  sample_time_ms: 7062.158\n",
      "  update_time_ms: 2.397\n",
      "timestamp: 1658395231\n",
      "timesteps_since_restore: 728000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 728000\n",
      "training_iteration: 182\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 732000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-38\n",
      "done: false\n",
      "episode_len_mean: 192.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.99\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4039\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.733165619405167e-31\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23269397020339966\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0046984548680484295\n",
      "        model: {}\n",
      "        policy_loss: 0.0030165272764861584\n",
      "        total_loss: 5.334408283233643\n",
      "        vf_explained_var: -0.05701425299048424\n",
      "        vf_loss: 5.33139181137085\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 732000\n",
      "  num_agent_steps_trained: 732000\n",
      "  num_steps_sampled: 732000\n",
      "  num_steps_trained: 732000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 183\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.50000000000001\n",
      "  ram_util_percent: 87.02727272727272\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0670606716121546\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0770957798970595\n",
      "  mean_inference_ms: 0.7340758468382326\n",
      "  mean_raw_obs_processing_ms: 0.08959063274587738\n",
      "time_since_restore: 1290.684063911438\n",
      "time_this_iter_s: 7.183666467666626\n",
      "time_total_s: 1290.684063911438\n",
      "timers:\n",
      "  learn_throughput: 1321.573\n",
      "  learn_time_ms: 3026.695\n",
      "  load_throughput: 23590011.249\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 562.046\n",
      "  sample_time_ms: 7116.857\n",
      "  update_time_ms: 2.428\n",
      "timestamp: 1658395238\n",
      "timesteps_since_restore: 732000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 732000\n",
      "training_iteration: 183\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 736000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-45\n",
      "done: false\n",
      "episode_len_mean: 194.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.28\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4060\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.3665828097025835e-31\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1952301412820816\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002670323010534048\n",
      "        model: {}\n",
      "        policy_loss: -0.005853717681020498\n",
      "        total_loss: 5.648032188415527\n",
      "        vf_explained_var: 0.001046867691911757\n",
      "        vf_loss: 5.653886318206787\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 736000\n",
      "  num_agent_steps_trained: 736000\n",
      "  num_steps_sampled: 736000\n",
      "  num_steps_trained: 736000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 184\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.37777777777777\n",
      "  ram_util_percent: 86.80000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06709509861483415\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07713432720292439\n",
      "  mean_inference_ms: 0.7344597146292398\n",
      "  mean_raw_obs_processing_ms: 0.08962998106803852\n",
      "time_since_restore: 1297.1835463047028\n",
      "time_this_iter_s: 6.4994823932647705\n",
      "time_total_s: 1297.1835463047028\n",
      "timers:\n",
      "  learn_throughput: 1319.861\n",
      "  learn_time_ms: 3030.622\n",
      "  load_throughput: 23649867.494\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 561.848\n",
      "  sample_time_ms: 7119.359\n",
      "  update_time_ms: 2.408\n",
      "timestamp: 1658395245\n",
      "timesteps_since_restore: 736000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 736000\n",
      "training_iteration: 184\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 740000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-52\n",
      "done: false\n",
      "episode_len_mean: 194.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.59\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4080\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.1832914048512917e-31\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1815556138753891\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001725141890347004\n",
      "        model: {}\n",
      "        policy_loss: 0.00825896579772234\n",
      "        total_loss: 7.66971492767334\n",
      "        vf_explained_var: 0.0012958984589204192\n",
      "        vf_loss: 7.6614556312561035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 740000\n",
      "  num_agent_steps_trained: 740000\n",
      "  num_steps_sampled: 740000\n",
      "  num_steps_trained: 740000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 185\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.7\n",
      "  ram_util_percent: 86.66000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06712045496786631\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07716366707557416\n",
      "  mean_inference_ms: 0.7347537647341893\n",
      "  mean_raw_obs_processing_ms: 0.08965941144950022\n",
      "time_since_restore: 1304.0554010868073\n",
      "time_this_iter_s: 6.871854782104492\n",
      "time_total_s: 1304.0554010868073\n",
      "timers:\n",
      "  learn_throughput: 1309.319\n",
      "  learn_time_ms: 3055.023\n",
      "  load_throughput: 24043015.191\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 561.1\n",
      "  sample_time_ms: 7128.851\n",
      "  update_time_ms: 2.323\n",
      "timestamp: 1658395252\n",
      "timesteps_since_restore: 740000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 740000\n",
      "training_iteration: 185\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 744000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-20-58\n",
      "done: false\n",
      "episode_len_mean: 196.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.45\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4100\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.916457024256459e-32\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1829000562429428\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0009081930620595813\n",
      "        model: {}\n",
      "        policy_loss: 0.0051850927993655205\n",
      "        total_loss: 3.7862167358398438\n",
      "        vf_explained_var: 0.0004335165140219033\n",
      "        vf_loss: 3.781031608581543\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 744000\n",
      "  num_agent_steps_trained: 744000\n",
      "  num_steps_sampled: 744000\n",
      "  num_steps_trained: 744000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 186\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.41111111111111\n",
      "  ram_util_percent: 86.67777777777778\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06713510488391881\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07718038240486427\n",
      "  mean_inference_ms: 0.7349364702064233\n",
      "  mean_raw_obs_processing_ms: 0.08967516023071273\n",
      "time_since_restore: 1310.5169780254364\n",
      "time_this_iter_s: 6.46157693862915\n",
      "time_total_s: 1310.5169780254364\n",
      "timers:\n",
      "  learn_throughput: 1306.711\n",
      "  learn_time_ms: 3061.121\n",
      "  load_throughput: 23838044.899\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 561.139\n",
      "  sample_time_ms: 7128.363\n",
      "  update_time_ms: 2.301\n",
      "timestamp: 1658395258\n",
      "timesteps_since_restore: 744000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 744000\n",
      "training_iteration: 186\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 748000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-21-06\n",
      "done: false\n",
      "episode_len_mean: 196.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.45\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4120\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.9582285121282294e-32\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21891768276691437\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0041655804961919785\n",
      "        model: {}\n",
      "        policy_loss: 0.0018483605235815048\n",
      "        total_loss: 3.7831344604492188\n",
      "        vf_explained_var: 0.0014004426775500178\n",
      "        vf_loss: 3.7812862396240234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 748000\n",
      "  num_agent_steps_trained: 748000\n",
      "  num_steps_sampled: 748000\n",
      "  num_steps_trained: 748000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 187\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.1090909090909\n",
      "  ram_util_percent: 86.68181818181819\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06712805848285701\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07717227886570009\n",
      "  mean_inference_ms: 0.7348733118381676\n",
      "  mean_raw_obs_processing_ms: 0.08966217823671144\n",
      "time_since_restore: 1318.3268613815308\n",
      "time_this_iter_s: 7.80988335609436\n",
      "time_total_s: 1318.3268613815308\n",
      "timers:\n",
      "  learn_throughput: 1278.07\n",
      "  learn_time_ms: 3129.72\n",
      "  load_throughput: 23546969.825\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 555.64\n",
      "  sample_time_ms: 7198.911\n",
      "  update_time_ms: 2.335\n",
      "timestamp: 1658395266\n",
      "timesteps_since_restore: 748000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 748000\n",
      "training_iteration: 187\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 752000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-21-14\n",
      "done: false\n",
      "episode_len_mean: 194.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.94\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 4142\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.4791142560641147e-32\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25943198800086975\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038213764782994986\n",
      "        model: {}\n",
      "        policy_loss: -0.016491470858454704\n",
      "        total_loss: 7.551692008972168\n",
      "        vf_explained_var: 0.005657917819917202\n",
      "        vf_loss: 7.568182945251465\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 752000\n",
      "  num_agent_steps_trained: 752000\n",
      "  num_steps_sampled: 752000\n",
      "  num_steps_trained: 752000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 188\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.88333333333333\n",
      "  ram_util_percent: 86.64999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06713717653585796\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07718227727289709\n",
      "  mean_inference_ms: 0.7349961093817409\n",
      "  mean_raw_obs_processing_ms: 0.0896730607743969\n",
      "time_since_restore: 1326.29358792305\n",
      "time_this_iter_s: 7.966726541519165\n",
      "time_total_s: 1326.29358792305\n",
      "timers:\n",
      "  learn_throughput: 1281.858\n",
      "  learn_time_ms: 3120.471\n",
      "  load_throughput: 23288750.694\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 540.875\n",
      "  sample_time_ms: 7395.421\n",
      "  update_time_ms: 2.278\n",
      "timestamp: 1658395274\n",
      "timesteps_since_restore: 752000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 752000\n",
      "training_iteration: 188\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 756000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-21-21\n",
      "done: false\n",
      "episode_len_mean: 193.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.28\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4163\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.395571280320573e-33\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24980635941028595\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004788488149642944\n",
      "        model: {}\n",
      "        policy_loss: -0.002347373403608799\n",
      "        total_loss: 2.230950117111206\n",
      "        vf_explained_var: -0.18950697779655457\n",
      "        vf_loss: 2.23329758644104\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 756000\n",
      "  num_agent_steps_trained: 756000\n",
      "  num_steps_sampled: 756000\n",
      "  num_steps_trained: 756000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 189\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.62\n",
      "  ram_util_percent: 86.61000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06715306906136727\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07720016183589493\n",
      "  mean_inference_ms: 0.7351878097603637\n",
      "  mean_raw_obs_processing_ms: 0.08969289487855074\n",
      "time_since_restore: 1333.5093791484833\n",
      "time_this_iter_s: 7.21579122543335\n",
      "time_total_s: 1333.5093791484833\n",
      "timers:\n",
      "  learn_throughput: 1290.392\n",
      "  learn_time_ms: 3099.833\n",
      "  load_throughput: 23324365.355\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 544.922\n",
      "  sample_time_ms: 7340.5\n",
      "  update_time_ms: 2.259\n",
      "timestamp: 1658395281\n",
      "timesteps_since_restore: 756000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 756000\n",
      "training_iteration: 189\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 760000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-21-29\n",
      "done: false\n",
      "episode_len_mean: 193.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.37\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4183\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.697785640160287e-33\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23350292444229126\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035135066136717796\n",
      "        model: {}\n",
      "        policy_loss: 0.0009888523491099477\n",
      "        total_loss: 3.1572396755218506\n",
      "        vf_explained_var: -0.13679088652133942\n",
      "        vf_loss: 3.1562509536743164\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 760000\n",
      "  num_agent_steps_trained: 760000\n",
      "  num_steps_sampled: 760000\n",
      "  num_steps_trained: 760000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 190\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.46363636363636\n",
      "  ram_util_percent: 86.37272727272727\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06717265150803868\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07722224728438362\n",
      "  mean_inference_ms: 0.7354121849552218\n",
      "  mean_raw_obs_processing_ms: 0.08971751241595144\n",
      "time_since_restore: 1341.207410812378\n",
      "time_this_iter_s: 7.698031663894653\n",
      "time_total_s: 1341.207410812378\n",
      "timers:\n",
      "  learn_throughput: 1265.926\n",
      "  learn_time_ms: 3159.742\n",
      "  load_throughput: 23125039.283\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 547.78\n",
      "  sample_time_ms: 7302.207\n",
      "  update_time_ms: 2.166\n",
      "timestamp: 1658395289\n",
      "timesteps_since_restore: 760000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 760000\n",
      "training_iteration: 190\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 764000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-21-36\n",
      "done: false\n",
      "episode_len_mean: 185.13\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.13\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 25\n",
      "episodes_total: 4208\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.8488928200801433e-33\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2601540982723236\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037602530792355537\n",
      "        model: {}\n",
      "        policy_loss: -0.012561540119349957\n",
      "        total_loss: 4.610103130340576\n",
      "        vf_explained_var: 0.003480454906821251\n",
      "        vf_loss: 4.622664451599121\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 764000\n",
      "  num_agent_steps_trained: 764000\n",
      "  num_steps_sampled: 764000\n",
      "  num_steps_trained: 764000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 191\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.29\n",
      "  ram_util_percent: 86.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06719869805043369\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07725052048707058\n",
      "  mean_inference_ms: 0.7357007234490835\n",
      "  mean_raw_obs_processing_ms: 0.08975206107302437\n",
      "time_since_restore: 1348.2073802947998\n",
      "time_this_iter_s: 6.999969482421875\n",
      "time_total_s: 1348.2073802947998\n",
      "timers:\n",
      "  learn_throughput: 1263.862\n",
      "  learn_time_ms: 3164.901\n",
      "  load_throughput: 23279056.473\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 544.623\n",
      "  sample_time_ms: 7344.531\n",
      "  update_time_ms: 2.15\n",
      "timestamp: 1658395296\n",
      "timesteps_since_restore: 764000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 764000\n",
      "training_iteration: 191\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 768000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-21-43\n",
      "done: false\n",
      "episode_len_mean: 182.63\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 182.63\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4229\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 9.244464100400717e-34\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24478267133235931\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034239895176142454\n",
      "        model: {}\n",
      "        policy_loss: 0.0013547325506806374\n",
      "        total_loss: 4.334989547729492\n",
      "        vf_explained_var: -0.02828875742852688\n",
      "        vf_loss: 4.333634853363037\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 768000\n",
      "  num_agent_steps_trained: 768000\n",
      "  num_steps_sampled: 768000\n",
      "  num_steps_trained: 768000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 192\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.279999999999994\n",
      "  ram_util_percent: 86.42999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06720704889137893\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07725789582961386\n",
      "  mean_inference_ms: 0.73578145772544\n",
      "  mean_raw_obs_processing_ms: 0.08976363053875466\n",
      "time_since_restore: 1355.3544125556946\n",
      "time_this_iter_s: 7.147032260894775\n",
      "time_total_s: 1355.3544125556946\n",
      "timers:\n",
      "  learn_throughput: 1250.532\n",
      "  learn_time_ms: 3198.64\n",
      "  load_throughput: 22838573.373\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 557.772\n",
      "  sample_time_ms: 7171.392\n",
      "  update_time_ms: 2.085\n",
      "timestamp: 1658395303\n",
      "timesteps_since_restore: 768000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 768000\n",
      "training_iteration: 192\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 772000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-21-50\n",
      "done: false\n",
      "episode_len_mean: 183.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 183.69\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 4251\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.622232050200358e-34\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23055854439735413\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002393718110397458\n",
      "        model: {}\n",
      "        policy_loss: -0.013321386650204659\n",
      "        total_loss: 5.274706840515137\n",
      "        vf_explained_var: 0.02319752238690853\n",
      "        vf_loss: 5.288028717041016\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 772000\n",
      "  num_agent_steps_trained: 772000\n",
      "  num_steps_sampled: 772000\n",
      "  num_steps_trained: 772000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 193\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.63333333333334\n",
      "  ram_util_percent: 86.53333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0671990586974204\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0772468663952481\n",
      "  mean_inference_ms: 0.7356831433676541\n",
      "  mean_raw_obs_processing_ms: 0.08975268392355669\n",
      "time_since_restore: 1361.8326692581177\n",
      "time_this_iter_s: 6.478256702423096\n",
      "time_total_s: 1361.8326692581177\n",
      "timers:\n",
      "  learn_throughput: 1261.444\n",
      "  learn_time_ms: 3170.97\n",
      "  load_throughput: 22938496.035\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 558.475\n",
      "  sample_time_ms: 7162.363\n",
      "  update_time_ms: 2.02\n",
      "timestamp: 1658395310\n",
      "timesteps_since_restore: 772000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 772000\n",
      "training_iteration: 193\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 776000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-21-57\n",
      "done: false\n",
      "episode_len_mean: 184.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.44\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4271\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.311116025100179e-34\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2203604131937027\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002254790160804987\n",
      "        model: {}\n",
      "        policy_loss: 0.00908250454813242\n",
      "        total_loss: 8.605448722839355\n",
      "        vf_explained_var: 0.010611203499138355\n",
      "        vf_loss: 8.596366882324219\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 776000\n",
      "  num_agent_steps_trained: 776000\n",
      "  num_steps_sampled: 776000\n",
      "  num_steps_trained: 776000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 194\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.26666666666666\n",
      "  ram_util_percent: 86.88333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06720259333899878\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07724823429969536\n",
      "  mean_inference_ms: 0.7357047745892262\n",
      "  mean_raw_obs_processing_ms: 0.08975522443965002\n",
      "time_since_restore: 1369.7044582366943\n",
      "time_this_iter_s: 7.87178897857666\n",
      "time_total_s: 1369.7044582366943\n",
      "timers:\n",
      "  learn_throughput: 1245.321\n",
      "  learn_time_ms: 3212.022\n",
      "  load_throughput: 22034693.985\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 553.206\n",
      "  sample_time_ms: 7230.577\n",
      "  update_time_ms: 2.055\n",
      "timestamp: 1658395317\n",
      "timesteps_since_restore: 776000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 776000\n",
      "training_iteration: 194\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 780000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-22-04\n",
      "done: false\n",
      "episode_len_mean: 187.34\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.34\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4291\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.1555580125500896e-34\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21364638209342957\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002220410853624344\n",
      "        model: {}\n",
      "        policy_loss: 0.004311231430619955\n",
      "        total_loss: 5.117559432983398\n",
      "        vf_explained_var: -0.05782508850097656\n",
      "        vf_loss: 5.113248348236084\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 780000\n",
      "  num_agent_steps_trained: 780000\n",
      "  num_steps_sampled: 780000\n",
      "  num_steps_trained: 780000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 195\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.96\n",
      "  ram_util_percent: 86.97\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0672045212031224\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07724809542119691\n",
      "  mean_inference_ms: 0.7357180635832813\n",
      "  mean_raw_obs_processing_ms: 0.08975529586967675\n",
      "time_since_restore: 1376.6135938167572\n",
      "time_this_iter_s: 6.909135580062866\n",
      "time_total_s: 1376.6135938167572\n",
      "timers:\n",
      "  learn_throughput: 1245.991\n",
      "  learn_time_ms: 3210.295\n",
      "  load_throughput: 21833961.478\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 549.558\n",
      "  sample_time_ms: 7278.571\n",
      "  update_time_ms: 2.046\n",
      "timestamp: 1658395324\n",
      "timesteps_since_restore: 780000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 780000\n",
      "training_iteration: 195\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 784000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-22-11\n",
      "done: false\n",
      "episode_len_mean: 193.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.52\n",
      "episode_reward_min: 104.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4311\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.777790062750448e-35\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24649350345134735\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0022952354047447443\n",
      "        model: {}\n",
      "        policy_loss: 0.00079822022235021\n",
      "        total_loss: 1.6438907384872437\n",
      "        vf_explained_var: -0.05819309875369072\n",
      "        vf_loss: 1.6430925130844116\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 784000\n",
      "  num_agent_steps_trained: 784000\n",
      "  num_steps_sampled: 784000\n",
      "  num_steps_trained: 784000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 196\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.699999999999996\n",
      "  ram_util_percent: 86.83\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06720728717144611\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07724887143878037\n",
      "  mean_inference_ms: 0.7357378387215663\n",
      "  mean_raw_obs_processing_ms: 0.08975493566523408\n",
      "time_since_restore: 1383.6225595474243\n",
      "time_this_iter_s: 7.008965730667114\n",
      "time_total_s: 1383.6225595474243\n",
      "timers:\n",
      "  learn_throughput: 1236.304\n",
      "  learn_time_ms: 3235.451\n",
      "  load_throughput: 21994252.753\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 547.463\n",
      "  sample_time_ms: 7306.43\n",
      "  update_time_ms: 2.135\n",
      "timestamp: 1658395331\n",
      "timesteps_since_restore: 784000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 784000\n",
      "training_iteration: 196\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 788000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-22-18\n",
      "done: false\n",
      "episode_len_mean: 196.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.39\n",
      "episode_reward_min: 104.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4331\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.888895031375224e-35\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2057199478149414\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002968104090541601\n",
      "        model: {}\n",
      "        policy_loss: -0.001492289244197309\n",
      "        total_loss: 0.31851091980934143\n",
      "        vf_explained_var: -0.13383807241916656\n",
      "        vf_loss: 0.3200032114982605\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 788000\n",
      "  num_agent_steps_trained: 788000\n",
      "  num_steps_sampled: 788000\n",
      "  num_steps_trained: 788000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 197\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.88\n",
      "  ram_util_percent: 86.9\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06720976907110073\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07724988554866215\n",
      "  mean_inference_ms: 0.7357616558807872\n",
      "  mean_raw_obs_processing_ms: 0.08975470209993688\n",
      "time_since_restore: 1390.5850455760956\n",
      "time_this_iter_s: 6.962486028671265\n",
      "time_total_s: 1390.5850455760956\n",
      "timers:\n",
      "  learn_throughput: 1251.362\n",
      "  learn_time_ms: 3196.517\n",
      "  load_throughput: 22151064.167\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 548.975\n",
      "  sample_time_ms: 7286.306\n",
      "  update_time_ms: 2.099\n",
      "timestamp: 1658395338\n",
      "timesteps_since_restore: 788000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 788000\n",
      "training_iteration: 197\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 792000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-22-26\n",
      "done: false\n",
      "episode_len_mean: 198.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.15\n",
      "episode_reward_min: 119.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4351\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.444447515687612e-35\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19836308062076569\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0046638366766273975\n",
      "        model: {}\n",
      "        policy_loss: -0.0020954362116754055\n",
      "        total_loss: 0.3059227168560028\n",
      "        vf_explained_var: -0.23988722264766693\n",
      "        vf_loss: 0.30801814794540405\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 792000\n",
      "  num_agent_steps_trained: 792000\n",
      "  num_steps_sampled: 792000\n",
      "  num_steps_trained: 792000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 198\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.13\n",
      "  ram_util_percent: 86.92\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06722212048607071\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07726227920422322\n",
      "  mean_inference_ms: 0.7359009135831533\n",
      "  mean_raw_obs_processing_ms: 0.08976555794769153\n",
      "time_since_restore: 1397.7554647922516\n",
      "time_this_iter_s: 7.170419216156006\n",
      "time_total_s: 1397.7554647922516\n",
      "timers:\n",
      "  learn_throughput: 1257.981\n",
      "  learn_time_ms: 3179.699\n",
      "  load_throughput: 21948215.594\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 556.709\n",
      "  sample_time_ms: 7185.078\n",
      "  update_time_ms: 2.078\n",
      "timestamp: 1658395346\n",
      "timesteps_since_restore: 792000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 792000\n",
      "training_iteration: 198\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 796000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-22-33\n",
      "done: false\n",
      "episode_len_mean: 198.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.49\n",
      "episode_reward_min: 119.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4371\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.22223757843806e-36\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21534115076065063\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0056336987763643265\n",
      "        model: {}\n",
      "        policy_loss: -0.002203569281846285\n",
      "        total_loss: 0.30186864733695984\n",
      "        vf_explained_var: -0.3220188021659851\n",
      "        vf_loss: 0.30407223105430603\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 796000\n",
      "  num_agent_steps_trained: 796000\n",
      "  num_steps_sampled: 796000\n",
      "  num_steps_trained: 796000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 199\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.410000000000004\n",
      "  ram_util_percent: 86.86\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06721850826631642\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07725711286135066\n",
      "  mean_inference_ms: 0.7358755702049234\n",
      "  mean_raw_obs_processing_ms: 0.08975714577991337\n",
      "time_since_restore: 1404.6891219615936\n",
      "time_this_iter_s: 6.933657169342041\n",
      "time_total_s: 1404.6891219615936\n",
      "timers:\n",
      "  learn_throughput: 1258.11\n",
      "  learn_time_ms: 3179.373\n",
      "  load_throughput: 22037588.336\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 560.206\n",
      "  sample_time_ms: 7140.233\n",
      "  update_time_ms: 2.082\n",
      "timestamp: 1658395353\n",
      "timesteps_since_restore: 796000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 796000\n",
      "training_iteration: 199\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 800000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-22-40\n",
      "done: false\n",
      "episode_len_mean: 199.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.03\n",
      "episode_reward_min: 142.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4392\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 7.22223757843806e-36\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2379661500453949\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002642714651301503\n",
      "        model: {}\n",
      "        policy_loss: 0.006125795654952526\n",
      "        total_loss: 7.108580112457275\n",
      "        vf_explained_var: 0.000687010760884732\n",
      "        vf_loss: 7.102455139160156\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 800000\n",
      "  num_agent_steps_trained: 800000\n",
      "  num_steps_sampled: 800000\n",
      "  num_steps_trained: 800000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 200\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.25454545454546\n",
      "  ram_util_percent: 86.91818181818182\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06722539719643669\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07726292491626055\n",
      "  mean_inference_ms: 0.735949838537597\n",
      "  mean_raw_obs_processing_ms: 0.08976113337470686\n",
      "time_since_restore: 1412.4006066322327\n",
      "time_this_iter_s: 7.711484670639038\n",
      "time_total_s: 1412.4006066322327\n",
      "timers:\n",
      "  learn_throughput: 1273.04\n",
      "  learn_time_ms: 3142.085\n",
      "  load_throughput: 21802749.838\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 557.284\n",
      "  sample_time_ms: 7177.67\n",
      "  update_time_ms: 2.161\n",
      "timestamp: 1658395360\n",
      "timesteps_since_restore: 800000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 800000\n",
      "training_iteration: 200\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 804000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-22-49\n",
      "done: false\n",
      "episode_len_mean: 196.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.42\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4413\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 3.61111878921903e-36\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2146061211824417\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004776685032993555\n",
      "        model: {}\n",
      "        policy_loss: 0.003183728316798806\n",
      "        total_loss: 6.293768882751465\n",
      "        vf_explained_var: 0.0032853318843990564\n",
      "        vf_loss: 6.290585041046143\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 804000\n",
      "  num_agent_steps_trained: 804000\n",
      "  num_steps_sampled: 804000\n",
      "  num_steps_trained: 804000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 201\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.03333333333333\n",
      "  ram_util_percent: 86.875\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06725039051441983\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0772901586144896\n",
      "  mean_inference_ms: 0.7362258751116719\n",
      "  mean_raw_obs_processing_ms: 0.08978739660075054\n",
      "time_since_restore: 1420.9749295711517\n",
      "time_this_iter_s: 8.574322938919067\n",
      "time_total_s: 1420.9749295711517\n",
      "timers:\n",
      "  learn_throughput: 1253.702\n",
      "  learn_time_ms: 3190.552\n",
      "  load_throughput: 21512009.232\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 551.692\n",
      "  sample_time_ms: 7250.421\n",
      "  update_time_ms: 2.167\n",
      "timestamp: 1658395369\n",
      "timesteps_since_restore: 804000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 804000\n",
      "training_iteration: 201\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000201/checkpoint-201\n",
      "agent_timesteps_total: 808000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-22-56\n",
      "done: false\n",
      "episode_len_mean: 195.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.05\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4434\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.805559394609515e-36\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1880127340555191\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002392211463302374\n",
      "        model: {}\n",
      "        policy_loss: 0.004649516195058823\n",
      "        total_loss: 5.63484001159668\n",
      "        vf_explained_var: 0.0011143172159790993\n",
      "        vf_loss: 5.630190372467041\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 808000\n",
      "  num_agent_steps_trained: 808000\n",
      "  num_steps_sampled: 808000\n",
      "  num_steps_trained: 808000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 202\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.88\n",
      "  ram_util_percent: 86.88\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06728101903285992\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07732446506343865\n",
      "  mean_inference_ms: 0.7365669095225721\n",
      "  mean_raw_obs_processing_ms: 0.0898201984027871\n",
      "time_since_restore: 1428.0991127490997\n",
      "time_this_iter_s: 7.124183177947998\n",
      "time_total_s: 1428.0991127490997\n",
      "timers:\n",
      "  learn_throughput: 1269.992\n",
      "  learn_time_ms: 3149.626\n",
      "  load_throughput: 21819763.298\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 545.043\n",
      "  sample_time_ms: 7338.866\n",
      "  update_time_ms: 2.164\n",
      "timestamp: 1658395376\n",
      "timesteps_since_restore: 808000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 808000\n",
      "training_iteration: 202\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 812000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-03\n",
      "done: false\n",
      "episode_len_mean: 194.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.44\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4454\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 9.027796973047575e-37\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21146512031555176\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025675545912235975\n",
      "        model: {}\n",
      "        policy_loss: 0.004805356729775667\n",
      "        total_loss: 5.447288513183594\n",
      "        vf_explained_var: 0.001601165859028697\n",
      "        vf_loss: 5.442482948303223\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 812000\n",
      "  num_agent_steps_trained: 812000\n",
      "  num_steps_sampled: 812000\n",
      "  num_steps_trained: 812000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 203\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.31\n",
      "  ram_util_percent: 86.81\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06730532703147021\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07735149016221471\n",
      "  mean_inference_ms: 0.7368311523406642\n",
      "  mean_raw_obs_processing_ms: 0.08984659500849008\n",
      "time_since_restore: 1434.9361517429352\n",
      "time_this_iter_s: 6.837038993835449\n",
      "time_total_s: 1434.9361517429352\n",
      "timers:\n",
      "  learn_throughput: 1264.804\n",
      "  learn_time_ms: 3162.545\n",
      "  load_throughput: 21734960.487\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 546.376\n",
      "  sample_time_ms: 7320.962\n",
      "  update_time_ms: 2.16\n",
      "timestamp: 1658395383\n",
      "timesteps_since_restore: 812000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 812000\n",
      "training_iteration: 203\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 816000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-09\n",
      "done: false\n",
      "episode_len_mean: 194.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.44\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4475\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 4.5138984865237875e-37\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19387607276439667\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027161394245922565\n",
      "        model: {}\n",
      "        policy_loss: -0.012251688167452812\n",
      "        total_loss: 5.066052436828613\n",
      "        vf_explained_var: -0.09516052156686783\n",
      "        vf_loss: 5.078303813934326\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 816000\n",
      "  num_agent_steps_trained: 816000\n",
      "  num_steps_sampled: 816000\n",
      "  num_steps_trained: 816000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 204\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.56666666666667\n",
      "  ram_util_percent: 87.12222222222223\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06732709251490973\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07737653670843288\n",
      "  mean_inference_ms: 0.7370688095849696\n",
      "  mean_raw_obs_processing_ms: 0.08987002513690694\n",
      "time_since_restore: 1441.4076850414276\n",
      "time_this_iter_s: 6.471533298492432\n",
      "time_total_s: 1441.4076850414276\n",
      "timers:\n",
      "  learn_throughput: 1283.79\n",
      "  learn_time_ms: 3115.774\n",
      "  load_throughput: 22727195.882\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 552.442\n",
      "  sample_time_ms: 7240.584\n",
      "  update_time_ms: 2.165\n",
      "timestamp: 1658395389\n",
      "timesteps_since_restore: 816000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 816000\n",
      "training_iteration: 204\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 820000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-16\n",
      "done: false\n",
      "episode_len_mean: 191.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.68\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4496\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.2569492432618937e-37\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2217019647359848\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032453062012791634\n",
      "        model: {}\n",
      "        policy_loss: 0.0054886904545128345\n",
      "        total_loss: 6.883082389831543\n",
      "        vf_explained_var: 0.0030174655839800835\n",
      "        vf_loss: 6.877593517303467\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 820000\n",
      "  num_agent_steps_trained: 820000\n",
      "  num_steps_sampled: 820000\n",
      "  num_steps_trained: 820000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 205\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.869999999999997\n",
      "  ram_util_percent: 87.02000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06733286967155204\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07738374110292633\n",
      "  mean_inference_ms: 0.7371341222052763\n",
      "  mean_raw_obs_processing_ms: 0.089873927343899\n",
      "time_since_restore: 1447.8273122310638\n",
      "time_this_iter_s: 6.4196271896362305\n",
      "time_total_s: 1447.8273122310638\n",
      "timers:\n",
      "  learn_throughput: 1293.346\n",
      "  learn_time_ms: 3092.753\n",
      "  load_throughput: 22668850.155\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 558.093\n",
      "  sample_time_ms: 7167.262\n",
      "  update_time_ms: 2.131\n",
      "timestamp: 1658395396\n",
      "timesteps_since_restore: 820000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 820000\n",
      "training_iteration: 205\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 824000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-22\n",
      "done: false\n",
      "episode_len_mean: 193.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.11\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4517\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.1284746216309469e-37\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2256002426147461\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030327944550663233\n",
      "        model: {}\n",
      "        policy_loss: 0.0016657583182677627\n",
      "        total_loss: 4.669269561767578\n",
      "        vf_explained_var: -0.12818032503128052\n",
      "        vf_loss: 4.667603969573975\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 824000\n",
      "  num_agent_steps_trained: 824000\n",
      "  num_steps_sampled: 824000\n",
      "  num_steps_trained: 824000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 206\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.533333333333335\n",
      "  ram_util_percent: 86.83333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0673186165107534\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07736798791504759\n",
      "  mean_inference_ms: 0.7369957272213189\n",
      "  mean_raw_obs_processing_ms: 0.08985550752781662\n",
      "time_since_restore: 1454.4254562854767\n",
      "time_this_iter_s: 6.598144054412842\n",
      "time_total_s: 1454.4254562854767\n",
      "timers:\n",
      "  learn_throughput: 1304.249\n",
      "  learn_time_ms: 3066.899\n",
      "  load_throughput: 21888083.496\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 561.066\n",
      "  sample_time_ms: 7129.285\n",
      "  update_time_ms: 2.084\n",
      "timestamp: 1658395402\n",
      "timesteps_since_restore: 824000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 824000\n",
      "training_iteration: 206\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 828000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-29\n",
      "done: false\n",
      "episode_len_mean: 192.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.46\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4538\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 5.642373108154734e-38\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22119693458080292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035376902669668198\n",
      "        model: {}\n",
      "        policy_loss: 0.0019252632046118379\n",
      "        total_loss: 4.266244411468506\n",
      "        vf_explained_var: -0.12749792635440826\n",
      "        vf_loss: 4.26431941986084\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 828000\n",
      "  num_agent_steps_trained: 828000\n",
      "  num_steps_sampled: 828000\n",
      "  num_steps_trained: 828000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 207\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.266666666666666\n",
      "  ram_util_percent: 86.75555555555556\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06729555009939696\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07734218550326165\n",
      "  mean_inference_ms: 0.7367548466518586\n",
      "  mean_raw_obs_processing_ms: 0.08982649021189143\n",
      "time_since_restore: 1461.0097346305847\n",
      "time_this_iter_s: 6.584278345108032\n",
      "time_total_s: 1461.0097346305847\n",
      "timers:\n",
      "  learn_throughput: 1311.686\n",
      "  learn_time_ms: 3049.51\n",
      "  load_throughput: 22020233.626\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 564.756\n",
      "  sample_time_ms: 7082.711\n",
      "  update_time_ms: 2.055\n",
      "timestamp: 1658395409\n",
      "timesteps_since_restore: 828000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 828000\n",
      "training_iteration: 207\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 832000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-36\n",
      "done: false\n",
      "episode_len_mean: 191.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.61\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4558\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 2.821186554077367e-38\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25934627652168274\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026584696024656296\n",
      "        model: {}\n",
      "        policy_loss: 0.002371532376855612\n",
      "        total_loss: 3.5987930297851562\n",
      "        vf_explained_var: -0.19406870007514954\n",
      "        vf_loss: 3.596421480178833\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 832000\n",
      "  num_agent_steps_trained: 832000\n",
      "  num_steps_sampled: 832000\n",
      "  num_steps_trained: 832000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 208\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.36999999999999\n",
      "  ram_util_percent: 86.85\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06726948242362407\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0773131378275541\n",
      "  mean_inference_ms: 0.7364837102869862\n",
      "  mean_raw_obs_processing_ms: 0.08979358250878348\n",
      "time_since_restore: 1467.6044080257416\n",
      "time_this_iter_s: 6.59467339515686\n",
      "time_total_s: 1467.6044080257416\n",
      "timers:\n",
      "  learn_throughput: 1307.268\n",
      "  learn_time_ms: 3059.817\n",
      "  load_throughput: 22159841.5\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 571.749\n",
      "  sample_time_ms: 6996.08\n",
      "  update_time_ms: 2.113\n",
      "timestamp: 1658395416\n",
      "timesteps_since_restore: 832000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 832000\n",
      "training_iteration: 208\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 836000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-42\n",
      "done: false\n",
      "episode_len_mean: 191.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.45\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4579\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 1.4105932770386836e-38\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26466822624206543\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004388903733342886\n",
      "        model: {}\n",
      "        policy_loss: -0.004431466106325388\n",
      "        total_loss: 1.4349066019058228\n",
      "        vf_explained_var: -0.20362518727779388\n",
      "        vf_loss: 1.439337968826294\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 836000\n",
      "  num_agent_steps_trained: 836000\n",
      "  num_steps_sampled: 836000\n",
      "  num_steps_trained: 836000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 209\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.88888888888889\n",
      "  ram_util_percent: 86.83333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06724595202476566\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07728680493227859\n",
      "  mean_inference_ms: 0.7362419440221621\n",
      "  mean_raw_obs_processing_ms: 0.08976461207185299\n",
      "time_since_restore: 1474.3797907829285\n",
      "time_this_iter_s: 6.77538275718689\n",
      "time_total_s: 1474.3797907829285\n",
      "timers:\n",
      "  learn_throughput: 1319.938\n",
      "  learn_time_ms: 3030.444\n",
      "  load_throughput: 21746229.423\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 569.786\n",
      "  sample_time_ms: 7020.178\n",
      "  update_time_ms: 2.072\n",
      "timestamp: 1658395422\n",
      "timesteps_since_restore: 836000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 836000\n",
      "training_iteration: 209\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 840000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-49\n",
      "done: false\n",
      "episode_len_mean: 192.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.1\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4600\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2303200364112854\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003341386094689369\n",
      "        model: {}\n",
      "        policy_loss: 0.008983490988612175\n",
      "        total_loss: 9.137008666992188\n",
      "        vf_explained_var: 0.0005121759022586048\n",
      "        vf_loss: 9.128024101257324\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 840000\n",
      "  num_agent_steps_trained: 840000\n",
      "  num_steps_sampled: 840000\n",
      "  num_steps_trained: 840000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 210\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.650000000000006\n",
      "  ram_util_percent: 86.85000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06722140772771702\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07725946474588741\n",
      "  mean_inference_ms: 0.7359897627612129\n",
      "  mean_raw_obs_processing_ms: 0.0897346921539452\n",
      "time_since_restore: 1480.7237479686737\n",
      "time_this_iter_s: 6.343957185745239\n",
      "time_total_s: 1480.7237479686737\n",
      "timers:\n",
      "  learn_throughput: 1344.332\n",
      "  learn_time_ms: 2975.455\n",
      "  load_throughput: 22206771.674\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 578.962\n",
      "  sample_time_ms: 6908.921\n",
      "  update_time_ms: 2.052\n",
      "timestamp: 1658395429\n",
      "timesteps_since_restore: 840000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 840000\n",
      "training_iteration: 210\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 844000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-23-55\n",
      "done: false\n",
      "episode_len_mean: 194.43\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.43\n",
      "episode_reward_min: 76.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4620\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.281157910823822\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035929412115365267\n",
      "        model: {}\n",
      "        policy_loss: 0.0032333876006305218\n",
      "        total_loss: 5.15457820892334\n",
      "        vf_explained_var: 0.005211960524320602\n",
      "        vf_loss: 5.1513447761535645\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 844000\n",
      "  num_agent_steps_trained: 844000\n",
      "  num_steps_sampled: 844000\n",
      "  num_steps_trained: 844000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 211\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 30.955555555555552\n",
      "  ram_util_percent: 86.87777777777778\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06719688884722322\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07723203516646213\n",
      "  mean_inference_ms: 0.7357272737238841\n",
      "  mean_raw_obs_processing_ms: 0.08970337152141937\n",
      "time_since_restore: 1487.1249837875366\n",
      "time_this_iter_s: 6.401235818862915\n",
      "time_total_s: 1487.1249837875366\n",
      "timers:\n",
      "  learn_throughput: 1385.266\n",
      "  learn_time_ms: 2887.532\n",
      "  load_throughput: 22690311.063\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 594.863\n",
      "  sample_time_ms: 6724.239\n",
      "  update_time_ms: 2.051\n",
      "timestamp: 1658395435\n",
      "timesteps_since_restore: 844000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 844000\n",
      "training_iteration: 211\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 848000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-02\n",
      "done: false\n",
      "episode_len_mean: 193.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.09\n",
      "episode_reward_min: 76.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4641\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2952084541320801\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0056982822716236115\n",
      "        model: {}\n",
      "        policy_loss: 0.0008641545427963138\n",
      "        total_loss: 3.6993916034698486\n",
      "        vf_explained_var: -0.08008557558059692\n",
      "        vf_loss: 3.6985273361206055\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 848000\n",
      "  num_agent_steps_trained: 848000\n",
      "  num_steps_sampled: 848000\n",
      "  num_steps_trained: 848000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 212\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.555555555555557\n",
      "  ram_util_percent: 86.83333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06717228011312948\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07720418447080324\n",
      "  mean_inference_ms: 0.7354716274015038\n",
      "  mean_raw_obs_processing_ms: 0.08967189748135534\n",
      "time_since_restore: 1493.6662883758545\n",
      "time_this_iter_s: 6.541304588317871\n",
      "time_total_s: 1493.6662883758545\n",
      "timers:\n",
      "  learn_throughput: 1388.557\n",
      "  learn_time_ms: 2880.688\n",
      "  load_throughput: 22638262.043\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 607.569\n",
      "  sample_time_ms: 6583.617\n",
      "  update_time_ms: 2.064\n",
      "timestamp: 1658395442\n",
      "timesteps_since_restore: 848000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 848000\n",
      "training_iteration: 212\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 852000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-09\n",
      "done: false\n",
      "episode_len_mean: 193.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.46\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4662\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2696135938167572\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023060347884893417\n",
      "        model: {}\n",
      "        policy_loss: 0.003315290668979287\n",
      "        total_loss: 3.6561665534973145\n",
      "        vf_explained_var: -0.06192370131611824\n",
      "        vf_loss: 3.6528513431549072\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 852000\n",
      "  num_agent_steps_trained: 852000\n",
      "  num_steps_sampled: 852000\n",
      "  num_steps_trained: 852000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 213\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.39999999999999\n",
      "  ram_util_percent: 86.86\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06714700963692026\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0771753260857745\n",
      "  mean_inference_ms: 0.7352054015366033\n",
      "  mean_raw_obs_processing_ms: 0.08963981657163067\n",
      "time_since_restore: 1500.5919890403748\n",
      "time_this_iter_s: 6.925700664520264\n",
      "time_total_s: 1500.5919890403748\n",
      "timers:\n",
      "  learn_throughput: 1368.399\n",
      "  learn_time_ms: 2923.124\n",
      "  load_throughput: 22635207.771\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 611.355\n",
      "  sample_time_ms: 6542.846\n",
      "  update_time_ms: 2.141\n",
      "timestamp: 1658395449\n",
      "timesteps_since_restore: 852000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 852000\n",
      "training_iteration: 213\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 856000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-15\n",
      "done: false\n",
      "episode_len_mean: 195.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.7\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4682\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24857263267040253\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002827715128660202\n",
      "        model: {}\n",
      "        policy_loss: 0.00868130475282669\n",
      "        total_loss: 7.77083158493042\n",
      "        vf_explained_var: 0.001778641133569181\n",
      "        vf_loss: 7.762150287628174\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 856000\n",
      "  num_agent_steps_trained: 856000\n",
      "  num_steps_sampled: 856000\n",
      "  num_steps_trained: 856000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 214\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.02222222222222\n",
      "  ram_util_percent: 86.85555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06711561134238192\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07713943139975302\n",
      "  mean_inference_ms: 0.7348768482568855\n",
      "  mean_raw_obs_processing_ms: 0.08959978175267168\n",
      "time_since_restore: 1506.7329392433167\n",
      "time_this_iter_s: 6.1409502029418945\n",
      "time_total_s: 1506.7329392433167\n",
      "timers:\n",
      "  learn_throughput: 1371.237\n",
      "  learn_time_ms: 2917.075\n",
      "  load_throughput: 22559117.924\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 609.864\n",
      "  sample_time_ms: 6558.84\n",
      "  update_time_ms: 2.115\n",
      "timestamp: 1658395455\n",
      "timesteps_since_restore: 856000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 856000\n",
      "training_iteration: 214\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 860000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-21\n",
      "done: false\n",
      "episode_len_mean: 195.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.2\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4702\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2590614855289459\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005280892364680767\n",
      "        model: {}\n",
      "        policy_loss: 0.0005739354528486729\n",
      "        total_loss: 4.539699077606201\n",
      "        vf_explained_var: -0.028984783217310905\n",
      "        vf_loss: 4.539124965667725\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 860000\n",
      "  num_agent_steps_trained: 860000\n",
      "  num_steps_sampled: 860000\n",
      "  num_steps_trained: 860000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 215\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.522222222222222\n",
      "  ram_util_percent: 86.83333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06708640945650629\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07710657060019853\n",
      "  mean_inference_ms: 0.7345742043172779\n",
      "  mean_raw_obs_processing_ms: 0.08956221706491764\n",
      "time_since_restore: 1513.2854108810425\n",
      "time_this_iter_s: 6.55247163772583\n",
      "time_total_s: 1513.2854108810425\n",
      "timers:\n",
      "  learn_throughput: 1370.084\n",
      "  learn_time_ms: 2919.529\n",
      "  load_throughput: 22674977.7\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 609.5\n",
      "  sample_time_ms: 6562.753\n",
      "  update_time_ms: 2.155\n",
      "timestamp: 1658395461\n",
      "timesteps_since_restore: 860000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 860000\n",
      "training_iteration: 215\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 864000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-28\n",
      "done: false\n",
      "episode_len_mean: 194.88\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.88\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4723\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2736697494983673\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031908410601317883\n",
      "        model: {}\n",
      "        policy_loss: 0.002098452765494585\n",
      "        total_loss: 3.8054778575897217\n",
      "        vf_explained_var: -0.034648261964321136\n",
      "        vf_loss: 3.8033790588378906\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 864000\n",
      "  num_agent_steps_trained: 864000\n",
      "  num_steps_sampled: 864000\n",
      "  num_steps_trained: 864000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 216\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.06666666666667\n",
      "  ram_util_percent: 86.86666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06705490620246915\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07707106778215315\n",
      "  mean_inference_ms: 0.734245260419178\n",
      "  mean_raw_obs_processing_ms: 0.08952194332470277\n",
      "time_since_restore: 1519.6068649291992\n",
      "time_this_iter_s: 6.321454048156738\n",
      "time_total_s: 1519.6068649291992\n",
      "timers:\n",
      "  learn_throughput: 1373.77\n",
      "  learn_time_ms: 2911.696\n",
      "  load_throughput: 23586694.784\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 611.102\n",
      "  sample_time_ms: 6545.553\n",
      "  update_time_ms: 2.113\n",
      "timestamp: 1658395468\n",
      "timesteps_since_restore: 864000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 864000\n",
      "training_iteration: 216\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 868000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-35\n",
      "done: false\n",
      "episode_len_mean: 194.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.25\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4744\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26485705375671387\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026580938138067722\n",
      "        model: {}\n",
      "        policy_loss: 0.0045021711848676205\n",
      "        total_loss: 6.719325542449951\n",
      "        vf_explained_var: 0.05739815905690193\n",
      "        vf_loss: 6.714822769165039\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 868000\n",
      "  num_agent_steps_trained: 868000\n",
      "  num_steps_sampled: 868000\n",
      "  num_steps_trained: 868000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 217\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.67\n",
      "  ram_util_percent: 86.92\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06702328340854015\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07703556227357727\n",
      "  mean_inference_ms: 0.7339191343078003\n",
      "  mean_raw_obs_processing_ms: 0.08948156688614635\n",
      "time_since_restore: 1526.4105246067047\n",
      "time_this_iter_s: 6.803659677505493\n",
      "time_total_s: 1526.4105246067047\n",
      "timers:\n",
      "  learn_throughput: 1365.851\n",
      "  learn_time_ms: 2928.578\n",
      "  load_throughput: 23520560.774\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 611.366\n",
      "  sample_time_ms: 6542.727\n",
      "  update_time_ms: 2.135\n",
      "timestamp: 1658395475\n",
      "timesteps_since_restore: 868000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 868000\n",
      "training_iteration: 217\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 872000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-41\n",
      "done: false\n",
      "episode_len_mean: 191.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.1\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 4766\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2770167589187622\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004715968854725361\n",
      "        model: {}\n",
      "        policy_loss: 0.0012498501455411315\n",
      "        total_loss: 5.356667995452881\n",
      "        vf_explained_var: -0.014723309315741062\n",
      "        vf_loss: 5.3554182052612305\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 872000\n",
      "  num_agent_steps_trained: 872000\n",
      "  num_steps_sampled: 872000\n",
      "  num_steps_trained: 872000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 218\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.388888888888886\n",
      "  ram_util_percent: 86.93333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06699549079961298\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07700453428944345\n",
      "  mean_inference_ms: 0.7336409434895367\n",
      "  mean_raw_obs_processing_ms: 0.08944619241490027\n",
      "time_since_restore: 1533.1006648540497\n",
      "time_this_iter_s: 6.690140247344971\n",
      "time_total_s: 1533.1006648540497\n",
      "timers:\n",
      "  learn_throughput: 1371.427\n",
      "  learn_time_ms: 2916.67\n",
      "  load_throughput: 23311401.973\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 607.782\n",
      "  sample_time_ms: 6581.304\n",
      "  update_time_ms: 2.07\n",
      "timestamp: 1658395481\n",
      "timesteps_since_restore: 872000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 872000\n",
      "training_iteration: 218\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 876000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-48\n",
      "done: false\n",
      "episode_len_mean: 189.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.35\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4787\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2707856297492981\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0021436766255646944\n",
      "        model: {}\n",
      "        policy_loss: 0.0014816753100603819\n",
      "        total_loss: 3.635564088821411\n",
      "        vf_explained_var: -0.06848843395709991\n",
      "        vf_loss: 3.634082555770874\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 876000\n",
      "  num_agent_steps_trained: 876000\n",
      "  num_steps_sampled: 876000\n",
      "  num_steps_trained: 876000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 219\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.769999999999996\n",
      "  ram_util_percent: 87.03\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06697344285736849\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07698021511460325\n",
      "  mean_inference_ms: 0.7334199352753287\n",
      "  mean_raw_obs_processing_ms: 0.08941855603679688\n",
      "time_since_restore: 1539.545574426651\n",
      "time_this_iter_s: 6.444909572601318\n",
      "time_total_s: 1539.545574426651\n",
      "timers:\n",
      "  learn_throughput: 1378.085\n",
      "  learn_time_ms: 2902.579\n",
      "  load_throughput: 23940091.324\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 610.546\n",
      "  sample_time_ms: 6551.516\n",
      "  update_time_ms: 2.142\n",
      "timestamp: 1658395488\n",
      "timesteps_since_restore: 876000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 876000\n",
      "training_iteration: 219\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 880000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-24-55\n",
      "done: false\n",
      "episode_len_mean: 188.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.1\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4808\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27784213423728943\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028346616309136152\n",
      "        model: {}\n",
      "        policy_loss: 0.001138424384407699\n",
      "        total_loss: 3.1615099906921387\n",
      "        vf_explained_var: -0.06890571117401123\n",
      "        vf_loss: 3.1603715419769287\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 880000\n",
      "  num_agent_steps_trained: 880000\n",
      "  num_steps_sampled: 880000\n",
      "  num_steps_trained: 880000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 220\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.666666666666664\n",
      "  ram_util_percent: 86.88888888888887\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06695031011138917\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07695482045651103\n",
      "  mean_inference_ms: 0.7331880694040208\n",
      "  mean_raw_obs_processing_ms: 0.08938975749345524\n",
      "time_since_restore: 1546.3663573265076\n",
      "time_this_iter_s: 6.820782899856567\n",
      "time_total_s: 1546.3663573265076\n",
      "timers:\n",
      "  learn_throughput: 1356.438\n",
      "  learn_time_ms: 2948.9\n",
      "  load_throughput: 23974301.229\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 611.718\n",
      "  sample_time_ms: 6538.962\n",
      "  update_time_ms: 2.081\n",
      "timestamp: 1658395495\n",
      "timesteps_since_restore: 880000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 880000\n",
      "training_iteration: 220\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 884000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-02\n",
      "done: false\n",
      "episode_len_mean: 190.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.01\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4828\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2679723799228668\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004542177077382803\n",
      "        model: {}\n",
      "        policy_loss: -0.0005669328384101391\n",
      "        total_loss: 2.298013687133789\n",
      "        vf_explained_var: -0.03998217359185219\n",
      "        vf_loss: 2.2985808849334717\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 884000\n",
      "  num_agent_steps_trained: 884000\n",
      "  num_steps_sampled: 884000\n",
      "  num_steps_trained: 884000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 221\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.12727272727272\n",
      "  ram_util_percent: 86.86363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06693440567219114\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07693747253083863\n",
      "  mean_inference_ms: 0.7330376138949762\n",
      "  mean_raw_obs_processing_ms: 0.08936976430703471\n",
      "time_since_restore: 1553.4484267234802\n",
      "time_this_iter_s: 7.082069396972656\n",
      "time_total_s: 1553.4484267234802\n",
      "timers:\n",
      "  learn_throughput: 1342.972\n",
      "  learn_time_ms: 2978.47\n",
      "  load_throughput: 22810626.785\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 603.949\n",
      "  sample_time_ms: 6623.079\n",
      "  update_time_ms: 2.156\n",
      "timestamp: 1658395502\n",
      "timesteps_since_restore: 884000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 884000\n",
      "training_iteration: 221\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 888000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-08\n",
      "done: false\n",
      "episode_len_mean: 191.88\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.88\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4849\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2775252163410187\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0021663152147084475\n",
      "        model: {}\n",
      "        policy_loss: 0.009328552521765232\n",
      "        total_loss: 8.124418258666992\n",
      "        vf_explained_var: 0.0025476040318608284\n",
      "        vf_loss: 8.115090370178223\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 888000\n",
      "  num_agent_steps_trained: 888000\n",
      "  num_steps_sampled: 888000\n",
      "  num_steps_trained: 888000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 222\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.699999999999996\n",
      "  ram_util_percent: 87.03333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06691744648356175\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07691876615209703\n",
      "  mean_inference_ms: 0.7328686841099328\n",
      "  mean_raw_obs_processing_ms: 0.08934878783716936\n",
      "time_since_restore: 1559.9418296813965\n",
      "time_this_iter_s: 6.49340295791626\n",
      "time_total_s: 1559.9418296813965\n",
      "timers:\n",
      "  learn_throughput: 1342.571\n",
      "  learn_time_ms: 2979.358\n",
      "  load_throughput: 22063671.752\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 601.654\n",
      "  sample_time_ms: 6648.336\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658395508\n",
      "timesteps_since_restore: 888000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 888000\n",
      "training_iteration: 222\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 892000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-15\n",
      "done: false\n",
      "episode_len_mean: 194.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.57\n",
      "episode_reward_min: 88.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4869\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26664820313453674\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032008832786232233\n",
      "        model: {}\n",
      "        policy_loss: 0.005661502480506897\n",
      "        total_loss: 6.407847881317139\n",
      "        vf_explained_var: 0.00315521820448339\n",
      "        vf_loss: 6.402186393737793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 892000\n",
      "  num_agent_steps_trained: 892000\n",
      "  num_steps_sampled: 892000\n",
      "  num_steps_trained: 892000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 223\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.72222222222222\n",
      "  ram_util_percent: 86.93333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06689845644455387\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07689789708197735\n",
      "  mean_inference_ms: 0.7326794370871501\n",
      "  mean_raw_obs_processing_ms: 0.08932550368645056\n",
      "time_since_restore: 1566.397569656372\n",
      "time_this_iter_s: 6.455739974975586\n",
      "time_total_s: 1566.397569656372\n",
      "timers:\n",
      "  learn_throughput: 1366.96\n",
      "  learn_time_ms: 2926.201\n",
      "  load_throughput: 22224421.778\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 600.997\n",
      "  sample_time_ms: 6655.612\n",
      "  update_time_ms: 2.073\n",
      "timestamp: 1658395515\n",
      "timesteps_since_restore: 892000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 892000\n",
      "training_iteration: 223\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 896000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-21\n",
      "done: false\n",
      "episode_len_mean: 195.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.78\n",
      "episode_reward_min: 88.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4889\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24240057170391083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00444053253158927\n",
      "        model: {}\n",
      "        policy_loss: 0.000858947285450995\n",
      "        total_loss: 2.409734010696411\n",
      "        vf_explained_var: -0.0016494884621351957\n",
      "        vf_loss: 2.4088752269744873\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 896000\n",
      "  num_agent_steps_trained: 896000\n",
      "  num_steps_sampled: 896000\n",
      "  num_steps_trained: 896000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 224\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.288888888888884\n",
      "  ram_util_percent: 86.92222222222223\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06688007454084287\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07687765152094374\n",
      "  mean_inference_ms: 0.7325033032735199\n",
      "  mean_raw_obs_processing_ms: 0.08930254277418732\n",
      "time_since_restore: 1572.9092283248901\n",
      "time_this_iter_s: 6.511658668518066\n",
      "time_total_s: 1572.9092283248901\n",
      "timers:\n",
      "  learn_throughput: 1366.074\n",
      "  learn_time_ms: 2928.099\n",
      "  load_throughput: 22245049.059\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 602.68\n",
      "  sample_time_ms: 6637.018\n",
      "  update_time_ms: 2.052\n",
      "timestamp: 1658395521\n",
      "timesteps_since_restore: 896000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 896000\n",
      "training_iteration: 224\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 900000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-28\n",
      "done: false\n",
      "episode_len_mean: 196.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.35\n",
      "episode_reward_min: 130.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4910\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24213361740112305\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005525924731045961\n",
      "        model: {}\n",
      "        policy_loss: 0.002507597440853715\n",
      "        total_loss: 5.080609321594238\n",
      "        vf_explained_var: 0.0034998354967683554\n",
      "        vf_loss: 5.078102111816406\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 900000\n",
      "  num_agent_steps_trained: 900000\n",
      "  num_steps_sampled: 900000\n",
      "  num_steps_trained: 900000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 225\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.730000000000004\n",
      "  ram_util_percent: 86.97999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06686155673073291\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07685655991930149\n",
      "  mean_inference_ms: 0.7323281433069928\n",
      "  mean_raw_obs_processing_ms: 0.08928012511950875\n",
      "time_since_restore: 1579.4469287395477\n",
      "time_this_iter_s: 6.537700414657593\n",
      "time_total_s: 1579.4469287395477\n",
      "timers:\n",
      "  learn_throughput: 1364.164\n",
      "  learn_time_ms: 2932.199\n",
      "  load_throughput: 22366639.115\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 603.01\n",
      "  sample_time_ms: 6633.395\n",
      "  update_time_ms: 2.028\n",
      "timestamp: 1658395528\n",
      "timesteps_since_restore: 900000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 900000\n",
      "training_iteration: 225\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 904000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-34\n",
      "done: false\n",
      "episode_len_mean: 197.3\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.3\n",
      "episode_reward_min: 130.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 4930\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24078123271465302\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003152869874611497\n",
      "        model: {}\n",
      "        policy_loss: 0.0032068868167698383\n",
      "        total_loss: 4.591014385223389\n",
      "        vf_explained_var: 0.0008995148236863315\n",
      "        vf_loss: 4.587807655334473\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 904000\n",
      "  num_agent_steps_trained: 904000\n",
      "  num_steps_sampled: 904000\n",
      "  num_steps_trained: 904000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 226\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.633333333333333\n",
      "  ram_util_percent: 86.92222222222222\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0668402159604741\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07683201242069244\n",
      "  mean_inference_ms: 0.7321160940020147\n",
      "  mean_raw_obs_processing_ms: 0.08925374708881387\n",
      "time_since_restore: 1585.9288668632507\n",
      "time_this_iter_s: 6.481938123703003\n",
      "time_total_s: 1585.9288668632507\n",
      "timers:\n",
      "  learn_throughput: 1363.616\n",
      "  learn_time_ms: 2933.377\n",
      "  load_throughput: 22322001.064\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 601.3\n",
      "  sample_time_ms: 6652.259\n",
      "  update_time_ms: 2.038\n",
      "timestamp: 1658395534\n",
      "timesteps_since_restore: 904000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 904000\n",
      "training_iteration: 226\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 908000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-41\n",
      "done: false\n",
      "episode_len_mean: 195.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.12\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4951\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23772650957107544\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023680650629103184\n",
      "        model: {}\n",
      "        policy_loss: 0.0037348726764321327\n",
      "        total_loss: 5.0547051429748535\n",
      "        vf_explained_var: 0.0010483894729986787\n",
      "        vf_loss: 5.050970554351807\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 908000\n",
      "  num_agent_steps_trained: 908000\n",
      "  num_steps_sampled: 908000\n",
      "  num_steps_trained: 908000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 227\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.05\n",
      "  ram_util_percent: 86.97\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06682045769809958\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.076809523540432\n",
      "  mean_inference_ms: 0.7319222532684689\n",
      "  mean_raw_obs_processing_ms: 0.08922911034833043\n",
      "time_since_restore: 1592.8065130710602\n",
      "time_this_iter_s: 6.877646207809448\n",
      "time_total_s: 1592.8065130710602\n",
      "timers:\n",
      "  learn_throughput: 1365.754\n",
      "  learn_time_ms: 2928.784\n",
      "  load_throughput: 21896653.615\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 600.129\n",
      "  sample_time_ms: 6665.236\n",
      "  update_time_ms: 2.08\n",
      "timestamp: 1658395541\n",
      "timesteps_since_restore: 908000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 908000\n",
      "training_iteration: 227\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 912000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-48\n",
      "done: false\n",
      "episode_len_mean: 194.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.7\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 4972\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2416684925556183\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003204474924132228\n",
      "        model: {}\n",
      "        policy_loss: 0.0038338820450007915\n",
      "        total_loss: 5.154930114746094\n",
      "        vf_explained_var: -0.028794942423701286\n",
      "        vf_loss: 5.151096343994141\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 912000\n",
      "  num_agent_steps_trained: 912000\n",
      "  num_steps_sampled: 912000\n",
      "  num_steps_trained: 912000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 228\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.44\n",
      "  ram_util_percent: 86.96000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06680262049070831\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07678888644029744\n",
      "  mean_inference_ms: 0.7317417581882795\n",
      "  mean_raw_obs_processing_ms: 0.0892062027390368\n",
      "time_since_restore: 1599.876974105835\n",
      "time_this_iter_s: 7.07046103477478\n",
      "time_total_s: 1599.876974105835\n",
      "timers:\n",
      "  learn_throughput: 1342.792\n",
      "  learn_time_ms: 2978.868\n",
      "  load_throughput: 21285480.842\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 601.568\n",
      "  sample_time_ms: 6649.285\n",
      "  update_time_ms: 2.155\n",
      "timestamp: 1658395548\n",
      "timesteps_since_restore: 912000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 912000\n",
      "training_iteration: 228\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 916000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-25-59\n",
      "done: false\n",
      "episode_len_mean: 191.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.04\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 4994\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26737362146377563\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00538723124191165\n",
      "        model: {}\n",
      "        policy_loss: 0.0004201099509373307\n",
      "        total_loss: 5.0801496505737305\n",
      "        vf_explained_var: -0.057537276297807693\n",
      "        vf_loss: 5.079729080200195\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 916000\n",
      "  num_agent_steps_trained: 916000\n",
      "  num_steps_sampled: 916000\n",
      "  num_steps_trained: 916000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 229\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 59.14666666666667\n",
      "  ram_util_percent: 87.31999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06681907712022467\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07680661062955689\n",
      "  mean_inference_ms: 0.7319176622460213\n",
      "  mean_raw_obs_processing_ms: 0.08922438772842563\n",
      "time_since_restore: 1610.3945806026459\n",
      "time_this_iter_s: 10.517606496810913\n",
      "time_total_s: 1610.3945806026459\n",
      "timers:\n",
      "  learn_throughput: 1257.809\n",
      "  learn_time_ms: 3180.133\n",
      "  load_throughput: 20697281.026\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 579.282\n",
      "  sample_time_ms: 6905.094\n",
      "  update_time_ms: 2.133\n",
      "timestamp: 1658395559\n",
      "timesteps_since_restore: 916000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 916000\n",
      "training_iteration: 229\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 920000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-26-07\n",
      "done: false\n",
      "episode_len_mean: 190.88\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.88\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5015\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2180083990097046\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002680582692846656\n",
      "        model: {}\n",
      "        policy_loss: -0.0053065745159983635\n",
      "        total_loss: 4.315977096557617\n",
      "        vf_explained_var: -0.03991534188389778\n",
      "        vf_loss: 4.32128381729126\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 920000\n",
      "  num_agent_steps_trained: 920000\n",
      "  num_steps_sampled: 920000\n",
      "  num_steps_trained: 920000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 230\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.918181818181814\n",
      "  ram_util_percent: 87.17272727272726\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06685301204047012\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07684368192923718\n",
      "  mean_inference_ms: 0.732271763106964\n",
      "  mean_raw_obs_processing_ms: 0.08926343764735789\n",
      "time_since_restore: 1618.2030997276306\n",
      "time_this_iter_s: 7.808519124984741\n",
      "time_total_s: 1618.2030997276306\n",
      "timers:\n",
      "  learn_throughput: 1265.153\n",
      "  learn_time_ms: 3161.673\n",
      "  load_throughput: 20058842.659\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 553.642\n",
      "  sample_time_ms: 7224.891\n",
      "  update_time_ms: 2.241\n",
      "timestamp: 1658395567\n",
      "timesteps_since_restore: 920000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 920000\n",
      "training_iteration: 230\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 924000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-26-14\n",
      "done: false\n",
      "episode_len_mean: 190.88\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.88\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5035\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21372579038143158\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0011227389331907034\n",
      "        model: {}\n",
      "        policy_loss: 0.001617209636606276\n",
      "        total_loss: 8.996097564697266\n",
      "        vf_explained_var: -0.00012038946442771703\n",
      "        vf_loss: 8.994481086730957\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 924000\n",
      "  num_agent_steps_trained: 924000\n",
      "  num_steps_sampled: 924000\n",
      "  num_steps_trained: 924000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 231\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.410000000000004\n",
      "  ram_util_percent: 86.77000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06689125805359089\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07688603758563213\n",
      "  mean_inference_ms: 0.732672726809115\n",
      "  mean_raw_obs_processing_ms: 0.08930762087913666\n",
      "time_since_restore: 1625.36310505867\n",
      "time_this_iter_s: 7.160005331039429\n",
      "time_total_s: 1625.36310505867\n",
      "timers:\n",
      "  learn_throughput: 1267.079\n",
      "  learn_time_ms: 3156.868\n",
      "  load_throughput: 20810240.635\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 553.985\n",
      "  sample_time_ms: 7220.409\n",
      "  update_time_ms: 2.153\n",
      "timestamp: 1658395574\n",
      "timesteps_since_restore: 924000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 924000\n",
      "training_iteration: 231\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 928000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-26-21\n",
      "done: false\n",
      "episode_len_mean: 192.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.75\n",
      "episode_reward_min: 108.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5055\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23903824388980865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004960831720381975\n",
      "        model: {}\n",
      "        policy_loss: 0.005696543026715517\n",
      "        total_loss: 7.253849506378174\n",
      "        vf_explained_var: 0.0030612999107688665\n",
      "        vf_loss: 7.248152732849121\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 928000\n",
      "  num_agent_steps_trained: 928000\n",
      "  num_steps_sampled: 928000\n",
      "  num_steps_trained: 928000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 232\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.71818181818182\n",
      "  ram_util_percent: 86.84545454545456\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06692909727040744\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07692768697001473\n",
      "  mean_inference_ms: 0.7330697273351997\n",
      "  mean_raw_obs_processing_ms: 0.08935115003767588\n",
      "time_since_restore: 1632.837560415268\n",
      "time_this_iter_s: 7.4744553565979\n",
      "time_total_s: 1632.837560415268\n",
      "timers:\n",
      "  learn_throughput: 1233.14\n",
      "  learn_time_ms: 3243.751\n",
      "  load_throughput: 21410433.895\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 553.631\n",
      "  sample_time_ms: 7225.03\n",
      "  update_time_ms: 2.203\n",
      "timestamp: 1658395581\n",
      "timesteps_since_restore: 928000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 928000\n",
      "training_iteration: 232\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 932000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-26-28\n",
      "done: false\n",
      "episode_len_mean: 193.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.05\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5076\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2645100951194763\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007533219177275896\n",
      "        model: {}\n",
      "        policy_loss: 0.0007604641723446548\n",
      "        total_loss: 5.0804643630981445\n",
      "        vf_explained_var: 0.004241439048200846\n",
      "        vf_loss: 5.079704284667969\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 932000\n",
      "  num_agent_steps_trained: 932000\n",
      "  num_steps_sampled: 932000\n",
      "  num_steps_trained: 932000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 233\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.05\n",
      "  ram_util_percent: 87.11000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06696843660759416\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07697131437468177\n",
      "  mean_inference_ms: 0.7334803477041396\n",
      "  mean_raw_obs_processing_ms: 0.08939615866549776\n",
      "time_since_restore: 1639.8036663532257\n",
      "time_this_iter_s: 6.966105937957764\n",
      "time_total_s: 1639.8036663532257\n",
      "timers:\n",
      "  learn_throughput: 1229.922\n",
      "  learn_time_ms: 3252.239\n",
      "  load_throughput: 20727966.395\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 543.773\n",
      "  sample_time_ms: 7356.009\n",
      "  update_time_ms: 2.173\n",
      "timestamp: 1658395588\n",
      "timesteps_since_restore: 932000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 932000\n",
      "training_iteration: 233\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 936000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-26-37\n",
      "done: false\n",
      "episode_len_mean: 192.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.01\n",
      "episode_reward_min: 95.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 5098\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26379939913749695\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004556905943900347\n",
      "        model: {}\n",
      "        policy_loss: 0.0017563115106895566\n",
      "        total_loss: 5.8704962730407715\n",
      "        vf_explained_var: 0.006173336878418922\n",
      "        vf_loss: 5.868739604949951\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 936000\n",
      "  num_agent_steps_trained: 936000\n",
      "  num_steps_sampled: 936000\n",
      "  num_steps_trained: 936000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 234\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.84615384615385\n",
      "  ram_util_percent: 87.38461538461539\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06698411254538245\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0769887446949925\n",
      "  mean_inference_ms: 0.733648943697857\n",
      "  mean_raw_obs_processing_ms: 0.08941313589951788\n",
      "time_since_restore: 1648.6648843288422\n",
      "time_this_iter_s: 8.861217975616455\n",
      "time_total_s: 1648.6648843288422\n",
      "timers:\n",
      "  learn_throughput: 1159.11\n",
      "  learn_time_ms: 3450.924\n",
      "  load_throughput: 19286373.146\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 540.523\n",
      "  sample_time_ms: 7400.244\n",
      "  update_time_ms: 2.253\n",
      "timestamp: 1658395597\n",
      "timesteps_since_restore: 936000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 936000\n",
      "training_iteration: 234\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 940000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-26-47\n",
      "done: false\n",
      "episode_len_mean: 189.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.12\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 5120\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27179959416389465\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004003269597887993\n",
      "        model: {}\n",
      "        policy_loss: 0.001324571087025106\n",
      "        total_loss: 4.739441871643066\n",
      "        vf_explained_var: -0.0011380782816559076\n",
      "        vf_loss: 4.738117218017578\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 940000\n",
      "  num_agent_steps_trained: 940000\n",
      "  num_steps_sampled: 940000\n",
      "  num_steps_trained: 940000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 235\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.52307692307692\n",
      "  ram_util_percent: 88.29999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06702268039440346\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07703201390887204\n",
      "  mean_inference_ms: 0.7340775692825396\n",
      "  mean_raw_obs_processing_ms: 0.08945899031376343\n",
      "time_since_restore: 1657.9422011375427\n",
      "time_this_iter_s: 9.277316808700562\n",
      "time_total_s: 1657.9422011375427\n",
      "timers:\n",
      "  learn_throughput: 1149.7\n",
      "  learn_time_ms: 3479.167\n",
      "  load_throughput: 19128053.814\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 509.753\n",
      "  sample_time_ms: 7846.932\n",
      "  update_time_ms: 2.25\n",
      "timestamp: 1658395607\n",
      "timesteps_since_restore: 940000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 940000\n",
      "training_iteration: 235\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 944000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-26-55\n",
      "done: false\n",
      "episode_len_mean: 185.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 185.71\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 5142\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.282877117395401\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003730153199285269\n",
      "        model: {}\n",
      "        policy_loss: 0.0013421965995803475\n",
      "        total_loss: 4.897707939147949\n",
      "        vf_explained_var: 0.009592419490218163\n",
      "        vf_loss: 4.896366119384766\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 944000\n",
      "  num_agent_steps_trained: 944000\n",
      "  num_steps_sampled: 944000\n",
      "  num_steps_trained: 944000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 236\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.449999999999996\n",
      "  ram_util_percent: 88.34166666666668\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06706599502906102\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07708031596913954\n",
      "  mean_inference_ms: 0.7345521955280833\n",
      "  mean_raw_obs_processing_ms: 0.08951141376551827\n",
      "time_since_restore: 1666.106595993042\n",
      "time_this_iter_s: 8.164394855499268\n",
      "time_total_s: 1666.106595993042\n",
      "timers:\n",
      "  learn_throughput: 1115.838\n",
      "  learn_time_ms: 3584.75\n",
      "  load_throughput: 18980898.292\n",
      "  load_time_ms: 0.211\n",
      "  sample_throughput: 503.923\n",
      "  sample_time_ms: 7937.716\n",
      "  update_time_ms: 2.262\n",
      "timestamp: 1658395615\n",
      "timesteps_since_restore: 944000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 944000\n",
      "training_iteration: 236\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 948000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-27-03\n",
      "done: false\n",
      "episode_len_mean: 184.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.45\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 5164\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2557753622531891\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032486808486282825\n",
      "        model: {}\n",
      "        policy_loss: 0.0034878805745393038\n",
      "        total_loss: 6.132172107696533\n",
      "        vf_explained_var: 0.02277241088449955\n",
      "        vf_loss: 6.128683567047119\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 948000\n",
      "  num_agent_steps_trained: 948000\n",
      "  num_steps_sampled: 948000\n",
      "  num_steps_trained: 948000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 237\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.21818181818182\n",
      "  ram_util_percent: 88.39090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06712430535064612\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07714518624114731\n",
      "  mean_inference_ms: 0.7351841655161251\n",
      "  mean_raw_obs_processing_ms: 0.0895815606053795\n",
      "time_since_restore: 1674.360055923462\n",
      "time_this_iter_s: 8.253459930419922\n",
      "time_total_s: 1674.360055923462\n",
      "timers:\n",
      "  learn_throughput: 1103.201\n",
      "  learn_time_ms: 3625.813\n",
      "  load_throughput: 18670393.946\n",
      "  load_time_ms: 0.214\n",
      "  sample_throughput: 491.385\n",
      "  sample_time_ms: 8140.254\n",
      "  update_time_ms: 2.282\n",
      "timestamp: 1658395623\n",
      "timesteps_since_restore: 948000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 948000\n",
      "training_iteration: 237\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 952000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-27-11\n",
      "done: false\n",
      "episode_len_mean: 186.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.91\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5184\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2558559477329254\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003887713886797428\n",
      "        model: {}\n",
      "        policy_loss: 0.0066887312568724155\n",
      "        total_loss: 7.354336261749268\n",
      "        vf_explained_var: 0.005159394349902868\n",
      "        vf_loss: 7.347646713256836\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 952000\n",
      "  num_agent_steps_trained: 952000\n",
      "  num_steps_sampled: 952000\n",
      "  num_steps_trained: 952000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 238\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.483333333333334\n",
      "  ram_util_percent: 88.36666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06718632137025383\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07721401311149126\n",
      "  mean_inference_ms: 0.735844113844857\n",
      "  mean_raw_obs_processing_ms: 0.08965560354773619\n",
      "time_since_restore: 1682.369687795639\n",
      "time_this_iter_s: 8.009631872177124\n",
      "time_total_s: 1682.369687795639\n",
      "timers:\n",
      "  learn_throughput: 1102.842\n",
      "  learn_time_ms: 3626.993\n",
      "  load_throughput: 19237720.445\n",
      "  load_time_ms: 0.208\n",
      "  sample_throughput: 483.428\n",
      "  sample_time_ms: 8274.235\n",
      "  update_time_ms: 2.265\n",
      "timestamp: 1658395631\n",
      "timesteps_since_restore: 952000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 952000\n",
      "training_iteration: 238\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 956000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-27-19\n",
      "done: false\n",
      "episode_len_mean: 184.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.11\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 5207\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26633065938949585\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003823577892035246\n",
      "        model: {}\n",
      "        policy_loss: 0.004190945997834206\n",
      "        total_loss: 6.381436824798584\n",
      "        vf_explained_var: 0.018801748752593994\n",
      "        vf_loss: 6.37724494934082\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 956000\n",
      "  num_agent_steps_trained: 956000\n",
      "  num_steps_sampled: 956000\n",
      "  num_steps_trained: 956000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 239\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.26363636363637\n",
      "  ram_util_percent: 88.35454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06725061877880237\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07728550015010377\n",
      "  mean_inference_ms: 0.7365111208638723\n",
      "  mean_raw_obs_processing_ms: 0.08973219668755818\n",
      "time_since_restore: 1690.0383932590485\n",
      "time_this_iter_s: 7.668705463409424\n",
      "time_total_s: 1690.0383932590485\n",
      "timers:\n",
      "  learn_throughput: 1152.475\n",
      "  learn_time_ms: 3470.792\n",
      "  load_throughput: 19604131.806\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 491.044\n",
      "  sample_time_ms: 8145.903\n",
      "  update_time_ms: 2.228\n",
      "timestamp: 1658395639\n",
      "timesteps_since_restore: 956000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 956000\n",
      "training_iteration: 239\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 960000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-27-29\n",
      "done: false\n",
      "episode_len_mean: 187.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.28\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5227\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2680639326572418\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030049439519643784\n",
      "        model: {}\n",
      "        policy_loss: 0.005050073843449354\n",
      "        total_loss: 6.1578826904296875\n",
      "        vf_explained_var: 0.004968876019120216\n",
      "        vf_loss: 6.152832984924316\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 960000\n",
      "  num_agent_steps_trained: 960000\n",
      "  num_steps_sampled: 960000\n",
      "  num_steps_trained: 960000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 240\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.34285714285714\n",
      "  ram_util_percent: 88.68571428571428\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0673147451445746\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07735731010958032\n",
      "  mean_inference_ms: 0.7371746354039866\n",
      "  mean_raw_obs_processing_ms: 0.08980913044633233\n",
      "time_since_restore: 1699.8534491062164\n",
      "time_this_iter_s: 9.815055847167969\n",
      "time_total_s: 1699.8534491062164\n",
      "timers:\n",
      "  learn_throughput: 1127.308\n",
      "  learn_time_ms: 3548.277\n",
      "  load_throughput: 19772794.343\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 493.139\n",
      "  sample_time_ms: 8111.3\n",
      "  update_time_ms: 2.199\n",
      "timestamp: 1658395649\n",
      "timesteps_since_restore: 960000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 960000\n",
      "training_iteration: 240\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 964000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-27-38\n",
      "done: false\n",
      "episode_len_mean: 190.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.48\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5247\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30963993072509766\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037729491014033556\n",
      "        model: {}\n",
      "        policy_loss: 1.2667717783187982e-05\n",
      "        total_loss: 3.5442371368408203\n",
      "        vf_explained_var: 0.009579588659107685\n",
      "        vf_loss: 3.544224262237549\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 964000\n",
      "  num_agent_steps_trained: 964000\n",
      "  num_steps_sampled: 964000\n",
      "  num_steps_trained: 964000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 241\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.65384615384615\n",
      "  ram_util_percent: 88.46923076923078\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.067391270620264\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07744390367899373\n",
      "  mean_inference_ms: 0.7379640213222446\n",
      "  mean_raw_obs_processing_ms: 0.08990050224160129\n",
      "time_since_restore: 1708.8458189964294\n",
      "time_this_iter_s: 8.992369890213013\n",
      "time_total_s: 1708.8458189964294\n",
      "timers:\n",
      "  learn_throughput: 1105.396\n",
      "  learn_time_ms: 3618.613\n",
      "  load_throughput: 19121513.563\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 481.863\n",
      "  sample_time_ms: 8301.117\n",
      "  update_time_ms: 2.458\n",
      "timestamp: 1658395658\n",
      "timesteps_since_restore: 964000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 964000\n",
      "training_iteration: 241\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 968000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-27-46\n",
      "done: false\n",
      "episode_len_mean: 189.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.62\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 5269\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27065566182136536\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004369918256998062\n",
      "        model: {}\n",
      "        policy_loss: -0.0009707348071970046\n",
      "        total_loss: 4.710563659667969\n",
      "        vf_explained_var: -0.04875815287232399\n",
      "        vf_loss: 4.71153450012207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 968000\n",
      "  num_agent_steps_trained: 968000\n",
      "  num_steps_sampled: 968000\n",
      "  num_steps_trained: 968000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 242\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.48181818181818\n",
      "  ram_util_percent: 88.74545454545455\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06747583974393977\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07753777306936856\n",
      "  mean_inference_ms: 0.7388303906889285\n",
      "  mean_raw_obs_processing_ms: 0.09000155973654905\n",
      "time_since_restore: 1716.997831106186\n",
      "time_this_iter_s: 8.15201210975647\n",
      "time_total_s: 1716.997831106186\n",
      "timers:\n",
      "  learn_throughput: 1114.411\n",
      "  learn_time_ms: 3589.338\n",
      "  load_throughput: 19165199.909\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 472.24\n",
      "  sample_time_ms: 8470.262\n",
      "  update_time_ms: 2.488\n",
      "timestamp: 1658395666\n",
      "timesteps_since_restore: 968000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 968000\n",
      "training_iteration: 242\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 972000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-27-56\n",
      "done: false\n",
      "episode_len_mean: 190.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.92\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5289\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26033347845077515\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00373461889103055\n",
      "        model: {}\n",
      "        policy_loss: 0.002860046224668622\n",
      "        total_loss: 5.0233473777771\n",
      "        vf_explained_var: 0.012591910548508167\n",
      "        vf_loss: 5.020486831665039\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 972000\n",
      "  num_agent_steps_trained: 972000\n",
      "  num_steps_sampled: 972000\n",
      "  num_steps_trained: 972000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 243\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 53.39333333333333\n",
      "  ram_util_percent: 88.81333333333332\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06757386461415052\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07764658740013322\n",
      "  mean_inference_ms: 0.7398322902225971\n",
      "  mean_raw_obs_processing_ms: 0.09011910268881625\n",
      "time_since_restore: 1727.163110256195\n",
      "time_this_iter_s: 10.165279150009155\n",
      "time_total_s: 1727.163110256195\n",
      "timers:\n",
      "  learn_throughput: 1077.298\n",
      "  learn_time_ms: 3712.995\n",
      "  load_throughput: 19472163.417\n",
      "  load_time_ms: 0.205\n",
      "  sample_throughput: 463.122\n",
      "  sample_time_ms: 8637.024\n",
      "  update_time_ms: 2.536\n",
      "timestamp: 1658395676\n",
      "timesteps_since_restore: 972000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 972000\n",
      "training_iteration: 243\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 976000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-28-06\n",
      "done: false\n",
      "episode_len_mean: 192.67\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.67\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5310\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.238214373588562\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029789672698825598\n",
      "        model: {}\n",
      "        policy_loss: 0.00019163303659297526\n",
      "        total_loss: 4.127821922302246\n",
      "        vf_explained_var: -0.03810926154255867\n",
      "        vf_loss: 4.127630710601807\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 976000\n",
      "  num_agent_steps_trained: 976000\n",
      "  num_steps_sampled: 976000\n",
      "  num_steps_trained: 976000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 244\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 50.68571428571429\n",
      "  ram_util_percent: 88.75714285714285\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06769564890533113\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07778228629081534\n",
      "  mean_inference_ms: 0.7410882942093724\n",
      "  mean_raw_obs_processing_ms: 0.09026484402794223\n",
      "time_since_restore: 1736.6660265922546\n",
      "time_this_iter_s: 9.50291633605957\n",
      "time_total_s: 1736.6660265922546\n",
      "timers:\n",
      "  learn_throughput: 1112.28\n",
      "  learn_time_ms: 3596.216\n",
      "  load_throughput: 20615895.797\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 447.263\n",
      "  sample_time_ms: 8943.278\n",
      "  update_time_ms: 2.484\n",
      "timestamp: 1658395686\n",
      "timesteps_since_restore: 976000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 976000\n",
      "training_iteration: 244\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 980000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-28-14\n",
      "done: false\n",
      "episode_len_mean: 191.67\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.67\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5331\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2308616042137146\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030637355521321297\n",
      "        model: {}\n",
      "        policy_loss: 0.0012056081322953105\n",
      "        total_loss: 4.162675857543945\n",
      "        vf_explained_var: -0.02055436000227928\n",
      "        vf_loss: 4.161470413208008\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 980000\n",
      "  num_agent_steps_trained: 980000\n",
      "  num_steps_sampled: 980000\n",
      "  num_steps_trained: 980000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 245\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.849999999999994\n",
      "  ram_util_percent: 88.75\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0678008439163573\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07789969289832933\n",
      "  mean_inference_ms: 0.7421624776380614\n",
      "  mean_raw_obs_processing_ms: 0.09039037888548704\n",
      "time_since_restore: 1745.4012830257416\n",
      "time_this_iter_s: 8.735256433486938\n",
      "time_total_s: 1745.4012830257416\n",
      "timers:\n",
      "  learn_throughput: 1091.532\n",
      "  learn_time_ms: 3664.576\n",
      "  load_throughput: 20172196.706\n",
      "  load_time_ms: 0.198\n",
      "  sample_throughput: 459.622\n",
      "  sample_time_ms: 8702.796\n",
      "  update_time_ms: 2.504\n",
      "timestamp: 1658395694\n",
      "timesteps_since_restore: 980000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 980000\n",
      "training_iteration: 245\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 984000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-28-22\n",
      "done: false\n",
      "episode_len_mean: 190.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.21\n",
      "episode_reward_min: 102.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 5353\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.242647185921669\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003505973843857646\n",
      "        model: {}\n",
      "        policy_loss: 0.002898139413446188\n",
      "        total_loss: 6.833164215087891\n",
      "        vf_explained_var: 0.039454638957977295\n",
      "        vf_loss: 6.830265998840332\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 984000\n",
      "  num_agent_steps_trained: 984000\n",
      "  num_steps_sampled: 984000\n",
      "  num_steps_trained: 984000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 246\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.554545454545455\n",
      "  ram_util_percent: 88.68181818181819\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06790041385347999\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07801047091476943\n",
      "  mean_inference_ms: 0.7431839920149421\n",
      "  mean_raw_obs_processing_ms: 0.09051118309756902\n",
      "time_since_restore: 1753.372286081314\n",
      "time_this_iter_s: 7.97100305557251\n",
      "time_total_s: 1753.372286081314\n",
      "timers:\n",
      "  learn_throughput: 1107.533\n",
      "  learn_time_ms: 3611.632\n",
      "  load_throughput: 20245222.638\n",
      "  load_time_ms: 0.198\n",
      "  sample_throughput: 454.265\n",
      "  sample_time_ms: 8805.442\n",
      "  update_time_ms: 2.53\n",
      "timestamp: 1658395702\n",
      "timesteps_since_restore: 984000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 984000\n",
      "training_iteration: 246\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 988000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-28-30\n",
      "done: false\n",
      "episode_len_mean: 188.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.37\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 5375\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2776392102241516\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004542702808976173\n",
      "        model: {}\n",
      "        policy_loss: 0.00044937466736882925\n",
      "        total_loss: 5.299128532409668\n",
      "        vf_explained_var: -0.020689181983470917\n",
      "        vf_loss: 5.298678874969482\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 988000\n",
      "  num_agent_steps_trained: 988000\n",
      "  num_steps_sampled: 988000\n",
      "  num_steps_trained: 988000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 247\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.2\n",
      "  ram_util_percent: 88.58333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06798857147852737\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07811027346601501\n",
      "  mean_inference_ms: 0.7440934562551547\n",
      "  mean_raw_obs_processing_ms: 0.09062004467877496\n",
      "time_since_restore: 1761.1597974300385\n",
      "time_this_iter_s: 7.787511348724365\n",
      "time_total_s: 1761.1597974300385\n",
      "timers:\n",
      "  learn_throughput: 1112.375\n",
      "  learn_time_ms: 3595.911\n",
      "  load_throughput: 20843851.41\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 458.615\n",
      "  sample_time_ms: 8721.919\n",
      "  update_time_ms: 2.517\n",
      "timestamp: 1658395710\n",
      "timesteps_since_restore: 988000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 988000\n",
      "training_iteration: 247\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 992000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-28-38\n",
      "done: false\n",
      "episode_len_mean: 188.29\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.29\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5395\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21903923153877258\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035837050527334213\n",
      "        model: {}\n",
      "        policy_loss: 0.004403837490826845\n",
      "        total_loss: 6.762742519378662\n",
      "        vf_explained_var: 0.0042189424857497215\n",
      "        vf_loss: 6.758338928222656\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 992000\n",
      "  num_agent_steps_trained: 992000\n",
      "  num_steps_sampled: 992000\n",
      "  num_steps_trained: 992000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 248\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.800000000000004\n",
      "  ram_util_percent: 88.5909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06804517666313516\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07817473397533745\n",
      "  mean_inference_ms: 0.7446795912766855\n",
      "  mean_raw_obs_processing_ms: 0.0906916452799621\n",
      "time_since_restore: 1768.979397535324\n",
      "time_this_iter_s: 7.8196001052856445\n",
      "time_total_s: 1768.979397535324\n",
      "timers:\n",
      "  learn_throughput: 1114.466\n",
      "  learn_time_ms: 3589.164\n",
      "  load_throughput: 20950569.431\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 460.102\n",
      "  sample_time_ms: 8693.728\n",
      "  update_time_ms: 2.533\n",
      "timestamp: 1658395718\n",
      "timesteps_since_restore: 992000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 992000\n",
      "training_iteration: 248\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 996000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-28-46\n",
      "done: false\n",
      "episode_len_mean: 190.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.14\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5416\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24237102270126343\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036550741642713547\n",
      "        model: {}\n",
      "        policy_loss: 0.0007672084029763937\n",
      "        total_loss: 4.413271903991699\n",
      "        vf_explained_var: 0.033895887434482574\n",
      "        vf_loss: 4.412504196166992\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 996000\n",
      "  num_agent_steps_trained: 996000\n",
      "  num_steps_sampled: 996000\n",
      "  num_steps_trained: 996000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 249\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.37272727272727\n",
      "  ram_util_percent: 88.52727272727272\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06808789492456077\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07822295711854\n",
      "  mean_inference_ms: 0.7451175478774626\n",
      "  mean_raw_obs_processing_ms: 0.0907464844997457\n",
      "time_since_restore: 1776.7935872077942\n",
      "time_this_iter_s: 7.814189672470093\n",
      "time_total_s: 1776.7935872077942\n",
      "timers:\n",
      "  learn_throughput: 1112.493\n",
      "  learn_time_ms: 3595.529\n",
      "  load_throughput: 20903583.354\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 460.001\n",
      "  sample_time_ms: 8695.628\n",
      "  update_time_ms: 2.533\n",
      "timestamp: 1658395726\n",
      "timesteps_since_restore: 996000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 996000\n",
      "training_iteration: 249\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1000000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-28-54\n",
      "done: false\n",
      "episode_len_mean: 190.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.99\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5436\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2530685365200043\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00343088386580348\n",
      "        model: {}\n",
      "        policy_loss: 0.0015410814667120576\n",
      "        total_loss: 4.826030254364014\n",
      "        vf_explained_var: 0.03501252084970474\n",
      "        vf_loss: 4.824489116668701\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1000000\n",
      "  num_agent_steps_trained: 1000000\n",
      "  num_steps_sampled: 1000000\n",
      "  num_steps_trained: 1000000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 250\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.525\n",
      "  ram_util_percent: 88.49166666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06812564895137782\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07826506643758266\n",
      "  mean_inference_ms: 0.7455032587653568\n",
      "  mean_raw_obs_processing_ms: 0.0907944517005191\n",
      "time_since_restore: 1784.960121870041\n",
      "time_this_iter_s: 8.166534662246704\n",
      "time_total_s: 1784.960121870041\n",
      "timers:\n",
      "  learn_throughput: 1121.158\n",
      "  learn_time_ms: 3567.74\n",
      "  load_throughput: 20082853.723\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 467.005\n",
      "  sample_time_ms: 8565.218\n",
      "  update_time_ms: 2.552\n",
      "timestamp: 1658395734\n",
      "timesteps_since_restore: 1000000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1000000\n",
      "training_iteration: 250\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1004000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-29-02\n",
      "done: false\n",
      "episode_len_mean: 193.34\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.34\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5456\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23997539281845093\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034453230910003185\n",
      "        model: {}\n",
      "        policy_loss: 0.0018392191268503666\n",
      "        total_loss: 3.5410797595977783\n",
      "        vf_explained_var: -0.029561921954154968\n",
      "        vf_loss: 3.539240598678589\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1004000\n",
      "  num_agent_steps_trained: 1004000\n",
      "  num_steps_sampled: 1004000\n",
      "  num_steps_trained: 1004000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 251\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.1\n",
      "  ram_util_percent: 88.38181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06816323329642783\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07830690758237026\n",
      "  mean_inference_ms: 0.7458803656594866\n",
      "  mean_raw_obs_processing_ms: 0.09084132853337168\n",
      "time_since_restore: 1792.8413670063019\n",
      "time_this_iter_s: 7.881245136260986\n",
      "time_total_s: 1792.8413670063019\n",
      "timers:\n",
      "  learn_throughput: 1133.931\n",
      "  learn_time_ms: 3527.552\n",
      "  load_throughput: 20631106.739\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 472.457\n",
      "  sample_time_ms: 8466.371\n",
      "  update_time_ms: 2.482\n",
      "timestamp: 1658395742\n",
      "timesteps_since_restore: 1004000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1004000\n",
      "training_iteration: 251\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1008000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-29-10\n",
      "done: false\n",
      "episode_len_mean: 197.29\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.29\n",
      "episode_reward_min: 116.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5476\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22157448530197144\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033017827663570642\n",
      "        model: {}\n",
      "        policy_loss: 0.0017241716850548983\n",
      "        total_loss: 3.535588026046753\n",
      "        vf_explained_var: -0.01958939991891384\n",
      "        vf_loss: 3.5338637828826904\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1008000\n",
      "  num_agent_steps_trained: 1008000\n",
      "  num_steps_sampled: 1008000\n",
      "  num_steps_trained: 1008000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 252\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.6\n",
      "  ram_util_percent: 88.45454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06820505973886509\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07835277373010109\n",
      "  mean_inference_ms: 0.7463031636908883\n",
      "  mean_raw_obs_processing_ms: 0.09089120466422805\n",
      "time_since_restore: 1800.9536867141724\n",
      "time_this_iter_s: 8.112319707870483\n",
      "time_total_s: 1800.9536867141724\n",
      "timers:\n",
      "  learn_throughput: 1134.637\n",
      "  learn_time_ms: 3525.356\n",
      "  load_throughput: 20763881.188\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 474.86\n",
      "  sample_time_ms: 8423.542\n",
      "  update_time_ms: 2.447\n",
      "timestamp: 1658395750\n",
      "timesteps_since_restore: 1008000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1008000\n",
      "training_iteration: 252\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1012000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-29-18\n",
      "done: false\n",
      "episode_len_mean: 195.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.75\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5497\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2149575799703598\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029749886598438025\n",
      "        model: {}\n",
      "        policy_loss: 0.0008108172914944589\n",
      "        total_loss: 2.999199390411377\n",
      "        vf_explained_var: 0.01718754693865776\n",
      "        vf_loss: 2.9983887672424316\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1012000\n",
      "  num_agent_steps_trained: 1012000\n",
      "  num_steps_sampled: 1012000\n",
      "  num_steps_trained: 1012000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 253\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.84166666666667\n",
      "  ram_util_percent: 88.45\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06824528356737572\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07839704137823406\n",
      "  mean_inference_ms: 0.7467162068766129\n",
      "  mean_raw_obs_processing_ms: 0.09093952195803041\n",
      "time_since_restore: 1809.020827293396\n",
      "time_this_iter_s: 8.067140579223633\n",
      "time_total_s: 1809.020827293396\n",
      "timers:\n",
      "  learn_throughput: 1148.43\n",
      "  learn_time_ms: 3483.017\n",
      "  load_throughput: 21055742.972\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 484.705\n",
      "  sample_time_ms: 8252.45\n",
      "  update_time_ms: 2.537\n",
      "timestamp: 1658395758\n",
      "timesteps_since_restore: 1012000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1012000\n",
      "training_iteration: 253\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1016000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-29-29\n",
      "done: false\n",
      "episode_len_mean: 196.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.37\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5518\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24792920053005219\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036223502829670906\n",
      "        model: {}\n",
      "        policy_loss: -0.01177135482430458\n",
      "        total_loss: 9.605189323425293\n",
      "        vf_explained_var: 0.004033822100609541\n",
      "        vf_loss: 9.616960525512695\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1016000\n",
      "  num_agent_steps_trained: 1016000\n",
      "  num_steps_sampled: 1016000\n",
      "  num_steps_trained: 1016000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 254\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 61.099999999999994\n",
      "  ram_util_percent: 88.375\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0683102426297817\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07846817376023195\n",
      "  mean_inference_ms: 0.7473882144625382\n",
      "  mean_raw_obs_processing_ms: 0.09101687460947136\n",
      "time_since_restore: 1820.0200402736664\n",
      "time_this_iter_s: 10.999212980270386\n",
      "time_total_s: 1820.0200402736664\n",
      "timers:\n",
      "  learn_throughput: 1110.652\n",
      "  learn_time_ms: 3601.487\n",
      "  load_throughput: 20435098.66\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 485.366\n",
      "  sample_time_ms: 8241.198\n",
      "  update_time_ms: 2.534\n",
      "timestamp: 1658395769\n",
      "timesteps_since_restore: 1016000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1016000\n",
      "training_iteration: 254\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1020000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-29-40\n",
      "done: false\n",
      "episode_len_mean: 197.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.19\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5538\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19618824124336243\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0010487489635124803\n",
      "        model: {}\n",
      "        policy_loss: -0.008281410671770573\n",
      "        total_loss: 9.540613174438477\n",
      "        vf_explained_var: 0.003678077831864357\n",
      "        vf_loss: 9.548894882202148\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1020000\n",
      "  num_agent_steps_trained: 1020000\n",
      "  num_steps_sampled: 1020000\n",
      "  num_steps_trained: 1020000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 255\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 62.46875\n",
      "  ram_util_percent: 89.1125\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06841852524300829\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07859386247174595\n",
      "  mean_inference_ms: 0.7485603848699179\n",
      "  mean_raw_obs_processing_ms: 0.09114355755612763\n",
      "time_since_restore: 1831.105277299881\n",
      "time_this_iter_s: 11.0852370262146\n",
      "time_total_s: 1831.105277299881\n",
      "timers:\n",
      "  learn_throughput: 1140.476\n",
      "  learn_time_ms: 3507.309\n",
      "  load_throughput: 21021445.934\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 460.364\n",
      "  sample_time_ms: 8688.773\n",
      "  update_time_ms: 2.56\n",
      "timestamp: 1658395780\n",
      "timesteps_since_restore: 1020000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1020000\n",
      "training_iteration: 255\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1024000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-29-48\n",
      "done: false\n",
      "episode_len_mean: 197.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.19\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5558\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2104351669549942\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025600427761673927\n",
      "        model: {}\n",
      "        policy_loss: -0.00846802070736885\n",
      "        total_loss: 9.464826583862305\n",
      "        vf_explained_var: 0.0005322581855580211\n",
      "        vf_loss: 9.473294258117676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1024000\n",
      "  num_agent_steps_trained: 1024000\n",
      "  num_steps_sampled: 1024000\n",
      "  num_steps_trained: 1024000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 256\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.709090909090904\n",
      "  ram_util_percent: 87.93636363636364\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685265871640513\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07871916559933295\n",
      "  mean_inference_ms: 0.7497280188345722\n",
      "  mean_raw_obs_processing_ms: 0.09126896677664771\n",
      "time_since_restore: 1838.8994035720825\n",
      "time_this_iter_s: 7.794126272201538\n",
      "time_total_s: 1838.8994035720825\n",
      "timers:\n",
      "  learn_throughput: 1143.347\n",
      "  learn_time_ms: 3498.499\n",
      "  load_throughput: 21116697.294\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 465.921\n",
      "  sample_time_ms: 8585.14\n",
      "  update_time_ms: 2.511\n",
      "timestamp: 1658395788\n",
      "timesteps_since_restore: 1024000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1024000\n",
      "training_iteration: 256\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1028000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-29-56\n",
      "done: false\n",
      "episode_len_mean: 196.26\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.26\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5578\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22477544844150543\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0019312294898554683\n",
      "        model: {}\n",
      "        policy_loss: 0.006493323482573032\n",
      "        total_loss: 6.451015472412109\n",
      "        vf_explained_var: 0.0008974371594376862\n",
      "        vf_loss: 6.444521903991699\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1028000\n",
      "  num_agent_steps_trained: 1028000\n",
      "  num_steps_sampled: 1028000\n",
      "  num_steps_trained: 1028000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 257\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.116666666666674\n",
      "  ram_util_percent: 87.94999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06863288796852554\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07884271712773239\n",
      "  mean_inference_ms: 0.7508720843489204\n",
      "  mean_raw_obs_processing_ms: 0.09139308413829543\n",
      "time_since_restore: 1847.1550889015198\n",
      "time_this_iter_s: 8.255685329437256\n",
      "time_total_s: 1847.1550889015198\n",
      "timers:\n",
      "  learn_throughput: 1131.972\n",
      "  learn_time_ms: 3533.656\n",
      "  load_throughput: 21031986.963\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 465.817\n",
      "  sample_time_ms: 8587.061\n",
      "  update_time_ms: 2.507\n",
      "timestamp: 1658395796\n",
      "timesteps_since_restore: 1028000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1028000\n",
      "training_iteration: 257\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1032000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-30-04\n",
      "done: false\n",
      "episode_len_mean: 198.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.15\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5598\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1857747733592987\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023723638150840998\n",
      "        model: {}\n",
      "        policy_loss: 0.004021374974399805\n",
      "        total_loss: 4.843128204345703\n",
      "        vf_explained_var: -3.263033795519732e-05\n",
      "        vf_loss: 4.839107513427734\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1032000\n",
      "  num_agent_steps_trained: 1032000\n",
      "  num_steps_sampled: 1032000\n",
      "  num_steps_trained: 1032000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 258\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.43636363636364\n",
      "  ram_util_percent: 86.44545454545455\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06874542401999571\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07897249658096393\n",
      "  mean_inference_ms: 0.7520779897631684\n",
      "  mean_raw_obs_processing_ms: 0.091523047347638\n",
      "time_since_restore: 1855.240268945694\n",
      "time_this_iter_s: 8.085180044174194\n",
      "time_total_s: 1855.240268945694\n",
      "timers:\n",
      "  learn_throughput: 1135.375\n",
      "  learn_time_ms: 3523.065\n",
      "  load_throughput: 20950569.431\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 461.912\n",
      "  sample_time_ms: 8659.661\n",
      "  update_time_ms: 2.463\n",
      "timestamp: 1658395804\n",
      "timesteps_since_restore: 1032000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1032000\n",
      "training_iteration: 258\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1036000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-30-11\n",
      "done: false\n",
      "episode_len_mean: 199.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.04\n",
      "episode_reward_min: 141.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5618\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21512918174266815\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029156983364373446\n",
      "        model: {}\n",
      "        policy_loss: 0.003468180540949106\n",
      "        total_loss: 4.843003273010254\n",
      "        vf_explained_var: 0.0011977754766121507\n",
      "        vf_loss: 4.839535713195801\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1036000\n",
      "  num_agent_steps_trained: 1036000\n",
      "  num_steps_sampled: 1036000\n",
      "  num_steps_trained: 1036000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 259\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.760000000000005\n",
      "  ram_util_percent: 85.53999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.068826908613486\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07906847847102919\n",
      "  mean_inference_ms: 0.7529579856475914\n",
      "  mean_raw_obs_processing_ms: 0.09161616031405892\n",
      "time_since_restore: 1862.0647246837616\n",
      "time_this_iter_s: 6.824455738067627\n",
      "time_total_s: 1862.0647246837616\n",
      "timers:\n",
      "  learn_throughput: 1148.619\n",
      "  learn_time_ms: 3482.442\n",
      "  load_throughput: 20963658.628\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 465.588\n",
      "  sample_time_ms: 8591.281\n",
      "  update_time_ms: 2.462\n",
      "timestamp: 1658395811\n",
      "timesteps_since_restore: 1036000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1036000\n",
      "training_iteration: 259\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1040000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-30-18\n",
      "done: false\n",
      "episode_len_mean: 197.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.04\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5639\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2261122465133667\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002538890577852726\n",
      "        model: {}\n",
      "        policy_loss: 0.003486787201836705\n",
      "        total_loss: 4.128281593322754\n",
      "        vf_explained_var: -0.03057722933590412\n",
      "        vf_loss: 4.1247944831848145\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1040000\n",
      "  num_agent_steps_trained: 1040000\n",
      "  num_steps_sampled: 1040000\n",
      "  num_steps_trained: 1040000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 260\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.955555555555556\n",
      "  ram_util_percent: 85.47777777777777\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06884957561404016\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07909224997491458\n",
      "  mean_inference_ms: 0.7531802828621872\n",
      "  mean_raw_obs_processing_ms: 0.09164090140981021\n",
      "time_since_restore: 1868.762282371521\n",
      "time_this_iter_s: 6.697557687759399\n",
      "time_total_s: 1868.762282371521\n",
      "timers:\n",
      "  learn_throughput: 1168.705\n",
      "  learn_time_ms: 3422.591\n",
      "  load_throughput: 22384544.363\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 472.622\n",
      "  sample_time_ms: 8463.43\n",
      "  update_time_ms: 2.412\n",
      "timestamp: 1658395818\n",
      "timesteps_since_restore: 1040000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1040000\n",
      "training_iteration: 260\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1044000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-30-25\n",
      "done: false\n",
      "episode_len_mean: 196.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.21\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5659\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23422344028949738\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004687331151217222\n",
      "        model: {}\n",
      "        policy_loss: -0.001687910407781601\n",
      "        total_loss: 1.5695892572402954\n",
      "        vf_explained_var: -0.2523469924926758\n",
      "        vf_loss: 1.5712772607803345\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1044000\n",
      "  num_agent_steps_trained: 1044000\n",
      "  num_steps_sampled: 1044000\n",
      "  num_steps_trained: 1044000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 261\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.59\n",
      "  ram_util_percent: 85.66000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06885883304342347\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07910118129910275\n",
      "  mean_inference_ms: 0.7532701993751035\n",
      "  mean_raw_obs_processing_ms: 0.09164997058510041\n",
      "time_since_restore: 1875.5304896831512\n",
      "time_this_iter_s: 6.768207311630249\n",
      "time_total_s: 1875.5304896831512\n",
      "timers:\n",
      "  learn_throughput: 1179.1\n",
      "  learn_time_ms: 3392.417\n",
      "  load_throughput: 22733355.014\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 480.623\n",
      "  sample_time_ms: 8322.526\n",
      "  update_time_ms: 2.23\n",
      "timestamp: 1658395825\n",
      "timesteps_since_restore: 1044000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1044000\n",
      "training_iteration: 261\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1048000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-30-32\n",
      "done: false\n",
      "episode_len_mean: 195.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.61\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5680\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.262320339679718\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004724781960248947\n",
      "        model: {}\n",
      "        policy_loss: 0.0037219750229269266\n",
      "        total_loss: 7.5110931396484375\n",
      "        vf_explained_var: 0.008766441605985165\n",
      "        vf_loss: 7.507371425628662\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1048000\n",
      "  num_agent_steps_trained: 1048000\n",
      "  num_steps_sampled: 1048000\n",
      "  num_steps_trained: 1048000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 262\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.3\n",
      "  ram_util_percent: 85.86363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06886083035025883\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07910236860007541\n",
      "  mean_inference_ms: 0.7532867729207885\n",
      "  mean_raw_obs_processing_ms: 0.09164960872077448\n",
      "time_since_restore: 1883.0168344974518\n",
      "time_this_iter_s: 7.486344814300537\n",
      "time_total_s: 1883.0168344974518\n",
      "timers:\n",
      "  learn_throughput: 1180.034\n",
      "  learn_time_ms: 3389.734\n",
      "  load_throughput: 22313094.826\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 485.912\n",
      "  sample_time_ms: 8231.938\n",
      "  update_time_ms: 2.208\n",
      "timestamp: 1658395832\n",
      "timesteps_since_restore: 1048000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1048000\n",
      "training_iteration: 262\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1052000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-30-40\n",
      "done: false\n",
      "episode_len_mean: 195.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.61\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5700\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24334119260311127\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003373151645064354\n",
      "        model: {}\n",
      "        policy_loss: 0.00129265571013093\n",
      "        total_loss: 2.8760204315185547\n",
      "        vf_explained_var: -0.055934809148311615\n",
      "        vf_loss: 2.874727487564087\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1052000\n",
      "  num_agent_steps_trained: 1052000\n",
      "  num_steps_sampled: 1052000\n",
      "  num_steps_trained: 1052000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 263\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.199999999999996\n",
      "  ram_util_percent: 85.98181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0688575384290761\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07909883123526894\n",
      "  mean_inference_ms: 0.75326096342096\n",
      "  mean_raw_obs_processing_ms: 0.0916440690359137\n",
      "time_since_restore: 1890.6149175167084\n",
      "time_this_iter_s: 7.598083019256592\n",
      "time_total_s: 1890.6149175167084\n",
      "timers:\n",
      "  learn_throughput: 1202.051\n",
      "  learn_time_ms: 3327.647\n",
      "  load_throughput: 22171555.438\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 485.169\n",
      "  sample_time_ms: 8244.552\n",
      "  update_time_ms: 2.176\n",
      "timestamp: 1658395840\n",
      "timesteps_since_restore: 1052000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1052000\n",
      "training_iteration: 263\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1056000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-30-47\n",
      "done: false\n",
      "episode_len_mean: 195.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.61\n",
      "episode_reward_min: 79.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5720\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23337845504283905\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00329808471724391\n",
      "        model: {}\n",
      "        policy_loss: 0.0009638112969696522\n",
      "        total_loss: 2.874812602996826\n",
      "        vf_explained_var: -0.03494521975517273\n",
      "        vf_loss: 2.8738486766815186\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1056000\n",
      "  num_agent_steps_trained: 1056000\n",
      "  num_steps_sampled: 1056000\n",
      "  num_steps_trained: 1056000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 264\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.011111111111106\n",
      "  ram_util_percent: 85.83333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06885551467845702\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07909670100804864\n",
      "  mean_inference_ms: 0.7532516840266714\n",
      "  mean_raw_obs_processing_ms: 0.0916406739449467\n",
      "time_since_restore: 1897.394760608673\n",
      "time_this_iter_s: 6.779843091964722\n",
      "time_total_s: 1897.394760608673\n",
      "timers:\n",
      "  learn_throughput: 1280.526\n",
      "  learn_time_ms: 3123.717\n",
      "  load_throughput: 23279056.473\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 502.255\n",
      "  sample_time_ms: 7964.077\n",
      "  update_time_ms: 2.183\n",
      "timestamp: 1658395847\n",
      "timesteps_since_restore: 1056000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1056000\n",
      "training_iteration: 264\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1060000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-30-55\n",
      "done: false\n",
      "episode_len_mean: 196.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.9\n",
      "episode_reward_min: 117.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5741\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23705434799194336\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029530648607760668\n",
      "        model: {}\n",
      "        policy_loss: -0.006849342957139015\n",
      "        total_loss: 4.1025896072387695\n",
      "        vf_explained_var: -0.06002254784107208\n",
      "        vf_loss: 4.109438896179199\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1060000\n",
      "  num_agent_steps_trained: 1060000\n",
      "  num_steps_sampled: 1060000\n",
      "  num_steps_trained: 1060000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 265\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.21538461538462\n",
      "  ram_util_percent: 85.68461538461541\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06886804577630262\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07911135844899993\n",
      "  mean_inference_ms: 0.7534002399670563\n",
      "  mean_raw_obs_processing_ms: 0.0916572392507733\n",
      "time_since_restore: 1905.9871664047241\n",
      "time_this_iter_s: 8.592405796051025\n",
      "time_total_s: 1905.9871664047241\n",
      "timers:\n",
      "  learn_throughput: 1245.109\n",
      "  learn_time_ms: 3212.571\n",
      "  load_throughput: 22813728.583\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 539.0\n",
      "  sample_time_ms: 7421.153\n",
      "  update_time_ms: 2.103\n",
      "timestamp: 1658395855\n",
      "timesteps_since_restore: 1060000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1060000\n",
      "training_iteration: 265\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1064000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-31-02\n",
      "done: false\n",
      "episode_len_mean: 196.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.37\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5761\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21375636756420135\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002617863705381751\n",
      "        model: {}\n",
      "        policy_loss: 0.004199285991489887\n",
      "        total_loss: 4.818954944610596\n",
      "        vf_explained_var: -0.06414493918418884\n",
      "        vf_loss: 4.814755439758301\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1064000\n",
      "  num_agent_steps_trained: 1064000\n",
      "  num_steps_sampled: 1064000\n",
      "  num_steps_trained: 1064000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 266\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.72222222222222\n",
      "  ram_util_percent: 85.52222222222221\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06888179597908413\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07912688619571817\n",
      "  mean_inference_ms: 0.7535633827568872\n",
      "  mean_raw_obs_processing_ms: 0.09167538801523101\n",
      "time_since_restore: 1912.8382687568665\n",
      "time_this_iter_s: 6.851102352142334\n",
      "time_total_s: 1912.8382687568665\n",
      "timers:\n",
      "  learn_throughput: 1256.882\n",
      "  learn_time_ms: 3182.478\n",
      "  load_throughput: 22577332.795\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 537.258\n",
      "  sample_time_ms: 7445.212\n",
      "  update_time_ms: 2.134\n",
      "timestamp: 1658395862\n",
      "timesteps_since_restore: 1064000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1064000\n",
      "training_iteration: 266\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1068000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-31-09\n",
      "done: false\n",
      "episode_len_mean: 197.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.76\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5781\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19449928402900696\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0013400021707639098\n",
      "        model: {}\n",
      "        policy_loss: 0.0027609276585280895\n",
      "        total_loss: 1.6666762828826904\n",
      "        vf_explained_var: -0.21475858986377716\n",
      "        vf_loss: 1.6639155149459839\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1068000\n",
      "  num_agent_steps_trained: 1068000\n",
      "  num_steps_sampled: 1068000\n",
      "  num_steps_trained: 1068000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 267\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.69\n",
      "  ram_util_percent: 85.54\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06888877662965555\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07913520720298776\n",
      "  mean_inference_ms: 0.7536565762356418\n",
      "  mean_raw_obs_processing_ms: 0.09168583670555339\n",
      "time_since_restore: 1919.491429567337\n",
      "time_this_iter_s: 6.653160810470581\n",
      "time_total_s: 1919.491429567337\n",
      "timers:\n",
      "  learn_throughput: 1283.863\n",
      "  learn_time_ms: 3115.596\n",
      "  load_throughput: 22835464.816\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 546.266\n",
      "  sample_time_ms: 7322.439\n",
      "  update_time_ms: 2.099\n",
      "timestamp: 1658395869\n",
      "timesteps_since_restore: 1068000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1068000\n",
      "training_iteration: 267\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1072000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-31-16\n",
      "done: false\n",
      "episode_len_mean: 197.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.76\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5801\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2218935340642929\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003601808799430728\n",
      "        model: {}\n",
      "        policy_loss: -0.0007682511932216585\n",
      "        total_loss: 1.6654024124145508\n",
      "        vf_explained_var: -0.15344123542308807\n",
      "        vf_loss: 1.666170597076416\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1072000\n",
      "  num_agent_steps_trained: 1072000\n",
      "  num_steps_sampled: 1072000\n",
      "  num_steps_trained: 1072000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 268\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.269999999999996\n",
      "  ram_util_percent: 85.54\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06888737199243546\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07913335287108512\n",
      "  mean_inference_ms: 0.7536436140189525\n",
      "  mean_raw_obs_processing_ms: 0.09168594393639092\n",
      "time_since_restore: 1926.2289125919342\n",
      "time_this_iter_s: 6.737483024597168\n",
      "time_total_s: 1926.2289125919342\n",
      "timers:\n",
      "  learn_throughput: 1293.114\n",
      "  learn_time_ms: 3093.308\n",
      "  load_throughput: 23109112.948\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 560.053\n",
      "  sample_time_ms: 7142.181\n",
      "  update_time_ms: 2.08\n",
      "timestamp: 1658395876\n",
      "timesteps_since_restore: 1072000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1072000\n",
      "training_iteration: 268\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1076000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-31-26\n",
      "done: false\n",
      "episode_len_mean: 196.95\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.95\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5822\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19112224876880646\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0016543685924261808\n",
      "        model: {}\n",
      "        policy_loss: 0.0028989736456424\n",
      "        total_loss: 3.165787696838379\n",
      "        vf_explained_var: -0.11602238565683365\n",
      "        vf_loss: 3.162888526916504\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1076000\n",
      "  num_agent_steps_trained: 1076000\n",
      "  num_steps_sampled: 1076000\n",
      "  num_steps_trained: 1076000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 269\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 57.65714285714286\n",
      "  ram_util_percent: 86.55714285714286\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06891996935319418\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0791696347539048\n",
      "  mean_inference_ms: 0.7539786234124819\n",
      "  mean_raw_obs_processing_ms: 0.09172650547829245\n",
      "time_since_restore: 1936.3633942604065\n",
      "time_this_iter_s: 10.13448166847229\n",
      "time_total_s: 1936.3633942604065\n",
      "timers:\n",
      "  learn_throughput: 1262.363\n",
      "  learn_time_ms: 3168.661\n",
      "  load_throughput: 22632154.323\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 542.424\n",
      "  sample_time_ms: 7374.31\n",
      "  update_time_ms: 2.197\n",
      "timestamp: 1658395886\n",
      "timesteps_since_restore: 1076000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1076000\n",
      "training_iteration: 269\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1080000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-31-33\n",
      "done: false\n",
      "episode_len_mean: 197.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.69\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5842\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2119181603193283\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00288947275839746\n",
      "        model: {}\n",
      "        policy_loss: 0.008823476731777191\n",
      "        total_loss: 7.670140266418457\n",
      "        vf_explained_var: 0.0006866187904961407\n",
      "        vf_loss: 7.661316394805908\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1080000\n",
      "  num_agent_steps_trained: 1080000\n",
      "  num_steps_sampled: 1080000\n",
      "  num_steps_trained: 1080000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 270\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.39090909090909\n",
      "  ram_util_percent: 87.0909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06894143911532312\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07919351410079875\n",
      "  mean_inference_ms: 0.7541943339995849\n",
      "  mean_raw_obs_processing_ms: 0.09175253815343723\n",
      "time_since_restore: 1943.7589457035065\n",
      "time_this_iter_s: 7.395551443099976\n",
      "time_total_s: 1943.7589457035065\n",
      "timers:\n",
      "  learn_throughput: 1245.315\n",
      "  learn_time_ms: 3212.04\n",
      "  load_throughput: 22438432.526\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 534.961\n",
      "  sample_time_ms: 7477.182\n",
      "  update_time_ms: 2.201\n",
      "timestamp: 1658395893\n",
      "timesteps_since_restore: 1080000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1080000\n",
      "training_iteration: 270\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1084000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-31-43\n",
      "done: false\n",
      "episode_len_mean: 199.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.19\n",
      "episode_reward_min: 119.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5862\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19857607781887054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032880359794944525\n",
      "        model: {}\n",
      "        policy_loss: 0.0070187244564294815\n",
      "        total_loss: 7.668327808380127\n",
      "        vf_explained_var: -0.00016320007853209972\n",
      "        vf_loss: 7.661308765411377\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1084000\n",
      "  num_agent_steps_trained: 1084000\n",
      "  num_steps_sampled: 1084000\n",
      "  num_steps_trained: 1084000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 271\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 54.36923076923077\n",
      "  ram_util_percent: 87.34615384615384\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06897045399207657\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07922606120840783\n",
      "  mean_inference_ms: 0.7544850670959707\n",
      "  mean_raw_obs_processing_ms: 0.09178816635892675\n",
      "time_since_restore: 1953.082269668579\n",
      "time_this_iter_s: 9.323323965072632\n",
      "time_total_s: 1953.082269668579\n",
      "timers:\n",
      "  learn_throughput: 1178.468\n",
      "  learn_time_ms: 3394.237\n",
      "  load_throughput: 22224421.778\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 526.745\n",
      "  sample_time_ms: 7593.809\n",
      "  update_time_ms: 2.304\n",
      "timestamp: 1658395903\n",
      "timesteps_since_restore: 1084000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1084000\n",
      "training_iteration: 271\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1088000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-31-53\n",
      "done: false\n",
      "episode_len_mean: 198.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.8\n",
      "episode_reward_min: 119.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5882\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21045629680156708\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003468486713245511\n",
      "        model: {}\n",
      "        policy_loss: 0.007521777879446745\n",
      "        total_loss: 7.570560455322266\n",
      "        vf_explained_var: 0.002829416422173381\n",
      "        vf_loss: 7.563038349151611\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1088000\n",
      "  num_agent_steps_trained: 1088000\n",
      "  num_steps_sampled: 1088000\n",
      "  num_steps_trained: 1088000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 272\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 55.87999999999999\n",
      "  ram_util_percent: 88.42\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06904193143636221\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07930403696476798\n",
      "  mean_inference_ms: 0.7552154886190601\n",
      "  mean_raw_obs_processing_ms: 0.09187465388102321\n",
      "time_since_restore: 1963.5980877876282\n",
      "time_this_iter_s: 10.515818119049072\n",
      "time_total_s: 1963.5980877876282\n",
      "timers:\n",
      "  learn_throughput: 1167.537\n",
      "  learn_time_ms: 3426.015\n",
      "  load_throughput: 22247998.939\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 496.924\n",
      "  sample_time_ms: 8049.515\n",
      "  update_time_ms: 2.4\n",
      "timestamp: 1658395913\n",
      "timesteps_since_restore: 1088000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1088000\n",
      "training_iteration: 272\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1092000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-01\n",
      "done: false\n",
      "episode_len_mean: 197.96\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.96\n",
      "episode_reward_min: 119.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5902\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21094448864459991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003016119357198477\n",
      "        model: {}\n",
      "        policy_loss: 0.001545612351037562\n",
      "        total_loss: 3.0176939964294434\n",
      "        vf_explained_var: -0.1881265640258789\n",
      "        vf_loss: 3.016148090362549\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1092000\n",
      "  num_agent_steps_trained: 1092000\n",
      "  num_steps_sampled: 1092000\n",
      "  num_steps_trained: 1092000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 273\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.97272727272727\n",
      "  ram_util_percent: 88.15454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06912381336230687\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07939414818979501\n",
      "  mean_inference_ms: 0.7560621789371822\n",
      "  mean_raw_obs_processing_ms: 0.09197402043273588\n",
      "time_since_restore: 1971.4644157886505\n",
      "time_this_iter_s: 7.866328001022339\n",
      "time_total_s: 1971.4644157886505\n",
      "timers:\n",
      "  learn_throughput: 1166.621\n",
      "  learn_time_ms: 3428.705\n",
      "  load_throughput: 22360677.063\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 493.246\n",
      "  sample_time_ms: 8109.538\n",
      "  update_time_ms: 2.308\n",
      "timestamp: 1658395921\n",
      "timesteps_since_restore: 1092000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1092000\n",
      "training_iteration: 273\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1096000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-08\n",
      "done: false\n",
      "episode_len_mean: 198.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.35\n",
      "episode_reward_min: 143.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 5923\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18790040910243988\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026289052329957485\n",
      "        model: {}\n",
      "        policy_loss: -0.006797391921281815\n",
      "        total_loss: 9.37073040008545\n",
      "        vf_explained_var: 0.0015949031803756952\n",
      "        vf_loss: 9.377528190612793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1096000\n",
      "  num_agent_steps_trained: 1096000\n",
      "  num_steps_sampled: 1096000\n",
      "  num_steps_trained: 1096000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 274\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.590909090909086\n",
      "  ram_util_percent: 87.91818181818181\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06917499294230092\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07945018806096954\n",
      "  mean_inference_ms: 0.7565900415024646\n",
      "  mean_raw_obs_processing_ms: 0.09203624668298307\n",
      "time_since_restore: 1978.554782629013\n",
      "time_this_iter_s: 7.090366840362549\n",
      "time_total_s: 1978.554782629013\n",
      "timers:\n",
      "  learn_throughput: 1152.533\n",
      "  learn_time_ms: 3470.616\n",
      "  load_throughput: 22124773.836\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 493.753\n",
      "  sample_time_ms: 8101.223\n",
      "  update_time_ms: 2.306\n",
      "timestamp: 1658395928\n",
      "timesteps_since_restore: 1096000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1096000\n",
      "training_iteration: 274\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1100000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-16\n",
      "done: false\n",
      "episode_len_mean: 198.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.35\n",
      "episode_reward_min: 143.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5943\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19565048813819885\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001945391413755715\n",
      "        model: {}\n",
      "        policy_loss: -0.005859434138983488\n",
      "        total_loss: 9.371668815612793\n",
      "        vf_explained_var: -0.00023319445608649403\n",
      "        vf_loss: 9.377528190612793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1100000\n",
      "  num_agent_steps_trained: 1100000\n",
      "  num_steps_sampled: 1100000\n",
      "  num_steps_trained: 1100000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 275\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.654545454545456\n",
      "  ram_util_percent: 87.82727272727271\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06923496404769097\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07951584507527959\n",
      "  mean_inference_ms: 0.7572099153593005\n",
      "  mean_raw_obs_processing_ms: 0.09210866086132491\n",
      "time_since_restore: 1986.7515542507172\n",
      "time_this_iter_s: 8.196771621704102\n",
      "time_total_s: 1986.7515542507172\n",
      "timers:\n",
      "  learn_throughput: 1168.923\n",
      "  learn_time_ms: 3421.952\n",
      "  load_throughput: 22156914.95\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 490.634\n",
      "  sample_time_ms: 8152.72\n",
      "  update_time_ms: 2.334\n",
      "timestamp: 1658395936\n",
      "timesteps_since_restore: 1100000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1100000\n",
      "training_iteration: 275\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1104000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-24\n",
      "done: false\n",
      "episode_len_mean: 196.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.75\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5963\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18941941857337952\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024277938064187765\n",
      "        model: {}\n",
      "        policy_loss: 0.005090461112558842\n",
      "        total_loss: 6.20515251159668\n",
      "        vf_explained_var: -0.12370822578668594\n",
      "        vf_loss: 6.200061798095703\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1104000\n",
      "  num_agent_steps_trained: 1104000\n",
      "  num_steps_sampled: 1104000\n",
      "  num_steps_trained: 1104000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 276\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.481818181818184\n",
      "  ram_util_percent: 87.75454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06928442282211517\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07957002849973917\n",
      "  mean_inference_ms: 0.7577296350131375\n",
      "  mean_raw_obs_processing_ms: 0.09216785116790077\n",
      "time_since_restore: 1993.9380702972412\n",
      "time_this_iter_s: 7.186516046524048\n",
      "time_total_s: 1993.9380702972412\n",
      "timers:\n",
      "  learn_throughput: 1155.253\n",
      "  learn_time_ms: 3462.444\n",
      "  load_throughput: 22456452.951\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 493.981\n",
      "  sample_time_ms: 8097.473\n",
      "  update_time_ms: 2.361\n",
      "timestamp: 1658395944\n",
      "timesteps_since_restore: 1104000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1104000\n",
      "training_iteration: 276\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1108000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-30\n",
      "done: false\n",
      "episode_len_mean: 197.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.14\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 5983\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19837157428264618\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0014149727066978812\n",
      "        model: {}\n",
      "        policy_loss: 0.001437135972082615\n",
      "        total_loss: 1.362554907798767\n",
      "        vf_explained_var: -0.23935717344284058\n",
      "        vf_loss: 1.3611178398132324\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1108000\n",
      "  num_agent_steps_trained: 1108000\n",
      "  num_steps_sampled: 1108000\n",
      "  num_steps_trained: 1108000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 277\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.644444444444446\n",
      "  ram_util_percent: 88.0111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06929574380942122\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07958306126411246\n",
      "  mean_inference_ms: 0.7578582018835286\n",
      "  mean_raw_obs_processing_ms: 0.0921816045619841\n",
      "time_since_restore: 2000.6846346855164\n",
      "time_this_iter_s: 6.7465643882751465\n",
      "time_total_s: 2000.6846346855164\n",
      "timers:\n",
      "  learn_throughput: 1160.607\n",
      "  learn_time_ms: 3446.471\n",
      "  load_throughput: 22286418.704\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 489.944\n",
      "  sample_time_ms: 8164.197\n",
      "  update_time_ms: 2.361\n",
      "timestamp: 1658395950\n",
      "timesteps_since_restore: 1108000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1108000\n",
      "training_iteration: 277\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1112000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-37\n",
      "done: false\n",
      "episode_len_mean: 197.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.7\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6004\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20376214385032654\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0021252851001918316\n",
      "        model: {}\n",
      "        policy_loss: 0.006639546249061823\n",
      "        total_loss: 6.937100887298584\n",
      "        vf_explained_var: -0.03232375532388687\n",
      "        vf_loss: 6.930461406707764\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1112000\n",
      "  num_agent_steps_trained: 1112000\n",
      "  num_steps_sampled: 1112000\n",
      "  num_steps_trained: 1112000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 278\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.839999999999996\n",
      "  ram_util_percent: 87.64\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06929442608542791\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07958118915514052\n",
      "  mean_inference_ms: 0.7578593047954674\n",
      "  mean_raw_obs_processing_ms: 0.09217948588748921\n",
      "time_since_restore: 2007.3609902858734\n",
      "time_this_iter_s: 6.676355600357056\n",
      "time_total_s: 2007.3609902858734\n",
      "timers:\n",
      "  learn_throughput: 1162.43\n",
      "  learn_time_ms: 3441.069\n",
      "  load_throughput: 21079552.708\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 490.948\n",
      "  sample_time_ms: 8147.504\n",
      "  update_time_ms: 2.348\n",
      "timestamp: 1658395957\n",
      "timesteps_since_restore: 1112000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1112000\n",
      "training_iteration: 278\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1116000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-44\n",
      "done: false\n",
      "episode_len_mean: 197.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.7\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6024\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21549052000045776\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00338218011893332\n",
      "        model: {}\n",
      "        policy_loss: 0.00767579535022378\n",
      "        total_loss: 7.9210076332092285\n",
      "        vf_explained_var: 1.3801359273202252e-05\n",
      "        vf_loss: 7.913331508636475\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1116000\n",
      "  num_agent_steps_trained: 1116000\n",
      "  num_steps_sampled: 1116000\n",
      "  num_steps_trained: 1116000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 279\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.06666666666667\n",
      "  ram_util_percent: 87.6888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06929045011304451\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07957571353174173\n",
      "  mean_inference_ms: 0.7578292236369042\n",
      "  mean_raw_obs_processing_ms: 0.09217317014052892\n",
      "time_since_restore: 2014.072289466858\n",
      "time_this_iter_s: 6.711299180984497\n",
      "time_total_s: 2014.072289466858\n",
      "timers:\n",
      "  learn_throughput: 1185.494\n",
      "  learn_time_ms: 3374.12\n",
      "  load_throughput: 21614552.95\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 508.476\n",
      "  sample_time_ms: 7866.652\n",
      "  update_time_ms: 2.261\n",
      "timestamp: 1658395964\n",
      "timesteps_since_restore: 1116000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1116000\n",
      "training_iteration: 279\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1120000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-51\n",
      "done: false\n",
      "episode_len_mean: 196.97\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.97\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6044\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2247047871351242\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0010703473817557096\n",
      "        model: {}\n",
      "        policy_loss: 0.004390073474496603\n",
      "        total_loss: 4.238290786743164\n",
      "        vf_explained_var: 0.001243338454514742\n",
      "        vf_loss: 4.233901023864746\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1120000\n",
      "  num_agent_steps_trained: 1120000\n",
      "  num_steps_sampled: 1120000\n",
      "  num_steps_trained: 1120000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 280\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.345454545454544\n",
      "  ram_util_percent: 87.7090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06927259398932929\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07955467913834362\n",
      "  mean_inference_ms: 0.75765276309481\n",
      "  mean_raw_obs_processing_ms: 0.09215005523538465\n",
      "time_since_restore: 2021.2976615428925\n",
      "time_this_iter_s: 7.225372076034546\n",
      "time_total_s: 2021.2976615428925\n",
      "timers:\n",
      "  learn_throughput: 1183.077\n",
      "  learn_time_ms: 3381.013\n",
      "  load_throughput: 21648020.645\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 514.503\n",
      "  sample_time_ms: 7774.493\n",
      "  update_time_ms: 2.265\n",
      "timestamp: 1658395971\n",
      "timesteps_since_restore: 1120000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1120000\n",
      "training_iteration: 280\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1124000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-32-58\n",
      "done: false\n",
      "episode_len_mean: 198.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.57\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6064\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23257775604724884\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036441388074308634\n",
      "        model: {}\n",
      "        policy_loss: 0.0028924737125635147\n",
      "        total_loss: 4.236804485321045\n",
      "        vf_explained_var: 0.0004361664759926498\n",
      "        vf_loss: 4.233911514282227\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1124000\n",
      "  num_agent_steps_trained: 1124000\n",
      "  num_steps_sampled: 1124000\n",
      "  num_steps_trained: 1124000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 281\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.63\n",
      "  ram_util_percent: 88.03999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0692578921997356\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0795365683707792\n",
      "  mean_inference_ms: 0.7575030626617192\n",
      "  mean_raw_obs_processing_ms: 0.09213135229301342\n",
      "time_since_restore: 2028.6415581703186\n",
      "time_this_iter_s: 7.3438966274261475\n",
      "time_total_s: 2028.6415581703186\n",
      "timers:\n",
      "  learn_throughput: 1241.152\n",
      "  learn_time_ms: 3222.812\n",
      "  load_throughput: 21706839.177\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 516.668\n",
      "  sample_time_ms: 7741.916\n",
      "  update_time_ms: 2.207\n",
      "timestamp: 1658395978\n",
      "timesteps_since_restore: 1124000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1124000\n",
      "training_iteration: 281\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1128000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-33-05\n",
      "done: false\n",
      "episode_len_mean: 198.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.57\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6084\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2236042618751526\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028403711039572954\n",
      "        model: {}\n",
      "        policy_loss: 0.002331931609660387\n",
      "        total_loss: 4.236327171325684\n",
      "        vf_explained_var: 0.0013440614566206932\n",
      "        vf_loss: 4.23399543762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1128000\n",
      "  num_agent_steps_trained: 1128000\n",
      "  num_steps_sampled: 1128000\n",
      "  num_steps_trained: 1128000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 282\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.75555555555556\n",
      "  ram_util_percent: 88.02222222222223\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06923746287657359\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07951146870329237\n",
      "  mean_inference_ms: 0.7572869165811952\n",
      "  mean_raw_obs_processing_ms: 0.09210525770667813\n",
      "time_since_restore: 2035.0559430122375\n",
      "time_this_iter_s: 6.414384841918945\n",
      "time_total_s: 2035.0559430122375\n",
      "timers:\n",
      "  learn_throughput: 1267.076\n",
      "  learn_time_ms: 3156.875\n",
      "  load_throughput: 22274583.112\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 552.709\n",
      "  sample_time_ms: 7237.085\n",
      "  update_time_ms: 2.111\n",
      "timestamp: 1658395985\n",
      "timesteps_since_restore: 1128000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1128000\n",
      "training_iteration: 282\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1132000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-33-12\n",
      "done: false\n",
      "episode_len_mean: 198.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.12\n",
      "episode_reward_min: 127.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6105\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21736016869544983\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032967915758490562\n",
      "        model: {}\n",
      "        policy_loss: 0.0006369093316607177\n",
      "        total_loss: 3.3146746158599854\n",
      "        vf_explained_var: -0.10636502504348755\n",
      "        vf_loss: 3.314037561416626\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1132000\n",
      "  num_agent_steps_trained: 1132000\n",
      "  num_steps_sampled: 1132000\n",
      "  num_steps_trained: 1132000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 283\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.709999999999994\n",
      "  ram_util_percent: 88.03\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06921905630109504\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07948880781565731\n",
      "  mean_inference_ms: 0.7570919236771843\n",
      "  mean_raw_obs_processing_ms: 0.09208249941074563\n",
      "time_since_restore: 2041.9514949321747\n",
      "time_this_iter_s: 6.895551919937134\n",
      "time_total_s: 2041.9514949321747\n",
      "timers:\n",
      "  learn_throughput: 1275.318\n",
      "  learn_time_ms: 3136.473\n",
      "  load_throughput: 22313094.826\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 564.169\n",
      "  sample_time_ms: 7090.076\n",
      "  update_time_ms: 2.133\n",
      "timestamp: 1658395992\n",
      "timesteps_since_restore: 1132000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1132000\n",
      "training_iteration: 283\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1136000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-33-19\n",
      "done: false\n",
      "episode_len_mean: 196.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.25\n",
      "episode_reward_min: 21.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6126\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22424325346946716\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004198156297206879\n",
      "        model: {}\n",
      "        policy_loss: 0.007287704385817051\n",
      "        total_loss: 8.706894874572754\n",
      "        vf_explained_var: 0.00014923028356861323\n",
      "        vf_loss: 8.699606895446777\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1136000\n",
      "  num_agent_steps_trained: 1136000\n",
      "  num_steps_sampled: 1136000\n",
      "  num_steps_trained: 1136000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 284\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.36\n",
      "  ram_util_percent: 88.0\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06920358817449453\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07947008366263447\n",
      "  mean_inference_ms: 0.7569335239238597\n",
      "  mean_raw_obs_processing_ms: 0.09206434390609874\n",
      "time_since_restore: 2049.049609184265\n",
      "time_this_iter_s: 7.098114252090454\n",
      "time_total_s: 2049.049609184265\n",
      "timers:\n",
      "  learn_throughput: 1277.387\n",
      "  learn_time_ms: 3131.391\n",
      "  load_throughput: 22423437.584\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 565.344\n",
      "  sample_time_ms: 7075.333\n",
      "  update_time_ms: 2.109\n",
      "timestamp: 1658395999\n",
      "timesteps_since_restore: 1136000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1136000\n",
      "training_iteration: 284\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1140000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-33-26\n",
      "done: false\n",
      "episode_len_mean: 196.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.25\n",
      "episode_reward_min: 21.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6146\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21628376841545105\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023487890139222145\n",
      "        model: {}\n",
      "        policy_loss: 0.005561056546866894\n",
      "        total_loss: 5.499527931213379\n",
      "        vf_explained_var: 5.709907054551877e-05\n",
      "        vf_loss: 5.493967533111572\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1140000\n",
      "  num_agent_steps_trained: 1140000\n",
      "  num_steps_sampled: 1140000\n",
      "  num_steps_trained: 1140000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 285\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.95\n",
      "  ram_util_percent: 88.05\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06918897354667905\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07945254332776491\n",
      "  mean_inference_ms: 0.7567866646312416\n",
      "  mean_raw_obs_processing_ms: 0.0920467489113133\n",
      "time_since_restore: 2055.8871142864227\n",
      "time_this_iter_s: 6.837505102157593\n",
      "time_total_s: 2055.8871142864227\n",
      "timers:\n",
      "  learn_throughput: 1288.569\n",
      "  learn_time_ms: 3104.219\n",
      "  load_throughput: 22816831.225\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 574.628\n",
      "  sample_time_ms: 6961.027\n",
      "  update_time_ms: 2.147\n",
      "timestamp: 1658396006\n",
      "timesteps_since_restore: 1140000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1140000\n",
      "training_iteration: 285\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1144000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-33-33\n",
      "done: false\n",
      "episode_len_mean: 196.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.25\n",
      "episode_reward_min: 21.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6166\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2339780479669571\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032782673370093107\n",
      "        model: {}\n",
      "        policy_loss: 0.003784204600378871\n",
      "        total_loss: 5.497750759124756\n",
      "        vf_explained_var: 0.00011500600521685556\n",
      "        vf_loss: 5.493966102600098\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1144000\n",
      "  num_agent_steps_trained: 1144000\n",
      "  num_steps_sampled: 1144000\n",
      "  num_steps_trained: 1144000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 286\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.800000000000004\n",
      "  ram_util_percent: 87.97272727272727\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06917877399539421\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07944057424951877\n",
      "  mean_inference_ms: 0.7566942773502754\n",
      "  mean_raw_obs_processing_ms: 0.09203544571394415\n",
      "time_since_restore: 2063.326542854309\n",
      "time_this_iter_s: 7.4394285678863525\n",
      "time_total_s: 2063.326542854309\n",
      "timers:\n",
      "  learn_throughput: 1301.019\n",
      "  learn_time_ms: 3074.513\n",
      "  load_throughput: 22540932.42\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 572.343\n",
      "  sample_time_ms: 6988.814\n",
      "  update_time_ms: 2.202\n",
      "timestamp: 1658396013\n",
      "timesteps_since_restore: 1144000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1144000\n",
      "training_iteration: 286\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1148000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-33-41\n",
      "done: false\n",
      "episode_len_mean: 194.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.8\n",
      "episode_reward_min: 21.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6187\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25205984711647034\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002880838932469487\n",
      "        model: {}\n",
      "        policy_loss: 0.0039514899253845215\n",
      "        total_loss: 5.243424415588379\n",
      "        vf_explained_var: 0.000157453803694807\n",
      "        vf_loss: 5.239472389221191\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1148000\n",
      "  num_agent_steps_trained: 1148000\n",
      "  num_steps_sampled: 1148000\n",
      "  num_steps_trained: 1148000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 287\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.650000000000006\n",
      "  ram_util_percent: 88.04\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0691778314003395\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07943930978661286\n",
      "  mean_inference_ms: 0.756705956176669\n",
      "  mean_raw_obs_processing_ms: 0.09203477583821984\n",
      "time_since_restore: 2070.7824857234955\n",
      "time_this_iter_s: 7.455942869186401\n",
      "time_total_s: 2070.7824857234955\n",
      "timers:\n",
      "  learn_throughput: 1284.243\n",
      "  learn_time_ms: 3114.675\n",
      "  load_throughput: 22619948.766\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 572.353\n",
      "  sample_time_ms: 6988.695\n",
      "  update_time_ms: 2.209\n",
      "timestamp: 1658396021\n",
      "timesteps_since_restore: 1148000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1148000\n",
      "training_iteration: 287\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1152000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-33-49\n",
      "done: false\n",
      "episode_len_mean: 193.87\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.87\n",
      "episode_reward_min: 21.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6208\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3032197654247284\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004258647561073303\n",
      "        model: {}\n",
      "        policy_loss: 0.006834307219833136\n",
      "        total_loss: 7.637884616851807\n",
      "        vf_explained_var: 0.0003803203289862722\n",
      "        vf_loss: 7.631049633026123\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1152000\n",
      "  num_agent_steps_trained: 1152000\n",
      "  num_steps_sampled: 1152000\n",
      "  num_steps_trained: 1152000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 288\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.916666666666664\n",
      "  ram_util_percent: 88.15833333333335\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06918694241655189\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07944937546176267\n",
      "  mean_inference_ms: 0.7568245159098091\n",
      "  mean_raw_obs_processing_ms: 0.09204616991540578\n",
      "time_since_restore: 2078.9166417121887\n",
      "time_this_iter_s: 8.134155988693237\n",
      "time_total_s: 2078.9166417121887\n",
      "timers:\n",
      "  learn_throughput: 1265.689\n",
      "  learn_time_ms: 3160.334\n",
      "  load_throughput: 23726793.947\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 561.063\n",
      "  sample_time_ms: 7129.322\n",
      "  update_time_ms: 2.292\n",
      "timestamp: 1658396029\n",
      "timesteps_since_restore: 1152000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1152000\n",
      "training_iteration: 288\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1156000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-33-59\n",
      "done: false\n",
      "episode_len_mean: 192.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.41\n",
      "episode_reward_min: 53.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 6230\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2613317370414734\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035635707899928093\n",
      "        model: {}\n",
      "        policy_loss: 0.0030511163640767336\n",
      "        total_loss: 6.363958835601807\n",
      "        vf_explained_var: -0.05942656099796295\n",
      "        vf_loss: 6.360908031463623\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1156000\n",
      "  num_agent_steps_trained: 1156000\n",
      "  num_steps_sampled: 1156000\n",
      "  num_steps_trained: 1156000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 289\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 58.25333333333334\n",
      "  ram_util_percent: 88.76\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06921028324789512\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07947512388215057\n",
      "  mean_inference_ms: 0.7570962497463342\n",
      "  mean_raw_obs_processing_ms: 0.09207417449460938\n",
      "time_since_restore: 2089.1684477329254\n",
      "time_this_iter_s: 10.251806020736694\n",
      "time_total_s: 2089.1684477329254\n",
      "timers:\n",
      "  learn_throughput: 1179.658\n",
      "  learn_time_ms: 3390.813\n",
      "  load_throughput: 23195376.745\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 548.069\n",
      "  sample_time_ms: 7298.356\n",
      "  update_time_ms: 2.405\n",
      "timestamp: 1658396039\n",
      "timesteps_since_restore: 1156000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1156000\n",
      "training_iteration: 289\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1160000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-34-10\n",
      "done: false\n",
      "episode_len_mean: 191.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.62\n",
      "episode_reward_min: 53.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6250\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2507527470588684\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001878627808764577\n",
      "        model: {}\n",
      "        policy_loss: 0.006380866747349501\n",
      "        total_loss: 5.974132537841797\n",
      "        vf_explained_var: -0.032179802656173706\n",
      "        vf_loss: 5.967751502990723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1160000\n",
      "  num_agent_steps_trained: 1160000\n",
      "  num_steps_sampled: 1160000\n",
      "  num_steps_trained: 1160000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 290\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 58.97333333333334\n",
      "  ram_util_percent: 89.25999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06926502843899439\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07953441295549624\n",
      "  mean_inference_ms: 0.7576835914648596\n",
      "  mean_raw_obs_processing_ms: 0.0921373022809497\n",
      "time_since_restore: 2099.7287538051605\n",
      "time_this_iter_s: 10.560306072235107\n",
      "time_total_s: 2099.7287538051605\n",
      "timers:\n",
      "  learn_throughput: 1160.433\n",
      "  learn_time_ms: 3446.988\n",
      "  load_throughput: 21994252.753\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 512.122\n",
      "  sample_time_ms: 7810.632\n",
      "  update_time_ms: 2.395\n",
      "timestamp: 1658396050\n",
      "timesteps_since_restore: 1160000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1160000\n",
      "training_iteration: 290\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1164000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-34-17\n",
      "done: false\n",
      "episode_len_mean: 190.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.38\n",
      "episode_reward_min: 53.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6271\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3075041174888611\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003877928014844656\n",
      "        model: {}\n",
      "        policy_loss: 0.006687053479254246\n",
      "        total_loss: 7.625136852264404\n",
      "        vf_explained_var: 0.00034260094980709255\n",
      "        vf_loss: 7.6184492111206055\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1164000\n",
      "  num_agent_steps_trained: 1164000\n",
      "  num_steps_sampled: 1164000\n",
      "  num_steps_trained: 1164000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 291\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.459999999999994\n",
      "  ram_util_percent: 89.22999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06931810448682864\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07959188194790752\n",
      "  mean_inference_ms: 0.7582496513316073\n",
      "  mean_raw_obs_processing_ms: 0.09219718867738702\n",
      "time_since_restore: 2106.826921224594\n",
      "time_this_iter_s: 7.098167419433594\n",
      "time_total_s: 2106.826921224594\n",
      "timers:\n",
      "  learn_throughput: 1167.493\n",
      "  learn_time_ms: 3426.145\n",
      "  load_throughput: 21968333.115\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 508.742\n",
      "  sample_time_ms: 7862.53\n",
      "  update_time_ms: 2.454\n",
      "timestamp: 1658396057\n",
      "timesteps_since_restore: 1164000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1164000\n",
      "training_iteration: 291\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1168000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-34-24\n",
      "done: false\n",
      "episode_len_mean: 188.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.44\n",
      "episode_reward_min: 51.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 6293\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.262645423412323\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004211981315165758\n",
      "        model: {}\n",
      "        policy_loss: -0.00023200716532301158\n",
      "        total_loss: 4.392429828643799\n",
      "        vf_explained_var: -0.0245821550488472\n",
      "        vf_loss: 4.3926615715026855\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1168000\n",
      "  num_agent_steps_trained: 1168000\n",
      "  num_steps_sampled: 1168000\n",
      "  num_steps_trained: 1168000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 292\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.300000000000004\n",
      "  ram_util_percent: 89.12\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06936752783881285\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07964515032840468\n",
      "  mean_inference_ms: 0.7587684663959918\n",
      "  mean_raw_obs_processing_ms: 0.09225300232735624\n",
      "time_since_restore: 2113.8069024086\n",
      "time_this_iter_s: 6.979981184005737\n",
      "time_total_s: 2113.8069024086\n",
      "timers:\n",
      "  learn_throughput: 1164.484\n",
      "  learn_time_ms: 3434.997\n",
      "  load_throughput: 21959706.806\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 506.985\n",
      "  sample_time_ms: 7889.781\n",
      "  update_time_ms: 2.582\n",
      "timestamp: 1658396064\n",
      "timesteps_since_restore: 1168000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1168000\n",
      "training_iteration: 292\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1172000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-34-32\n",
      "done: false\n",
      "episode_len_mean: 187.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.31\n",
      "episode_reward_min: 51.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6314\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2539958655834198\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003955710679292679\n",
      "        model: {}\n",
      "        policy_loss: 0.004852629732340574\n",
      "        total_loss: 6.978140830993652\n",
      "        vf_explained_var: 0.0002896779915317893\n",
      "        vf_loss: 6.973287105560303\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1172000\n",
      "  num_agent_steps_trained: 1172000\n",
      "  num_steps_sampled: 1172000\n",
      "  num_steps_trained: 1172000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 293\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.790909090909096\n",
      "  ram_util_percent: 89.26363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06940870238929678\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07968960749892898\n",
      "  mean_inference_ms: 0.7592025550323355\n",
      "  mean_raw_obs_processing_ms: 0.09229908254121912\n",
      "time_since_restore: 2121.5964031219482\n",
      "time_this_iter_s: 7.789500713348389\n",
      "time_total_s: 2121.5964031219482\n",
      "timers:\n",
      "  learn_throughput: 1148.265\n",
      "  learn_time_ms: 3483.516\n",
      "  load_throughput: 21301696.293\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 503.749\n",
      "  sample_time_ms: 7940.468\n",
      "  update_time_ms: 2.566\n",
      "timestamp: 1658396072\n",
      "timesteps_since_restore: 1172000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1172000\n",
      "training_iteration: 293\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1176000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-34-39\n",
      "done: false\n",
      "episode_len_mean: 190.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.75\n",
      "episode_reward_min: 51.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6334\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25752225518226624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038772246334701777\n",
      "        model: {}\n",
      "        policy_loss: -0.0019033347489312291\n",
      "        total_loss: 1.6866261959075928\n",
      "        vf_explained_var: -0.01379446405917406\n",
      "        vf_loss: 1.68852961063385\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1176000\n",
      "  num_agent_steps_trained: 1176000\n",
      "  num_steps_sampled: 1176000\n",
      "  num_steps_trained: 1176000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 294\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.15\n",
      "  ram_util_percent: 89.29\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06943652353026397\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07971897260008207\n",
      "  mean_inference_ms: 0.7594899544347592\n",
      "  mean_raw_obs_processing_ms: 0.09232992561941845\n",
      "time_since_restore: 2128.731838941574\n",
      "time_this_iter_s: 7.1354358196258545\n",
      "time_total_s: 2128.731838941574\n",
      "timers:\n",
      "  learn_throughput: 1156.662\n",
      "  learn_time_ms: 3458.226\n",
      "  load_throughput: 21437791.975\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 498.883\n",
      "  sample_time_ms: 8017.916\n",
      "  update_time_ms: 2.569\n",
      "timestamp: 1658396079\n",
      "timesteps_since_restore: 1176000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1176000\n",
      "training_iteration: 294\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1180000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-34-46\n",
      "done: false\n",
      "episode_len_mean: 192.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.25\n",
      "episode_reward_min: 51.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6354\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2279314249753952\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037095050793141127\n",
      "        model: {}\n",
      "        policy_loss: -0.0007735008839517832\n",
      "        total_loss: 1.2593116760253906\n",
      "        vf_explained_var: -0.1512303203344345\n",
      "        vf_loss: 1.260085105895996\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1180000\n",
      "  num_agent_steps_trained: 1180000\n",
      "  num_steps_sampled: 1180000\n",
      "  num_steps_trained: 1180000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 295\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.720000000000006\n",
      "  ram_util_percent: 89.28999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06943821528572662\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07972073455815468\n",
      "  mean_inference_ms: 0.7595095470941945\n",
      "  mean_raw_obs_processing_ms: 0.09233147643449904\n",
      "time_since_restore: 2135.7622742652893\n",
      "time_this_iter_s: 7.03043532371521\n",
      "time_total_s: 2135.7622742652893\n",
      "timers:\n",
      "  learn_throughput: 1156.318\n",
      "  learn_time_ms: 3459.255\n",
      "  load_throughput: 21429577.213\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 499.341\n",
      "  sample_time_ms: 8010.564\n",
      "  update_time_ms: 2.582\n",
      "timestamp: 1658396086\n",
      "timesteps_since_restore: 1180000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1180000\n",
      "training_iteration: 295\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1184000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-34-53\n",
      "done: false\n",
      "episode_len_mean: 193.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.31\n",
      "episode_reward_min: 51.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6374\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2533321678638458\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024822598788887262\n",
      "        model: {}\n",
      "        policy_loss: -0.00034302237327210605\n",
      "        total_loss: 1.2143841981887817\n",
      "        vf_explained_var: -0.05017122998833656\n",
      "        vf_loss: 1.2147272825241089\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1184000\n",
      "  num_agent_steps_trained: 1184000\n",
      "  num_steps_sampled: 1184000\n",
      "  num_steps_trained: 1184000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 296\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.959999999999994\n",
      "  ram_util_percent: 89.28999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06943743495459043\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07971963325364269\n",
      "  mean_inference_ms: 0.7595022063752154\n",
      "  mean_raw_obs_processing_ms: 0.09233061091716152\n",
      "time_since_restore: 2142.5151839256287\n",
      "time_this_iter_s: 6.7529096603393555\n",
      "time_total_s: 2142.5151839256287\n",
      "timers:\n",
      "  learn_throughput: 1159.111\n",
      "  learn_time_ms: 3450.92\n",
      "  load_throughput: 21670390.08\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 502.995\n",
      "  sample_time_ms: 7952.36\n",
      "  update_time_ms: 2.453\n",
      "timestamp: 1658396093\n",
      "timesteps_since_restore: 1184000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1184000\n",
      "training_iteration: 296\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1188000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-00\n",
      "done: false\n",
      "episode_len_mean: 197.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.08\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6395\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2028021365404129\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003099242690950632\n",
      "        model: {}\n",
      "        policy_loss: 0.0006050430238246918\n",
      "        total_loss: 4.539419174194336\n",
      "        vf_explained_var: -0.016613123938441277\n",
      "        vf_loss: 4.538813591003418\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1188000\n",
      "  num_agent_steps_trained: 1188000\n",
      "  num_steps_sampled: 1188000\n",
      "  num_steps_trained: 1188000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 297\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.910000000000004\n",
      "  ram_util_percent: 89.15\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06943628995707118\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07971760425246917\n",
      "  mean_inference_ms: 0.7594916084970147\n",
      "  mean_raw_obs_processing_ms: 0.09232848472867942\n",
      "time_since_restore: 2149.46488571167\n",
      "time_this_iter_s: 6.94970178604126\n",
      "time_total_s: 2149.46488571167\n",
      "timers:\n",
      "  learn_throughput: 1165.425\n",
      "  learn_time_ms: 3432.223\n",
      "  load_throughput: 21743411.094\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 505.562\n",
      "  sample_time_ms: 7911.98\n",
      "  update_time_ms: 2.414\n",
      "timestamp: 1658396100\n",
      "timesteps_since_restore: 1188000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1188000\n",
      "training_iteration: 297\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1192000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-06\n",
      "done: false\n",
      "episode_len_mean: 197.07\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.07\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6416\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.233226478099823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025772268418222666\n",
      "        model: {}\n",
      "        policy_loss: -0.008306159637868404\n",
      "        total_loss: 6.120738983154297\n",
      "        vf_explained_var: 0.00013020352344028652\n",
      "        vf_loss: 6.129045009613037\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1192000\n",
      "  num_agent_steps_trained: 1192000\n",
      "  num_steps_sampled: 1192000\n",
      "  num_steps_trained: 1192000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 298\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.18888888888889\n",
      "  ram_util_percent: 89.03333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06942824848383823\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07970728896088654\n",
      "  mean_inference_ms: 0.7594003735101379\n",
      "  mean_raw_obs_processing_ms: 0.09231710205968974\n",
      "time_since_restore: 2156.079966545105\n",
      "time_this_iter_s: 6.615080833435059\n",
      "time_total_s: 2156.079966545105\n",
      "timers:\n",
      "  learn_throughput: 1184.231\n",
      "  learn_time_ms: 3377.72\n",
      "  load_throughput: 21956832.875\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 513.137\n",
      "  sample_time_ms: 7795.187\n",
      "  update_time_ms: 2.352\n",
      "timestamp: 1658396106\n",
      "timesteps_since_restore: 1192000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1192000\n",
      "training_iteration: 298\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1196000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-14\n",
      "done: false\n",
      "episode_len_mean: 196.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.61\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6436\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21322040259838104\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002437649993225932\n",
      "        model: {}\n",
      "        policy_loss: 0.005150171462446451\n",
      "        total_loss: 5.831770420074463\n",
      "        vf_explained_var: 9.144627983914688e-05\n",
      "        vf_loss: 5.826620101928711\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1196000\n",
      "  num_agent_steps_trained: 1196000\n",
      "  num_steps_sampled: 1196000\n",
      "  num_steps_trained: 1196000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 299\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.975\n",
      "  ram_util_percent: 87.05000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06942487430339624\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07970325491066067\n",
      "  mean_inference_ms: 0.759378552056343\n",
      "  mean_raw_obs_processing_ms: 0.09231273204882687\n",
      "time_since_restore: 2164.220516681671\n",
      "time_this_iter_s: 8.140550136566162\n",
      "time_total_s: 2164.220516681671\n",
      "timers:\n",
      "  learn_throughput: 1253.867\n",
      "  learn_time_ms: 3190.132\n",
      "  load_throughput: 20982011.006\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 518.322\n",
      "  sample_time_ms: 7717.207\n",
      "  update_time_ms: 2.225\n",
      "timestamp: 1658396114\n",
      "timesteps_since_restore: 1196000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1196000\n",
      "training_iteration: 299\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1200000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-22\n",
      "done: false\n",
      "episode_len_mean: 196.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.61\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6456\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22257524728775024\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002741073025390506\n",
      "        model: {}\n",
      "        policy_loss: 0.003263649297878146\n",
      "        total_loss: 4.337944030761719\n",
      "        vf_explained_var: 2.187169957323931e-05\n",
      "        vf_loss: 4.334680557250977\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1200000\n",
      "  num_agent_steps_trained: 1200000\n",
      "  num_steps_sampled: 1200000\n",
      "  num_steps_trained: 1200000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 300\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.82727272727273\n",
      "  ram_util_percent: 86.41818181818182\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06942602080799899\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07970385446867591\n",
      "  mean_inference_ms: 0.759413537048691\n",
      "  mean_raw_obs_processing_ms: 0.09231462839459594\n",
      "time_since_restore: 2172.040759563446\n",
      "time_this_iter_s: 7.820242881774902\n",
      "time_total_s: 2172.040759563446\n",
      "timers:\n",
      "  learn_throughput: 1278.188\n",
      "  learn_time_ms: 3129.43\n",
      "  load_throughput: 22049173.347\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 546.993\n",
      "  sample_time_ms: 7312.701\n",
      "  update_time_ms: 2.233\n",
      "timestamp: 1658396122\n",
      "timesteps_since_restore: 1200000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1200000\n",
      "training_iteration: 300\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1204000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-30\n",
      "done: false\n",
      "episode_len_mean: 195.26\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.26\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6477\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22460061311721802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004099193494766951\n",
      "        model: {}\n",
      "        policy_loss: 0.0038473661988973618\n",
      "        total_loss: 7.461006164550781\n",
      "        vf_explained_var: 0.00012318280641920865\n",
      "        vf_loss: 7.457158088684082\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1204000\n",
      "  num_agent_steps_trained: 1204000\n",
      "  num_steps_sampled: 1204000\n",
      "  num_steps_trained: 1204000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 301\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.31818181818182\n",
      "  ram_util_percent: 85.80000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06943423857483105\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07971311092215255\n",
      "  mean_inference_ms: 0.7595328882653188\n",
      "  mean_raw_obs_processing_ms: 0.09232544753143962\n",
      "time_since_restore: 2179.56778550148\n",
      "time_this_iter_s: 7.527025938034058\n",
      "time_total_s: 2179.56778550148\n",
      "timers:\n",
      "  learn_throughput: 1276.81\n",
      "  learn_time_ms: 3132.808\n",
      "  load_throughput: 21885228.281\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 548.534\n",
      "  sample_time_ms: 7292.166\n",
      "  update_time_ms: 2.16\n",
      "timestamp: 1658396130\n",
      "timesteps_since_restore: 1204000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1204000\n",
      "training_iteration: 301\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000301/checkpoint-301\n",
      "agent_timesteps_total: 1208000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-37\n",
      "done: false\n",
      "episode_len_mean: 195.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.04\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6498\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22310975193977356\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00227917917072773\n",
      "        model: {}\n",
      "        policy_loss: 0.003626755205914378\n",
      "        total_loss: 7.039921283721924\n",
      "        vf_explained_var: 6.405801104847342e-05\n",
      "        vf_loss: 7.036294937133789\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1208000\n",
      "  num_agent_steps_trained: 1208000\n",
      "  num_steps_sampled: 1208000\n",
      "  num_steps_trained: 1208000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 302\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.45\n",
      "  ram_util_percent: 85.38\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.069443352518335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07972340529718393\n",
      "  mean_inference_ms: 0.759664285140858\n",
      "  mean_raw_obs_processing_ms: 0.09233728282620499\n",
      "time_since_restore: 2186.3680815696716\n",
      "time_this_iter_s: 6.800296068191528\n",
      "time_total_s: 2186.3680815696716\n",
      "timers:\n",
      "  learn_throughput: 1287.697\n",
      "  learn_time_ms: 3106.32\n",
      "  load_throughput: 21698416.968\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 547.592\n",
      "  sample_time_ms: 7304.713\n",
      "  update_time_ms: 2.018\n",
      "timestamp: 1658396137\n",
      "timesteps_since_restore: 1208000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1208000\n",
      "training_iteration: 302\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1212000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-44\n",
      "done: false\n",
      "episode_len_mean: 195.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.86\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6518\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20401640236377716\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0019581604283303022\n",
      "        model: {}\n",
      "        policy_loss: 0.006943893618881702\n",
      "        total_loss: 8.666218757629395\n",
      "        vf_explained_var: 2.4923008822952397e-05\n",
      "        vf_loss: 8.659274101257324\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1212000\n",
      "  num_agent_steps_trained: 1212000\n",
      "  num_steps_sampled: 1212000\n",
      "  num_steps_trained: 1212000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 303\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.63\n",
      "  ram_util_percent: 85.39\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06945299747354892\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07973492139265405\n",
      "  mean_inference_ms: 0.7598001639010985\n",
      "  mean_raw_obs_processing_ms: 0.09234943005118104\n",
      "time_since_restore: 2193.2605180740356\n",
      "time_this_iter_s: 6.892436504364014\n",
      "time_total_s: 2193.2605180740356\n",
      "timers:\n",
      "  learn_throughput: 1308.015\n",
      "  learn_time_ms: 3058.068\n",
      "  load_throughput: 22537904.352\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 552.792\n",
      "  sample_time_ms: 7236.001\n",
      "  update_time_ms: 2.002\n",
      "timestamp: 1658396144\n",
      "timesteps_since_restore: 1212000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1212000\n",
      "training_iteration: 303\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1216000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-50\n",
      "done: false\n",
      "episode_len_mean: 192.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.15\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 6540\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24407830834388733\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024631740525364876\n",
      "        model: {}\n",
      "        policy_loss: 0.0028415450360625982\n",
      "        total_loss: 5.370791912078857\n",
      "        vf_explained_var: 6.853546801721677e-05\n",
      "        vf_loss: 5.367950916290283\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1216000\n",
      "  num_agent_steps_trained: 1216000\n",
      "  num_steps_sampled: 1216000\n",
      "  num_steps_trained: 1216000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 304\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.81\n",
      "  ram_util_percent: 85.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06945426473540646\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07973649730599855\n",
      "  mean_inference_ms: 0.7598370117214993\n",
      "  mean_raw_obs_processing_ms: 0.0923501775244046\n",
      "time_since_restore: 2200.1747443675995\n",
      "time_this_iter_s: 6.914226293563843\n",
      "time_total_s: 2200.1747443675995\n",
      "timers:\n",
      "  learn_throughput: 1303.164\n",
      "  learn_time_ms: 3069.452\n",
      "  load_throughput: 22516730.64\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 559.13\n",
      "  sample_time_ms: 7153.976\n",
      "  update_time_ms: 2.053\n",
      "timestamp: 1658396150\n",
      "timesteps_since_restore: 1216000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1216000\n",
      "training_iteration: 304\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1220000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-35-57\n",
      "done: false\n",
      "episode_len_mean: 192.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.15\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6560\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21610136330127716\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002141712000593543\n",
      "        model: {}\n",
      "        policy_loss: 0.00392806064337492\n",
      "        total_loss: 5.0946550369262695\n",
      "        vf_explained_var: 2.856401988537982e-05\n",
      "        vf_loss: 5.090726852416992\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1220000\n",
      "  num_agent_steps_trained: 1220000\n",
      "  num_steps_sampled: 1220000\n",
      "  num_steps_trained: 1220000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 305\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.77777777777778\n",
      "  ram_util_percent: 85.43333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06944827886892382\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07973029960554959\n",
      "  mean_inference_ms: 0.7597909707286693\n",
      "  mean_raw_obs_processing_ms: 0.09234159698120155\n",
      "time_since_restore: 2206.7913134098053\n",
      "time_this_iter_s: 6.6165690422058105\n",
      "time_total_s: 2206.7913134098053\n",
      "timers:\n",
      "  learn_throughput: 1311.922\n",
      "  learn_time_ms: 3048.962\n",
      "  load_throughput: 22516730.64\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 559.849\n",
      "  sample_time_ms: 7144.779\n",
      "  update_time_ms: 2.023\n",
      "timestamp: 1658396157\n",
      "timesteps_since_restore: 1220000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1220000\n",
      "training_iteration: 305\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1224000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-04\n",
      "done: false\n",
      "episode_len_mean: 191.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.16\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6581\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24475012719631195\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004352112300693989\n",
      "        model: {}\n",
      "        policy_loss: 0.001066872151568532\n",
      "        total_loss: 5.008641719818115\n",
      "        vf_explained_var: -0.03219904005527496\n",
      "        vf_loss: 5.007574558258057\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1224000\n",
      "  num_agent_steps_trained: 1224000\n",
      "  num_steps_sampled: 1224000\n",
      "  num_steps_trained: 1224000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 306\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.57\n",
      "  ram_util_percent: 85.42\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06943635197472567\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07971690600363114\n",
      "  mean_inference_ms: 0.7596791484051352\n",
      "  mean_raw_obs_processing_ms: 0.09232472287482306\n",
      "time_since_restore: 2213.479203939438\n",
      "time_this_iter_s: 6.687890529632568\n",
      "time_total_s: 2213.479203939438\n",
      "timers:\n",
      "  learn_throughput: 1316.751\n",
      "  learn_time_ms: 3037.78\n",
      "  load_throughput: 22474502.344\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 561.169\n",
      "  sample_time_ms: 7127.981\n",
      "  update_time_ms: 2.061\n",
      "timestamp: 1658396164\n",
      "timesteps_since_restore: 1224000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1224000\n",
      "training_iteration: 306\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1228000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-11\n",
      "done: false\n",
      "episode_len_mean: 190.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.92\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6602\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20656485855579376\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003064712043851614\n",
      "        model: {}\n",
      "        policy_loss: 0.0009197601466439664\n",
      "        total_loss: 4.116345405578613\n",
      "        vf_explained_var: 0.0037657981738448143\n",
      "        vf_loss: 4.1154255867004395\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1228000\n",
      "  num_agent_steps_trained: 1228000\n",
      "  num_steps_sampled: 1228000\n",
      "  num_steps_trained: 1228000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 307\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.566666666666663\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06942175553409038\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07970136266952761\n",
      "  mean_inference_ms: 0.7595565159941313\n",
      "  mean_raw_obs_processing_ms: 0.09230527260782004\n",
      "time_since_restore: 2220.2575011253357\n",
      "time_this_iter_s: 6.778297185897827\n",
      "time_total_s: 2220.2575011253357\n",
      "timers:\n",
      "  learn_throughput: 1322.113\n",
      "  learn_time_ms: 3025.459\n",
      "  load_throughput: 22510688.313\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 562.432\n",
      "  sample_time_ms: 7111.965\n",
      "  update_time_ms: 2.15\n",
      "timestamp: 1658396171\n",
      "timesteps_since_restore: 1228000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1228000\n",
      "training_iteration: 307\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1232000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-17\n",
      "done: false\n",
      "episode_len_mean: 188.07\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.07\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 6624\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19867931306362152\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023933846969157457\n",
      "        model: {}\n",
      "        policy_loss: 0.003941578324884176\n",
      "        total_loss: 5.160199165344238\n",
      "        vf_explained_var: 0.02160496823489666\n",
      "        vf_loss: 5.156257152557373\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1232000\n",
      "  num_agent_steps_trained: 1232000\n",
      "  num_steps_sampled: 1232000\n",
      "  num_steps_trained: 1232000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 308\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.72\n",
      "  ram_util_percent: 85.53\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06940438913658646\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07968301865803794\n",
      "  mean_inference_ms: 0.7594071359430731\n",
      "  mean_raw_obs_processing_ms: 0.09228283367280408\n",
      "time_since_restore: 2226.865744829178\n",
      "time_this_iter_s: 6.608243703842163\n",
      "time_total_s: 2226.865744829178\n",
      "timers:\n",
      "  learn_throughput: 1322.845\n",
      "  learn_time_ms: 3023.786\n",
      "  load_throughput: 22399487.316\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 563.222\n",
      "  sample_time_ms: 7101.999\n",
      "  update_time_ms: 2.142\n",
      "timestamp: 1658396177\n",
      "timesteps_since_restore: 1232000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1232000\n",
      "training_iteration: 308\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1236000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-24\n",
      "done: false\n",
      "episode_len_mean: 189.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.93\n",
      "episode_reward_min: 76.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6645\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20250803232192993\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004025718662887812\n",
      "        model: {}\n",
      "        policy_loss: 0.0004189598257653415\n",
      "        total_loss: 4.375421047210693\n",
      "        vf_explained_var: 4.4065265683457255e-05\n",
      "        vf_loss: 4.375001907348633\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1236000\n",
      "  num_agent_steps_trained: 1236000\n",
      "  num_steps_sampled: 1236000\n",
      "  num_steps_trained: 1236000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 309\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.58888888888889\n",
      "  ram_util_percent: 85.6\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06938705252451664\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07966486511439762\n",
      "  mean_inference_ms: 0.7592556373330536\n",
      "  mean_raw_obs_processing_ms: 0.09226052262328878\n",
      "time_since_restore: 2233.6198103427887\n",
      "time_this_iter_s: 6.75406551361084\n",
      "time_total_s: 2233.6198103427887\n",
      "timers:\n",
      "  learn_throughput: 1344.178\n",
      "  learn_time_ms: 2975.797\n",
      "  load_throughput: 24094809.708\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 570.624\n",
      "  sample_time_ms: 7009.864\n",
      "  update_time_ms: 2.154\n",
      "timestamp: 1658396184\n",
      "timesteps_since_restore: 1236000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1236000\n",
      "training_iteration: 309\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1240000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-31\n",
      "done: false\n",
      "episode_len_mean: 190.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.27\n",
      "episode_reward_min: 76.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6665\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.182556614279747\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028678961098194122\n",
      "        model: {}\n",
      "        policy_loss: 0.0037409039214253426\n",
      "        total_loss: 4.741645812988281\n",
      "        vf_explained_var: 4.6931927499827e-06\n",
      "        vf_loss: 4.737904071807861\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1240000\n",
      "  num_agent_steps_trained: 1240000\n",
      "  num_steps_sampled: 1240000\n",
      "  num_steps_trained: 1240000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 310\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.910000000000004\n",
      "  ram_util_percent: 85.49\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06937187510618671\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0796486410449764\n",
      "  mean_inference_ms: 0.7591197077189912\n",
      "  mean_raw_obs_processing_ms: 0.09224047667473126\n",
      "time_since_restore: 2240.404552221298\n",
      "time_this_iter_s: 6.7847418785095215\n",
      "time_total_s: 2240.404552221298\n",
      "timers:\n",
      "  learn_throughput: 1366.548\n",
      "  learn_time_ms: 2927.083\n",
      "  load_throughput: 24325382.05\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 579.18\n",
      "  sample_time_ms: 6906.314\n",
      "  update_time_ms: 2.16\n",
      "timestamp: 1658396191\n",
      "timesteps_since_restore: 1240000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1240000\n",
      "training_iteration: 310\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1244000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-37\n",
      "done: false\n",
      "episode_len_mean: 191.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.31\n",
      "episode_reward_min: 76.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6686\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23281541466712952\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023951686453074217\n",
      "        model: {}\n",
      "        policy_loss: 0.0015896440017968416\n",
      "        total_loss: 3.358447790145874\n",
      "        vf_explained_var: -0.15454265475273132\n",
      "        vf_loss: 3.356858015060425\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1244000\n",
      "  num_agent_steps_trained: 1244000\n",
      "  num_steps_sampled: 1244000\n",
      "  num_steps_trained: 1244000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 311\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.87\n",
      "  ram_util_percent: 85.47\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06935550307736267\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07963189486760214\n",
      "  mean_inference_ms: 0.7589705720691431\n",
      "  mean_raw_obs_processing_ms: 0.09221936024475952\n",
      "time_since_restore: 2247.0363907814026\n",
      "time_this_iter_s: 6.63183856010437\n",
      "time_total_s: 2247.0363907814026\n",
      "timers:\n",
      "  learn_throughput: 1379.915\n",
      "  learn_time_ms: 2898.729\n",
      "  load_throughput: 24734212.001\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 588.534\n",
      "  sample_time_ms: 6796.552\n",
      "  update_time_ms: 2.161\n",
      "timestamp: 1658396197\n",
      "timesteps_since_restore: 1244000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1244000\n",
      "training_iteration: 311\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1248000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-44\n",
      "done: false\n",
      "episode_len_mean: 192.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.9\n",
      "episode_reward_min: 81.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6706\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.16601690649986267\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024437170941382647\n",
      "        model: {}\n",
      "        policy_loss: 0.0010997960343956947\n",
      "        total_loss: 1.5131977796554565\n",
      "        vf_explained_var: -0.14460505545139313\n",
      "        vf_loss: 1.5120978355407715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1248000\n",
      "  num_agent_steps_trained: 1248000\n",
      "  num_steps_sampled: 1248000\n",
      "  num_steps_trained: 1248000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 312\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.544444444444444\n",
      "  ram_util_percent: 85.48888888888888\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06933974430332507\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07961616575253752\n",
      "  mean_inference_ms: 0.7588141672653983\n",
      "  mean_raw_obs_processing_ms: 0.09219882300848985\n",
      "time_since_restore: 2253.7168774604797\n",
      "time_this_iter_s: 6.680486679077148\n",
      "time_total_s: 2253.7168774604797\n",
      "timers:\n",
      "  learn_throughput: 1374.998\n",
      "  learn_time_ms: 2909.095\n",
      "  load_throughput: 24895705.594\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 593.035\n",
      "  sample_time_ms: 6744.96\n",
      "  update_time_ms: 2.174\n",
      "timestamp: 1658396204\n",
      "timesteps_since_restore: 1248000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1248000\n",
      "training_iteration: 312\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1252000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-51\n",
      "done: false\n",
      "episode_len_mean: 195.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.48\n",
      "episode_reward_min: 81.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6726\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17588309943675995\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002736953552812338\n",
      "        model: {}\n",
      "        policy_loss: 0.00017423770623281598\n",
      "        total_loss: 1.5122721195220947\n",
      "        vf_explained_var: 0.08211752027273178\n",
      "        vf_loss: 1.5120978355407715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1252000\n",
      "  num_agent_steps_trained: 1252000\n",
      "  num_steps_sampled: 1252000\n",
      "  num_steps_trained: 1252000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 313\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.46\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0693245029899257\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07960037664312286\n",
      "  mean_inference_ms: 0.7586620996264822\n",
      "  mean_raw_obs_processing_ms: 0.09217847960790536\n",
      "time_since_restore: 2260.455500125885\n",
      "time_this_iter_s: 6.738622665405273\n",
      "time_total_s: 2260.455500125885\n",
      "timers:\n",
      "  learn_throughput: 1376.27\n",
      "  learn_time_ms: 2906.407\n",
      "  load_throughput: 24888319.24\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 593.217\n",
      "  sample_time_ms: 6742.893\n",
      "  update_time_ms: 2.177\n",
      "timestamp: 1658396211\n",
      "timesteps_since_restore: 1252000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1252000\n",
      "training_iteration: 313\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1256000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-36-58\n",
      "done: false\n",
      "episode_len_mean: 197.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.36\n",
      "episode_reward_min: 96.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6746\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19120174646377563\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002125461120158434\n",
      "        model: {}\n",
      "        policy_loss: 0.0009096305584535003\n",
      "        total_loss: 1.5130081176757812\n",
      "        vf_explained_var: -0.18817488849163055\n",
      "        vf_loss: 1.5120986700057983\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1256000\n",
      "  num_agent_steps_trained: 1256000\n",
      "  num_steps_sampled: 1256000\n",
      "  num_steps_trained: 1256000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 314\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.67777777777778\n",
      "  ram_util_percent: 85.47777777777777\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06930846214676559\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07958357210050672\n",
      "  mean_inference_ms: 0.7584997973202909\n",
      "  mean_raw_obs_processing_ms: 0.09215727595471862\n",
      "time_since_restore: 2267.1271073818207\n",
      "time_this_iter_s: 6.671607255935669\n",
      "time_total_s: 2267.1271073818207\n",
      "timers:\n",
      "  learn_throughput: 1379.472\n",
      "  learn_time_ms: 2899.661\n",
      "  load_throughput: 24807357.682\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 594.995\n",
      "  sample_time_ms: 6722.744\n",
      "  update_time_ms: 2.12\n",
      "timestamp: 1658396218\n",
      "timesteps_since_restore: 1256000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1256000\n",
      "training_iteration: 314\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1260000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-04\n",
      "done: false\n",
      "episode_len_mean: 194.97\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.97\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 6768\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.173617422580719\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0020358238834887743\n",
      "        model: {}\n",
      "        policy_loss: -0.012046764604747295\n",
      "        total_loss: 5.9380598068237305\n",
      "        vf_explained_var: -0.033796850591897964\n",
      "        vf_loss: 5.950106620788574\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1260000\n",
      "  num_agent_steps_trained: 1260000\n",
      "  num_steps_sampled: 1260000\n",
      "  num_steps_trained: 1260000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 315\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.910000000000004\n",
      "  ram_util_percent: 85.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06929068974832531\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07956526971274033\n",
      "  mean_inference_ms: 0.7583226348621843\n",
      "  mean_raw_obs_processing_ms: 0.09213423241537835\n",
      "time_since_restore: 2273.7852489948273\n",
      "time_this_iter_s: 6.658141613006592\n",
      "time_total_s: 2273.7852489948273\n",
      "timers:\n",
      "  learn_throughput: 1380.003\n",
      "  learn_time_ms: 2898.545\n",
      "  load_throughput: 24973527.836\n",
      "  load_time_ms: 0.16\n",
      "  sample_throughput: 595.138\n",
      "  sample_time_ms: 6721.127\n",
      "  update_time_ms: 2.137\n",
      "timestamp: 1658396224\n",
      "timesteps_since_restore: 1260000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1260000\n",
      "training_iteration: 315\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1264000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-11\n",
      "done: false\n",
      "episode_len_mean: 196.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.99\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6788\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1723131537437439\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026920705568045378\n",
      "        model: {}\n",
      "        policy_loss: 0.006457889918237925\n",
      "        total_loss: 6.508473873138428\n",
      "        vf_explained_var: 4.4376938603818417e-05\n",
      "        vf_loss: 6.502016067504883\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1264000\n",
      "  num_agent_steps_trained: 1264000\n",
      "  num_steps_sampled: 1264000\n",
      "  num_steps_trained: 1264000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 316\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.644444444444446\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06927368931218511\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07954749365414264\n",
      "  mean_inference_ms: 0.7581485110173322\n",
      "  mean_raw_obs_processing_ms: 0.0921122373510852\n",
      "time_since_restore: 2280.3685812950134\n",
      "time_this_iter_s: 6.583332300186157\n",
      "time_total_s: 2280.3685812950134\n",
      "timers:\n",
      "  learn_throughput: 1378.318\n",
      "  learn_time_ms: 2902.087\n",
      "  load_throughput: 24969810.984\n",
      "  load_time_ms: 0.16\n",
      "  sample_throughput: 596.478\n",
      "  sample_time_ms: 6706.03\n",
      "  update_time_ms: 2.155\n",
      "timestamp: 1658396231\n",
      "timesteps_since_restore: 1264000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1264000\n",
      "training_iteration: 316\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1268000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-18\n",
      "done: false\n",
      "episode_len_mean: 195.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.55\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6809\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20260807871818542\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004683458246290684\n",
      "        model: {}\n",
      "        policy_loss: -0.00853393878787756\n",
      "        total_loss: 5.991971015930176\n",
      "        vf_explained_var: 1.9133283785777166e-05\n",
      "        vf_loss: 6.000504493713379\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1268000\n",
      "  num_agent_steps_trained: 1268000\n",
      "  num_steps_sampled: 1268000\n",
      "  num_steps_trained: 1268000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 317\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.730000000000004\n",
      "  ram_util_percent: 85.39\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06925618785308568\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.079528422423193\n",
      "  mean_inference_ms: 0.7579758865917364\n",
      "  mean_raw_obs_processing_ms: 0.09209021931703734\n",
      "time_since_restore: 2287.02787065506\n",
      "time_this_iter_s: 6.659289360046387\n",
      "time_total_s: 2287.02787065506\n",
      "timers:\n",
      "  learn_throughput: 1381.471\n",
      "  learn_time_ms: 2895.465\n",
      "  load_throughput: 24719634.596\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 596.475\n",
      "  sample_time_ms: 6706.067\n",
      "  update_time_ms: 2.106\n",
      "timestamp: 1658396238\n",
      "timesteps_since_restore: 1268000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1268000\n",
      "training_iteration: 317\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1272000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-24\n",
      "done: false\n",
      "episode_len_mean: 195.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.55\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6829\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17200486361980438\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0012444021413102746\n",
      "        model: {}\n",
      "        policy_loss: -0.003819238394498825\n",
      "        total_loss: 9.277935028076172\n",
      "        vf_explained_var: 4.649738912121393e-06\n",
      "        vf_loss: 9.281754493713379\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1272000\n",
      "  num_agent_steps_trained: 1272000\n",
      "  num_steps_sampled: 1272000\n",
      "  num_steps_trained: 1272000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 318\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.166666666666664\n",
      "  ram_util_percent: 85.51111111111112\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06923928421666567\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07951033169231256\n",
      "  mean_inference_ms: 0.7578098737348463\n",
      "  mean_raw_obs_processing_ms: 0.09206879634373742\n",
      "time_since_restore: 2293.6552612781525\n",
      "time_this_iter_s: 6.627390623092651\n",
      "time_total_s: 2293.6552612781525\n",
      "timers:\n",
      "  learn_throughput: 1381.414\n",
      "  learn_time_ms: 2895.584\n",
      "  load_throughput: 24719634.596\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 596.962\n",
      "  sample_time_ms: 6700.599\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658396244\n",
      "timesteps_since_restore: 1272000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1272000\n",
      "training_iteration: 318\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1276000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-31\n",
      "done: false\n",
      "episode_len_mean: 193.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.12\n",
      "episode_reward_min: 71.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6850\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17273469269275665\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0020841422956436872\n",
      "        model: {}\n",
      "        policy_loss: 0.00121681101154536\n",
      "        total_loss: 3.093458414077759\n",
      "        vf_explained_var: -0.17457696795463562\n",
      "        vf_loss: 3.0922412872314453\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1276000\n",
      "  num_agent_steps_trained: 1276000\n",
      "  num_steps_sampled: 1276000\n",
      "  num_steps_trained: 1276000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 319\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.989999999999995\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06922322373230962\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07949381270146531\n",
      "  mean_inference_ms: 0.757654887037628\n",
      "  mean_raw_obs_processing_ms: 0.09204835380967491\n",
      "time_since_restore: 2300.4976420402527\n",
      "time_this_iter_s: 6.84238076210022\n",
      "time_total_s: 2300.4976420402527\n",
      "timers:\n",
      "  learn_throughput: 1380.895\n",
      "  learn_time_ms: 2896.672\n",
      "  load_throughput: 24748806.609\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 596.26\n",
      "  sample_time_ms: 6708.481\n",
      "  update_time_ms: 2.091\n",
      "timestamp: 1658396251\n",
      "timesteps_since_restore: 1276000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1276000\n",
      "training_iteration: 319\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1280000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-38\n",
      "done: false\n",
      "episode_len_mean: 193.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.04\n",
      "episode_reward_min: 71.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6871\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18303310871124268\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024695643223822117\n",
      "        model: {}\n",
      "        policy_loss: -2.9346378141781315e-05\n",
      "        total_loss: 1.5271899700164795\n",
      "        vf_explained_var: -0.13018734753131866\n",
      "        vf_loss: 1.5272191762924194\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1280000\n",
      "  num_agent_steps_trained: 1280000\n",
      "  num_steps_sampled: 1280000\n",
      "  num_steps_trained: 1280000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 320\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.22\n",
      "  ram_util_percent: 85.49\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06920673721221364\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07947662011887259\n",
      "  mean_inference_ms: 0.7574991999749223\n",
      "  mean_raw_obs_processing_ms: 0.09202745454379137\n",
      "time_since_restore: 2307.336933374405\n",
      "time_this_iter_s: 6.839291334152222\n",
      "time_total_s: 2307.336933374405\n",
      "timers:\n",
      "  learn_throughput: 1375.717\n",
      "  learn_time_ms: 2907.574\n",
      "  load_throughput: 24708712.813\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 596.597\n",
      "  sample_time_ms: 6704.691\n",
      "  update_time_ms: 2.105\n",
      "timestamp: 1658396258\n",
      "timesteps_since_restore: 1280000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1280000\n",
      "training_iteration: 320\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1284000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-45\n",
      "done: false\n",
      "episode_len_mean: 192.54\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.54\n",
      "episode_reward_min: 71.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 6892\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2241957187652588\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004614594392478466\n",
      "        model: {}\n",
      "        policy_loss: -0.004253532737493515\n",
      "        total_loss: 8.803709983825684\n",
      "        vf_explained_var: 9.754780876392033e-06\n",
      "        vf_loss: 8.807963371276855\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1284000\n",
      "  num_agent_steps_trained: 1284000\n",
      "  num_steps_sampled: 1284000\n",
      "  num_steps_trained: 1284000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 321\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.24444444444444\n",
      "  ram_util_percent: 85.5111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06919225617937545\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0794611073154185\n",
      "  mean_inference_ms: 0.7573600062547345\n",
      "  mean_raw_obs_processing_ms: 0.09200851578368621\n",
      "time_since_restore: 2314.020651578903\n",
      "time_this_iter_s: 6.683718204498291\n",
      "time_total_s: 2314.020651578903\n",
      "timers:\n",
      "  learn_throughput: 1374.523\n",
      "  learn_time_ms: 2910.1\n",
      "  load_throughput: 24748806.609\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 595.393\n",
      "  sample_time_ms: 6718.254\n",
      "  update_time_ms: 2.079\n",
      "timestamp: 1658396265\n",
      "timesteps_since_restore: 1284000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1284000\n",
      "training_iteration: 321\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1288000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-52\n",
      "done: false\n",
      "episode_len_mean: 192.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.66\n",
      "episode_reward_min: 71.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6912\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2019462287425995\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004514425527304411\n",
      "        model: {}\n",
      "        policy_loss: 0.004782406147569418\n",
      "        total_loss: 7.4065470695495605\n",
      "        vf_explained_var: -0.018779290840029716\n",
      "        vf_loss: 7.401764869689941\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1288000\n",
      "  num_agent_steps_trained: 1288000\n",
      "  num_steps_sampled: 1288000\n",
      "  num_steps_trained: 1288000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 322\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.64\n",
      "  ram_util_percent: 85.55\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06917993328839363\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07944809842097358\n",
      "  mean_inference_ms: 0.7572391662847536\n",
      "  mean_raw_obs_processing_ms: 0.09199179606114775\n",
      "time_since_restore: 2320.841307401657\n",
      "time_this_iter_s: 6.820655822753906\n",
      "time_total_s: 2320.841307401657\n",
      "timers:\n",
      "  learn_throughput: 1375.681\n",
      "  learn_time_ms: 2907.651\n",
      "  load_throughput: 24701436.985\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 593.703\n",
      "  sample_time_ms: 6737.376\n",
      "  update_time_ms: 2.089\n",
      "timestamp: 1658396272\n",
      "timesteps_since_restore: 1288000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1288000\n",
      "training_iteration: 322\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1292000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-37-58\n",
      "done: false\n",
      "episode_len_mean: 191.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.5\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 6934\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24070516228675842\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035711831878870726\n",
      "        model: {}\n",
      "        policy_loss: 0.003688946133479476\n",
      "        total_loss: 6.561148643493652\n",
      "        vf_explained_var: -0.032164063304662704\n",
      "        vf_loss: 6.557459831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1292000\n",
      "  num_agent_steps_trained: 1292000\n",
      "  num_steps_sampled: 1292000\n",
      "  num_steps_trained: 1292000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 323\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.6\n",
      "  ram_util_percent: 85.47999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06916726988634307\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07943452210941095\n",
      "  mean_inference_ms: 0.7571179606463158\n",
      "  mean_raw_obs_processing_ms: 0.09197468344739967\n",
      "time_since_restore: 2327.5980775356293\n",
      "time_this_iter_s: 6.756770133972168\n",
      "time_total_s: 2327.5980775356293\n",
      "timers:\n",
      "  learn_throughput: 1376.823\n",
      "  learn_time_ms: 2905.239\n",
      "  load_throughput: 24046461.23\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 593.563\n",
      "  sample_time_ms: 6738.965\n",
      "  update_time_ms: 2.081\n",
      "timestamp: 1658396278\n",
      "timesteps_since_restore: 1292000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1292000\n",
      "training_iteration: 323\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1296000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-38-05\n",
      "done: false\n",
      "episode_len_mean: 193.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.2\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6954\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21077927947044373\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028393894899636507\n",
      "        model: {}\n",
      "        policy_loss: 0.00562805961817503\n",
      "        total_loss: 7.351898193359375\n",
      "        vf_explained_var: 3.24020475090947e-05\n",
      "        vf_loss: 7.3462700843811035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1296000\n",
      "  num_agent_steps_trained: 1296000\n",
      "  num_steps_sampled: 1296000\n",
      "  num_steps_trained: 1296000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 324\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.72222222222222\n",
      "  ram_util_percent: 85.51111111111112\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06915442732563724\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07942038380854113\n",
      "  mean_inference_ms: 0.75699380487371\n",
      "  mean_raw_obs_processing_ms: 0.09195691146834281\n",
      "time_since_restore: 2334.1528232097626\n",
      "time_this_iter_s: 6.554745674133301\n",
      "time_total_s: 2334.1528232097626\n",
      "timers:\n",
      "  learn_throughput: 1382.667\n",
      "  learn_time_ms: 2892.96\n",
      "  load_throughput: 23882158.007\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 593.707\n",
      "  sample_time_ms: 6737.327\n",
      "  update_time_ms: 2.078\n",
      "timestamp: 1658396285\n",
      "timesteps_since_restore: 1296000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1296000\n",
      "training_iteration: 324\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1300000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-38-12\n",
      "done: false\n",
      "episode_len_mean: 195.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.12\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6974\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22925415635108948\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003467535600066185\n",
      "        model: {}\n",
      "        policy_loss: 0.005603059660643339\n",
      "        total_loss: 6.550462245941162\n",
      "        vf_explained_var: 3.353677675477229e-05\n",
      "        vf_loss: 6.544858932495117\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1300000\n",
      "  num_agent_steps_trained: 1300000\n",
      "  num_steps_sampled: 1300000\n",
      "  num_steps_trained: 1300000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 325\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.629999999999995\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06914207297329991\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07940702540628918\n",
      "  mean_inference_ms: 0.7568721684424315\n",
      "  mean_raw_obs_processing_ms: 0.09193952764335667\n",
      "time_since_restore: 2340.9312019348145\n",
      "time_this_iter_s: 6.77837872505188\n",
      "time_total_s: 2340.9312019348145\n",
      "timers:\n",
      "  learn_throughput: 1377.17\n",
      "  learn_time_ms: 2904.506\n",
      "  load_throughput: 23639870.368\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 594.755\n",
      "  sample_time_ms: 6725.457\n",
      "  update_time_ms: 2.051\n",
      "timestamp: 1658396292\n",
      "timesteps_since_restore: 1300000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1300000\n",
      "training_iteration: 325\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1304000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-38-19\n",
      "done: false\n",
      "episode_len_mean: 194.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.71\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 6994\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19767414033412933\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002006678143516183\n",
      "        model: {}\n",
      "        policy_loss: 0.002761115785688162\n",
      "        total_loss: 3.6544759273529053\n",
      "        vf_explained_var: -0.031092483550310135\n",
      "        vf_loss: 3.651714324951172\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1304000\n",
      "  num_agent_steps_trained: 1304000\n",
      "  num_steps_sampled: 1304000\n",
      "  num_steps_trained: 1304000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 326\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.519999999999996\n",
      "  ram_util_percent: 85.46000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0691290407155905\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07939305287750412\n",
      "  mean_inference_ms: 0.7567485542843577\n",
      "  mean_raw_obs_processing_ms: 0.09192130521618293\n",
      "time_since_restore: 2347.7954597473145\n",
      "time_this_iter_s: 6.8642578125\n",
      "time_total_s: 2347.7954597473145\n",
      "timers:\n",
      "  learn_throughput: 1369.523\n",
      "  learn_time_ms: 2920.724\n",
      "  load_throughput: 23425322.536\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 592.627\n",
      "  sample_time_ms: 6749.611\n",
      "  update_time_ms: 2.029\n",
      "timestamp: 1658396299\n",
      "timesteps_since_restore: 1304000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1304000\n",
      "training_iteration: 326\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1308000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-38-25\n",
      "done: false\n",
      "episode_len_mean: 195.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.79\n",
      "episode_reward_min: 124.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7014\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19800211489200592\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024011170025914907\n",
      "        model: {}\n",
      "        policy_loss: 0.0021544701885432005\n",
      "        total_loss: 2.4215095043182373\n",
      "        vf_explained_var: -0.14258041977882385\n",
      "        vf_loss: 2.4193551540374756\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1308000\n",
      "  num_agent_steps_trained: 1308000\n",
      "  num_steps_sampled: 1308000\n",
      "  num_steps_trained: 1308000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 327\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.85555555555556\n",
      "  ram_util_percent: 85.49999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06911494479841424\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07937813006898303\n",
      "  mean_inference_ms: 0.7566135065068323\n",
      "  mean_raw_obs_processing_ms: 0.09190230333980136\n",
      "time_since_restore: 2354.5771193504333\n",
      "time_this_iter_s: 6.7816596031188965\n",
      "time_total_s: 2354.5771193504333\n",
      "timers:\n",
      "  learn_throughput: 1364.007\n",
      "  learn_time_ms: 2932.536\n",
      "  load_throughput: 23646534.179\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 591.328\n",
      "  sample_time_ms: 6764.433\n",
      "  update_time_ms: 2.028\n",
      "timestamp: 1658396305\n",
      "timesteps_since_restore: 1308000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1308000\n",
      "training_iteration: 327\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1312000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-38-33\n",
      "done: false\n",
      "episode_len_mean: 198.63\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.63\n",
      "episode_reward_min: 159.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7034\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2226710468530655\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002511675236746669\n",
      "        model: {}\n",
      "        policy_loss: 0.0001834959111874923\n",
      "        total_loss: 1.512280821800232\n",
      "        vf_explained_var: -0.238612100481987\n",
      "        vf_loss: 1.5120973587036133\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1312000\n",
      "  num_agent_steps_trained: 1312000\n",
      "  num_steps_sampled: 1312000\n",
      "  num_steps_trained: 1312000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 328\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.445454545454545\n",
      "  ram_util_percent: 85.44545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06910257460871999\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.079365206996364\n",
      "  mean_inference_ms: 0.7565007006062927\n",
      "  mean_raw_obs_processing_ms: 0.09188513749831774\n",
      "time_since_restore: 2361.8833906650543\n",
      "time_this_iter_s: 7.306271314620972\n",
      "time_total_s: 2361.8833906650543\n",
      "timers:\n",
      "  learn_throughput: 1345.511\n",
      "  learn_time_ms: 2972.847\n",
      "  load_throughput: 23643201.804\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 587.852\n",
      "  sample_time_ms: 6804.435\n",
      "  update_time_ms: 2.001\n",
      "timestamp: 1658396313\n",
      "timesteps_since_restore: 1312000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1312000\n",
      "training_iteration: 328\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1316000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-38-40\n",
      "done: false\n",
      "episode_len_mean: 198.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.94\n",
      "episode_reward_min: 159.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7054\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22623944282531738\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00420891959220171\n",
      "        model: {}\n",
      "        policy_loss: -0.0011619280558079481\n",
      "        total_loss: 1.51093590259552\n",
      "        vf_explained_var: -0.05060385540127754\n",
      "        vf_loss: 1.5120978355407715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1316000\n",
      "  num_agent_steps_trained: 1316000\n",
      "  num_steps_sampled: 1316000\n",
      "  num_steps_trained: 1316000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 329\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.63\n",
      "  ram_util_percent: 85.49\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06909570148509797\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07935824605579561\n",
      "  mean_inference_ms: 0.756446988398539\n",
      "  mean_raw_obs_processing_ms: 0.09187485159345357\n",
      "time_since_restore: 2369.2426042556763\n",
      "time_this_iter_s: 7.359213590621948\n",
      "time_total_s: 2369.2426042556763\n",
      "timers:\n",
      "  learn_throughput: 1338.44\n",
      "  learn_time_ms: 2988.555\n",
      "  load_throughput: 23334097.357\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 581.337\n",
      "  sample_time_ms: 6880.692\n",
      "  update_time_ms: 2.011\n",
      "timestamp: 1658396320\n",
      "timesteps_since_restore: 1316000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1316000\n",
      "training_iteration: 329\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1320000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-38-47\n",
      "done: false\n",
      "episode_len_mean: 198.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.4\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7075\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.221560537815094\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0020514465868473053\n",
      "        model: {}\n",
      "        policy_loss: 0.007099406328052282\n",
      "        total_loss: 7.02323055267334\n",
      "        vf_explained_var: -0.03224673867225647\n",
      "        vf_loss: 7.016129970550537\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1320000\n",
      "  num_agent_steps_trained: 1320000\n",
      "  num_steps_sampled: 1320000\n",
      "  num_steps_trained: 1320000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 330\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.129999999999995\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06909042877787089\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0793528132074302\n",
      "  mean_inference_ms: 0.7564087245150531\n",
      "  mean_raw_obs_processing_ms: 0.09186678907225877\n",
      "time_since_restore: 2376.086754798889\n",
      "time_this_iter_s: 6.844150543212891\n",
      "time_total_s: 2376.086754798889\n",
      "timers:\n",
      "  learn_throughput: 1346.102\n",
      "  learn_time_ms: 2971.543\n",
      "  load_throughput: 23156957.902\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 578.589\n",
      "  sample_time_ms: 6913.367\n",
      "  update_time_ms: 2.007\n",
      "timestamp: 1658396327\n",
      "timesteps_since_restore: 1320000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1320000\n",
      "training_iteration: 330\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1324000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-38-54\n",
      "done: false\n",
      "episode_len_mean: 198.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.41\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7095\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24163344502449036\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00440985569730401\n",
      "        model: {}\n",
      "        policy_loss: 0.004602537024766207\n",
      "        total_loss: 6.60742712020874\n",
      "        vf_explained_var: 8.634149708086625e-06\n",
      "        vf_loss: 6.6028242111206055\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1324000\n",
      "  num_agent_steps_trained: 1324000\n",
      "  num_steps_sampled: 1324000\n",
      "  num_steps_trained: 1324000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 331\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.39\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0690867197620027\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0793493368217833\n",
      "  mean_inference_ms: 0.7563855454433537\n",
      "  mean_raw_obs_processing_ms: 0.09186100470406963\n",
      "time_since_restore: 2382.9514124393463\n",
      "time_this_iter_s: 6.864657640457153\n",
      "time_total_s: 2382.9514124393463\n",
      "timers:\n",
      "  learn_throughput: 1342.623\n",
      "  learn_time_ms: 2979.243\n",
      "  load_throughput: 22647429.806\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 579.207\n",
      "  sample_time_ms: 6905.998\n",
      "  update_time_ms: 2.066\n",
      "timestamp: 1658396334\n",
      "timesteps_since_restore: 1324000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1324000\n",
      "training_iteration: 331\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1328000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-01\n",
      "done: false\n",
      "episode_len_mean: 197.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.21\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7116\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2671682834625244\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027048613410443068\n",
      "        model: {}\n",
      "        policy_loss: 0.0015950691886246204\n",
      "        total_loss: 3.071153402328491\n",
      "        vf_explained_var: -0.15239307284355164\n",
      "        vf_loss: 3.0695581436157227\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1328000\n",
      "  num_agent_steps_trained: 1328000\n",
      "  num_steps_sampled: 1328000\n",
      "  num_steps_trained: 1328000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 332\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.03\n",
      "  ram_util_percent: 85.55\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06908331953160098\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07934585930237166\n",
      "  mean_inference_ms: 0.7563683548937311\n",
      "  mean_raw_obs_processing_ms: 0.09185547227400416\n",
      "time_since_restore: 2390.0578413009644\n",
      "time_this_iter_s: 7.106428861618042\n",
      "time_total_s: 2390.0578413009644\n",
      "timers:\n",
      "  learn_throughput: 1328.042\n",
      "  learn_time_ms: 3011.953\n",
      "  load_throughput: 22583410.957\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 578.921\n",
      "  sample_time_ms: 6909.4\n",
      "  update_time_ms: 2.057\n",
      "timestamp: 1658396341\n",
      "timesteps_since_restore: 1328000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1328000\n",
      "training_iteration: 332\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1332000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-08\n",
      "done: false\n",
      "episode_len_mean: 195.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.94\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7136\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25641271471977234\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0022158301435410976\n",
      "        model: {}\n",
      "        policy_loss: 0.0016106005059555173\n",
      "        total_loss: 2.1714704036712646\n",
      "        vf_explained_var: -0.21976856887340546\n",
      "        vf_loss: 2.1698598861694336\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1332000\n",
      "  num_agent_steps_trained: 1332000\n",
      "  num_steps_sampled: 1332000\n",
      "  num_steps_trained: 1332000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 333\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.83\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06908066171935631\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07934302436883445\n",
      "  mean_inference_ms: 0.7563490024938264\n",
      "  mean_raw_obs_processing_ms: 0.09185059436597168\n",
      "time_since_restore: 2397.2151052951813\n",
      "time_this_iter_s: 7.157263994216919\n",
      "time_total_s: 2397.2151052951813\n",
      "timers:\n",
      "  learn_throughput: 1319.269\n",
      "  learn_time_ms: 3031.981\n",
      "  load_throughput: 22684175.23\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 574.521\n",
      "  sample_time_ms: 6962.318\n",
      "  update_time_ms: 2.02\n",
      "timestamp: 1658396348\n",
      "timesteps_since_restore: 1332000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1332000\n",
      "training_iteration: 333\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1336000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-15\n",
      "done: false\n",
      "episode_len_mean: 194.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.01\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7157\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2541981339454651\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006396271754056215\n",
      "        model: {}\n",
      "        policy_loss: -0.004508623853325844\n",
      "        total_loss: 1.6411586999893188\n",
      "        vf_explained_var: -0.13249698281288147\n",
      "        vf_loss: 1.645667314529419\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1336000\n",
      "  num_agent_steps_trained: 1336000\n",
      "  num_steps_sampled: 1336000\n",
      "  num_steps_trained: 1336000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 334\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.660000000000004\n",
      "  ram_util_percent: 85.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06907317708698654\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07933504129691957\n",
      "  mean_inference_ms: 0.756277675542386\n",
      "  mean_raw_obs_processing_ms: 0.09183972702311938\n",
      "time_since_restore: 2403.9370291233063\n",
      "time_this_iter_s: 6.721923828125\n",
      "time_total_s: 2403.9370291233063\n",
      "timers:\n",
      "  learn_throughput: 1314.302\n",
      "  learn_time_ms: 3043.441\n",
      "  load_throughput: 22807525.829\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 572.498\n",
      "  sample_time_ms: 6986.928\n",
      "  update_time_ms: 2.072\n",
      "timestamp: 1658396355\n",
      "timesteps_since_restore: 1336000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1336000\n",
      "training_iteration: 334\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1340000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-22\n",
      "done: false\n",
      "episode_len_mean: 193.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.41\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7178\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2716809809207916\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004837366286665201\n",
      "        model: {}\n",
      "        policy_loss: -0.0023409565910696983\n",
      "        total_loss: 2.3464505672454834\n",
      "        vf_explained_var: -0.1925075203180313\n",
      "        vf_loss: 2.3487913608551025\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1340000\n",
      "  num_agent_steps_trained: 1340000\n",
      "  num_steps_sampled: 1340000\n",
      "  num_steps_trained: 1340000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 335\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.83\n",
      "  ram_util_percent: 85.52000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06906752933348209\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07932959253364266\n",
      "  mean_inference_ms: 0.7562291677965522\n",
      "  mean_raw_obs_processing_ms: 0.09183190117111904\n",
      "time_since_restore: 2410.96222114563\n",
      "time_this_iter_s: 7.025192022323608\n",
      "time_total_s: 2410.96222114563\n",
      "timers:\n",
      "  learn_throughput: 1317.802\n",
      "  learn_time_ms: 3035.357\n",
      "  load_throughput: 22944770.241\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 568.873\n",
      "  sample_time_ms: 7031.449\n",
      "  update_time_ms: 2.102\n",
      "timestamp: 1658396362\n",
      "timesteps_since_restore: 1340000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1340000\n",
      "training_iteration: 335\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1344000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-29\n",
      "done: false\n",
      "episode_len_mean: 190.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.69\n",
      "episode_reward_min: 73.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 7200\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28389331698417664\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00570203410461545\n",
      "        model: {}\n",
      "        policy_loss: 0.0027601253241300583\n",
      "        total_loss: 6.870206356048584\n",
      "        vf_explained_var: 1.733258250169456e-05\n",
      "        vf_loss: 6.867445945739746\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1344000\n",
      "  num_agent_steps_trained: 1344000\n",
      "  num_steps_sampled: 1344000\n",
      "  num_steps_trained: 1344000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 336\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.120000000000005\n",
      "  ram_util_percent: 85.4\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06906177468670063\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07932384626625065\n",
      "  mean_inference_ms: 0.756177533136557\n",
      "  mean_raw_obs_processing_ms: 0.09182363213888195\n",
      "time_since_restore: 2417.9039199352264\n",
      "time_this_iter_s: 6.941698789596558\n",
      "time_total_s: 2417.9039199352264\n",
      "timers:\n",
      "  learn_throughput: 1318.097\n",
      "  learn_time_ms: 3034.678\n",
      "  load_throughput: 23188964.755\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 568.885\n",
      "  sample_time_ms: 7031.302\n",
      "  update_time_ms: 2.107\n",
      "timestamp: 1658396369\n",
      "timesteps_since_restore: 1344000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1344000\n",
      "training_iteration: 336\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1348000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-36\n",
      "done: false\n",
      "episode_len_mean: 190.87\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.87\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7221\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28057071566581726\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003726200433447957\n",
      "        model: {}\n",
      "        policy_loss: 0.0002603166794870049\n",
      "        total_loss: 3.556208848953247\n",
      "        vf_explained_var: 0.007046077400445938\n",
      "        vf_loss: 3.555948257446289\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1348000\n",
      "  num_agent_steps_trained: 1348000\n",
      "  num_steps_sampled: 1348000\n",
      "  num_steps_trained: 1348000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 337\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.89\n",
      "  ram_util_percent: 85.46000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0690544782591618\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07931690521488144\n",
      "  mean_inference_ms: 0.7561113475882848\n",
      "  mean_raw_obs_processing_ms: 0.09181399196817808\n",
      "time_since_restore: 2424.583818912506\n",
      "time_this_iter_s: 6.679898977279663\n",
      "time_total_s: 2424.583818912506\n",
      "timers:\n",
      "  learn_throughput: 1320.931\n",
      "  learn_time_ms: 3028.167\n",
      "  load_throughput: 23014013.717\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 569.256\n",
      "  sample_time_ms: 7026.717\n",
      "  update_time_ms: 2.1\n",
      "timestamp: 1658396376\n",
      "timesteps_since_restore: 1348000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1348000\n",
      "training_iteration: 337\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1352000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-43\n",
      "done: false\n",
      "episode_len_mean: 189.97\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.97\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7241\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26349613070487976\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004211269319057465\n",
      "        model: {}\n",
      "        policy_loss: 0.0001561121898703277\n",
      "        total_loss: 2.192697286605835\n",
      "        vf_explained_var: -0.09138810634613037\n",
      "        vf_loss: 2.1925411224365234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1352000\n",
      "  num_agent_steps_trained: 1352000\n",
      "  num_steps_sampled: 1352000\n",
      "  num_steps_trained: 1352000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 338\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.8\n",
      "  ram_util_percent: 85.37\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06904757519987753\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07931100351515549\n",
      "  mean_inference_ms: 0.7560522112151616\n",
      "  mean_raw_obs_processing_ms: 0.09180551626267366\n",
      "time_since_restore: 2431.7046217918396\n",
      "time_this_iter_s: 7.120802879333496\n",
      "time_total_s: 2431.7046217918396\n",
      "timers:\n",
      "  learn_throughput: 1327.678\n",
      "  learn_time_ms: 3012.778\n",
      "  load_throughput: 23121852.26\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 570.085\n",
      "  sample_time_ms: 7016.493\n",
      "  update_time_ms: 2.118\n",
      "timestamp: 1658396383\n",
      "timesteps_since_restore: 1352000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1352000\n",
      "training_iteration: 338\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1356000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-50\n",
      "done: false\n",
      "episode_len_mean: 189.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.48\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 7263\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2781231105327606\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005166240967810154\n",
      "        model: {}\n",
      "        policy_loss: -0.0004632806812878698\n",
      "        total_loss: 4.702171325683594\n",
      "        vf_explained_var: -0.07213049381971359\n",
      "        vf_loss: 4.702634811401367\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1356000\n",
      "  num_agent_steps_trained: 1356000\n",
      "  num_steps_sampled: 1356000\n",
      "  num_steps_trained: 1356000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 339\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.84\n",
      "  ram_util_percent: 85.36\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06904129880075803\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07930561536242864\n",
      "  mean_inference_ms: 0.7560008202541196\n",
      "  mean_raw_obs_processing_ms: 0.09179784750915695\n",
      "time_since_restore: 2438.6259627342224\n",
      "time_this_iter_s: 6.9213409423828125\n",
      "time_total_s: 2438.6259627342224\n",
      "timers:\n",
      "  learn_throughput: 1335.816\n",
      "  learn_time_ms: 2994.423\n",
      "  load_throughput: 23311401.973\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 573.433\n",
      "  sample_time_ms: 6975.527\n",
      "  update_time_ms: 2.154\n",
      "timestamp: 1658396390\n",
      "timesteps_since_restore: 1356000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1356000\n",
      "training_iteration: 339\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1360000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-39-57\n",
      "done: false\n",
      "episode_len_mean: 190.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.52\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7283\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25228744745254517\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002706984058022499\n",
      "        model: {}\n",
      "        policy_loss: 0.006819522008299828\n",
      "        total_loss: 6.307222366333008\n",
      "        vf_explained_var: 4.907513357466087e-06\n",
      "        vf_loss: 6.300403118133545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1360000\n",
      "  num_agent_steps_trained: 1360000\n",
      "  num_steps_sampled: 1360000\n",
      "  num_steps_trained: 1360000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 340\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.57\n",
      "  ram_util_percent: 85.36000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06903267466414506\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07929747680805327\n",
      "  mean_inference_ms: 0.7559229660773462\n",
      "  mean_raw_obs_processing_ms: 0.09178669096338357\n",
      "time_since_restore: 2445.573016643524\n",
      "time_this_iter_s: 6.947053909301758\n",
      "time_total_s: 2445.573016643524\n",
      "timers:\n",
      "  learn_throughput: 1323.829\n",
      "  learn_time_ms: 3021.538\n",
      "  load_throughput: 23504085.178\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 576.327\n",
      "  sample_time_ms: 6940.51\n",
      "  update_time_ms: 2.15\n",
      "timestamp: 1658396397\n",
      "timesteps_since_restore: 1360000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1360000\n",
      "training_iteration: 340\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1364000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-40-04\n",
      "done: false\n",
      "episode_len_mean: 190.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.98\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7304\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22732193768024445\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034027027431875467\n",
      "        model: {}\n",
      "        policy_loss: 0.004067299421876669\n",
      "        total_loss: 5.7676777839660645\n",
      "        vf_explained_var: -0.008041374385356903\n",
      "        vf_loss: 5.76361083984375\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1364000\n",
      "  num_agent_steps_trained: 1364000\n",
      "  num_steps_sampled: 1364000\n",
      "  num_steps_trained: 1364000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 341\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.739999999999995\n",
      "  ram_util_percent: 85.35000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06902444481539001\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07928973680001314\n",
      "  mean_inference_ms: 0.7558494890075177\n",
      "  mean_raw_obs_processing_ms: 0.09177635903182596\n",
      "time_since_restore: 2452.6573741436005\n",
      "time_this_iter_s: 7.084357500076294\n",
      "time_total_s: 2452.6573741436005\n",
      "timers:\n",
      "  learn_throughput: 1315.343\n",
      "  learn_time_ms: 3041.032\n",
      "  load_throughput: 23841432.429\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 573.851\n",
      "  sample_time_ms: 6970.445\n",
      "  update_time_ms: 2.096\n",
      "timestamp: 1658396404\n",
      "timesteps_since_restore: 1364000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1364000\n",
      "training_iteration: 341\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1368000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-40-11\n",
      "done: false\n",
      "episode_len_mean: 190.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.33\n",
      "episode_reward_min: 95.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 7326\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26534441113471985\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003881530836224556\n",
      "        model: {}\n",
      "        policy_loss: 0.0017333877040073276\n",
      "        total_loss: 4.260815620422363\n",
      "        vf_explained_var: 0.03163907676935196\n",
      "        vf_loss: 4.259082317352295\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1368000\n",
      "  num_agent_steps_trained: 1368000\n",
      "  num_steps_sampled: 1368000\n",
      "  num_steps_trained: 1368000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 342\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.589999999999996\n",
      "  ram_util_percent: 85.33999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06901942726436681\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0792853844079745\n",
      "  mean_inference_ms: 0.7558109272575843\n",
      "  mean_raw_obs_processing_ms: 0.09177004770434845\n",
      "time_since_restore: 2460.017502784729\n",
      "time_this_iter_s: 7.36012864112854\n",
      "time_total_s: 2460.017502784729\n",
      "timers:\n",
      "  learn_throughput: 1315.64\n",
      "  learn_time_ms: 3040.346\n",
      "  load_throughput: 23656536.943\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 570.076\n",
      "  sample_time_ms: 7016.609\n",
      "  update_time_ms: 2.128\n",
      "timestamp: 1658396411\n",
      "timesteps_since_restore: 1368000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1368000\n",
      "training_iteration: 342\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1372000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-40-18\n",
      "done: false\n",
      "episode_len_mean: 189.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.49\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7347\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2605459690093994\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003203602973371744\n",
      "        model: {}\n",
      "        policy_loss: 0.0055677928030490875\n",
      "        total_loss: 7.344277858734131\n",
      "        vf_explained_var: 2.234450039395597e-05\n",
      "        vf_loss: 7.338709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1372000\n",
      "  num_agent_steps_trained: 1372000\n",
      "  num_steps_sampled: 1372000\n",
      "  num_steps_trained: 1372000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 343\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.290000000000006\n",
      "  ram_util_percent: 85.31\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06901332406853813\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07927927099229963\n",
      "  mean_inference_ms: 0.7557581395547017\n",
      "  mean_raw_obs_processing_ms: 0.09176162036113908\n",
      "time_since_restore: 2467.0443484783173\n",
      "time_this_iter_s: 7.026845693588257\n",
      "time_total_s: 2467.0443484783173\n",
      "timers:\n",
      "  learn_throughput: 1313.053\n",
      "  learn_time_ms: 3046.335\n",
      "  load_throughput: 23981154.946\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 571.71\n",
      "  sample_time_ms: 6996.559\n",
      "  update_time_ms: 2.261\n",
      "timestamp: 1658396418\n",
      "timesteps_since_restore: 1372000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1372000\n",
      "training_iteration: 343\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1376000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-40-25\n",
      "done: false\n",
      "episode_len_mean: 190.47\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.47\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7367\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2815711796283722\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004326563328504562\n",
      "        model: {}\n",
      "        policy_loss: 0.002055519726127386\n",
      "        total_loss: 5.259115219116211\n",
      "        vf_explained_var: -0.09375479817390442\n",
      "        vf_loss: 5.257059574127197\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1376000\n",
      "  num_agent_steps_trained: 1376000\n",
      "  num_steps_sampled: 1376000\n",
      "  num_steps_trained: 1376000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 344\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.970000000000006\n",
      "  ram_util_percent: 85.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06900665252490716\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07927289336930497\n",
      "  mean_inference_ms: 0.7556982935382338\n",
      "  mean_raw_obs_processing_ms: 0.09175253165007036\n",
      "time_since_restore: 2473.9695999622345\n",
      "time_this_iter_s: 6.925251483917236\n",
      "time_total_s: 2473.9695999622345\n",
      "timers:\n",
      "  learn_throughput: 1307.727\n",
      "  learn_time_ms: 3058.742\n",
      "  load_throughput: 24077520.092\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 570.482\n",
      "  sample_time_ms: 7011.62\n",
      "  update_time_ms: 2.199\n",
      "timestamp: 1658396425\n",
      "timesteps_since_restore: 1376000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1376000\n",
      "training_iteration: 344\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1380000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-40-32\n",
      "done: false\n",
      "episode_len_mean: 190.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.93\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7387\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23054087162017822\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005752844270318747\n",
      "        model: {}\n",
      "        policy_loss: -0.004873678088188171\n",
      "        total_loss: 0.3832319378852844\n",
      "        vf_explained_var: -0.24785488843917847\n",
      "        vf_loss: 0.3881056308746338\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1380000\n",
      "  num_agent_steps_trained: 1380000\n",
      "  num_steps_sampled: 1380000\n",
      "  num_steps_trained: 1380000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 345\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.0090909090909\n",
      "  ram_util_percent: 85.33636363636366\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06900132225729781\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07926801939729251\n",
      "  mean_inference_ms: 0.7556555944207523\n",
      "  mean_raw_obs_processing_ms: 0.0917458319008227\n",
      "time_since_restore: 2481.3423495292664\n",
      "time_this_iter_s: 7.37274956703186\n",
      "time_total_s: 2481.3423495292664\n",
      "timers:\n",
      "  learn_throughput: 1285.763\n",
      "  learn_time_ms: 3110.993\n",
      "  load_throughput: 23804222.474\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 570.92\n",
      "  sample_time_ms: 7006.233\n",
      "  update_time_ms: 2.165\n",
      "timestamp: 1658396432\n",
      "timesteps_since_restore: 1380000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1380000\n",
      "training_iteration: 345\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1384000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-40-40\n",
      "done: false\n",
      "episode_len_mean: 192.3\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.3\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 7409\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23253369331359863\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003865990322083235\n",
      "        model: {}\n",
      "        policy_loss: -0.002538616070523858\n",
      "        total_loss: 2.966216564178467\n",
      "        vf_explained_var: -0.10138384997844696\n",
      "        vf_loss: 2.9687552452087402\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1384000\n",
      "  num_agent_steps_trained: 1384000\n",
      "  num_steps_sampled: 1384000\n",
      "  num_steps_trained: 1384000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 346\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.239999999999995\n",
      "  ram_util_percent: 85.35\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06899552150305965\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07926254008612711\n",
      "  mean_inference_ms: 0.7556082823253897\n",
      "  mean_raw_obs_processing_ms: 0.0917383939759285\n",
      "time_since_restore: 2488.4993419647217\n",
      "time_this_iter_s: 7.156992435455322\n",
      "time_total_s: 2488.4993419647217\n",
      "timers:\n",
      "  learn_throughput: 1280.684\n",
      "  learn_time_ms: 3123.33\n",
      "  load_throughput: 23736864.743\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 566.001\n",
      "  sample_time_ms: 7067.12\n",
      "  update_time_ms: 2.154\n",
      "timestamp: 1658396440\n",
      "timesteps_since_restore: 1384000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1384000\n",
      "training_iteration: 346\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1388000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-40-46\n",
      "done: false\n",
      "episode_len_mean: 193.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.98\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7429\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24580998718738556\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002806297969073057\n",
      "        model: {}\n",
      "        policy_loss: 0.0051801628433167934\n",
      "        total_loss: 6.083808898925781\n",
      "        vf_explained_var: 1.5860923667787574e-05\n",
      "        vf_loss: 6.078629016876221\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1388000\n",
      "  num_agent_steps_trained: 1388000\n",
      "  num_steps_sampled: 1388000\n",
      "  num_steps_trained: 1388000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 347\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.45\n",
      "  ram_util_percent: 85.42999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06898796065106648\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07925442166037401\n",
      "  mean_inference_ms: 0.7555373526210206\n",
      "  mean_raw_obs_processing_ms: 0.0917284829607707\n",
      "time_since_restore: 2495.28013753891\n",
      "time_this_iter_s: 6.780795574188232\n",
      "time_total_s: 2495.28013753891\n",
      "timers:\n",
      "  learn_throughput: 1278.98\n",
      "  learn_time_ms: 3127.491\n",
      "  load_throughput: 23504085.178\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 564.494\n",
      "  sample_time_ms: 7085.998\n",
      "  update_time_ms: 2.149\n",
      "timestamp: 1658396446\n",
      "timesteps_since_restore: 1388000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1388000\n",
      "training_iteration: 347\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1392000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-40-53\n",
      "done: false\n",
      "episode_len_mean: 195.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.52\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7449\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24673691391944885\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032547342125326395\n",
      "        model: {}\n",
      "        policy_loss: 0.00373749528080225\n",
      "        total_loss: 4.892850399017334\n",
      "        vf_explained_var: 4.503034745084733e-07\n",
      "        vf_loss: 4.889112949371338\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1392000\n",
      "  num_agent_steps_trained: 1392000\n",
      "  num_steps_sampled: 1392000\n",
      "  num_steps_trained: 1392000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 348\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.72\n",
      "  ram_util_percent: 85.4\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06898086021685307\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07924687558945794\n",
      "  mean_inference_ms: 0.7554732448042805\n",
      "  mean_raw_obs_processing_ms: 0.09171924543408004\n",
      "time_since_restore: 2502.215391635895\n",
      "time_this_iter_s: 6.935254096984863\n",
      "time_total_s: 2502.215391635895\n",
      "timers:\n",
      "  learn_throughput: 1283.005\n",
      "  learn_time_ms: 3117.682\n",
      "  load_throughput: 23321123.158\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 564.879\n",
      "  sample_time_ms: 7081.164\n",
      "  update_time_ms: 2.166\n",
      "timestamp: 1658396453\n",
      "timesteps_since_restore: 1392000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1392000\n",
      "training_iteration: 348\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1396000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-00\n",
      "done: false\n",
      "episode_len_mean: 196.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.89\n",
      "episode_reward_min: 120.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7469\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2597755491733551\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002230084501206875\n",
      "        model: {}\n",
      "        policy_loss: 0.0043800342828035355\n",
      "        total_loss: 4.89349365234375\n",
      "        vf_explained_var: 1.6207336557272356e-06\n",
      "        vf_loss: 4.889113426208496\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1396000\n",
      "  num_agent_steps_trained: 1396000\n",
      "  num_steps_sampled: 1396000\n",
      "  num_steps_trained: 1396000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 349\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.833333333333336\n",
      "  ram_util_percent: 85.45555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06897360493815095\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07923862519515176\n",
      "  mean_inference_ms: 0.7554059777558354\n",
      "  mean_raw_obs_processing_ms: 0.09170985040363884\n",
      "time_since_restore: 2508.9420568943024\n",
      "time_this_iter_s: 6.726665258407593\n",
      "time_total_s: 2508.9420568943024\n",
      "timers:\n",
      "  learn_throughput: 1285.368\n",
      "  learn_time_ms: 3111.95\n",
      "  load_throughput: 23321123.158\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 566.742\n",
      "  sample_time_ms: 7057.887\n",
      "  update_time_ms: 2.135\n",
      "timestamp: 1658396460\n",
      "timesteps_since_restore: 1396000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1396000\n",
      "training_iteration: 349\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1400000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-07\n",
      "done: false\n",
      "episode_len_mean: 194.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.83\n",
      "episode_reward_min: 104.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7490\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28678518533706665\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003211363684386015\n",
      "        model: {}\n",
      "        policy_loss: 0.0034826621413230896\n",
      "        total_loss: 4.71366548538208\n",
      "        vf_explained_var: 4.0504241951566655e-06\n",
      "        vf_loss: 4.7101826667785645\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1400000\n",
      "  num_agent_steps_trained: 1400000\n",
      "  num_steps_sampled: 1400000\n",
      "  num_steps_trained: 1400000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 350\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.8\n",
      "  ram_util_percent: 85.53\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0689644348876593\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07922774925496558\n",
      "  mean_inference_ms: 0.755317195472017\n",
      "  mean_raw_obs_processing_ms: 0.0916972164049869\n",
      "time_since_restore: 2515.654423713684\n",
      "time_this_iter_s: 6.712366819381714\n",
      "time_total_s: 2515.654423713684\n",
      "timers:\n",
      "  learn_throughput: 1295.622\n",
      "  learn_time_ms: 3087.319\n",
      "  load_throughput: 23039296.896\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 567.127\n",
      "  sample_time_ms: 7053.099\n",
      "  update_time_ms: 2.137\n",
      "timestamp: 1658396467\n",
      "timesteps_since_restore: 1400000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1400000\n",
      "training_iteration: 350\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1404000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-14\n",
      "done: false\n",
      "episode_len_mean: 195.84\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.84\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7511\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28985869884490967\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005850424990057945\n",
      "        model: {}\n",
      "        policy_loss: 0.0009182150242850184\n",
      "        total_loss: 5.081564903259277\n",
      "        vf_explained_var: 6.5674062170728575e-06\n",
      "        vf_loss: 5.08064603805542\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1404000\n",
      "  num_agent_steps_trained: 1404000\n",
      "  num_steps_sampled: 1404000\n",
      "  num_steps_trained: 1404000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 351\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.82\n",
      "  ram_util_percent: 85.49\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06895520910475893\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07921727918980812\n",
      "  mean_inference_ms: 0.755227985283019\n",
      "  mean_raw_obs_processing_ms: 0.09168443907138624\n",
      "time_since_restore: 2522.5123193264008\n",
      "time_this_iter_s: 6.857895612716675\n",
      "time_total_s: 2522.5123193264008\n",
      "timers:\n",
      "  learn_throughput: 1305.91\n",
      "  learn_time_ms: 3062.998\n",
      "  load_throughput: 23208211.371\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 568.968\n",
      "  sample_time_ms: 7030.276\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658396474\n",
      "timesteps_since_restore: 1404000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1404000\n",
      "training_iteration: 351\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1408000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-21\n",
      "done: false\n",
      "episode_len_mean: 195.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.76\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7531\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2690032124519348\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0039568510837852955\n",
      "        model: {}\n",
      "        policy_loss: 0.0019160662777721882\n",
      "        total_loss: 4.626413822174072\n",
      "        vf_explained_var: 4.317555521993199e-06\n",
      "        vf_loss: 4.624496936798096\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1408000\n",
      "  num_agent_steps_trained: 1408000\n",
      "  num_steps_sampled: 1408000\n",
      "  num_steps_trained: 1408000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 352\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.379999999999995\n",
      "  ram_util_percent: 85.44999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06894915958638757\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0792105799622707\n",
      "  mean_inference_ms: 0.7551729361820146\n",
      "  mean_raw_obs_processing_ms: 0.09167513592721022\n",
      "time_since_restore: 2529.7924880981445\n",
      "time_this_iter_s: 7.280168771743774\n",
      "time_total_s: 2529.7924880981445\n",
      "timers:\n",
      "  learn_throughput: 1308.439\n",
      "  learn_time_ms: 3057.078\n",
      "  load_throughput: 23067806.957\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 571.201\n",
      "  sample_time_ms: 7002.792\n",
      "  update_time_ms: 2.115\n",
      "timestamp: 1658396481\n",
      "timesteps_since_restore: 1408000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1408000\n",
      "training_iteration: 352\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1412000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-29\n",
      "done: false\n",
      "episode_len_mean: 193.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.61\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7552\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2702180743217468\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00472704553976655\n",
      "        model: {}\n",
      "        policy_loss: 0.0010188114829361439\n",
      "        total_loss: 4.885095119476318\n",
      "        vf_explained_var: -0.03225290775299072\n",
      "        vf_loss: 4.88407564163208\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1412000\n",
      "  num_agent_steps_trained: 1412000\n",
      "  num_steps_sampled: 1412000\n",
      "  num_steps_trained: 1412000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 353\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.65454545454545\n",
      "  ram_util_percent: 85.39090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06894652483327202\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07920739148935181\n",
      "  mean_inference_ms: 0.7551506149498951\n",
      "  mean_raw_obs_processing_ms: 0.09167106857280821\n",
      "time_since_restore: 2537.2372262477875\n",
      "time_this_iter_s: 7.444738149642944\n",
      "time_total_s: 2537.2372262477875\n",
      "timers:\n",
      "  learn_throughput: 1306.505\n",
      "  learn_time_ms: 3061.602\n",
      "  load_throughput: 22835464.816\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 568.614\n",
      "  sample_time_ms: 7034.655\n",
      "  update_time_ms: 2.024\n",
      "timestamp: 1658396489\n",
      "timesteps_since_restore: 1412000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1412000\n",
      "training_iteration: 353\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1416000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-36\n",
      "done: false\n",
      "episode_len_mean: 192.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.42\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7573\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23974718153476715\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002701397053897381\n",
      "        model: {}\n",
      "        policy_loss: 0.00586006511002779\n",
      "        total_loss: 7.034590244293213\n",
      "        vf_explained_var: 8.094182703644037e-06\n",
      "        vf_loss: 7.0287299156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1416000\n",
      "  num_agent_steps_trained: 1416000\n",
      "  num_steps_sampled: 1416000\n",
      "  num_steps_trained: 1416000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 354\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.99\n",
      "  ram_util_percent: 85.34\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06894459076216945\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07920507849501472\n",
      "  mean_inference_ms: 0.7551362635219466\n",
      "  mean_raw_obs_processing_ms: 0.09166733308858617\n",
      "time_since_restore: 2544.292293548584\n",
      "time_this_iter_s: 7.055067300796509\n",
      "time_total_s: 2544.292293548584\n",
      "timers:\n",
      "  learn_throughput: 1302.132\n",
      "  learn_time_ms: 3071.885\n",
      "  load_throughput: 22678042.714\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 568.097\n",
      "  sample_time_ms: 7041.051\n",
      "  update_time_ms: 2.096\n",
      "timestamp: 1658396496\n",
      "timesteps_since_restore: 1416000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1416000\n",
      "training_iteration: 354\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1420000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-43\n",
      "done: false\n",
      "episode_len_mean: 194.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.08\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7593\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26292523741722107\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038681020960211754\n",
      "        model: {}\n",
      "        policy_loss: 0.004747571423649788\n",
      "        total_loss: 6.007772445678711\n",
      "        vf_explained_var: 4.169569365330972e-06\n",
      "        vf_loss: 6.003024578094482\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1420000\n",
      "  num_agent_steps_trained: 1420000\n",
      "  num_steps_sampled: 1420000\n",
      "  num_steps_trained: 1420000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 355\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.29\n",
      "  ram_util_percent: 85.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06894419614483319\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07920468008870571\n",
      "  mean_inference_ms: 0.7551369839677196\n",
      "  mean_raw_obs_processing_ms: 0.0916651337062407\n",
      "time_since_restore: 2551.270955324173\n",
      "time_this_iter_s: 6.978661775588989\n",
      "time_total_s: 2551.270955324173\n",
      "timers:\n",
      "  learn_throughput: 1318.969\n",
      "  learn_time_ms: 3032.672\n",
      "  load_throughput: 22882182.215\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 567.331\n",
      "  sample_time_ms: 7050.555\n",
      "  update_time_ms: 2.147\n",
      "timestamp: 1658396503\n",
      "timesteps_since_restore: 1420000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1420000\n",
      "training_iteration: 355\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1424000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-50\n",
      "done: false\n",
      "episode_len_mean: 193.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.66\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7614\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22642461955547333\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028180135414004326\n",
      "        model: {}\n",
      "        policy_loss: 0.0035907747223973274\n",
      "        total_loss: 4.925467491149902\n",
      "        vf_explained_var: -0.009519482962787151\n",
      "        vf_loss: 4.921876430511475\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1424000\n",
      "  num_agent_steps_trained: 1424000\n",
      "  num_steps_sampled: 1424000\n",
      "  num_steps_trained: 1424000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 356\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.8\n",
      "  ram_util_percent: 85.52000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06894482434157216\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07920468532761973\n",
      "  mean_inference_ms: 0.7551497155853282\n",
      "  mean_raw_obs_processing_ms: 0.09166455460077585\n",
      "time_since_restore: 2558.252794981003\n",
      "time_this_iter_s: 6.981839656829834\n",
      "time_total_s: 2558.252794981003\n",
      "timers:\n",
      "  learn_throughput: 1331.701\n",
      "  learn_time_ms: 3003.676\n",
      "  load_throughput: 22860356.997\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 569.434\n",
      "  sample_time_ms: 7024.521\n",
      "  update_time_ms: 2.191\n",
      "timestamp: 1658396510\n",
      "timesteps_since_restore: 1424000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1424000\n",
      "training_iteration: 356\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1428000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-41-57\n",
      "done: false\n",
      "episode_len_mean: 194.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.41\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7634\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22114750742912292\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036589661613106728\n",
      "        model: {}\n",
      "        policy_loss: 0.0029478243086487055\n",
      "        total_loss: 5.748915672302246\n",
      "        vf_explained_var: 2.608119757496752e-06\n",
      "        vf_loss: 5.745967864990234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1428000\n",
      "  num_agent_steps_trained: 1428000\n",
      "  num_steps_sampled: 1428000\n",
      "  num_steps_trained: 1428000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 357\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.07\n",
      "  ram_util_percent: 85.4\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0689423184078971\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07920133610634535\n",
      "  mean_inference_ms: 0.7551260536119843\n",
      "  mean_raw_obs_processing_ms: 0.091660258716108\n",
      "time_since_restore: 2565.1576619148254\n",
      "time_this_iter_s: 6.904866933822632\n",
      "time_total_s: 2565.1576619148254\n",
      "timers:\n",
      "  learn_throughput: 1324.866\n",
      "  learn_time_ms: 3019.173\n",
      "  load_throughput: 23214634.011\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 572.031\n",
      "  sample_time_ms: 6992.629\n",
      "  update_time_ms: 2.204\n",
      "timestamp: 1658396517\n",
      "timesteps_since_restore: 1428000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1428000\n",
      "training_iteration: 357\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1432000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-42-04\n",
      "done: false\n",
      "episode_len_mean: 196.56\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.56\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7654\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21779519319534302\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003809385932981968\n",
      "        model: {}\n",
      "        policy_loss: 0.004360117018222809\n",
      "        total_loss: 5.750330924987793\n",
      "        vf_explained_var: -5.024094775762933e-07\n",
      "        vf_loss: 5.745970249176025\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1432000\n",
      "  num_agent_steps_trained: 1432000\n",
      "  num_steps_sampled: 1432000\n",
      "  num_steps_trained: 1432000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 358\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.980000000000004\n",
      "  ram_util_percent: 85.47999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.068937509010711\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.079195770355034\n",
      "  mean_inference_ms: 0.7550768962447719\n",
      "  mean_raw_obs_processing_ms: 0.0916522438161088\n",
      "time_since_restore: 2572.106383562088\n",
      "time_this_iter_s: 6.948721647262573\n",
      "time_total_s: 2572.106383562088\n",
      "timers:\n",
      "  learn_throughput: 1324.937\n",
      "  learn_time_ms: 3019.012\n",
      "  load_throughput: 22200894.535\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 570.646\n",
      "  sample_time_ms: 7009.601\n",
      "  update_time_ms: 2.18\n",
      "timestamp: 1658396524\n",
      "timesteps_since_restore: 1432000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1432000\n",
      "training_iteration: 358\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1436000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-42-11\n",
      "done: false\n",
      "episode_len_mean: 197.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.75\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7674\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22447897493839264\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002963972045108676\n",
      "        model: {}\n",
      "        policy_loss: 0.005678578745573759\n",
      "        total_loss: 5.751646518707275\n",
      "        vf_explained_var: 2.8046227384947997e-07\n",
      "        vf_loss: 5.745967864990234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1436000\n",
      "  num_agent_steps_trained: 1436000\n",
      "  num_steps_sampled: 1436000\n",
      "  num_steps_trained: 1436000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 359\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.239999999999995\n",
      "  ram_util_percent: 85.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06893348017819789\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07919131376740518\n",
      "  mean_inference_ms: 0.7550422136340516\n",
      "  mean_raw_obs_processing_ms: 0.09164548228738592\n",
      "time_since_restore: 2579.375090122223\n",
      "time_this_iter_s: 7.268706560134888\n",
      "time_total_s: 2579.375090122223\n",
      "timers:\n",
      "  learn_throughput: 1309.179\n",
      "  learn_time_ms: 3055.35\n",
      "  load_throughput: 22165696.922\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 569.176\n",
      "  sample_time_ms: 7027.703\n",
      "  update_time_ms: 2.144\n",
      "timestamp: 1658396531\n",
      "timesteps_since_restore: 1436000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1436000\n",
      "training_iteration: 359\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1440000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-42-17\n",
      "done: false\n",
      "episode_len_mean: 198.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.17\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7694\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23628172278404236\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023513231426477432\n",
      "        model: {}\n",
      "        policy_loss: 0.0054919058457016945\n",
      "        total_loss: 5.751461505889893\n",
      "        vf_explained_var: 5.959823283774313e-07\n",
      "        vf_loss: 5.745969295501709\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1440000\n",
      "  num_agent_steps_trained: 1440000\n",
      "  num_steps_sampled: 1440000\n",
      "  num_steps_trained: 1440000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 360\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.86666666666667\n",
      "  ram_util_percent: 85.3111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06892676157868928\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07918361885933776\n",
      "  mean_inference_ms: 0.7549786147356937\n",
      "  mean_raw_obs_processing_ms: 0.09163503103043089\n",
      "time_since_restore: 2585.934413909912\n",
      "time_this_iter_s: 6.559323787689209\n",
      "time_total_s: 2585.934413909912\n",
      "timers:\n",
      "  learn_throughput: 1310.894\n",
      "  learn_time_ms: 3051.352\n",
      "  load_throughput: 22342809.961\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 567.186\n",
      "  sample_time_ms: 7052.362\n",
      "  update_time_ms: 2.153\n",
      "timestamp: 1658396537\n",
      "timesteps_since_restore: 1440000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1440000\n",
      "training_iteration: 360\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1444000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-42-25\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7714\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20995771884918213\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002179850824177265\n",
      "        model: {}\n",
      "        policy_loss: 0.0057664355263113976\n",
      "        total_loss: 5.751734733581543\n",
      "        vf_explained_var: 3.227623608381691e-07\n",
      "        vf_loss: 5.745968341827393\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1444000\n",
      "  num_agent_steps_trained: 1444000\n",
      "  num_steps_sampled: 1444000\n",
      "  num_steps_trained: 1444000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 361\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.85454545454545\n",
      "  ram_util_percent: 85.28181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06892000034117077\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07917661580781524\n",
      "  mean_inference_ms: 0.7549195864991431\n",
      "  mean_raw_obs_processing_ms: 0.09162405819407571\n",
      "time_since_restore: 2593.3234684467316\n",
      "time_this_iter_s: 7.389054536819458\n",
      "time_total_s: 2593.3234684467316\n",
      "timers:\n",
      "  learn_throughput: 1294.887\n",
      "  learn_time_ms: 3089.072\n",
      "  load_throughput: 22124773.836\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 566.269\n",
      "  sample_time_ms: 7063.783\n",
      "  update_time_ms: 2.12\n",
      "timestamp: 1658396545\n",
      "timesteps_since_restore: 1444000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1444000\n",
      "training_iteration: 361\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1448000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-42-32\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7734\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22974102199077606\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0018455673707649112\n",
      "        model: {}\n",
      "        policy_loss: 0.005723797716200352\n",
      "        total_loss: 5.751691818237305\n",
      "        vf_explained_var: 1.5351721458500833e-06\n",
      "        vf_loss: 5.745967864990234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1448000\n",
      "  num_agent_steps_trained: 1448000\n",
      "  num_steps_sampled: 1448000\n",
      "  num_steps_trained: 1448000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 362\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.945454545454545\n",
      "  ram_util_percent: 85.20909090909089\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06891562264335363\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07917242869189227\n",
      "  mean_inference_ms: 0.7548938050130747\n",
      "  mean_raw_obs_processing_ms: 0.09161659726462418\n",
      "time_since_restore: 2600.7946298122406\n",
      "time_this_iter_s: 7.471161365509033\n",
      "time_total_s: 2600.7946298122406\n",
      "timers:\n",
      "  learn_throughput: 1286.526\n",
      "  learn_time_ms: 3109.149\n",
      "  load_throughput: 22414450.234\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 563.339\n",
      "  sample_time_ms: 7100.522\n",
      "  update_time_ms: 2.039\n",
      "timestamp: 1658396552\n",
      "timesteps_since_restore: 1448000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1448000\n",
      "training_iteration: 362\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1452000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-42-39\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7754\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2191580981016159\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00362145877443254\n",
      "        model: {}\n",
      "        policy_loss: 0.004918168298900127\n",
      "        total_loss: 5.750888347625732\n",
      "        vf_explained_var: -1.2268302498341654e-06\n",
      "        vf_loss: 5.745969772338867\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1452000\n",
      "  num_agent_steps_trained: 1452000\n",
      "  num_steps_sampled: 1452000\n",
      "  num_steps_trained: 1452000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 363\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.5\n",
      "  ram_util_percent: 85.17777777777776\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06890855396487033\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07916533216133599\n",
      "  mean_inference_ms: 0.754843440982319\n",
      "  mean_raw_obs_processing_ms: 0.09160594821383611\n",
      "time_since_restore: 2607.67444729805\n",
      "time_this_iter_s: 6.879817485809326\n",
      "time_total_s: 2607.67444729805\n",
      "timers:\n",
      "  learn_throughput: 1287.682\n",
      "  learn_time_ms: 3106.358\n",
      "  load_throughput: 22495596.675\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 566.133\n",
      "  sample_time_ms: 7065.474\n",
      "  update_time_ms: 2.036\n",
      "timestamp: 1658396559\n",
      "timesteps_since_restore: 1452000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1452000\n",
      "training_iteration: 363\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1456000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-42-47\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7774\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2307366281747818\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003050792496651411\n",
      "        model: {}\n",
      "        policy_loss: 0.005832315422594547\n",
      "        total_loss: 5.751801490783691\n",
      "        vf_explained_var: 1.2099102377760573e-06\n",
      "        vf_loss: 5.745968818664551\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1456000\n",
      "  num_agent_steps_trained: 1456000\n",
      "  num_steps_sampled: 1456000\n",
      "  num_steps_trained: 1456000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 364\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.481818181818184\n",
      "  ram_util_percent: 85.25454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06890255859271237\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07915925390760886\n",
      "  mean_inference_ms: 0.7547995522901931\n",
      "  mean_raw_obs_processing_ms: 0.09159649342398637\n",
      "time_since_restore: 2615.0724518299103\n",
      "time_this_iter_s: 7.398004531860352\n",
      "time_total_s: 2615.0724518299103\n",
      "timers:\n",
      "  learn_throughput: 1281.974\n",
      "  learn_time_ms: 3120.188\n",
      "  load_throughput: 22604710.321\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 564.716\n",
      "  sample_time_ms: 7083.207\n",
      "  update_time_ms: 2.012\n",
      "timestamp: 1658396567\n",
      "timesteps_since_restore: 1456000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1456000\n",
      "training_iteration: 364\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1460000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-42-54\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7794\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23688732087612152\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034798940178006887\n",
      "        model: {}\n",
      "        policy_loss: 0.005371895618736744\n",
      "        total_loss: 5.751339912414551\n",
      "        vf_explained_var: 1.4997298194430186e-06\n",
      "        vf_loss: 5.745967864990234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1460000\n",
      "  num_agent_steps_trained: 1460000\n",
      "  num_steps_sampled: 1460000\n",
      "  num_steps_trained: 1460000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 365\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.17272727272728\n",
      "  ram_util_percent: 85.21818181818182\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06890097187779236\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07915854272989284\n",
      "  mean_inference_ms: 0.7548058639232458\n",
      "  mean_raw_obs_processing_ms: 0.09159378526713169\n",
      "time_since_restore: 2622.5059309005737\n",
      "time_this_iter_s: 7.433479070663452\n",
      "time_total_s: 2622.5059309005737\n",
      "timers:\n",
      "  learn_throughput: 1271.932\n",
      "  learn_time_ms: 3144.822\n",
      "  load_throughput: 22583410.957\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 561.888\n",
      "  sample_time_ms: 7118.862\n",
      "  update_time_ms: 1.96\n",
      "timestamp: 1658396574\n",
      "timesteps_since_restore: 1460000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1460000\n",
      "training_iteration: 365\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1464000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-01\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7814\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2557537853717804\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002604468259960413\n",
      "        model: {}\n",
      "        policy_loss: 0.00597251346334815\n",
      "        total_loss: 5.751948356628418\n",
      "        vf_explained_var: 1.3766109532298287e-06\n",
      "        vf_loss: 5.745975494384766\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1464000\n",
      "  num_agent_steps_trained: 1464000\n",
      "  num_steps_sampled: 1464000\n",
      "  num_steps_trained: 1464000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 366\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.67777777777778\n",
      "  ram_util_percent: 85.25555555555556\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06889659618384843\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07915461027910038\n",
      "  mean_inference_ms: 0.7547781906226655\n",
      "  mean_raw_obs_processing_ms: 0.09158785998583839\n",
      "time_since_restore: 2629.181117773056\n",
      "time_this_iter_s: 6.6751868724823\n",
      "time_total_s: 2629.181117773056\n",
      "timers:\n",
      "  learn_throughput: 1272.472\n",
      "  learn_time_ms: 3143.488\n",
      "  load_throughput: 21631273.853\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 562.376\n",
      "  sample_time_ms: 7112.677\n",
      "  update_time_ms: 1.927\n",
      "timestamp: 1658396581\n",
      "timesteps_since_restore: 1464000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1464000\n",
      "training_iteration: 366\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1468000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-08\n",
      "done: false\n",
      "episode_len_mean: 198.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.93\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7834\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2535969913005829\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004672172479331493\n",
      "        model: {}\n",
      "        policy_loss: -0.0007528860005550086\n",
      "        total_loss: 2.3455183506011963\n",
      "        vf_explained_var: -0.02166423387825489\n",
      "        vf_loss: 2.34627103805542\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1468000\n",
      "  num_agent_steps_trained: 1468000\n",
      "  num_steps_sampled: 1468000\n",
      "  num_steps_trained: 1468000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 367\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.14\n",
      "  ram_util_percent: 85.30999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06889122961086279\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07914951471779\n",
      "  mean_inference_ms: 0.7547370857211376\n",
      "  mean_raw_obs_processing_ms: 0.09158025752164062\n",
      "time_since_restore: 2636.0342302322388\n",
      "time_this_iter_s: 6.853112459182739\n",
      "time_total_s: 2636.0342302322388\n",
      "timers:\n",
      "  learn_throughput: 1281.702\n",
      "  learn_time_ms: 3120.85\n",
      "  load_throughput: 21514767.889\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 561.137\n",
      "  sample_time_ms: 7128.39\n",
      "  update_time_ms: 1.911\n",
      "timestamp: 1658396588\n",
      "timesteps_since_restore: 1468000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1468000\n",
      "training_iteration: 367\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1472000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-14\n",
      "done: false\n",
      "episode_len_mean: 198.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.93\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7854\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24162223935127258\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037344794254750013\n",
      "        model: {}\n",
      "        policy_loss: -0.001397665124386549\n",
      "        total_loss: 0.35142508149147034\n",
      "        vf_explained_var: -0.2784237563610077\n",
      "        vf_loss: 0.3528227210044861\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1472000\n",
      "  num_agent_steps_trained: 1472000\n",
      "  num_steps_sampled: 1472000\n",
      "  num_steps_trained: 1472000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 368\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.7\n",
      "  ram_util_percent: 85.28888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06888701364882092\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07914530120367617\n",
      "  mean_inference_ms: 0.7547065355051279\n",
      "  mean_raw_obs_processing_ms: 0.0915744680624633\n",
      "time_since_restore: 2642.6869678497314\n",
      "time_this_iter_s: 6.652737617492676\n",
      "time_total_s: 2642.6869678497314\n",
      "timers:\n",
      "  learn_throughput: 1288.284\n",
      "  learn_time_ms: 3104.905\n",
      "  load_throughput: 22647429.806\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 564.02\n",
      "  sample_time_ms: 7091.947\n",
      "  update_time_ms: 1.933\n",
      "timestamp: 1658396594\n",
      "timesteps_since_restore: 1472000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1472000\n",
      "training_iteration: 368\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1476000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-21\n",
      "done: false\n",
      "episode_len_mean: 197.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.42\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 7875\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22591590881347656\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004732723813503981\n",
      "        model: {}\n",
      "        policy_loss: -0.004412309732288122\n",
      "        total_loss: 0.7188743948936462\n",
      "        vf_explained_var: -0.32257965207099915\n",
      "        vf_loss: 0.7232866287231445\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1476000\n",
      "  num_agent_steps_trained: 1476000\n",
      "  num_steps_sampled: 1476000\n",
      "  num_steps_trained: 1476000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 369\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.059999999999995\n",
      "  ram_util_percent: 85.30000000000003\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.068879814786815\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07913793581692297\n",
      "  mean_inference_ms: 0.7546442007252605\n",
      "  mean_raw_obs_processing_ms: 0.09156495138094865\n",
      "time_since_restore: 2649.443975687027\n",
      "time_this_iter_s: 6.757007837295532\n",
      "time_total_s: 2649.443975687027\n",
      "timers:\n",
      "  learn_throughput: 1301.297\n",
      "  learn_time_ms: 3073.857\n",
      "  load_throughput: 22426434.969\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 566.94\n",
      "  sample_time_ms: 7055.426\n",
      "  update_time_ms: 1.956\n",
      "timestamp: 1658396601\n",
      "timesteps_since_restore: 1476000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1476000\n",
      "training_iteration: 369\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1480000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-28\n",
      "done: false\n",
      "episode_len_mean: 197.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.42\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7895\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23867878317832947\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025134675670415163\n",
      "        model: {}\n",
      "        policy_loss: 0.0027498325798660517\n",
      "        total_loss: 2.8253307342529297\n",
      "        vf_explained_var: -0.12903358042240143\n",
      "        vf_loss: 2.8225808143615723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1480000\n",
      "  num_agent_steps_trained: 1480000\n",
      "  num_steps_sampled: 1480000\n",
      "  num_steps_trained: 1480000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 370\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.6\n",
      "  ram_util_percent: 85.39000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06887040864746362\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0791278162676825\n",
      "  mean_inference_ms: 0.7545565316512473\n",
      "  mean_raw_obs_processing_ms: 0.09155260824907305\n",
      "time_since_restore: 2656.458909034729\n",
      "time_this_iter_s: 7.014933347702026\n",
      "time_total_s: 2656.458909034729\n",
      "timers:\n",
      "  learn_throughput: 1290.042\n",
      "  learn_time_ms: 3100.674\n",
      "  load_throughput: 22411456.051\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 567.9\n",
      "  sample_time_ms: 7043.489\n",
      "  update_time_ms: 1.94\n",
      "timestamp: 1658396608\n",
      "timesteps_since_restore: 1480000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1480000\n",
      "training_iteration: 370\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1484000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-35\n",
      "done: false\n",
      "episode_len_mean: 197.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.42\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7915\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22622442245483398\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004410832189023495\n",
      "        model: {}\n",
      "        policy_loss: 0.0008594319224357605\n",
      "        total_loss: 2.8234405517578125\n",
      "        vf_explained_var: -0.12856239080429077\n",
      "        vf_loss: 2.8225808143615723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1484000\n",
      "  num_agent_steps_trained: 1484000\n",
      "  num_steps_sampled: 1484000\n",
      "  num_steps_trained: 1484000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 371\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.72\n",
      "  ram_util_percent: 85.4\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06886164577829462\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07911840168440092\n",
      "  mean_inference_ms: 0.7544774647175855\n",
      "  mean_raw_obs_processing_ms: 0.09154082647301573\n",
      "time_since_restore: 2663.174447774887\n",
      "time_this_iter_s: 6.715538740158081\n",
      "time_total_s: 2663.174447774887\n",
      "timers:\n",
      "  learn_throughput: 1308.507\n",
      "  learn_time_ms: 3056.919\n",
      "  load_throughput: 22650487.377\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 567.648\n",
      "  sample_time_ms: 7046.626\n",
      "  update_time_ms: 1.958\n",
      "timestamp: 1658396615\n",
      "timesteps_since_restore: 1484000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1484000\n",
      "training_iteration: 371\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1488000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-41\n",
      "done: false\n",
      "episode_len_mean: 198.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.49\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7935\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22498148679733276\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0013922099024057388\n",
      "        model: {}\n",
      "        policy_loss: 0.0037170404102653265\n",
      "        total_loss: 2.826298236846924\n",
      "        vf_explained_var: -0.06655672192573547\n",
      "        vf_loss: 2.822580575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1488000\n",
      "  num_agent_steps_trained: 1488000\n",
      "  num_steps_sampled: 1488000\n",
      "  num_steps_trained: 1488000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 372\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.77777777777778\n",
      "  ram_util_percent: 85.26666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06885113899331236\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07910711578925109\n",
      "  mean_inference_ms: 0.7543769326917473\n",
      "  mean_raw_obs_processing_ms: 0.09152707001193326\n",
      "time_since_restore: 2669.821930408478\n",
      "time_this_iter_s: 6.647482633590698\n",
      "time_total_s: 2669.821930408478\n",
      "timers:\n",
      "  learn_throughput: 1329.662\n",
      "  learn_time_ms: 3008.284\n",
      "  load_throughput: 22629101.699\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 573.952\n",
      "  sample_time_ms: 6969.225\n",
      "  update_time_ms: 2.066\n",
      "timestamp: 1658396621\n",
      "timesteps_since_restore: 1488000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1488000\n",
      "training_iteration: 372\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1492000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-49\n",
      "done: false\n",
      "episode_len_mean: 198.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.49\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7955\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2147218883037567\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004353905096650124\n",
      "        model: {}\n",
      "        policy_loss: 0.0016928790137171745\n",
      "        total_loss: 2.8242738246917725\n",
      "        vf_explained_var: -0.00698421336710453\n",
      "        vf_loss: 2.8225808143615723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1492000\n",
      "  num_agent_steps_trained: 1492000\n",
      "  num_steps_sampled: 1492000\n",
      "  num_steps_trained: 1492000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 373\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.48181818181819\n",
      "  ram_util_percent: 85.32727272727274\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06884315114217024\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07909844756575712\n",
      "  mean_inference_ms: 0.7542988406105242\n",
      "  mean_raw_obs_processing_ms: 0.09151551442648075\n",
      "time_since_restore: 2677.0308475494385\n",
      "time_this_iter_s: 7.208917140960693\n",
      "time_total_s: 2677.0308475494385\n",
      "timers:\n",
      "  learn_throughput: 1329.304\n",
      "  learn_time_ms: 3009.094\n",
      "  load_throughput: 22711812.644\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 575.156\n",
      "  sample_time_ms: 6954.634\n",
      "  update_time_ms: 2.05\n",
      "timestamp: 1658396629\n",
      "timesteps_since_restore: 1492000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1492000\n",
      "training_iteration: 373\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1496000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-43-56\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7975\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23637710511684418\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037066799122840166\n",
      "        model: {}\n",
      "        policy_loss: 0.0021744961850345135\n",
      "        total_loss: 2.8247554302215576\n",
      "        vf_explained_var: -0.06331967562437057\n",
      "        vf_loss: 2.822580575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1496000\n",
      "  num_agent_steps_trained: 1496000\n",
      "  num_steps_sampled: 1496000\n",
      "  num_steps_trained: 1496000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 374\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.555555555555564\n",
      "  ram_util_percent: 85.32222222222222\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06883523664591182\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07909012424063805\n",
      "  mean_inference_ms: 0.7542241620135425\n",
      "  mean_raw_obs_processing_ms: 0.09150440513251928\n",
      "time_since_restore: 2683.911439180374\n",
      "time_this_iter_s: 6.880591630935669\n",
      "time_total_s: 2683.911439180374\n",
      "timers:\n",
      "  learn_throughput: 1341.843\n",
      "  learn_time_ms: 2980.976\n",
      "  load_throughput: 22638262.043\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 577.046\n",
      "  sample_time_ms: 6931.852\n",
      "  update_time_ms: 2.032\n",
      "timestamp: 1658396636\n",
      "timesteps_since_restore: 1496000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1496000\n",
      "training_iteration: 374\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1500000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-02\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 7995\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2556283473968506\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004044386558234692\n",
      "        model: {}\n",
      "        policy_loss: 0.001059305970557034\n",
      "        total_loss: 2.8236405849456787\n",
      "        vf_explained_var: -0.07118195295333862\n",
      "        vf_loss: 2.8225810527801514\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1500000\n",
      "  num_agent_steps_trained: 1500000\n",
      "  num_steps_sampled: 1500000\n",
      "  num_steps_trained: 1500000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 375\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.60000000000001\n",
      "  ram_util_percent: 85.27000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06882649378135192\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07908104977257677\n",
      "  mean_inference_ms: 0.754142224216441\n",
      "  mean_raw_obs_processing_ms: 0.09149193871742604\n",
      "time_since_restore: 2690.6588790416718\n",
      "time_this_iter_s: 6.747439861297607\n",
      "time_total_s: 2690.6588790416718\n",
      "timers:\n",
      "  learn_throughput: 1355.719\n",
      "  learn_time_ms: 2950.464\n",
      "  load_throughput: 22721040.087\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 582.631\n",
      "  sample_time_ms: 6865.406\n",
      "  update_time_ms: 2.106\n",
      "timestamp: 1658396642\n",
      "timesteps_since_restore: 1500000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1500000\n",
      "training_iteration: 375\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1504000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-10\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8015\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23601482808589935\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004441693890839815\n",
      "        model: {}\n",
      "        policy_loss: 0.0008097782847471535\n",
      "        total_loss: 2.8233907222747803\n",
      "        vf_explained_var: 0.023346150293946266\n",
      "        vf_loss: 2.822580575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1504000\n",
      "  num_agent_steps_trained: 1504000\n",
      "  num_steps_sampled: 1504000\n",
      "  num_steps_trained: 1504000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 376\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.79\n",
      "  ram_util_percent: 85.28000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0688207750931698\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0790751696427287\n",
      "  mean_inference_ms: 0.754091152029583\n",
      "  mean_raw_obs_processing_ms: 0.09148366851105638\n",
      "time_since_restore: 2697.8049790859222\n",
      "time_this_iter_s: 7.146100044250488\n",
      "time_total_s: 2697.8049790859222\n",
      "timers:\n",
      "  learn_throughput: 1351.997\n",
      "  learn_time_ms: 2958.587\n",
      "  load_throughput: 23807600.397\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 581.867\n",
      "  sample_time_ms: 6874.422\n",
      "  update_time_ms: 2.077\n",
      "timestamp: 1658396650\n",
      "timesteps_since_restore: 1504000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1504000\n",
      "training_iteration: 376\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1508000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-17\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8035\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26415979862213135\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003149726428091526\n",
      "        model: {}\n",
      "        policy_loss: 0.0013474546140059829\n",
      "        total_loss: 2.8239283561706543\n",
      "        vf_explained_var: -0.03985141962766647\n",
      "        vf_loss: 2.8225808143615723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1508000\n",
      "  num_agent_steps_trained: 1508000\n",
      "  num_steps_sampled: 1508000\n",
      "  num_steps_trained: 1508000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 377\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.6\n",
      "  ram_util_percent: 85.32000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06881668851283354\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07907114462823789\n",
      "  mean_inference_ms: 0.7540601998533033\n",
      "  mean_raw_obs_processing_ms: 0.09147767892108707\n",
      "time_since_restore: 2704.7296648025513\n",
      "time_this_iter_s: 6.924685716629028\n",
      "time_total_s: 2704.7296648025513\n",
      "timers:\n",
      "  learn_throughput: 1347.941\n",
      "  learn_time_ms: 2967.49\n",
      "  load_throughput: 23402449.435\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 581.322\n",
      "  sample_time_ms: 6880.866\n",
      "  update_time_ms: 2.082\n",
      "timestamp: 1658396657\n",
      "timesteps_since_restore: 1508000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1508000\n",
      "training_iteration: 377\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1512000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-24\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8055\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24939076602458954\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003949770703911781\n",
      "        model: {}\n",
      "        policy_loss: 0.0003492266987450421\n",
      "        total_loss: 2.8229305744171143\n",
      "        vf_explained_var: -0.11606405675411224\n",
      "        vf_loss: 2.8225810527801514\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1512000\n",
      "  num_agent_steps_trained: 1512000\n",
      "  num_steps_sampled: 1512000\n",
      "  num_steps_trained: 1512000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 378\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.239999999999995\n",
      "  ram_util_percent: 85.28999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06881248789849889\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07906740160271494\n",
      "  mean_inference_ms: 0.7540358978999205\n",
      "  mean_raw_obs_processing_ms: 0.09147226593310898\n",
      "time_since_restore: 2711.721100091934\n",
      "time_this_iter_s: 6.991435289382935\n",
      "time_total_s: 2711.721100091934\n",
      "timers:\n",
      "  learn_throughput: 1344.538\n",
      "  learn_time_ms: 2975.0\n",
      "  load_throughput: 23211422.247\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 578.356\n",
      "  sample_time_ms: 6916.157\n",
      "  update_time_ms: 2.047\n",
      "timestamp: 1658396664\n",
      "timesteps_since_restore: 1512000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1512000\n",
      "training_iteration: 378\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1516000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-31\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8075\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2600705921649933\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004218156449496746\n",
      "        model: {}\n",
      "        policy_loss: 0.0010147751308977604\n",
      "        total_loss: 2.8235957622528076\n",
      "        vf_explained_var: -0.1144542247056961\n",
      "        vf_loss: 2.822580575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1516000\n",
      "  num_agent_steps_trained: 1516000\n",
      "  num_steps_sampled: 1516000\n",
      "  num_steps_trained: 1516000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 379\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.39090909090909\n",
      "  ram_util_percent: 85.29090909090908\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06880878863241051\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0790639640344303\n",
      "  mean_inference_ms: 0.7540131375862025\n",
      "  mean_raw_obs_processing_ms: 0.09146741408950777\n",
      "time_since_restore: 2718.9364533424377\n",
      "time_this_iter_s: 7.21535325050354\n",
      "time_total_s: 2718.9364533424377\n",
      "timers:\n",
      "  learn_throughput: 1326.69\n",
      "  learn_time_ms: 3015.022\n",
      "  load_throughput: 23425322.536\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 577.258\n",
      "  sample_time_ms: 6929.312\n",
      "  update_time_ms: 2.119\n",
      "timestamp: 1658396671\n",
      "timesteps_since_restore: 1516000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1516000\n",
      "training_iteration: 379\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1520000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-37\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8095\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23750390112400055\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002849540440365672\n",
      "        model: {}\n",
      "        policy_loss: 0.0010882718488574028\n",
      "        total_loss: 2.823669672012329\n",
      "        vf_explained_var: -0.12903223931789398\n",
      "        vf_loss: 2.8225808143615723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1520000\n",
      "  num_agent_steps_trained: 1520000\n",
      "  num_steps_sampled: 1520000\n",
      "  num_steps_trained: 1520000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 380\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.166666666666664\n",
      "  ram_util_percent: 85.46666666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06880484986914231\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07906032814830885\n",
      "  mean_inference_ms: 0.7539876441712134\n",
      "  mean_raw_obs_processing_ms: 0.09146250778414249\n",
      "time_since_restore: 2725.578476667404\n",
      "time_this_iter_s: 6.642023324966431\n",
      "time_total_s: 2725.578476667404\n",
      "timers:\n",
      "  learn_throughput: 1338.552\n",
      "  learn_time_ms: 2988.303\n",
      "  load_throughput: 21492718.422\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 574.861\n",
      "  sample_time_ms: 6958.201\n",
      "  update_time_ms: 2.185\n",
      "timestamp: 1658396677\n",
      "timesteps_since_restore: 1520000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1520000\n",
      "training_iteration: 380\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1524000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-44\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8115\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22943082451820374\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035280638840049505\n",
      "        model: {}\n",
      "        policy_loss: 0.0016150240553542972\n",
      "        total_loss: 2.8241961002349854\n",
      "        vf_explained_var: -0.015297715552151203\n",
      "        vf_loss: 2.8225810527801514\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1524000\n",
      "  num_agent_steps_trained: 1524000\n",
      "  num_steps_sampled: 1524000\n",
      "  num_steps_trained: 1524000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 381\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.730000000000004\n",
      "  ram_util_percent: 85.38000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06879718501027841\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0790525962898557\n",
      "  mean_inference_ms: 0.7539229230758154\n",
      "  mean_raw_obs_processing_ms: 0.09145288893524012\n",
      "time_since_restore: 2732.2478840351105\n",
      "time_this_iter_s: 6.669407367706299\n",
      "time_total_s: 2732.2478840351105\n",
      "timers:\n",
      "  learn_throughput: 1336.901\n",
      "  learn_time_ms: 2991.993\n",
      "  load_throughput: 21536862.644\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 577.741\n",
      "  sample_time_ms: 6923.515\n",
      "  update_time_ms: 2.274\n",
      "timestamp: 1658396684\n",
      "timesteps_since_restore: 1524000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1524000\n",
      "training_iteration: 381\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1528000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-51\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8135\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22018691897392273\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0020701836328953505\n",
      "        model: {}\n",
      "        policy_loss: 0.002154040150344372\n",
      "        total_loss: 2.824735403060913\n",
      "        vf_explained_var: -0.044491857290267944\n",
      "        vf_loss: 2.8225810527801514\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1528000\n",
      "  num_agent_steps_trained: 1528000\n",
      "  num_steps_sampled: 1528000\n",
      "  num_steps_trained: 1528000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 382\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.8\n",
      "  ram_util_percent: 85.45\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06879079703906937\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07904603122748911\n",
      "  mean_inference_ms: 0.7538659167454491\n",
      "  mean_raw_obs_processing_ms: 0.09144440148888519\n",
      "time_since_restore: 2739.4512956142426\n",
      "time_this_iter_s: 7.20341157913208\n",
      "time_total_s: 2739.4512956142426\n",
      "timers:\n",
      "  learn_throughput: 1324.576\n",
      "  learn_time_ms: 3019.833\n",
      "  load_throughput: 21481710.627\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 574.976\n",
      "  sample_time_ms: 6956.808\n",
      "  update_time_ms: 2.233\n",
      "timestamp: 1658396691\n",
      "timesteps_since_restore: 1528000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1528000\n",
      "training_iteration: 382\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1532000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-44-58\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8155\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24980507791042328\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003908079583197832\n",
      "        model: {}\n",
      "        policy_loss: 0.0007985609699971974\n",
      "        total_loss: 2.8233792781829834\n",
      "        vf_explained_var: -0.10583233833312988\n",
      "        vf_loss: 2.822580575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1532000\n",
      "  num_agent_steps_trained: 1532000\n",
      "  num_steps_sampled: 1532000\n",
      "  num_steps_trained: 1532000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 383\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.31\n",
      "  ram_util_percent: 85.35\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06878462432871423\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07903917904760693\n",
      "  mean_inference_ms: 0.7538083777684603\n",
      "  mean_raw_obs_processing_ms: 0.0914363700299041\n",
      "time_since_restore: 2746.491895198822\n",
      "time_this_iter_s: 7.040599584579468\n",
      "time_total_s: 2746.491895198822\n",
      "timers:\n",
      "  learn_throughput: 1334.507\n",
      "  learn_time_ms: 2997.361\n",
      "  load_throughput: 20945338.327\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 572.317\n",
      "  sample_time_ms: 6989.138\n",
      "  update_time_ms: 2.256\n",
      "timestamp: 1658396698\n",
      "timesteps_since_restore: 1532000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1532000\n",
      "training_iteration: 383\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1536000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-45-06\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8175\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24054765701293945\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00307447905652225\n",
      "        model: {}\n",
      "        policy_loss: 0.0022348808124661446\n",
      "        total_loss: 2.8248157501220703\n",
      "        vf_explained_var: 0.009726780466735363\n",
      "        vf_loss: 2.8225808143615723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1536000\n",
      "  num_agent_steps_trained: 1536000\n",
      "  num_steps_sampled: 1536000\n",
      "  num_steps_trained: 1536000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 384\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.269999999999996\n",
      "  ram_util_percent: 85.44000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0687776217309485\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0790312018013399\n",
      "  mean_inference_ms: 0.7537424965874578\n",
      "  mean_raw_obs_processing_ms: 0.09142729166161079\n",
      "time_since_restore: 2753.6982860565186\n",
      "time_this_iter_s: 7.206390857696533\n",
      "time_total_s: 2753.6982860565186\n",
      "timers:\n",
      "  learn_throughput: 1317.088\n",
      "  learn_time_ms: 3037.004\n",
      "  load_throughput: 20953185.962\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 574.729\n",
      "  sample_time_ms: 6959.797\n",
      "  update_time_ms: 2.236\n",
      "timestamp: 1658396706\n",
      "timesteps_since_restore: 1536000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1536000\n",
      "training_iteration: 384\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1540000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-45-13\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8195\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20454753935337067\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027702911756932735\n",
      "        model: {}\n",
      "        policy_loss: 0.0019777724519371986\n",
      "        total_loss: 2.824558973312378\n",
      "        vf_explained_var: -0.12018664926290512\n",
      "        vf_loss: 2.8225810527801514\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1540000\n",
      "  num_agent_steps_trained: 1540000\n",
      "  num_steps_sampled: 1540000\n",
      "  num_steps_trained: 1540000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 385\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.81818181818182\n",
      "  ram_util_percent: 85.37272727272727\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06877374050003107\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0790264985438725\n",
      "  mean_inference_ms: 0.7537101398933248\n",
      "  mean_raw_obs_processing_ms: 0.09142145145911652\n",
      "time_since_restore: 2760.9965381622314\n",
      "time_this_iter_s: 7.298252105712891\n",
      "time_total_s: 2760.9965381622314\n",
      "timers:\n",
      "  learn_throughput: 1306.354\n",
      "  learn_time_ms: 3061.957\n",
      "  load_throughput: 20846441.352\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 569.066\n",
      "  sample_time_ms: 7029.064\n",
      "  update_time_ms: 2.218\n",
      "timestamp: 1658396713\n",
      "timesteps_since_restore: 1540000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1540000\n",
      "training_iteration: 385\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1544000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-45-20\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8215\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2109432816505432\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029891657177358866\n",
      "        model: {}\n",
      "        policy_loss: 0.002816492458805442\n",
      "        total_loss: 2.825397253036499\n",
      "        vf_explained_var: -0.10638317465782166\n",
      "        vf_loss: 2.822580575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1544000\n",
      "  num_agent_steps_trained: 1544000\n",
      "  num_steps_sampled: 1544000\n",
      "  num_steps_trained: 1544000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 386\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.577777777777776\n",
      "  ram_util_percent: 85.46666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06877064767732712\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07902269638785682\n",
      "  mean_inference_ms: 0.7536866902004892\n",
      "  mean_raw_obs_processing_ms: 0.09141634658980907\n",
      "time_since_restore: 2767.7681550979614\n",
      "time_this_iter_s: 6.7716169357299805\n",
      "time_total_s: 2767.7681550979614\n",
      "timers:\n",
      "  learn_throughput: 1308.951\n",
      "  learn_time_ms: 3055.881\n",
      "  load_throughput: 20697281.026\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 569.606\n",
      "  sample_time_ms: 7022.395\n",
      "  update_time_ms: 2.233\n",
      "timestamp: 1658396720\n",
      "timesteps_since_restore: 1544000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1544000\n",
      "training_iteration: 386\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1548000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-45-27\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8235\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18799562752246857\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002735241549089551\n",
      "        model: {}\n",
      "        policy_loss: 0.0017693910049274564\n",
      "        total_loss: 2.8243515491485596\n",
      "        vf_explained_var: -0.008844747208058834\n",
      "        vf_loss: 2.8225817680358887\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1548000\n",
      "  num_agent_steps_trained: 1548000\n",
      "  num_steps_sampled: 1548000\n",
      "  num_steps_trained: 1548000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 387\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.83\n",
      "  ram_util_percent: 85.4\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06876544460930081\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07901651341638209\n",
      "  mean_inference_ms: 0.7536423295764862\n",
      "  mean_raw_obs_processing_ms: 0.09140868497639533\n",
      "time_since_restore: 2774.8008291721344\n",
      "time_this_iter_s: 7.032674074172974\n",
      "time_total_s: 2774.8008291721344\n",
      "timers:\n",
      "  learn_throughput: 1298.402\n",
      "  learn_time_ms: 3080.711\n",
      "  load_throughput: 20997767.209\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 571.233\n",
      "  sample_time_ms: 7002.393\n",
      "  update_time_ms: 2.22\n",
      "timestamp: 1658396727\n",
      "timesteps_since_restore: 1548000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1548000\n",
      "training_iteration: 387\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1552000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-45-34\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8255\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19698499143123627\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027543853502720594\n",
      "        model: {}\n",
      "        policy_loss: 0.0030810576863586903\n",
      "        total_loss: 2.825662136077881\n",
      "        vf_explained_var: -0.06535384804010391\n",
      "        vf_loss: 2.822580575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1552000\n",
      "  num_agent_steps_trained: 1552000\n",
      "  num_steps_sampled: 1552000\n",
      "  num_steps_trained: 1552000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 388\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.25454545454546\n",
      "  ram_util_percent: 85.33636363636366\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06876006196859509\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0790098698533933\n",
      "  mean_inference_ms: 0.7535912228641525\n",
      "  mean_raw_obs_processing_ms: 0.09140064329479732\n",
      "time_since_restore: 2781.9827086925507\n",
      "time_this_iter_s: 7.18187952041626\n",
      "time_total_s: 2781.9827086925507\n",
      "timers:\n",
      "  learn_throughput: 1287.922\n",
      "  learn_time_ms: 3105.779\n",
      "  load_throughput: 21175332.576\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 569.704\n",
      "  sample_time_ms: 7021.187\n",
      "  update_time_ms: 2.272\n",
      "timestamp: 1658396734\n",
      "timesteps_since_restore: 1552000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1552000\n",
      "training_iteration: 388\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1556000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-45-41\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8275\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23802123963832855\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0048037501983344555\n",
      "        model: {}\n",
      "        policy_loss: 0.0003887329075951129\n",
      "        total_loss: 2.822969913482666\n",
      "        vf_explained_var: -0.0331546887755394\n",
      "        vf_loss: 2.8225808143615723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1556000\n",
      "  num_agent_steps_trained: 1556000\n",
      "  num_steps_sampled: 1556000\n",
      "  num_steps_trained: 1556000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 389\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.88\n",
      "  ram_util_percent: 85.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06875546081452169\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07900470339485918\n",
      "  mean_inference_ms: 0.7535515003564907\n",
      "  mean_raw_obs_processing_ms: 0.09139363510595162\n",
      "time_since_restore: 2789.074069738388\n",
      "time_this_iter_s: 7.091361045837402\n",
      "time_total_s: 2789.074069738388\n",
      "timers:\n",
      "  learn_throughput: 1293.796\n",
      "  learn_time_ms: 3091.676\n",
      "  load_throughput: 21226234.818\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 567.504\n",
      "  sample_time_ms: 7048.405\n",
      "  update_time_ms: 2.184\n",
      "timestamp: 1658396741\n",
      "timesteps_since_restore: 1556000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1556000\n",
      "training_iteration: 389\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1560000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-45-48\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8295\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2194361537694931\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0042783827520906925\n",
      "        model: {}\n",
      "        policy_loss: -0.0003012072411365807\n",
      "        total_loss: 2.822279691696167\n",
      "        vf_explained_var: -0.1290316879749298\n",
      "        vf_loss: 2.8225808143615723\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1560000\n",
      "  num_agent_steps_trained: 1560000\n",
      "  num_steps_sampled: 1560000\n",
      "  num_steps_trained: 1560000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 390\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.93333333333333\n",
      "  ram_util_percent: 85.52222222222221\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06874833348043209\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07899670221079115\n",
      "  mean_inference_ms: 0.753480317611739\n",
      "  mean_raw_obs_processing_ms: 0.09138381613142776\n",
      "time_since_restore: 2795.8301146030426\n",
      "time_this_iter_s: 6.756044864654541\n",
      "time_total_s: 2795.8301146030426\n",
      "timers:\n",
      "  learn_throughput: 1289.704\n",
      "  learn_time_ms: 3101.487\n",
      "  load_throughput: 23205001.383\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 568.5\n",
      "  sample_time_ms: 7036.065\n",
      "  update_time_ms: 2.151\n",
      "timestamp: 1658396748\n",
      "timesteps_since_restore: 1560000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1560000\n",
      "training_iteration: 390\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1564000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-45-55\n",
      "done: false\n",
      "episode_len_mean: 199.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.86\n",
      "episode_reward_min: 186.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8315\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23443174362182617\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00421149330213666\n",
      "        model: {}\n",
      "        policy_loss: -0.00015985177014954388\n",
      "        total_loss: 2.399034261703491\n",
      "        vf_explained_var: -0.05309338867664337\n",
      "        vf_loss: 2.3991940021514893\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1564000\n",
      "  num_agent_steps_trained: 1564000\n",
      "  num_steps_sampled: 1564000\n",
      "  num_steps_trained: 1564000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 391\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.054545454545455\n",
      "  ram_util_percent: 85.45454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06874114780139542\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07898876174137541\n",
      "  mean_inference_ms: 0.7534063383964765\n",
      "  mean_raw_obs_processing_ms: 0.0913738763765154\n",
      "time_since_restore: 2803.0194833278656\n",
      "time_this_iter_s: 7.189368724822998\n",
      "time_total_s: 2803.0194833278656\n",
      "timers:\n",
      "  learn_throughput: 1270.682\n",
      "  learn_time_ms: 3147.915\n",
      "  load_throughput: 22998239.89\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 567.221\n",
      "  sample_time_ms: 7051.931\n",
      "  update_time_ms: 2.134\n",
      "timestamp: 1658396755\n",
      "timesteps_since_restore: 1564000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1564000\n",
      "training_iteration: 391\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1568000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-02\n",
      "done: false\n",
      "episode_len_mean: 198.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.71\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8336\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24533842504024506\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004532682243734598\n",
      "        model: {}\n",
      "        policy_loss: 0.0031323861330747604\n",
      "        total_loss: 5.975917339324951\n",
      "        vf_explained_var: -0.0014797819312661886\n",
      "        vf_loss: 5.972784996032715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1568000\n",
      "  num_agent_steps_trained: 1568000\n",
      "  num_steps_sampled: 1568000\n",
      "  num_steps_trained: 1568000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 392\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.519999999999996\n",
      "  ram_util_percent: 85.36999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06873374308841053\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.078980870788435\n",
      "  mean_inference_ms: 0.7533357682825499\n",
      "  mean_raw_obs_processing_ms: 0.09136357530586274\n",
      "time_since_restore: 2809.8778524398804\n",
      "time_this_iter_s: 6.8583691120147705\n",
      "time_total_s: 2809.8778524398804\n",
      "timers:\n",
      "  learn_throughput: 1277.722\n",
      "  learn_time_ms: 3130.57\n",
      "  load_throughput: 23198584.071\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 565.06\n",
      "  sample_time_ms: 7078.893\n",
      "  update_time_ms: 2.12\n",
      "timestamp: 1658396762\n",
      "timesteps_since_restore: 1568000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1568000\n",
      "training_iteration: 392\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1572000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-09\n",
      "done: false\n",
      "episode_len_mean: 198.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.71\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8356\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2446015328168869\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004928938578814268\n",
      "        model: {}\n",
      "        policy_loss: 0.0044335490092635155\n",
      "        total_loss: 6.405643939971924\n",
      "        vf_explained_var: 5.805364367006405e-07\n",
      "        vf_loss: 6.401209831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1572000\n",
      "  num_agent_steps_trained: 1572000\n",
      "  num_steps_sampled: 1572000\n",
      "  num_steps_trained: 1572000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 393\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.89\n",
      "  ram_util_percent: 85.4\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06872582568245982\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07897295586610106\n",
      "  mean_inference_ms: 0.7532634430736752\n",
      "  mean_raw_obs_processing_ms: 0.09135257732576253\n",
      "time_since_restore: 2816.973912715912\n",
      "time_this_iter_s: 7.096060276031494\n",
      "time_total_s: 2816.973912715912\n",
      "timers:\n",
      "  learn_throughput: 1269.983\n",
      "  learn_time_ms: 3149.65\n",
      "  load_throughput: 24018920.544\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 567.469\n",
      "  sample_time_ms: 7048.841\n",
      "  update_time_ms: 2.118\n",
      "timestamp: 1658396769\n",
      "timesteps_since_restore: 1572000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1572000\n",
      "training_iteration: 393\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1576000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-16\n",
      "done: false\n",
      "episode_len_mean: 198.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.69\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8376\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2318187654018402\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004047419410198927\n",
      "        model: {}\n",
      "        policy_loss: 0.0053540850058197975\n",
      "        total_loss: 6.336000442504883\n",
      "        vf_explained_var: 1.537992147859768e-06\n",
      "        vf_loss: 6.330645561218262\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1576000\n",
      "  num_agent_steps_trained: 1576000\n",
      "  num_steps_sampled: 1576000\n",
      "  num_steps_trained: 1576000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 394\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.833333333333336\n",
      "  ram_util_percent: 85.43333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06871778488746946\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07896463392265472\n",
      "  mean_inference_ms: 0.7531880403543826\n",
      "  mean_raw_obs_processing_ms: 0.09134139084407167\n",
      "time_since_restore: 2823.7710485458374\n",
      "time_this_iter_s: 6.797135829925537\n",
      "time_total_s: 2823.7710485458374\n",
      "timers:\n",
      "  learn_throughput: 1289.655\n",
      "  learn_time_ms: 3101.605\n",
      "  load_throughput: 24160737.327\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 565.381\n",
      "  sample_time_ms: 7074.877\n",
      "  update_time_ms: 2.156\n",
      "timestamp: 1658396776\n",
      "timesteps_since_restore: 1576000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1576000\n",
      "training_iteration: 394\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1580000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-23\n",
      "done: false\n",
      "episode_len_mean: 196.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.66\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8397\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23709750175476074\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003974835854023695\n",
      "        model: {}\n",
      "        policy_loss: -0.00030775947379879653\n",
      "        total_loss: 2.905440330505371\n",
      "        vf_explained_var: -0.03899631276726723\n",
      "        vf_loss: 2.9057483673095703\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1580000\n",
      "  num_agent_steps_trained: 1580000\n",
      "  num_steps_sampled: 1580000\n",
      "  num_steps_trained: 1580000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 395\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.57\n",
      "  ram_util_percent: 85.46000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0687099116509886\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07895622723936233\n",
      "  mean_inference_ms: 0.753117002176117\n",
      "  mean_raw_obs_processing_ms: 0.09133086656455464\n",
      "time_since_restore: 2830.5624520778656\n",
      "time_this_iter_s: 6.791403532028198\n",
      "time_total_s: 2830.5624520778656\n",
      "timers:\n",
      "  learn_throughput: 1300.655\n",
      "  learn_time_ms: 3075.373\n",
      "  load_throughput: 24185117.486\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 571.195\n",
      "  sample_time_ms: 7002.868\n",
      "  update_time_ms: 2.113\n",
      "timestamp: 1658396783\n",
      "timesteps_since_restore: 1580000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1580000\n",
      "training_iteration: 395\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1584000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-29\n",
      "done: false\n",
      "episode_len_mean: 196.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.8\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8417\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26556751132011414\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0055833859369158745\n",
      "        model: {}\n",
      "        policy_loss: 0.003916288260370493\n",
      "        total_loss: 6.153110504150391\n",
      "        vf_explained_var: 1.3607804021376069e-06\n",
      "        vf_loss: 6.14919376373291\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1584000\n",
      "  num_agent_steps_trained: 1584000\n",
      "  num_steps_sampled: 1584000\n",
      "  num_steps_trained: 1584000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 396\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.91\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06870185206141638\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07894706549394412\n",
      "  mean_inference_ms: 0.7530411011775681\n",
      "  mean_raw_obs_processing_ms: 0.09131991582331925\n",
      "time_since_restore: 2837.239054918289\n",
      "time_this_iter_s: 6.676602840423584\n",
      "time_total_s: 2837.239054918289\n",
      "timers:\n",
      "  learn_throughput: 1299.761\n",
      "  learn_time_ms: 3077.488\n",
      "  load_throughput: 24474421.59\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 574.294\n",
      "  sample_time_ms: 6965.075\n",
      "  update_time_ms: 2.112\n",
      "timestamp: 1658396789\n",
      "timesteps_since_restore: 1584000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1584000\n",
      "training_iteration: 396\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1588000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-36\n",
      "done: false\n",
      "episode_len_mean: 197.95\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.95\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8437\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21856965124607086\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030326673295348883\n",
      "        model: {}\n",
      "        policy_loss: 0.0057695903815329075\n",
      "        total_loss: 6.15496301651001\n",
      "        vf_explained_var: 1.6434217968708253e-06\n",
      "        vf_loss: 6.14919376373291\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1588000\n",
      "  num_agent_steps_trained: 1588000\n",
      "  num_steps_sampled: 1588000\n",
      "  num_steps_trained: 1588000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 397\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.877777777777776\n",
      "  ram_util_percent: 85.53333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06869289685395585\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07893634641708645\n",
      "  mean_inference_ms: 0.7529545480612092\n",
      "  mean_raw_obs_processing_ms: 0.09130799764462458\n",
      "time_since_restore: 2844.0656566619873\n",
      "time_this_iter_s: 6.82660174369812\n",
      "time_total_s: 2844.0656566619873\n",
      "timers:\n",
      "  learn_throughput: 1306.477\n",
      "  learn_time_ms: 3061.67\n",
      "  load_throughput: 24647004.554\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 574.526\n",
      "  sample_time_ms: 6962.257\n",
      "  update_time_ms: 2.249\n",
      "timestamp: 1658396796\n",
      "timesteps_since_restore: 1588000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1588000\n",
      "training_iteration: 397\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1592000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-43\n",
      "done: false\n",
      "episode_len_mean: 197.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.03\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8457\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23749883472919464\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002878690604120493\n",
      "        model: {}\n",
      "        policy_loss: 0.0007341821328736842\n",
      "        total_loss: 3.135817289352417\n",
      "        vf_explained_var: -0.05281832069158554\n",
      "        vf_loss: 3.135082960128784\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1592000\n",
      "  num_agent_steps_trained: 1592000\n",
      "  num_steps_sampled: 1592000\n",
      "  num_steps_trained: 1592000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 398\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.129999999999995\n",
      "  ram_util_percent: 85.54\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06868181585853678\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07892315970283854\n",
      "  mean_inference_ms: 0.7528473865404948\n",
      "  mean_raw_obs_processing_ms: 0.09129317625576333\n",
      "time_since_restore: 2850.9296295642853\n",
      "time_this_iter_s: 6.863972902297974\n",
      "time_total_s: 2850.9296295642853\n",
      "timers:\n",
      "  learn_throughput: 1307.012\n",
      "  learn_time_ms: 3060.416\n",
      "  load_throughput: 24513758.036\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 578.355\n",
      "  sample_time_ms: 6916.165\n",
      "  update_time_ms: 2.179\n",
      "timestamp: 1658396803\n",
      "timesteps_since_restore: 1592000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1592000\n",
      "training_iteration: 398\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1596000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-50\n",
      "done: false\n",
      "episode_len_mean: 197.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.1\n",
      "episode_reward_min: 103.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8478\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26315170526504517\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003498929087072611\n",
      "        model: {}\n",
      "        policy_loss: 0.00017641615704633296\n",
      "        total_loss: 2.550579786300659\n",
      "        vf_explained_var: -0.08197537809610367\n",
      "        vf_loss: 2.550403118133545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1596000\n",
      "  num_agent_steps_trained: 1596000\n",
      "  num_steps_sampled: 1596000\n",
      "  num_steps_trained: 1596000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 399\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.99\n",
      "  ram_util_percent: 85.52000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0686715939520315\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07890990613537599\n",
      "  mean_inference_ms: 0.7527441998452232\n",
      "  mean_raw_obs_processing_ms: 0.09127920802259767\n",
      "time_since_restore: 2857.830185651779\n",
      "time_this_iter_s: 6.9005560874938965\n",
      "time_total_s: 2857.830185651779\n",
      "timers:\n",
      "  learn_throughput: 1317.342\n",
      "  learn_time_ms: 3036.417\n",
      "  load_throughput: 24560409.896\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 578.08\n",
      "  sample_time_ms: 6919.456\n",
      "  update_time_ms: 2.186\n",
      "timestamp: 1658396810\n",
      "timesteps_since_restore: 1596000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1596000\n",
      "training_iteration: 399\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1600000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-46-57\n",
      "done: false\n",
      "episode_len_mean: 198.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.11\n",
      "episode_reward_min: 103.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8498\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2590099275112152\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003919924143701792\n",
      "        model: {}\n",
      "        policy_loss: 0.007018611300736666\n",
      "        total_loss: 6.7106475830078125\n",
      "        vf_explained_var: 1.9841297671518987e-06\n",
      "        vf_loss: 6.703629016876221\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1600000\n",
      "  num_agent_steps_trained: 1600000\n",
      "  num_steps_sampled: 1600000\n",
      "  num_steps_trained: 1600000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 400\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.529999999999994\n",
      "  ram_util_percent: 85.54999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0686619953444426\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07889761637012774\n",
      "  mean_inference_ms: 0.7526497636662477\n",
      "  mean_raw_obs_processing_ms: 0.09126587774900491\n",
      "time_since_restore: 2864.720819711685\n",
      "time_this_iter_s: 6.890634059906006\n",
      "time_total_s: 2864.720819711685\n",
      "timers:\n",
      "  learn_throughput: 1315.82\n",
      "  learn_time_ms: 3039.928\n",
      "  load_throughput: 24567602.87\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 579.212\n",
      "  sample_time_ms: 6905.933\n",
      "  update_time_ms: 2.15\n",
      "timestamp: 1658396817\n",
      "timesteps_since_restore: 1600000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1600000\n",
      "training_iteration: 400\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1604000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-04\n",
      "done: false\n",
      "episode_len_mean: 198.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.11\n",
      "episode_reward_min: 103.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8518\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22858497500419617\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004407010041177273\n",
      "        model: {}\n",
      "        policy_loss: 0.0054974923841655254\n",
      "        total_loss: 6.709127902984619\n",
      "        vf_explained_var: 1.2248434586581425e-06\n",
      "        vf_loss: 6.703629970550537\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1604000\n",
      "  num_agent_steps_trained: 1604000\n",
      "  num_steps_sampled: 1604000\n",
      "  num_steps_trained: 1604000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 401\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.99999999999999\n",
      "  ram_util_percent: 85.61\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06865397162184916\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07888739774163665\n",
      "  mean_inference_ms: 0.7525755789331668\n",
      "  mean_raw_obs_processing_ms: 0.09125486788369892\n",
      "time_since_restore: 2871.6877670288086\n",
      "time_this_iter_s: 6.966947317123413\n",
      "time_total_s: 2871.6877670288086\n",
      "timers:\n",
      "  learn_throughput: 1330.631\n",
      "  learn_time_ms: 3006.092\n",
      "  load_throughput: 23606607.57\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 578.027\n",
      "  sample_time_ms: 6920.09\n",
      "  update_time_ms: 2.114\n",
      "timestamp: 1658396824\n",
      "timesteps_since_restore: 1604000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1604000\n",
      "training_iteration: 401\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000401/checkpoint-401\n",
      "agent_timesteps_total: 1608000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-11\n",
      "done: false\n",
      "episode_len_mean: 197.13\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.13\n",
      "episode_reward_min: 102.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8538\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2544785141944885\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003619255730882287\n",
      "        model: {}\n",
      "        policy_loss: 0.003932577557861805\n",
      "        total_loss: 5.472687244415283\n",
      "        vf_explained_var: -0.00957358255982399\n",
      "        vf_loss: 5.468754291534424\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1608000\n",
      "  num_agent_steps_trained: 1608000\n",
      "  num_steps_sampled: 1608000\n",
      "  num_steps_trained: 1608000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 402\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.959999999999994\n",
      "  ram_util_percent: 85.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.068647572288446\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07887912497730504\n",
      "  mean_inference_ms: 0.7525158119534282\n",
      "  mean_raw_obs_processing_ms: 0.09124548242239992\n",
      "time_since_restore: 2878.656615257263\n",
      "time_this_iter_s: 6.96884822845459\n",
      "time_total_s: 2878.656615257263\n",
      "timers:\n",
      "  learn_throughput: 1327.951\n",
      "  learn_time_ms: 3012.16\n",
      "  load_throughput: 23550275.126\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 580.322\n",
      "  sample_time_ms: 6892.724\n",
      "  update_time_ms: 2.148\n",
      "timestamp: 1658396831\n",
      "timesteps_since_restore: 1608000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1608000\n",
      "training_iteration: 402\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1612000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-18\n",
      "done: false\n",
      "episode_len_mean: 196.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.85\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8559\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2391246110200882\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003636107314378023\n",
      "        model: {}\n",
      "        policy_loss: -2.8023156119161285e-05\n",
      "        total_loss: 2.7721495628356934\n",
      "        vf_explained_var: -0.11738113313913345\n",
      "        vf_loss: 2.7721774578094482\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1612000\n",
      "  num_agent_steps_trained: 1612000\n",
      "  num_steps_sampled: 1612000\n",
      "  num_steps_trained: 1612000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 403\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.61\n",
      "  ram_util_percent: 85.47\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06864325472271986\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07887342836091707\n",
      "  mean_inference_ms: 0.7524797409697166\n",
      "  mean_raw_obs_processing_ms: 0.0912389912204101\n",
      "time_since_restore: 2885.5387437343597\n",
      "time_this_iter_s: 6.882128477096558\n",
      "time_total_s: 2885.5387437343597\n",
      "timers:\n",
      "  learn_throughput: 1339.368\n",
      "  learn_time_ms: 2986.484\n",
      "  load_throughput: 23576750.984\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 579.491\n",
      "  sample_time_ms: 6902.612\n",
      "  update_time_ms: 2.146\n",
      "timestamp: 1658396838\n",
      "timesteps_since_restore: 1612000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1612000\n",
      "training_iteration: 403\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1616000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-25\n",
      "done: false\n",
      "episode_len_mean: 197.82\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.82\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8579\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26733359694480896\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002900614868849516\n",
      "        model: {}\n",
      "        policy_loss: 0.004732585046440363\n",
      "        total_loss: 5.801103591918945\n",
      "        vf_explained_var: 3.4415593290759716e-06\n",
      "        vf_loss: 5.796370983123779\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1616000\n",
      "  num_agent_steps_trained: 1616000\n",
      "  num_steps_sampled: 1616000\n",
      "  num_steps_trained: 1616000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 404\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.88\n",
      "  ram_util_percent: 85.63000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06864052147179857\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07887030247424677\n",
      "  mean_inference_ms: 0.7524659885582085\n",
      "  mean_raw_obs_processing_ms: 0.09123455351625402\n",
      "time_since_restore: 2892.6289184093475\n",
      "time_this_iter_s: 7.090174674987793\n",
      "time_total_s: 2892.6289184093475\n",
      "timers:\n",
      "  learn_throughput: 1339.508\n",
      "  learn_time_ms: 2986.172\n",
      "  load_throughput: 23156957.902\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 579.173\n",
      "  sample_time_ms: 6906.402\n",
      "  update_time_ms: 2.095\n",
      "timestamp: 1658396845\n",
      "timesteps_since_restore: 1616000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1616000\n",
      "training_iteration: 404\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1620000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-32\n",
      "done: false\n",
      "episode_len_mean: 193.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.6\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 8601\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27848148345947266\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033699318300932646\n",
      "        model: {}\n",
      "        policy_loss: -0.0009081359603442252\n",
      "        total_loss: 2.90231990814209\n",
      "        vf_explained_var: -0.17369024455547333\n",
      "        vf_loss: 2.9032278060913086\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1620000\n",
      "  num_agent_steps_trained: 1620000\n",
      "  num_steps_sampled: 1620000\n",
      "  num_steps_trained: 1620000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 405\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.61\n",
      "  ram_util_percent: 85.52000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06863833751321667\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0788678082608947\n",
      "  mean_inference_ms: 0.7524554680600488\n",
      "  mean_raw_obs_processing_ms: 0.09123085993191168\n",
      "time_since_restore: 2899.4454414844513\n",
      "time_this_iter_s: 6.81652307510376\n",
      "time_total_s: 2899.4454414844513\n",
      "timers:\n",
      "  learn_throughput: 1342.262\n",
      "  learn_time_ms: 2980.044\n",
      "  load_throughput: 23366596.1\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 578.492\n",
      "  sample_time_ms: 6914.535\n",
      "  update_time_ms: 2.103\n",
      "timestamp: 1658396852\n",
      "timesteps_since_restore: 1620000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1620000\n",
      "training_iteration: 405\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1624000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-39\n",
      "done: false\n",
      "episode_len_mean: 191.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.61\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8622\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2521967887878418\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003347753081470728\n",
      "        model: {}\n",
      "        policy_loss: 0.0015609677648171782\n",
      "        total_loss: 3.86496901512146\n",
      "        vf_explained_var: -0.031232912093400955\n",
      "        vf_loss: 3.863407850265503\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1624000\n",
      "  num_agent_steps_trained: 1624000\n",
      "  num_steps_sampled: 1624000\n",
      "  num_steps_trained: 1624000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 406\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.83333333333334\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06863483479751607\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07886378741149747\n",
      "  mean_inference_ms: 0.7524289188374391\n",
      "  mean_raw_obs_processing_ms: 0.09122588665613723\n",
      "time_since_restore: 2906.186538696289\n",
      "time_this_iter_s: 6.7410972118377686\n",
      "time_total_s: 2906.186538696289\n",
      "timers:\n",
      "  learn_throughput: 1340.706\n",
      "  learn_time_ms: 2983.504\n",
      "  load_throughput: 23298452.993\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 578.781\n",
      "  sample_time_ms: 6911.078\n",
      "  update_time_ms: 2.138\n",
      "timestamp: 1658396859\n",
      "timesteps_since_restore: 1624000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1624000\n",
      "training_iteration: 406\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1628000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-45\n",
      "done: false\n",
      "episode_len_mean: 192.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.12\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8642\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25560706853866577\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0046806326135993\n",
      "        model: {}\n",
      "        policy_loss: -0.0006688801222480834\n",
      "        total_loss: 3.247819423675537\n",
      "        vf_explained_var: -0.11361562460660934\n",
      "        vf_loss: 3.248488426208496\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1628000\n",
      "  num_agent_steps_trained: 1628000\n",
      "  num_steps_sampled: 1628000\n",
      "  num_steps_trained: 1628000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 407\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.480000000000004\n",
      "  ram_util_percent: 85.49999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06863039421084792\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07885881810570625\n",
      "  mean_inference_ms: 0.7523935100297416\n",
      "  mean_raw_obs_processing_ms: 0.09122033726750935\n",
      "time_since_restore: 2912.854949951172\n",
      "time_this_iter_s: 6.6684112548828125\n",
      "time_total_s: 2912.854949951172\n",
      "timers:\n",
      "  learn_throughput: 1350.416\n",
      "  learn_time_ms: 2962.051\n",
      "  load_throughput: 23051959.329\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 578.023\n",
      "  sample_time_ms: 6920.141\n",
      "  update_time_ms: 2.016\n",
      "timestamp: 1658396865\n",
      "timesteps_since_restore: 1628000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1628000\n",
      "training_iteration: 407\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1632000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-53\n",
      "done: false\n",
      "episode_len_mean: 193.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.32\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8662\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23884132504463196\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035918899811804295\n",
      "        model: {}\n",
      "        policy_loss: 0.000806428724899888\n",
      "        total_loss: 2.3697586059570312\n",
      "        vf_explained_var: -0.07606816291809082\n",
      "        vf_loss: 2.3689520359039307\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1632000\n",
      "  num_agent_steps_trained: 1632000\n",
      "  num_steps_sampled: 1632000\n",
      "  num_steps_trained: 1632000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 408\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.58\n",
      "  ram_util_percent: 85.49999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06862521758577422\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07885296120403498\n",
      "  mean_inference_ms: 0.7523498511700533\n",
      "  mean_raw_obs_processing_ms: 0.09121368448772146\n",
      "time_since_restore: 2920.112845659256\n",
      "time_this_iter_s: 7.2578957080841064\n",
      "time_total_s: 2920.112845659256\n",
      "timers:\n",
      "  learn_throughput: 1342.505\n",
      "  learn_time_ms: 2979.505\n",
      "  load_throughput: 23224274.64\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 578.029\n",
      "  sample_time_ms: 6920.067\n",
      "  update_time_ms: 2.195\n",
      "timestamp: 1658396873\n",
      "timesteps_since_restore: 1632000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1632000\n",
      "training_iteration: 408\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1636000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-47-59\n",
      "done: false\n",
      "episode_len_mean: 194.43\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.43\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8682\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24719414114952087\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003383641131222248\n",
      "        model: {}\n",
      "        policy_loss: 0.0006646717665717006\n",
      "        total_loss: 2.3696179389953613\n",
      "        vf_explained_var: -0.022723635658621788\n",
      "        vf_loss: 2.368953227996826\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1636000\n",
      "  num_agent_steps_trained: 1636000\n",
      "  num_steps_sampled: 1636000\n",
      "  num_steps_trained: 1636000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 409\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.790000000000006\n",
      "  ram_util_percent: 85.53\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06861577262911771\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07884215548027657\n",
      "  mean_inference_ms: 0.752261184591193\n",
      "  mean_raw_obs_processing_ms: 0.09120189242699234\n",
      "time_since_restore: 2926.7290897369385\n",
      "time_this_iter_s: 6.616244077682495\n",
      "time_total_s: 2926.7290897369385\n",
      "timers:\n",
      "  learn_throughput: 1341.243\n",
      "  learn_time_ms: 2982.307\n",
      "  load_throughput: 23311401.973\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 579.114\n",
      "  sample_time_ms: 6907.109\n",
      "  update_time_ms: 2.223\n",
      "timestamp: 1658396879\n",
      "timesteps_since_restore: 1636000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1636000\n",
      "training_iteration: 409\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1640000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-48-06\n",
      "done: false\n",
      "episode_len_mean: 197.54\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.54\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8702\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25185278058052063\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003894639201462269\n",
      "        model: {}\n",
      "        policy_loss: 0.00018382392590865493\n",
      "        total_loss: 2.369135856628418\n",
      "        vf_explained_var: -0.005593390204012394\n",
      "        vf_loss: 2.3689515590667725\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1640000\n",
      "  num_agent_steps_trained: 1640000\n",
      "  num_steps_sampled: 1640000\n",
      "  num_steps_trained: 1640000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 410\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.555555555555557\n",
      "  ram_util_percent: 85.51111111111112\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06860485972426858\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07882960291002945\n",
      "  mean_inference_ms: 0.7521578423725185\n",
      "  mean_raw_obs_processing_ms: 0.09118788080741663\n",
      "time_since_restore: 2933.432204246521\n",
      "time_this_iter_s: 6.7031145095825195\n",
      "time_total_s: 2933.432204246521\n",
      "timers:\n",
      "  learn_throughput: 1344.387\n",
      "  learn_time_ms: 2975.335\n",
      "  load_throughput: 23317881.862\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 579.873\n",
      "  sample_time_ms: 6898.058\n",
      "  update_time_ms: 2.318\n",
      "timestamp: 1658396886\n",
      "timesteps_since_restore: 1640000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1640000\n",
      "training_iteration: 410\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1644000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-48-13\n",
      "done: false\n",
      "episode_len_mean: 199.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.53\n",
      "episode_reward_min: 162.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8722\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24539774656295776\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004210826009511948\n",
      "        model: {}\n",
      "        policy_loss: -0.000617502722889185\n",
      "        total_loss: 2.3683347702026367\n",
      "        vf_explained_var: -0.018158748745918274\n",
      "        vf_loss: 2.3689517974853516\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1644000\n",
      "  num_agent_steps_trained: 1644000\n",
      "  num_steps_sampled: 1644000\n",
      "  num_steps_trained: 1644000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 411\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.97\n",
      "  ram_util_percent: 85.50999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859423521499285\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07881722748160457\n",
      "  mean_inference_ms: 0.7520550762501645\n",
      "  mean_raw_obs_processing_ms: 0.09117364962163817\n",
      "time_since_restore: 2940.3094787597656\n",
      "time_this_iter_s: 6.877274513244629\n",
      "time_total_s: 2940.3094787597656\n",
      "timers:\n",
      "  learn_throughput: 1340.903\n",
      "  learn_time_ms: 2983.064\n",
      "  load_throughput: 24119056.929\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 581.886\n",
      "  sample_time_ms: 6874.203\n",
      "  update_time_ms: 2.296\n",
      "timestamp: 1658396893\n",
      "timesteps_since_restore: 1644000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1644000\n",
      "training_iteration: 411\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1648000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-48-20\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8742\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2470390349626541\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003980313893407583\n",
      "        model: {}\n",
      "        policy_loss: 0.0003813881485257298\n",
      "        total_loss: 2.369333505630493\n",
      "        vf_explained_var: -0.07060486078262329\n",
      "        vf_loss: 2.3689520359039307\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1648000\n",
      "  num_agent_steps_trained: 1648000\n",
      "  num_steps_sampled: 1648000\n",
      "  num_steps_trained: 1648000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 412\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.96363636363637\n",
      "  ram_util_percent: 85.52727272727273\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685868513275158\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07880832287188368\n",
      "  mean_inference_ms: 0.7519841546245928\n",
      "  mean_raw_obs_processing_ms: 0.09116364790451975\n",
      "time_since_restore: 2947.6660952568054\n",
      "time_this_iter_s: 7.356616497039795\n",
      "time_total_s: 2947.6660952568054\n",
      "timers:\n",
      "  learn_throughput: 1334.985\n",
      "  learn_time_ms: 2996.288\n",
      "  load_throughput: 24108659.29\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 579.13\n",
      "  sample_time_ms: 6906.911\n",
      "  update_time_ms: 2.274\n",
      "timestamp: 1658396900\n",
      "timesteps_since_restore: 1648000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1648000\n",
      "training_iteration: 412\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1652000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-48-27\n",
      "done: false\n",
      "episode_len_mean: 198.74\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.74\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8763\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23352722823619843\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030133898835629225\n",
      "        model: {}\n",
      "        policy_loss: 0.0028526748064905405\n",
      "        total_loss: 3.67724871635437\n",
      "        vf_explained_var: -0.036199480295181274\n",
      "        vf_loss: 3.67439603805542\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1652000\n",
      "  num_agent_steps_trained: 1652000\n",
      "  num_steps_sampled: 1652000\n",
      "  num_steps_trained: 1652000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 413\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.955555555555556\n",
      "  ram_util_percent: 85.56666666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06857908220446043\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07879959167756208\n",
      "  mean_inference_ms: 0.7519055664310906\n",
      "  mean_raw_obs_processing_ms: 0.09115376796446223\n",
      "time_since_restore: 2954.4925322532654\n",
      "time_this_iter_s: 6.826436996459961\n",
      "time_total_s: 2954.4925322532654\n",
      "timers:\n",
      "  learn_throughput: 1332.578\n",
      "  learn_time_ms: 3001.7\n",
      "  load_throughput: 24074065.146\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 578.95\n",
      "  sample_time_ms: 6909.059\n",
      "  update_time_ms: 2.313\n",
      "timestamp: 1658396907\n",
      "timesteps_since_restore: 1652000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1652000\n",
      "training_iteration: 413\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1656000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-48-34\n",
      "done: false\n",
      "episode_len_mean: 198.58\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.58\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8783\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2428741157054901\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004296520724892616\n",
      "        model: {}\n",
      "        policy_loss: 0.0040785628370940685\n",
      "        total_loss: 5.377063751220703\n",
      "        vf_explained_var: 1.0110358061865554e-06\n",
      "        vf_loss: 5.372984886169434\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1656000\n",
      "  num_agent_steps_trained: 1656000\n",
      "  num_steps_sampled: 1656000\n",
      "  num_steps_trained: 1656000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 414\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.82000000000001\n",
      "  ram_util_percent: 85.50999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06857379280022874\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07879323792278844\n",
      "  mean_inference_ms: 0.7518488076100716\n",
      "  mean_raw_obs_processing_ms: 0.09114650904479438\n",
      "time_since_restore: 2961.234955072403\n",
      "time_this_iter_s: 6.742422819137573\n",
      "time_total_s: 2961.234955072403\n",
      "timers:\n",
      "  learn_throughput: 1333.89\n",
      "  learn_time_ms: 2998.748\n",
      "  load_throughput: 24485137.186\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 581.141\n",
      "  sample_time_ms: 6883.01\n",
      "  update_time_ms: 2.347\n",
      "timestamp: 1658396914\n",
      "timesteps_since_restore: 1656000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1656000\n",
      "training_iteration: 414\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1660000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-48-41\n",
      "done: false\n",
      "episode_len_mean: 196.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.06\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8804\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26583629846572876\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0040253461338579655\n",
      "        model: {}\n",
      "        policy_loss: -0.00037888300721533597\n",
      "        total_loss: 2.809603691101074\n",
      "        vf_explained_var: 0.0008852920145727694\n",
      "        vf_loss: 2.8099818229675293\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1660000\n",
      "  num_agent_steps_trained: 1660000\n",
      "  num_steps_sampled: 1660000\n",
      "  num_steps_trained: 1660000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 415\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.03\n",
      "  ram_util_percent: 85.51\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06857025388234622\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07878886600362449\n",
      "  mean_inference_ms: 0.7518074445438969\n",
      "  mean_raw_obs_processing_ms: 0.09114196447990022\n",
      "time_since_restore: 2968.3406677246094\n",
      "time_this_iter_s: 7.105712652206421\n",
      "time_total_s: 2968.3406677246094\n",
      "timers:\n",
      "  learn_throughput: 1322.029\n",
      "  learn_time_ms: 3025.653\n",
      "  load_throughput: 24438770.575\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 581.201\n",
      "  sample_time_ms: 6882.301\n",
      "  update_time_ms: 2.342\n",
      "timestamp: 1658396921\n",
      "timesteps_since_restore: 1660000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1660000\n",
      "training_iteration: 415\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1664000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-48-48\n",
      "done: false\n",
      "episode_len_mean: 194.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.9\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8825\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2632157802581787\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003874350106343627\n",
      "        model: {}\n",
      "        policy_loss: 0.0036717364564538\n",
      "        total_loss: 5.427061080932617\n",
      "        vf_explained_var: -0.006545640993863344\n",
      "        vf_loss: 5.423389434814453\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1664000\n",
      "  num_agent_steps_trained: 1664000\n",
      "  num_steps_sampled: 1664000\n",
      "  num_steps_trained: 1664000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 416\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.11\n",
      "  ram_util_percent: 85.47999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06856667509623049\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07878470808945269\n",
      "  mean_inference_ms: 0.7517704733900002\n",
      "  mean_raw_obs_processing_ms: 0.09113759403609496\n",
      "time_since_restore: 2975.131755590439\n",
      "time_this_iter_s: 6.791087865829468\n",
      "time_total_s: 2975.131755590439\n",
      "timers:\n",
      "  learn_throughput: 1323.736\n",
      "  learn_time_ms: 3021.751\n",
      "  load_throughput: 24321855.61\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 578.203\n",
      "  sample_time_ms: 6917.988\n",
      "  update_time_ms: 2.349\n",
      "timestamp: 1658396928\n",
      "timesteps_since_restore: 1664000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1664000\n",
      "training_iteration: 416\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1668000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-48-54\n",
      "done: false\n",
      "episode_len_mean: 191.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.79\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8846\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27426546812057495\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003965291194617748\n",
      "        model: {}\n",
      "        policy_loss: 0.001424998277798295\n",
      "        total_loss: 3.895076036453247\n",
      "        vf_explained_var: -0.0029961031395941973\n",
      "        vf_loss: 3.893650770187378\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1668000\n",
      "  num_agent_steps_trained: 1668000\n",
      "  num_steps_sampled: 1668000\n",
      "  num_steps_trained: 1668000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 417\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.57000000000001\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06856087096690712\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877809912535662\n",
      "  mean_inference_ms: 0.7517095401662448\n",
      "  mean_raw_obs_processing_ms: 0.09113029755704365\n",
      "time_since_restore: 2981.92138504982\n",
      "time_this_iter_s: 6.7896294593811035\n",
      "time_total_s: 2981.92138504982\n",
      "timers:\n",
      "  learn_throughput: 1320.537\n",
      "  learn_time_ms: 3029.07\n",
      "  load_throughput: 24399674.229\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 578.097\n",
      "  sample_time_ms: 6919.256\n",
      "  update_time_ms: 2.34\n",
      "timestamp: 1658396934\n",
      "timesteps_since_restore: 1668000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1668000\n",
      "training_iteration: 417\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1672000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-02\n",
      "done: false\n",
      "episode_len_mean: 191.72\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.72\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8867\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24790196120738983\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002651780843734741\n",
      "        model: {}\n",
      "        policy_loss: 0.005230681039392948\n",
      "        total_loss: 6.0636982917785645\n",
      "        vf_explained_var: 2.8437184482754674e-06\n",
      "        vf_loss: 6.058467864990234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1672000\n",
      "  num_agent_steps_trained: 1672000\n",
      "  num_steps_sampled: 1672000\n",
      "  num_steps_trained: 1672000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 418\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.5\n",
      "  ram_util_percent: 85.50999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.068556378765874\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877214002800284\n",
      "  mean_inference_ms: 0.7516620479541252\n",
      "  mean_raw_obs_processing_ms: 0.09112402816332832\n",
      "time_since_restore: 2988.9224576950073\n",
      "time_this_iter_s: 7.001072645187378\n",
      "time_total_s: 2988.9224576950073\n",
      "timers:\n",
      "  learn_throughput: 1334.791\n",
      "  learn_time_ms: 2996.724\n",
      "  load_throughput: 24220031.76\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 576.88\n",
      "  sample_time_ms: 6933.85\n",
      "  update_time_ms: 2.206\n",
      "timestamp: 1658396942\n",
      "timesteps_since_restore: 1672000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1672000\n",
      "training_iteration: 418\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1676000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-09\n",
      "done: false\n",
      "episode_len_mean: 191.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.38\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8887\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2589363753795624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037599774077534676\n",
      "        model: {}\n",
      "        policy_loss: 0.0006464460748247802\n",
      "        total_loss: 3.559114933013916\n",
      "        vf_explained_var: -0.03225700929760933\n",
      "        vf_loss: 3.5584683418273926\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1676000\n",
      "  num_agent_steps_trained: 1676000\n",
      "  num_steps_sampled: 1676000\n",
      "  num_steps_trained: 1676000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 419\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.220000000000006\n",
      "  ram_util_percent: 85.57\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06855335326162706\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876828435280635\n",
      "  mean_inference_ms: 0.7516314203393367\n",
      "  mean_raw_obs_processing_ms: 0.09111959626897254\n",
      "time_since_restore: 2995.9245257377625\n",
      "time_this_iter_s: 7.002068042755127\n",
      "time_total_s: 2995.9245257377625\n",
      "timers:\n",
      "  learn_throughput: 1334.769\n",
      "  learn_time_ms: 2996.774\n",
      "  load_throughput: 23882158.007\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 576.438\n",
      "  sample_time_ms: 6939.166\n",
      "  update_time_ms: 2.215\n",
      "timestamp: 1658396949\n",
      "timesteps_since_restore: 1676000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1676000\n",
      "training_iteration: 419\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1680000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-16\n",
      "done: false\n",
      "episode_len_mean: 193.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.9\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8907\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2370705008506775\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0018745660781860352\n",
      "        model: {}\n",
      "        policy_loss: 0.0022879713214933872\n",
      "        total_loss: 2.1696267127990723\n",
      "        vf_explained_var: -0.02715477906167507\n",
      "        vf_loss: 2.1673386096954346\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1680000\n",
      "  num_agent_steps_trained: 1680000\n",
      "  num_steps_sampled: 1680000\n",
      "  num_steps_trained: 1680000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 420\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.82\n",
      "  ram_util_percent: 85.52000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06855002264903545\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876427763503661\n",
      "  mean_inference_ms: 0.7515967906146318\n",
      "  mean_raw_obs_processing_ms: 0.09111457482723338\n",
      "time_since_restore: 3003.0472280979156\n",
      "time_this_iter_s: 7.122702360153198\n",
      "time_total_s: 3003.0472280979156\n",
      "timers:\n",
      "  learn_throughput: 1322.325\n",
      "  learn_time_ms: 3024.974\n",
      "  load_throughput: 23699980.223\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 575.284\n",
      "  sample_time_ms: 6953.092\n",
      "  update_time_ms: 2.12\n",
      "timestamp: 1658396956\n",
      "timesteps_since_restore: 1680000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1680000\n",
      "training_iteration: 420\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1684000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-23\n",
      "done: false\n",
      "episode_len_mean: 193.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.9\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 8928\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24092213809490204\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003039657138288021\n",
      "        model: {}\n",
      "        policy_loss: 0.001851979410275817\n",
      "        total_loss: 3.651047706604004\n",
      "        vf_explained_var: -0.09677325934171677\n",
      "        vf_loss: 3.649195671081543\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1684000\n",
      "  num_agent_steps_trained: 1684000\n",
      "  num_steps_sampled: 1684000\n",
      "  num_steps_trained: 1684000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 421\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.269999999999996\n",
      "  ram_util_percent: 85.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685476157215306\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876125009920046\n",
      "  mean_inference_ms: 0.751570667951137\n",
      "  mean_raw_obs_processing_ms: 0.09111080571662722\n",
      "time_since_restore: 3010.081348657608\n",
      "time_this_iter_s: 7.034120559692383\n",
      "time_total_s: 3010.081348657608\n",
      "timers:\n",
      "  learn_throughput: 1323.778\n",
      "  learn_time_ms: 3021.655\n",
      "  load_throughput: 23340589.872\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 571.392\n",
      "  sample_time_ms: 7000.447\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658396963\n",
      "timesteps_since_restore: 1684000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1684000\n",
      "training_iteration: 421\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1688000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-30\n",
      "done: false\n",
      "episode_len_mean: 197.96\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.96\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8948\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23004917800426483\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003350179409608245\n",
      "        model: {}\n",
      "        policy_loss: 0.005840154364705086\n",
      "        total_loss: 6.407050132751465\n",
      "        vf_explained_var: 1.1079414434789214e-06\n",
      "        vf_loss: 6.401209831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1688000\n",
      "  num_agent_steps_trained: 1688000\n",
      "  num_steps_sampled: 1688000\n",
      "  num_steps_trained: 1688000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 422\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.529999999999994\n",
      "  ram_util_percent: 85.58000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06854811269450355\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876138931620207\n",
      "  mean_inference_ms: 0.7515771084069197\n",
      "  mean_raw_obs_processing_ms: 0.09111009539060494\n",
      "time_since_restore: 3017.334673166275\n",
      "time_this_iter_s: 7.253324508666992\n",
      "time_total_s: 3017.334673166275\n",
      "timers:\n",
      "  learn_throughput: 1330.921\n",
      "  learn_time_ms: 3005.437\n",
      "  load_throughput: 23334097.357\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 571.178\n",
      "  sample_time_ms: 7003.074\n",
      "  update_time_ms: 2.114\n",
      "timestamp: 1658396970\n",
      "timesteps_since_restore: 1688000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1688000\n",
      "training_iteration: 422\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1692000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-37\n",
      "done: false\n",
      "episode_len_mean: 198.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.5\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8968\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24909180402755737\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005174029618501663\n",
      "        model: {}\n",
      "        policy_loss: 0.003380927722901106\n",
      "        total_loss: 6.404594898223877\n",
      "        vf_explained_var: 1.735777004796546e-06\n",
      "        vf_loss: 6.401213645935059\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1692000\n",
      "  num_agent_steps_trained: 1692000\n",
      "  num_steps_sampled: 1692000\n",
      "  num_steps_trained: 1692000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 423\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.67\n",
      "  ram_util_percent: 85.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06854893342390735\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876217403058243\n",
      "  mean_inference_ms: 0.7515924233451986\n",
      "  mean_raw_obs_processing_ms: 0.09111025030310094\n",
      "time_since_restore: 3024.3566777706146\n",
      "time_this_iter_s: 7.0220046043396\n",
      "time_total_s: 3024.3566777706146\n",
      "timers:\n",
      "  learn_throughput: 1331.603\n",
      "  learn_time_ms: 3003.898\n",
      "  load_throughput: 23134605.626\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 570.74\n",
      "  sample_time_ms: 7008.439\n",
      "  update_time_ms: 2.079\n",
      "timestamp: 1658396977\n",
      "timesteps_since_restore: 1692000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1692000\n",
      "training_iteration: 423\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1696000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-44\n",
      "done: false\n",
      "episode_len_mean: 198.84\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.84\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 8988\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22492863237857819\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003959184046834707\n",
      "        model: {}\n",
      "        policy_loss: 0.005759522784501314\n",
      "        total_loss: 6.40696907043457\n",
      "        vf_explained_var: -3.028300454843702e-07\n",
      "        vf_loss: 6.401209831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1696000\n",
      "  num_agent_steps_trained: 1696000\n",
      "  num_steps_sampled: 1696000\n",
      "  num_steps_trained: 1696000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 424\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.03000000000001\n",
      "  ram_util_percent: 85.55\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06854867500262893\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876165080271733\n",
      "  mean_inference_ms: 0.7515965797582357\n",
      "  mean_raw_obs_processing_ms: 0.09110942033319874\n",
      "time_since_restore: 3031.168930053711\n",
      "time_this_iter_s: 6.8122522830963135\n",
      "time_total_s: 3031.168930053711\n",
      "timers:\n",
      "  learn_throughput: 1331.436\n",
      "  learn_time_ms: 3004.275\n",
      "  load_throughput: 22690311.063\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 570.336\n",
      "  sample_time_ms: 7013.408\n",
      "  update_time_ms: 2.077\n",
      "timestamp: 1658396984\n",
      "timesteps_since_restore: 1696000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1696000\n",
      "training_iteration: 424\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1700000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-51\n",
      "done: false\n",
      "episode_len_mean: 198.82\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.82\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9008\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2538798749446869\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004103428218513727\n",
      "        model: {}\n",
      "        policy_loss: 0.005372979212552309\n",
      "        total_loss: 6.381381988525391\n",
      "        vf_explained_var: 4.99493353345315e-06\n",
      "        vf_loss: 6.3760085105896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1700000\n",
      "  num_agent_steps_trained: 1700000\n",
      "  num_steps_sampled: 1700000\n",
      "  num_steps_trained: 1700000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 425\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.209999999999994\n",
      "  ram_util_percent: 85.42999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685491714719408\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876153363551856\n",
      "  mean_inference_ms: 0.7516098589626776\n",
      "  mean_raw_obs_processing_ms: 0.09110933161658519\n",
      "time_since_restore: 3038.2361352443695\n",
      "time_this_iter_s: 7.067205190658569\n",
      "time_total_s: 3038.2361352443695\n",
      "timers:\n",
      "  learn_throughput: 1335.037\n",
      "  learn_time_ms: 2996.172\n",
      "  load_throughput: 22721040.087\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 569.958\n",
      "  sample_time_ms: 7018.065\n",
      "  update_time_ms: 2.066\n",
      "timestamp: 1658396991\n",
      "timesteps_since_restore: 1700000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1700000\n",
      "training_iteration: 425\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1704000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-49-58\n",
      "done: false\n",
      "episode_len_mean: 197.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.32\n",
      "episode_reward_min: 70.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9029\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23266500234603882\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030201226472854614\n",
      "        model: {}\n",
      "        policy_loss: 0.0072125825099647045\n",
      "        total_loss: 8.308633804321289\n",
      "        vf_explained_var: 4.666723270929651e-06\n",
      "        vf_loss: 8.301421165466309\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1704000\n",
      "  num_agent_steps_trained: 1704000\n",
      "  num_steps_sampled: 1704000\n",
      "  num_steps_trained: 1704000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 426\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.78\n",
      "  ram_util_percent: 85.4\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685489577312842\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0787603700918088\n",
      "  mean_inference_ms: 0.751614105809147\n",
      "  mean_raw_obs_processing_ms: 0.09110799121301566\n",
      "time_since_restore: 3045.136374235153\n",
      "time_this_iter_s: 6.900238990783691\n",
      "time_total_s: 3045.136374235153\n",
      "timers:\n",
      "  learn_throughput: 1330.963\n",
      "  learn_time_ms: 3005.342\n",
      "  load_throughput: 22537904.352\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 570.451\n",
      "  sample_time_ms: 7011.993\n",
      "  update_time_ms: 2.009\n",
      "timestamp: 1658396998\n",
      "timesteps_since_restore: 1704000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1704000\n",
      "training_iteration: 426\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1708000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-50-05\n",
      "done: false\n",
      "episode_len_mean: 192.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.93\n",
      "episode_reward_min: 70.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 9051\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24439211189746857\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033554851543158293\n",
      "        model: {}\n",
      "        policy_loss: 0.000592692696955055\n",
      "        total_loss: 4.50161075592041\n",
      "        vf_explained_var: -0.1253606677055359\n",
      "        vf_loss: 4.501018047332764\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1708000\n",
      "  num_agent_steps_trained: 1708000\n",
      "  num_steps_sampled: 1708000\n",
      "  num_steps_trained: 1708000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 427\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.510000000000005\n",
      "  ram_util_percent: 85.49\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06854549748544618\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07875567472609367\n",
      "  mean_inference_ms: 0.7515806495810213\n",
      "  mean_raw_obs_processing_ms: 0.0911029374728608\n",
      "time_since_restore: 3052.1936271190643\n",
      "time_this_iter_s: 7.057252883911133\n",
      "time_total_s: 3052.1936271190643\n",
      "timers:\n",
      "  learn_throughput: 1318.466\n",
      "  learn_time_ms: 3033.83\n",
      "  load_throughput: 22733355.014\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 569.872\n",
      "  sample_time_ms: 7019.12\n",
      "  update_time_ms: 1.999\n",
      "timestamp: 1658397005\n",
      "timesteps_since_restore: 1708000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1708000\n",
      "training_iteration: 427\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1712000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-50-12\n",
      "done: false\n",
      "episode_len_mean: 191.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.6\n",
      "episode_reward_min: 67.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9072\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22351431846618652\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028165781404823065\n",
      "        model: {}\n",
      "        policy_loss: 0.002545037306845188\n",
      "        total_loss: 4.049923896789551\n",
      "        vf_explained_var: -0.03225552663207054\n",
      "        vf_loss: 4.047379016876221\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1712000\n",
      "  num_agent_steps_trained: 1712000\n",
      "  num_steps_sampled: 1712000\n",
      "  num_steps_trained: 1712000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 428\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.06\n",
      "  ram_util_percent: 85.52000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06854218201796744\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07875093623614891\n",
      "  mean_inference_ms: 0.7515437437798763\n",
      "  mean_raw_obs_processing_ms: 0.09109763319626922\n",
      "time_since_restore: 3059.085331439972\n",
      "time_this_iter_s: 6.891704320907593\n",
      "time_total_s: 3059.085331439972\n",
      "timers:\n",
      "  learn_throughput: 1323.641\n",
      "  learn_time_ms: 3021.968\n",
      "  load_throughput: 22829250.238\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 567.564\n",
      "  sample_time_ms: 7047.665\n",
      "  update_time_ms: 1.999\n",
      "timestamp: 1658397012\n",
      "timesteps_since_restore: 1712000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1712000\n",
      "training_iteration: 428\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1716000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-50-19\n",
      "done: false\n",
      "episode_len_mean: 189.43\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.43\n",
      "episode_reward_min: 67.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9093\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21096675097942352\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004970421548932791\n",
      "        model: {}\n",
      "        policy_loss: 0.0038536761421710253\n",
      "        total_loss: 6.639437675476074\n",
      "        vf_explained_var: 2.658879793671076e-06\n",
      "        vf_loss: 6.635584831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1716000\n",
      "  num_agent_steps_trained: 1716000\n",
      "  num_steps_sampled: 1716000\n",
      "  num_steps_trained: 1716000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 429\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.349999999999994\n",
      "  ram_util_percent: 85.34\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06853831796190865\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07874551391677723\n",
      "  mean_inference_ms: 0.7515007113392178\n",
      "  mean_raw_obs_processing_ms: 0.09109128567798877\n",
      "time_since_restore: 3066.1688990592957\n",
      "time_this_iter_s: 7.0835676193237305\n",
      "time_total_s: 3066.1688990592957\n",
      "timers:\n",
      "  learn_throughput: 1312.455\n",
      "  learn_time_ms: 3047.725\n",
      "  load_throughput: 22819934.712\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 569.974\n",
      "  sample_time_ms: 7017.859\n",
      "  update_time_ms: 2.07\n",
      "timestamp: 1658397019\n",
      "timesteps_since_restore: 1716000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1716000\n",
      "training_iteration: 429\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1720000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-50-26\n",
      "done: false\n",
      "episode_len_mean: 190.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.75\n",
      "episode_reward_min: 67.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9113\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20222248136997223\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026875375770032406\n",
      "        model: {}\n",
      "        policy_loss: 0.0020403980743139982\n",
      "        total_loss: 3.530266523361206\n",
      "        vf_explained_var: -0.03225802257657051\n",
      "        vf_loss: 3.528225898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1720000\n",
      "  num_agent_steps_trained: 1720000\n",
      "  num_steps_sampled: 1720000\n",
      "  num_steps_trained: 1720000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 430\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.24999999999999\n",
      "  ram_util_percent: 85.42999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06853637058145118\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07874263331838727\n",
      "  mean_inference_ms: 0.7514794402189463\n",
      "  mean_raw_obs_processing_ms: 0.0910872860941774\n",
      "time_since_restore: 3073.2741343975067\n",
      "time_this_iter_s: 7.10523533821106\n",
      "time_total_s: 3073.2741343975067\n",
      "timers:\n",
      "  learn_throughput: 1325.813\n",
      "  learn_time_ms: 3017.016\n",
      "  load_throughput: 22779655.126\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 565.533\n",
      "  sample_time_ms: 7072.976\n",
      "  update_time_ms: 2.06\n",
      "timestamp: 1658397026\n",
      "timesteps_since_restore: 1720000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1720000\n",
      "training_iteration: 430\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1724000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-50-33\n",
      "done: false\n",
      "episode_len_mean: 192.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.65\n",
      "episode_reward_min: 67.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9133\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2067728191614151\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030354238115251064\n",
      "        model: {}\n",
      "        policy_loss: 0.0006402972503565252\n",
      "        total_loss: 2.828261613845825\n",
      "        vf_explained_var: -0.075214684009552\n",
      "        vf_loss: 2.8276209831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1724000\n",
      "  num_agent_steps_trained: 1724000\n",
      "  num_steps_sampled: 1724000\n",
      "  num_steps_trained: 1724000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 431\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.05\n",
      "  ram_util_percent: 85.41\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06853373972457436\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07873888643142893\n",
      "  mean_inference_ms: 0.7514554062561786\n",
      "  mean_raw_obs_processing_ms: 0.09108263686692196\n",
      "time_since_restore: 3079.9706654548645\n",
      "time_this_iter_s: 6.696531057357788\n",
      "time_total_s: 3079.9706654548645\n",
      "timers:\n",
      "  learn_throughput: 1334.598\n",
      "  learn_time_ms: 2997.158\n",
      "  load_throughput: 23422052.213\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 569.118\n",
      "  sample_time_ms: 7028.42\n",
      "  update_time_ms: 2.08\n",
      "timestamp: 1658397033\n",
      "timesteps_since_restore: 1724000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1724000\n",
      "training_iteration: 431\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1728000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-50-40\n",
      "done: false\n",
      "episode_len_mean: 195.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.04\n",
      "episode_reward_min: 67.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9154\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19044014811515808\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023935819044709206\n",
      "        model: {}\n",
      "        policy_loss: 0.00659908726811409\n",
      "        total_loss: 5.712246894836426\n",
      "        vf_explained_var: -0.006408351473510265\n",
      "        vf_loss: 5.7056474685668945\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1728000\n",
      "  num_agent_steps_trained: 1728000\n",
      "  num_steps_sampled: 1728000\n",
      "  num_steps_trained: 1728000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 432\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.459999999999994\n",
      "  ram_util_percent: 85.42999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06853112310727286\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07873509192848176\n",
      "  mean_inference_ms: 0.7514321407879615\n",
      "  mean_raw_obs_processing_ms: 0.09107796075186742\n",
      "time_since_restore: 3086.7838411331177\n",
      "time_this_iter_s: 6.813175678253174\n",
      "time_total_s: 3086.7838411331177\n",
      "timers:\n",
      "  learn_throughput: 1339.768\n",
      "  learn_time_ms: 2985.592\n",
      "  load_throughput: 23497501.401\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 573.396\n",
      "  sample_time_ms: 6975.986\n",
      "  update_time_ms: 2.093\n",
      "timestamp: 1658397040\n",
      "timesteps_since_restore: 1728000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1728000\n",
      "training_iteration: 432\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1732000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-50-46\n",
      "done: false\n",
      "episode_len_mean: 196.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.37\n",
      "episode_reward_min: 70.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9174\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21347767114639282\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002413592766970396\n",
      "        model: {}\n",
      "        policy_loss: 0.00685895886272192\n",
      "        total_loss: 6.256858825683594\n",
      "        vf_explained_var: -6.254001050365332e-07\n",
      "        vf_loss: 6.25\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1732000\n",
      "  num_agent_steps_trained: 1732000\n",
      "  num_steps_sampled: 1732000\n",
      "  num_steps_trained: 1732000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 433\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.511111111111106\n",
      "  ram_util_percent: 85.45555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06852680057880368\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872965711151794\n",
      "  mean_inference_ms: 0.7513956230441812\n",
      "  mean_raw_obs_processing_ms: 0.09107175042092547\n",
      "time_since_restore: 3093.4895491600037\n",
      "time_this_iter_s: 6.705708026885986\n",
      "time_total_s: 3093.4895491600037\n",
      "timers:\n",
      "  learn_throughput: 1341.742\n",
      "  learn_time_ms: 2981.2\n",
      "  load_throughput: 23750305.776\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 576.655\n",
      "  sample_time_ms: 6936.559\n",
      "  update_time_ms: 2.133\n",
      "timestamp: 1658397046\n",
      "timesteps_since_restore: 1732000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1732000\n",
      "training_iteration: 433\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1736000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-50-54\n",
      "done: false\n",
      "episode_len_mean: 198.54\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.54\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9194\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24419158697128296\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032135769724845886\n",
      "        model: {}\n",
      "        policy_loss: 0.005428586155176163\n",
      "        total_loss: 6.255429744720459\n",
      "        vf_explained_var: 1.8006370510192937e-06\n",
      "        vf_loss: 6.250000953674316\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1736000\n",
      "  num_agent_steps_trained: 1736000\n",
      "  num_steps_sampled: 1736000\n",
      "  num_steps_trained: 1736000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 434\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.46363636363636\n",
      "  ram_util_percent: 85.43636363636364\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06852555005307626\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872799570460483\n",
      "  mean_inference_ms: 0.751395930191753\n",
      "  mean_raw_obs_processing_ms: 0.09106981426639366\n",
      "time_since_restore: 3100.722833633423\n",
      "time_this_iter_s: 7.2332844734191895\n",
      "time_total_s: 3100.722833633423\n",
      "timers:\n",
      "  learn_throughput: 1339.891\n",
      "  learn_time_ms: 2985.318\n",
      "  load_throughput: 24269081.441\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 573.861\n",
      "  sample_time_ms: 6970.326\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658397054\n",
      "timesteps_since_restore: 1736000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1736000\n",
      "training_iteration: 434\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1740000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-01\n",
      "done: false\n",
      "episode_len_mean: 198.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.41\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9214\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22550317645072937\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003793115960434079\n",
      "        model: {}\n",
      "        policy_loss: 0.004388860892504454\n",
      "        total_loss: 6.188866138458252\n",
      "        vf_explained_var: 8.216782589443028e-05\n",
      "        vf_loss: 6.184476852416992\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1740000\n",
      "  num_agent_steps_trained: 1740000\n",
      "  num_steps_sampled: 1740000\n",
      "  num_steps_trained: 1740000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 435\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.62\n",
      "  ram_util_percent: 85.42\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685221379130169\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872394296627\n",
      "  mean_inference_ms: 0.7513758240051069\n",
      "  mean_raw_obs_processing_ms: 0.09106509334384935\n",
      "time_since_restore: 3107.9103491306305\n",
      "time_this_iter_s: 7.187515497207642\n",
      "time_total_s: 3107.9103491306305\n",
      "timers:\n",
      "  learn_throughput: 1331.754\n",
      "  learn_time_ms: 3003.559\n",
      "  load_throughput: 24230525.708\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 574.04\n",
      "  sample_time_ms: 6968.156\n",
      "  update_time_ms: 2.217\n",
      "timestamp: 1658397061\n",
      "timesteps_since_restore: 1740000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1740000\n",
      "training_iteration: 435\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1744000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-08\n",
      "done: false\n",
      "episode_len_mean: 195.29\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.29\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 9236\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22307997941970825\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003833751194179058\n",
      "        model: {}\n",
      "        policy_loss: -0.006700184661895037\n",
      "        total_loss: 5.968605995178223\n",
      "        vf_explained_var: 0.0029105283319950104\n",
      "        vf_loss: 5.975306034088135\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1744000\n",
      "  num_agent_steps_trained: 1744000\n",
      "  num_steps_sampled: 1744000\n",
      "  num_steps_trained: 1744000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 436\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.620000000000005\n",
      "  ram_util_percent: 85.49\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06852090452194824\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872235747523341\n",
      "  mean_inference_ms: 0.7513761748878375\n",
      "  mean_raw_obs_processing_ms: 0.09106292258748125\n",
      "time_since_restore: 3115.2487008571625\n",
      "time_this_iter_s: 7.338351726531982\n",
      "time_total_s: 3115.2487008571625\n",
      "timers:\n",
      "  learn_throughput: 1321.12\n",
      "  learn_time_ms: 3027.733\n",
      "  load_throughput: 24374859.8\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 570.953\n",
      "  sample_time_ms: 7005.828\n",
      "  update_time_ms: 2.31\n",
      "timestamp: 1658397068\n",
      "timesteps_since_restore: 1744000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1744000\n",
      "training_iteration: 436\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1748000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-16\n",
      "done: false\n",
      "episode_len_mean: 196.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.42\n",
      "episode_reward_min: 113.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9256\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2120020091533661\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002383706159889698\n",
      "        model: {}\n",
      "        policy_loss: 0.009906373918056488\n",
      "        total_loss: 9.05728530883789\n",
      "        vf_explained_var: 1.987071482290048e-05\n",
      "        vf_loss: 9.047379493713379\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1748000\n",
      "  num_agent_steps_trained: 1748000\n",
      "  num_steps_sampled: 1748000\n",
      "  num_steps_trained: 1748000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 437\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.145454545454534\n",
      "  ram_util_percent: 85.47272727272728\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06852118175819767\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872253771149618\n",
      "  mean_inference_ms: 0.7513916854095541\n",
      "  mean_raw_obs_processing_ms: 0.09106285670751164\n",
      "time_since_restore: 3122.6301233768463\n",
      "time_this_iter_s: 7.381422519683838\n",
      "time_total_s: 3122.6301233768463\n",
      "timers:\n",
      "  learn_throughput: 1316.661\n",
      "  learn_time_ms: 3037.988\n",
      "  load_throughput: 24325382.05\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 567.006\n",
      "  sample_time_ms: 7054.598\n",
      "  update_time_ms: 2.299\n",
      "timestamp: 1658397076\n",
      "timesteps_since_restore: 1748000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1748000\n",
      "training_iteration: 437\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1752000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-23\n",
      "done: false\n",
      "episode_len_mean: 196.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.42\n",
      "episode_reward_min: 113.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9276\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20983009040355682\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035107547882944345\n",
      "        model: {}\n",
      "        policy_loss: 0.007406792603433132\n",
      "        total_loss: 8.374342918395996\n",
      "        vf_explained_var: 2.8982469302718528e-05\n",
      "        vf_loss: 8.366935729980469\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1752000\n",
      "  num_agent_steps_trained: 1752000\n",
      "  num_steps_sampled: 1752000\n",
      "  num_steps_trained: 1752000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 438\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.010000000000005\n",
      "  ram_util_percent: 85.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06852331434477966\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872496859757094\n",
      "  mean_inference_ms: 0.7514244124043893\n",
      "  mean_raw_obs_processing_ms: 0.09106432657142413\n",
      "time_since_restore: 3129.887460231781\n",
      "time_this_iter_s: 7.257336854934692\n",
      "time_total_s: 3129.887460231781\n",
      "timers:\n",
      "  learn_throughput: 1303.417\n",
      "  learn_time_ms: 3068.857\n",
      "  load_throughput: 23919612.204\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 565.736\n",
      "  sample_time_ms: 7070.435\n",
      "  update_time_ms: 2.279\n",
      "timestamp: 1658397083\n",
      "timesteps_since_restore: 1752000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1752000\n",
      "training_iteration: 438\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1756000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-30\n",
      "done: false\n",
      "episode_len_mean: 194.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.16\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9297\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22751757502555847\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005664996337145567\n",
      "        model: {}\n",
      "        policy_loss: 0.004182855598628521\n",
      "        total_loss: 6.949748992919922\n",
      "        vf_explained_var: 5.952517312834971e-06\n",
      "        vf_loss: 6.945566654205322\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1756000\n",
      "  num_agent_steps_trained: 1756000\n",
      "  num_steps_sampled: 1756000\n",
      "  num_steps_trained: 1756000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 439\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.56\n",
      "  ram_util_percent: 85.46\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06852298599568113\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872489071731381\n",
      "  mean_inference_ms: 0.7514283337763831\n",
      "  mean_raw_obs_processing_ms: 0.09106207227130396\n",
      "time_since_restore: 3136.919490814209\n",
      "time_this_iter_s: 7.0320305824279785\n",
      "time_total_s: 3136.919490814209\n",
      "timers:\n",
      "  learn_throughput: 1308.83\n",
      "  learn_time_ms: 3056.164\n",
      "  load_throughput: 24202562.031\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 562.672\n",
      "  sample_time_ms: 7108.935\n",
      "  update_time_ms: 2.175\n",
      "timestamp: 1658397090\n",
      "timesteps_since_restore: 1756000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1756000\n",
      "training_iteration: 439\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1760000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-37\n",
      "done: false\n",
      "episode_len_mean: 195.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.04\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9317\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17858801782131195\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034454776905477047\n",
      "        model: {}\n",
      "        policy_loss: 0.004947743844240904\n",
      "        total_loss: 7.010996341705322\n",
      "        vf_explained_var: 7.90867125033401e-05\n",
      "        vf_loss: 7.006048202514648\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1760000\n",
      "  num_agent_steps_trained: 1760000\n",
      "  num_steps_sampled: 1760000\n",
      "  num_steps_trained: 1760000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 440\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.94\n",
      "  ram_util_percent: 85.46\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06852185016769011\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872385076894046\n",
      "  mean_inference_ms: 0.7514222580569426\n",
      "  mean_raw_obs_processing_ms: 0.09105910985204545\n",
      "time_since_restore: 3143.6110389232635\n",
      "time_this_iter_s: 6.691548109054565\n",
      "time_total_s: 3143.6110389232635\n",
      "timers:\n",
      "  learn_throughput: 1311.624\n",
      "  learn_time_ms: 3049.655\n",
      "  load_throughput: 24403223.273\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 566.473\n",
      "  sample_time_ms: 7061.237\n",
      "  update_time_ms: 2.211\n",
      "timestamp: 1658397097\n",
      "timesteps_since_restore: 1760000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1760000\n",
      "training_iteration: 440\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1764000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-44\n",
      "done: false\n",
      "episode_len_mean: 196.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.62\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9337\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21259215474128723\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003189602168276906\n",
      "        model: {}\n",
      "        policy_loss: 0.0006859390414319932\n",
      "        total_loss: 2.407440185546875\n",
      "        vf_explained_var: 0.008307291194796562\n",
      "        vf_loss: 2.406754493713379\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1764000\n",
      "  num_agent_steps_trained: 1764000\n",
      "  num_steps_sampled: 1764000\n",
      "  num_steps_trained: 1764000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 441\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.660000000000004\n",
      "  ram_util_percent: 85.46000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06852006241132762\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07872053414804761\n",
      "  mean_inference_ms: 0.7513959712482253\n",
      "  mean_raw_obs_processing_ms: 0.09105358228967528\n",
      "time_since_restore: 3150.5746948719025\n",
      "time_this_iter_s: 6.963655948638916\n",
      "time_total_s: 3150.5746948719025\n",
      "timers:\n",
      "  learn_throughput: 1300.271\n",
      "  learn_time_ms: 3076.281\n",
      "  load_throughput: 24167698.07\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 566.972\n",
      "  sample_time_ms: 7055.02\n",
      "  update_time_ms: 2.172\n",
      "timestamp: 1658397104\n",
      "timesteps_since_restore: 1764000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1764000\n",
      "training_iteration: 441\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1768000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-51\n",
      "done: false\n",
      "episode_len_mean: 196.72\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.72\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9357\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22834545373916626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002356098499149084\n",
      "        model: {}\n",
      "        policy_loss: 0.0014784556115046144\n",
      "        total_loss: 2.0176079273223877\n",
      "        vf_explained_var: -0.013617629185318947\n",
      "        vf_loss: 2.0161292552948\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1768000\n",
      "  num_agent_steps_trained: 1768000\n",
      "  num_steps_sampled: 1768000\n",
      "  num_steps_trained: 1768000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 442\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.629999999999995\n",
      "  ram_util_percent: 85.47999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06851720018807933\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07871613844958258\n",
      "  mean_inference_ms: 0.751366691891282\n",
      "  mean_raw_obs_processing_ms: 0.09104668561699303\n",
      "time_since_restore: 3157.7828805446625\n",
      "time_this_iter_s: 7.20818567276001\n",
      "time_total_s: 3157.7828805446625\n",
      "timers:\n",
      "  learn_throughput: 1288.333\n",
      "  learn_time_ms: 3104.788\n",
      "  load_throughput: 23981154.946\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 563.98\n",
      "  sample_time_ms: 7092.447\n",
      "  update_time_ms: 2.117\n",
      "timestamp: 1658397111\n",
      "timesteps_since_restore: 1768000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1768000\n",
      "training_iteration: 442\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1772000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-51-58\n",
      "done: false\n",
      "episode_len_mean: 195.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.85\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9378\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24296998977661133\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00488320691511035\n",
      "        model: {}\n",
      "        policy_loss: 0.002292861696332693\n",
      "        total_loss: 6.189293384552002\n",
      "        vf_explained_var: -0.033953096717596054\n",
      "        vf_loss: 6.187000751495361\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1772000\n",
      "  num_agent_steps_trained: 1772000\n",
      "  num_steps_sampled: 1772000\n",
      "  num_steps_trained: 1772000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 443\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.39\n",
      "  ram_util_percent: 85.42999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06851156360085328\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07870851669498254\n",
      "  mean_inference_ms: 0.7513070810824053\n",
      "  mean_raw_obs_processing_ms: 0.09103688253295887\n",
      "time_since_restore: 3164.4523589611053\n",
      "time_this_iter_s: 6.669478416442871\n",
      "time_total_s: 3164.4523589611053\n",
      "timers:\n",
      "  learn_throughput: 1286.487\n",
      "  learn_time_ms: 3109.243\n",
      "  load_throughput: 23967451.429\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 562.431\n",
      "  sample_time_ms: 7111.986\n",
      "  update_time_ms: 2.13\n",
      "timestamp: 1658397118\n",
      "timesteps_since_restore: 1772000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1772000\n",
      "training_iteration: 443\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1776000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-05\n",
      "done: false\n",
      "episode_len_mean: 197.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.99\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9398\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.254360556602478\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036835044156759977\n",
      "        model: {}\n",
      "        policy_loss: 0.007344364654272795\n",
      "        total_loss: 7.376295566558838\n",
      "        vf_explained_var: 1.2183894796180539e-05\n",
      "        vf_loss: 7.368951797485352\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1776000\n",
      "  num_agent_steps_trained: 1776000\n",
      "  num_steps_sampled: 1776000\n",
      "  num_steps_trained: 1776000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 444\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.33\n",
      "  ram_util_percent: 85.47999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06850829441429354\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07870294662825408\n",
      "  mean_inference_ms: 0.7512717402491274\n",
      "  mean_raw_obs_processing_ms: 0.09103041955666397\n",
      "time_since_restore: 3171.4851455688477\n",
      "time_this_iter_s: 7.03278660774231\n",
      "time_total_s: 3171.4851455688477\n",
      "timers:\n",
      "  learn_throughput: 1290.108\n",
      "  learn_time_ms: 3100.516\n",
      "  load_throughput: 22795130.435\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 562.93\n",
      "  sample_time_ms: 7105.681\n",
      "  update_time_ms: 2.137\n",
      "timestamp: 1658397125\n",
      "timesteps_since_restore: 1776000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1776000\n",
      "training_iteration: 444\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1780000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-12\n",
      "done: false\n",
      "episode_len_mean: 198.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.01\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9418\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2666933834552765\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005476751830428839\n",
      "        model: {}\n",
      "        policy_loss: 0.005954887252300978\n",
      "        total_loss: 7.012003421783447\n",
      "        vf_explained_var: 4.749144366655855e-08\n",
      "        vf_loss: 7.006048202514648\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1780000\n",
      "  num_agent_steps_trained: 1780000\n",
      "  num_steps_sampled: 1780000\n",
      "  num_steps_trained: 1780000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 445\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.410000000000004\n",
      "  ram_util_percent: 85.47999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06850616578810957\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07869860434160113\n",
      "  mean_inference_ms: 0.7512482429988743\n",
      "  mean_raw_obs_processing_ms: 0.09102554117932388\n",
      "time_since_restore: 3178.5173490047455\n",
      "time_this_iter_s: 7.032203435897827\n",
      "time_total_s: 3178.5173490047455\n",
      "timers:\n",
      "  learn_throughput: 1298.521\n",
      "  learn_time_ms: 3080.428\n",
      "  load_throughput: 21780106.452\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 563.261\n",
      "  sample_time_ms: 7101.498\n",
      "  update_time_ms: 2.022\n",
      "timestamp: 1658397132\n",
      "timesteps_since_restore: 1780000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1780000\n",
      "training_iteration: 445\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1784000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-19\n",
      "done: false\n",
      "episode_len_mean: 197.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.92\n",
      "episode_reward_min: 113.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9438\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2618107199668884\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003867149818688631\n",
      "        model: {}\n",
      "        policy_loss: 0.0015195328742265701\n",
      "        total_loss: 5.021687984466553\n",
      "        vf_explained_var: -0.06438331305980682\n",
      "        vf_loss: 5.020168781280518\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1784000\n",
      "  num_agent_steps_trained: 1784000\n",
      "  num_steps_sampled: 1784000\n",
      "  num_steps_trained: 1784000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 446\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.85\n",
      "  ram_util_percent: 85.46\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06850493108227922\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07869701823505691\n",
      "  mean_inference_ms: 0.7512503036378122\n",
      "  mean_raw_obs_processing_ms: 0.09102400665344287\n",
      "time_since_restore: 3185.559700012207\n",
      "time_this_iter_s: 7.042351007461548\n",
      "time_total_s: 3185.559700012207\n",
      "timers:\n",
      "  learn_throughput: 1313.564\n",
      "  learn_time_ms: 3045.151\n",
      "  load_throughput: 21873814.863\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 564.397\n",
      "  sample_time_ms: 7087.209\n",
      "  update_time_ms: 1.945\n",
      "timestamp: 1658397139\n",
      "timesteps_since_restore: 1784000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1784000\n",
      "training_iteration: 446\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1788000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-26\n",
      "done: false\n",
      "episode_len_mean: 197.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.17\n",
      "episode_reward_min: 113.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9459\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24858860671520233\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0039419387467205524\n",
      "        model: {}\n",
      "        policy_loss: -0.001571273198351264\n",
      "        total_loss: 1.943994164466858\n",
      "        vf_explained_var: -0.02134307473897934\n",
      "        vf_loss: 1.9455653429031372\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1788000\n",
      "  num_agent_steps_trained: 1788000\n",
      "  num_steps_sampled: 1788000\n",
      "  num_steps_trained: 1788000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 447\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.589999999999996\n",
      "  ram_util_percent: 85.49999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06850408507018234\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07869593985766707\n",
      "  mean_inference_ms: 0.7512490580593287\n",
      "  mean_raw_obs_processing_ms: 0.09102283429322146\n",
      "time_since_restore: 3192.4864008426666\n",
      "time_this_iter_s: 6.926700830459595\n",
      "time_total_s: 3192.4864008426666\n",
      "timers:\n",
      "  learn_throughput: 1329.167\n",
      "  learn_time_ms: 3009.404\n",
      "  load_throughput: 20769022.035\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 568.215\n",
      "  sample_time_ms: 7039.591\n",
      "  update_time_ms: 2.026\n",
      "timestamp: 1658397146\n",
      "timesteps_since_restore: 1788000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1788000\n",
      "training_iteration: 447\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1792000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-32\n",
      "done: false\n",
      "episode_len_mean: 197.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.79\n",
      "episode_reward_min: 124.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9479\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.242049902677536\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028275211807340384\n",
      "        model: {}\n",
      "        policy_loss: 0.006071953568607569\n",
      "        total_loss: 7.062524318695068\n",
      "        vf_explained_var: 1.945611074916087e-06\n",
      "        vf_loss: 7.056451797485352\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1792000\n",
      "  num_agent_steps_trained: 1792000\n",
      "  num_steps_sampled: 1792000\n",
      "  num_steps_trained: 1792000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 448\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.25\n",
      "  ram_util_percent: 85.44\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06850396421710363\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07869546223244339\n",
      "  mean_inference_ms: 0.7512574877082847\n",
      "  mean_raw_obs_processing_ms: 0.09102230563011382\n",
      "time_since_restore: 3199.2639989852905\n",
      "time_this_iter_s: 6.777598142623901\n",
      "time_total_s: 3199.2639989852905\n",
      "timers:\n",
      "  learn_throughput: 1341.965\n",
      "  learn_time_ms: 2980.703\n",
      "  load_throughput: 21076904.523\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 572.592\n",
      "  sample_time_ms: 6985.774\n",
      "  update_time_ms: 2.041\n",
      "timestamp: 1658397152\n",
      "timesteps_since_restore: 1792000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1792000\n",
      "training_iteration: 448\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1796000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-39\n",
      "done: false\n",
      "episode_len_mean: 197.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.91\n",
      "episode_reward_min: 124.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9499\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24026039242744446\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030061209108680487\n",
      "        model: {}\n",
      "        policy_loss: 0.005563871469348669\n",
      "        total_loss: 6.557983875274658\n",
      "        vf_explained_var: -8.366441193174978e-07\n",
      "        vf_loss: 6.552419185638428\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1796000\n",
      "  num_agent_steps_trained: 1796000\n",
      "  num_steps_sampled: 1796000\n",
      "  num_steps_trained: 1796000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 449\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.922222222222217\n",
      "  ram_util_percent: 85.57777777777778\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06850105109974901\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07869209456778084\n",
      "  mean_inference_ms: 0.7512380919526512\n",
      "  mean_raw_obs_processing_ms: 0.09101851825379147\n",
      "time_since_restore: 3205.9640090465546\n",
      "time_this_iter_s: 6.700010061264038\n",
      "time_total_s: 3205.9640090465546\n",
      "timers:\n",
      "  learn_throughput: 1352.9\n",
      "  learn_time_ms: 2956.611\n",
      "  load_throughput: 21003024.537\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 575.64\n",
      "  sample_time_ms: 6948.786\n",
      "  update_time_ms: 2.041\n",
      "timestamp: 1658397159\n",
      "timesteps_since_restore: 1796000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1796000\n",
      "training_iteration: 449\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1800000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-46\n",
      "done: false\n",
      "episode_len_mean: 197.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.91\n",
      "episode_reward_min: 124.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9519\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2867097556591034\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.012145308777689934\n",
      "        model: {}\n",
      "        policy_loss: 0.0016976413317024708\n",
      "        total_loss: 6.554117679595947\n",
      "        vf_explained_var: 1.8146089360016049e-06\n",
      "        vf_loss: 6.552419662475586\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1800000\n",
      "  num_agent_steps_trained: 1800000\n",
      "  num_steps_sampled: 1800000\n",
      "  num_steps_trained: 1800000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 450\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.709999999999994\n",
      "  ram_util_percent: 85.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06849686526891094\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07868747332200625\n",
      "  mean_inference_ms: 0.7512072198475033\n",
      "  mean_raw_obs_processing_ms: 0.09101336800597588\n",
      "time_since_restore: 3212.7378435134888\n",
      "time_this_iter_s: 6.773834466934204\n",
      "time_total_s: 3212.7378435134888\n",
      "timers:\n",
      "  learn_throughput: 1349.494\n",
      "  learn_time_ms: 2964.074\n",
      "  load_throughput: 21000395.544\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 577.64\n",
      "  sample_time_ms: 6924.734\n",
      "  update_time_ms: 2.029\n",
      "timestamp: 1658397166\n",
      "timesteps_since_restore: 1800000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1800000\n",
      "training_iteration: 450\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1804000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-53\n",
      "done: false\n",
      "episode_len_mean: 198.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.31\n",
      "episode_reward_min: 144.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9539\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2729826867580414\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034343190491199493\n",
      "        model: {}\n",
      "        policy_loss: 0.0017589917406439781\n",
      "        total_loss: 4.842989921569824\n",
      "        vf_explained_var: -0.032253824174404144\n",
      "        vf_loss: 4.841230869293213\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1804000\n",
      "  num_agent_steps_trained: 1804000\n",
      "  num_steps_sampled: 1804000\n",
      "  num_steps_trained: 1804000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 451\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.366666666666667\n",
      "  ram_util_percent: 85.64444444444445\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06849035180654772\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07867981610259815\n",
      "  mean_inference_ms: 0.7511484327238023\n",
      "  mean_raw_obs_processing_ms: 0.09100487116279471\n",
      "time_since_restore: 3219.4557609558105\n",
      "time_this_iter_s: 6.717917442321777\n",
      "time_total_s: 3219.4557609558105\n",
      "timers:\n",
      "  learn_throughput: 1358.811\n",
      "  learn_time_ms: 2943.751\n",
      "  load_throughput: 20893170.61\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 577.391\n",
      "  sample_time_ms: 6927.712\n",
      "  update_time_ms: 2.04\n",
      "timestamp: 1658397173\n",
      "timesteps_since_restore: 1804000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1804000\n",
      "training_iteration: 451\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1808000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-52-59\n",
      "done: false\n",
      "episode_len_mean: 199.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.11\n",
      "episode_reward_min: 152.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9559\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27081385254859924\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00271068443544209\n",
      "        model: {}\n",
      "        policy_loss: 0.0025309377815574408\n",
      "        total_loss: 3.3291447162628174\n",
      "        vf_explained_var: 0.0023306612856686115\n",
      "        vf_loss: 3.326613426208496\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1808000\n",
      "  num_agent_steps_trained: 1808000\n",
      "  num_steps_sampled: 1808000\n",
      "  num_steps_trained: 1808000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 452\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.25\n",
      "  ram_util_percent: 85.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06848271100548098\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07867060760564637\n",
      "  mean_inference_ms: 0.7510803091313456\n",
      "  mean_raw_obs_processing_ms: 0.09099507044695378\n",
      "time_since_restore: 3226.224425792694\n",
      "time_this_iter_s: 6.768664836883545\n",
      "time_total_s: 3226.224425792694\n",
      "timers:\n",
      "  learn_throughput: 1371.751\n",
      "  learn_time_ms: 2915.982\n",
      "  load_throughput: 20955803.148\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 580.45\n",
      "  sample_time_ms: 6891.206\n",
      "  update_time_ms: 2.097\n",
      "timestamp: 1658397179\n",
      "timesteps_since_restore: 1808000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1808000\n",
      "training_iteration: 452\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1812000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-53-06\n",
      "done: false\n",
      "episode_len_mean: 198.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.51\n",
      "episode_reward_min: 115.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9580\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2700355648994446\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00347718084231019\n",
      "        model: {}\n",
      "        policy_loss: -0.004309667740017176\n",
      "        total_loss: 7.636842727661133\n",
      "        vf_explained_var: 1.647267254156759e-06\n",
      "        vf_loss: 7.6411519050598145\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1812000\n",
      "  num_agent_steps_trained: 1812000\n",
      "  num_steps_sampled: 1812000\n",
      "  num_steps_trained: 1812000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 453\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.16\n",
      "  ram_util_percent: 85.54\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06847432445280781\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07866123591743966\n",
      "  mean_inference_ms: 0.7510024894554299\n",
      "  mean_raw_obs_processing_ms: 0.0909858269867913\n",
      "time_since_restore: 3233.026654958725\n",
      "time_this_iter_s: 6.802229166030884\n",
      "time_total_s: 3233.026654958725\n",
      "timers:\n",
      "  learn_throughput: 1369.14\n",
      "  learn_time_ms: 2921.541\n",
      "  load_throughput: 20958420.987\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 582.093\n",
      "  sample_time_ms: 6871.76\n",
      "  update_time_ms: 2.117\n",
      "timestamp: 1658397186\n",
      "timesteps_since_restore: 1812000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1812000\n",
      "training_iteration: 453\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1816000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-53-13\n",
      "done: false\n",
      "episode_len_mean: 196.64\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.64\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9601\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28292301297187805\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005911956075578928\n",
      "        model: {}\n",
      "        policy_loss: -0.015428773127496243\n",
      "        total_loss: 9.107555389404297\n",
      "        vf_explained_var: 4.944109150528675e-06\n",
      "        vf_loss: 9.122983932495117\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1816000\n",
      "  num_agent_steps_trained: 1816000\n",
      "  num_steps_sampled: 1816000\n",
      "  num_steps_trained: 1816000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 454\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.440000000000005\n",
      "  ram_util_percent: 85.6\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06846622572900825\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07865226588148987\n",
      "  mean_inference_ms: 0.7509296682067582\n",
      "  mean_raw_obs_processing_ms: 0.09097695091830534\n",
      "time_since_restore: 3239.886860847473\n",
      "time_this_iter_s: 6.860205888748169\n",
      "time_total_s: 3239.886860847473\n",
      "timers:\n",
      "  learn_throughput: 1363.295\n",
      "  learn_time_ms: 2934.068\n",
      "  load_throughput: 21754688.797\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 584.144\n",
      "  sample_time_ms: 6847.624\n",
      "  update_time_ms: 2.104\n",
      "timestamp: 1658397193\n",
      "timesteps_since_restore: 1816000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1816000\n",
      "training_iteration: 454\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1820000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-53-20\n",
      "done: false\n",
      "episode_len_mean: 194.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.68\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9622\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22345350682735443\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004180988762527704\n",
      "        model: {}\n",
      "        policy_loss: -0.017300916835665703\n",
      "        total_loss: 9.004983901977539\n",
      "        vf_explained_var: 0.00018525893392506987\n",
      "        vf_loss: 9.022283554077148\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1820000\n",
      "  num_agent_steps_trained: 1820000\n",
      "  num_steps_sampled: 1820000\n",
      "  num_steps_trained: 1820000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 455\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.37777777777778\n",
      "  ram_util_percent: 85.57777777777778\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06845789301219324\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0786429411963516\n",
      "  mean_inference_ms: 0.7508546335674473\n",
      "  mean_raw_obs_processing_ms: 0.09096772932319545\n",
      "time_since_restore: 3246.5649790763855\n",
      "time_this_iter_s: 6.6781182289123535\n",
      "time_total_s: 3246.5649790763855\n",
      "timers:\n",
      "  learn_throughput: 1371.547\n",
      "  learn_time_ms: 2916.415\n",
      "  load_throughput: 22829250.238\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 584.593\n",
      "  sample_time_ms: 6842.365\n",
      "  update_time_ms: 2.116\n",
      "timestamp: 1658397200\n",
      "timesteps_since_restore: 1820000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1820000\n",
      "training_iteration: 455\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1824000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-53-27\n",
      "done: false\n",
      "episode_len_mean: 195.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.32\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9642\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23750048875808716\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026746068615466356\n",
      "        model: {}\n",
      "        policy_loss: -0.015834709629416466\n",
      "        total_loss: 9.888400077819824\n",
      "        vf_explained_var: 1.5984298897819826e-06\n",
      "        vf_loss: 9.904233932495117\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1824000\n",
      "  num_agent_steps_trained: 1824000\n",
      "  num_steps_sampled: 1824000\n",
      "  num_steps_trained: 1824000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 456\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.58\n",
      "  ram_util_percent: 85.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06845023056540565\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07863458075290733\n",
      "  mean_inference_ms: 0.7507830238991551\n",
      "  mean_raw_obs_processing_ms: 0.09095865426558188\n",
      "time_since_restore: 3253.298513650894\n",
      "time_this_iter_s: 6.733534574508667\n",
      "time_total_s: 3253.298513650894\n",
      "timers:\n",
      "  learn_throughput: 1370.254\n",
      "  learn_time_ms: 2919.167\n",
      "  load_throughput: 22897797.188\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 588.986\n",
      "  sample_time_ms: 6791.33\n",
      "  update_time_ms: 2.114\n",
      "timestamp: 1658397207\n",
      "timesteps_since_restore: 1824000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1824000\n",
      "training_iteration: 456\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1828000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-53-34\n",
      "done: false\n",
      "episode_len_mean: 195.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.32\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9662\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24765969812870026\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003590516746044159\n",
      "        model: {}\n",
      "        policy_loss: -0.016818039119243622\n",
      "        total_loss: 9.887415885925293\n",
      "        vf_explained_var: 3.6034532513440354e-06\n",
      "        vf_loss: 9.904233932495117\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1828000\n",
      "  num_agent_steps_trained: 1828000\n",
      "  num_steps_sampled: 1828000\n",
      "  num_steps_trained: 1828000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 457\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.46\n",
      "  ram_util_percent: 85.55999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0684445569179526\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07862855320537157\n",
      "  mean_inference_ms: 0.7507302206352836\n",
      "  mean_raw_obs_processing_ms: 0.09095147590394705\n",
      "time_since_restore: 3260.483711719513\n",
      "time_this_iter_s: 7.185198068618774\n",
      "time_total_s: 3260.483711719513\n",
      "timers:\n",
      "  learn_throughput: 1362.703\n",
      "  learn_time_ms: 2935.342\n",
      "  load_throughput: 24087890.883\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 587.886\n",
      "  sample_time_ms: 6804.038\n",
      "  update_time_ms: 2.059\n",
      "timestamp: 1658397214\n",
      "timesteps_since_restore: 1828000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1828000\n",
      "training_iteration: 457\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1832000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-53-41\n",
      "done: false\n",
      "episode_len_mean: 195.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.39\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9682\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26440709829330444\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004623894114047289\n",
      "        model: {}\n",
      "        policy_loss: 0.004918394144624472\n",
      "        total_loss: 9.037176132202148\n",
      "        vf_explained_var: 8.008492841327097e-06\n",
      "        vf_loss: 9.032258033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1832000\n",
      "  num_agent_steps_trained: 1832000\n",
      "  num_steps_sampled: 1832000\n",
      "  num_steps_trained: 1832000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 458\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.72\n",
      "  ram_util_percent: 85.54999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06843971764911144\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07862314266078525\n",
      "  mean_inference_ms: 0.7506860880547848\n",
      "  mean_raw_obs_processing_ms: 0.09094408382844556\n",
      "time_since_restore: 3267.2886729240417\n",
      "time_this_iter_s: 6.804961204528809\n",
      "time_total_s: 3267.2886729240417\n",
      "timers:\n",
      "  learn_throughput: 1363.406\n",
      "  learn_time_ms: 2933.829\n",
      "  load_throughput: 23871963.574\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 586.166\n",
      "  sample_time_ms: 6824.008\n",
      "  update_time_ms: 2.078\n",
      "timestamp: 1658397221\n",
      "timesteps_since_restore: 1832000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1832000\n",
      "training_iteration: 458\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1836000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-53-47\n",
      "done: false\n",
      "episode_len_mean: 196.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.78\n",
      "episode_reward_min: 43.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9702\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27474191784858704\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004457524046301842\n",
      "        model: {}\n",
      "        policy_loss: 0.0006357236416079104\n",
      "        total_loss: 4.678056240081787\n",
      "        vf_explained_var: 0.0015544620109722018\n",
      "        vf_loss: 4.677420616149902\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1836000\n",
      "  num_agent_steps_trained: 1836000\n",
      "  num_steps_sampled: 1836000\n",
      "  num_steps_trained: 1836000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 459\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.040000000000006\n",
      "  ram_util_percent: 85.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06843542322619961\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0786180350945168\n",
      "  mean_inference_ms: 0.7506436939335213\n",
      "  mean_raw_obs_processing_ms: 0.09093725514483544\n",
      "time_since_restore: 3274.0615327358246\n",
      "time_this_iter_s: 6.772859811782837\n",
      "time_total_s: 3274.0615327358246\n",
      "timers:\n",
      "  learn_throughput: 1363.525\n",
      "  learn_time_ms: 2933.572\n",
      "  load_throughput: 23527157.481\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 585.705\n",
      "  sample_time_ms: 6829.376\n",
      "  update_time_ms: 2.161\n",
      "timestamp: 1658397227\n",
      "timesteps_since_restore: 1836000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1836000\n",
      "training_iteration: 459\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1840000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-53-54\n",
      "done: false\n",
      "episode_len_mean: 197.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.51\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9723\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25248634815216064\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004173578694462776\n",
      "        model: {}\n",
      "        policy_loss: 0.0033487509936094284\n",
      "        total_loss: 4.990749835968018\n",
      "        vf_explained_var: -3.6916425472099945e-08\n",
      "        vf_loss: 4.987400054931641\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1840000\n",
      "  num_agent_steps_trained: 1840000\n",
      "  num_steps_sampled: 1840000\n",
      "  num_steps_trained: 1840000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 460\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.65555555555555\n",
      "  ram_util_percent: 85.56666666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0684315755276808\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07861355810214722\n",
      "  mean_inference_ms: 0.7506061794602888\n",
      "  mean_raw_obs_processing_ms: 0.09093082816661426\n",
      "time_since_restore: 3280.8498985767365\n",
      "time_this_iter_s: 6.788365840911865\n",
      "time_total_s: 3280.8498985767365\n",
      "timers:\n",
      "  learn_throughput: 1364.285\n",
      "  learn_time_ms: 2931.938\n",
      "  load_throughput: 23471203.134\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 585.41\n",
      "  sample_time_ms: 6832.816\n",
      "  update_time_ms: 2.135\n",
      "timestamp: 1658397234\n",
      "timesteps_since_restore: 1840000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1840000\n",
      "training_iteration: 460\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1844000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-01\n",
      "done: false\n",
      "episode_len_mean: 197.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.4\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9743\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28086718916893005\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030537950806319714\n",
      "        model: {}\n",
      "        policy_loss: 0.006170942448079586\n",
      "        total_loss: 7.239034175872803\n",
      "        vf_explained_var: 8.626009844192595e-07\n",
      "        vf_loss: 7.232862949371338\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1844000\n",
      "  num_agent_steps_trained: 1844000\n",
      "  num_steps_sampled: 1844000\n",
      "  num_steps_trained: 1844000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 461\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.43\n",
      "  ram_util_percent: 85.58\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06842789191566148\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07860936873971865\n",
      "  mean_inference_ms: 0.7505753206411004\n",
      "  mean_raw_obs_processing_ms: 0.09092525694950437\n",
      "time_since_restore: 3287.848608016968\n",
      "time_this_iter_s: 6.998709440231323\n",
      "time_total_s: 3287.848608016968\n",
      "timers:\n",
      "  learn_throughput: 1354.489\n",
      "  learn_time_ms: 2953.142\n",
      "  load_throughput: 23064635.689\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 584.998\n",
      "  sample_time_ms: 6837.632\n",
      "  update_time_ms: 2.194\n",
      "timestamp: 1658397241\n",
      "timesteps_since_restore: 1844000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1844000\n",
      "training_iteration: 461\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1848000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-08\n",
      "done: false\n",
      "episode_len_mean: 195.64\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.64\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9764\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23811133205890656\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026628216728568077\n",
      "        model: {}\n",
      "        policy_loss: 0.0004176130751147866\n",
      "        total_loss: 3.4328815937042236\n",
      "        vf_explained_var: -0.011125343851745129\n",
      "        vf_loss: 3.4324638843536377\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1848000\n",
      "  num_agent_steps_trained: 1848000\n",
      "  num_steps_sampled: 1848000\n",
      "  num_steps_trained: 1848000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 462\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.230000000000004\n",
      "  ram_util_percent: 85.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06842284123129434\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07860333385062493\n",
      "  mean_inference_ms: 0.7505279834512508\n",
      "  mean_raw_obs_processing_ms: 0.09091814751949155\n",
      "time_since_restore: 3294.6400616168976\n",
      "time_this_iter_s: 6.79145359992981\n",
      "time_total_s: 3294.6400616168976\n",
      "timers:\n",
      "  learn_throughput: 1355.316\n",
      "  learn_time_ms: 2951.34\n",
      "  load_throughput: 23201792.283\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 582.677\n",
      "  sample_time_ms: 6864.867\n",
      "  update_time_ms: 2.175\n",
      "timestamp: 1658397248\n",
      "timesteps_since_restore: 1848000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1848000\n",
      "training_iteration: 462\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1852000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-15\n",
      "done: false\n",
      "episode_len_mean: 195.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.53\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9784\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2381349802017212\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004203129559755325\n",
      "        model: {}\n",
      "        policy_loss: 0.00029068475123494864\n",
      "        total_loss: 4.3526129722595215\n",
      "        vf_explained_var: 2.428408549803862e-07\n",
      "        vf_loss: 4.352322101593018\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1852000\n",
      "  num_agent_steps_trained: 1852000\n",
      "  num_steps_sampled: 1852000\n",
      "  num_steps_trained: 1852000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 463\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.83\n",
      "  ram_util_percent: 85.53\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06841752166523657\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0785969876854644\n",
      "  mean_inference_ms: 0.7504771806221524\n",
      "  mean_raw_obs_processing_ms: 0.09091061850026648\n",
      "time_since_restore: 3301.3797736167908\n",
      "time_this_iter_s: 6.7397119998931885\n",
      "time_total_s: 3301.3797736167908\n",
      "timers:\n",
      "  learn_throughput: 1359.358\n",
      "  learn_time_ms: 2942.565\n",
      "  load_throughput: 22944770.241\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 582.579\n",
      "  sample_time_ms: 6866.021\n",
      "  update_time_ms: 2.148\n",
      "timestamp: 1658397255\n",
      "timesteps_since_restore: 1852000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1852000\n",
      "training_iteration: 463\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1856000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-22\n",
      "done: false\n",
      "episode_len_mean: 196.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.01\n",
      "episode_reward_min: 77.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9804\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2398470938205719\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002953477669507265\n",
      "        model: {}\n",
      "        policy_loss: 0.0031193476170301437\n",
      "        total_loss: 3.682555913925171\n",
      "        vf_explained_var: 1.8682531788272172e-07\n",
      "        vf_loss: 3.679436206817627\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1856000\n",
      "  num_agent_steps_trained: 1856000\n",
      "  num_steps_sampled: 1856000\n",
      "  num_steps_trained: 1856000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 464\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.47\n",
      "  ram_util_percent: 85.56\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06841172851052382\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07858992390638722\n",
      "  mean_inference_ms: 0.7504177956690462\n",
      "  mean_raw_obs_processing_ms: 0.09090204089951232\n",
      "time_since_restore: 3308.2978451251984\n",
      "time_this_iter_s: 6.918071508407593\n",
      "time_total_s: 3308.2978451251984\n",
      "timers:\n",
      "  learn_throughput: 1353.225\n",
      "  learn_time_ms: 2955.901\n",
      "  load_throughput: 23134605.626\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 584.012\n",
      "  sample_time_ms: 6849.176\n",
      "  update_time_ms: 2.142\n",
      "timestamp: 1658397262\n",
      "timesteps_since_restore: 1856000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1856000\n",
      "training_iteration: 464\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1860000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-28\n",
      "done: false\n",
      "episode_len_mean: 196.73\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.73\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9824\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2578767240047455\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0039054909721016884\n",
      "        model: {}\n",
      "        policy_loss: -0.00143525714520365\n",
      "        total_loss: 3.0782034397125244\n",
      "        vf_explained_var: 0.0030216649174690247\n",
      "        vf_loss: 3.079638719558716\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1860000\n",
      "  num_agent_steps_trained: 1860000\n",
      "  num_steps_sampled: 1860000\n",
      "  num_steps_trained: 1860000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 465\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.91111111111111\n",
      "  ram_util_percent: 85.5888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0684048487611702\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07858154884900168\n",
      "  mean_inference_ms: 0.7503467703351581\n",
      "  mean_raw_obs_processing_ms: 0.09089220792920502\n",
      "time_since_restore: 3314.913552761078\n",
      "time_this_iter_s: 6.615707635879517\n",
      "time_total_s: 3314.913552761078\n",
      "timers:\n",
      "  learn_throughput: 1353.153\n",
      "  learn_time_ms: 2956.059\n",
      "  load_throughput: 22826144.218\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 583.443\n",
      "  sample_time_ms: 6855.851\n",
      "  update_time_ms: 2.161\n",
      "timestamp: 1658397268\n",
      "timesteps_since_restore: 1860000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1860000\n",
      "training_iteration: 465\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1864000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-35\n",
      "done: false\n",
      "episode_len_mean: 197.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.19\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9844\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2640804350376129\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005272626411169767\n",
      "        model: {}\n",
      "        policy_loss: -0.0029705408960580826\n",
      "        total_loss: 1.1059021949768066\n",
      "        vf_explained_var: 0.007573341950774193\n",
      "        vf_loss: 1.108872652053833\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1864000\n",
      "  num_agent_steps_trained: 1864000\n",
      "  num_steps_sampled: 1864000\n",
      "  num_steps_trained: 1864000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 466\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.239999999999995\n",
      "  ram_util_percent: 85.67\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06839752408922135\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07857277388260499\n",
      "  mean_inference_ms: 0.7502719661728321\n",
      "  mean_raw_obs_processing_ms: 0.09088207798086875\n",
      "time_since_restore: 3321.6415824890137\n",
      "time_this_iter_s: 6.728029727935791\n",
      "time_total_s: 3321.6415824890137\n",
      "timers:\n",
      "  learn_throughput: 1353.953\n",
      "  learn_time_ms: 2954.312\n",
      "  load_throughput: 22595577.104\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 583.338\n",
      "  sample_time_ms: 6857.093\n",
      "  update_time_ms: 2.145\n",
      "timestamp: 1658397275\n",
      "timesteps_since_restore: 1864000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1864000\n",
      "training_iteration: 466\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1868000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-42\n",
      "done: false\n",
      "episode_len_mean: 197.26\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.26\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9865\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2623305022716522\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0045601860620081425\n",
      "        model: {}\n",
      "        policy_loss: 0.0013251922791823745\n",
      "        total_loss: 5.223107814788818\n",
      "        vf_explained_var: 0.029325345531105995\n",
      "        vf_loss: 5.221782684326172\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1868000\n",
      "  num_agent_steps_trained: 1868000\n",
      "  num_steps_sampled: 1868000\n",
      "  num_steps_trained: 1868000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 467\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.877777777777776\n",
      "  ram_util_percent: 85.69999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06838902581600714\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07856255364120811\n",
      "  mean_inference_ms: 0.750189192973435\n",
      "  mean_raw_obs_processing_ms: 0.09087085551360459\n",
      "time_since_restore: 3328.3794054985046\n",
      "time_this_iter_s: 6.737823009490967\n",
      "time_total_s: 3328.3794054985046\n",
      "timers:\n",
      "  learn_throughput: 1363.349\n",
      "  learn_time_ms: 2933.952\n",
      "  load_throughput: 22002906.23\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 585.603\n",
      "  sample_time_ms: 6830.566\n",
      "  update_time_ms: 2.146\n",
      "timestamp: 1658397282\n",
      "timesteps_since_restore: 1868000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1868000\n",
      "training_iteration: 467\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1872000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-49\n",
      "done: false\n",
      "episode_len_mean: 197.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.11\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9886\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2671871483325958\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004257579799741507\n",
      "        model: {}\n",
      "        policy_loss: -0.006687713786959648\n",
      "        total_loss: 5.356215953826904\n",
      "        vf_explained_var: 5.281804533296963e-06\n",
      "        vf_loss: 5.362903118133545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1872000\n",
      "  num_agent_steps_trained: 1872000\n",
      "  num_steps_sampled: 1872000\n",
      "  num_steps_trained: 1872000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 468\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.730000000000004\n",
      "  ram_util_percent: 85.81\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06838048990464303\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07855226193938324\n",
      "  mean_inference_ms: 0.750105438564884\n",
      "  mean_raw_obs_processing_ms: 0.09085958677090016\n",
      "time_since_restore: 3335.092885017395\n",
      "time_this_iter_s: 6.713479518890381\n",
      "time_total_s: 3335.092885017395\n",
      "timers:\n",
      "  learn_throughput: 1362.983\n",
      "  learn_time_ms: 2934.739\n",
      "  load_throughput: 22259806.289\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 588.227\n",
      "  sample_time_ms: 6800.093\n",
      "  update_time_ms: 2.222\n",
      "timestamp: 1658397289\n",
      "timesteps_since_restore: 1872000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1872000\n",
      "training_iteration: 468\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1876000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-54-56\n",
      "done: false\n",
      "episode_len_mean: 197.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.11\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9906\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25954365730285645\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002513832412660122\n",
      "        model: {}\n",
      "        policy_loss: -0.003937242552638054\n",
      "        total_loss: 9.22993278503418\n",
      "        vf_explained_var: 7.119742804206908e-06\n",
      "        vf_loss: 9.233870506286621\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1876000\n",
      "  num_agent_steps_trained: 1876000\n",
      "  num_steps_sampled: 1876000\n",
      "  num_steps_trained: 1876000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 469\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.4\n",
      "  ram_util_percent: 85.77\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06837204013226163\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07854246306136564\n",
      "  mean_inference_ms: 0.7500262113950827\n",
      "  mean_raw_obs_processing_ms: 0.09084869742118151\n",
      "time_since_restore: 3341.9581456184387\n",
      "time_this_iter_s: 6.865260601043701\n",
      "time_total_s: 3341.9581456184387\n",
      "timers:\n",
      "  learn_throughput: 1353.339\n",
      "  learn_time_ms: 2955.653\n",
      "  load_throughput: 21828279.99\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 589.11\n",
      "  sample_time_ms: 6789.906\n",
      "  update_time_ms: 2.139\n",
      "timestamp: 1658397296\n",
      "timesteps_since_restore: 1876000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1876000\n",
      "training_iteration: 469\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1880000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-03\n",
      "done: false\n",
      "episode_len_mean: 196.88\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.88\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9926\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2558441758155823\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004951012320816517\n",
      "        model: {}\n",
      "        policy_loss: 0.007072010543197393\n",
      "        total_loss: 8.721792221069336\n",
      "        vf_explained_var: -2.2712574718752876e-06\n",
      "        vf_loss: 8.714719772338867\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1880000\n",
      "  num_agent_steps_trained: 1880000\n",
      "  num_steps_sampled: 1880000\n",
      "  num_steps_trained: 1880000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 470\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.15\n",
      "  ram_util_percent: 85.74999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06836550551388525\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07853470683184316\n",
      "  mean_inference_ms: 0.7499657323357749\n",
      "  mean_raw_obs_processing_ms: 0.09084005364537003\n",
      "time_since_restore: 3349.145378112793\n",
      "time_this_iter_s: 7.187232494354248\n",
      "time_total_s: 3349.145378112793\n",
      "timers:\n",
      "  learn_throughput: 1339.933\n",
      "  learn_time_ms: 2985.223\n",
      "  load_throughput: 21709648.033\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 586.467\n",
      "  sample_time_ms: 6820.499\n",
      "  update_time_ms: 2.288\n",
      "timestamp: 1658397303\n",
      "timesteps_since_restore: 1880000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1880000\n",
      "training_iteration: 470\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1884000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-10\n",
      "done: false\n",
      "episode_len_mean: 194.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.65\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 9947\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2572856843471527\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002839247230440378\n",
      "        model: {}\n",
      "        policy_loss: 0.005869222339242697\n",
      "        total_loss: 7.016963958740234\n",
      "        vf_explained_var: 6.3247580328607e-06\n",
      "        vf_loss: 7.011094093322754\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1884000\n",
      "  num_agent_steps_trained: 1884000\n",
      "  num_steps_sampled: 1884000\n",
      "  num_steps_trained: 1884000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 471\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.19\n",
      "  ram_util_percent: 85.68\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06835946252249411\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07852753080792396\n",
      "  mean_inference_ms: 0.7499088240577406\n",
      "  mean_raw_obs_processing_ms: 0.09083155872481666\n",
      "time_since_restore: 3356.1146018505096\n",
      "time_this_iter_s: 6.969223737716675\n",
      "time_total_s: 3356.1146018505096\n",
      "timers:\n",
      "  learn_throughput: 1342.169\n",
      "  learn_time_ms: 2980.25\n",
      "  load_throughput: 22313094.826\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 583.678\n",
      "  sample_time_ms: 6853.099\n",
      "  update_time_ms: 2.215\n",
      "timestamp: 1658397310\n",
      "timesteps_since_restore: 1884000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1884000\n",
      "training_iteration: 471\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1888000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-17\n",
      "done: false\n",
      "episode_len_mean: 195.88\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.88\n",
      "episode_reward_min: 96.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9967\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2783668339252472\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004086736589670181\n",
      "        model: {}\n",
      "        policy_loss: 1.060001295627444e-06\n",
      "        total_loss: 4.228832721710205\n",
      "        vf_explained_var: 7.3892456384783145e-06\n",
      "        vf_loss: 4.228831768035889\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1888000\n",
      "  num_agent_steps_trained: 1888000\n",
      "  num_steps_sampled: 1888000\n",
      "  num_steps_trained: 1888000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 472\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.53\n",
      "  ram_util_percent: 85.86\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06835458027799522\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0785218629717287\n",
      "  mean_inference_ms: 0.7498630443412934\n",
      "  mean_raw_obs_processing_ms: 0.09082428071558078\n",
      "time_since_restore: 3363.0723028182983\n",
      "time_this_iter_s: 6.957700967788696\n",
      "time_total_s: 3363.0723028182983\n",
      "timers:\n",
      "  learn_throughput: 1336.712\n",
      "  learn_time_ms: 2992.418\n",
      "  load_throughput: 22301230.892\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 583.909\n",
      "  sample_time_ms: 6850.384\n",
      "  update_time_ms: 2.217\n",
      "timestamp: 1658397317\n",
      "timesteps_since_restore: 1888000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1888000\n",
      "training_iteration: 472\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1892000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-24\n",
      "done: false\n",
      "episode_len_mean: 196.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.92\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 9987\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2759016156196594\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005448600742965937\n",
      "        model: {}\n",
      "        policy_loss: -0.0001319985167356208\n",
      "        total_loss: 3.8305139541625977\n",
      "        vf_explained_var: 2.181273657697602e-06\n",
      "        vf_loss: 3.8306453227996826\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1892000\n",
      "  num_agent_steps_trained: 1892000\n",
      "  num_steps_sampled: 1892000\n",
      "  num_steps_trained: 1892000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 473\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.67\n",
      "  ram_util_percent: 85.83\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0683499939242853\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07851656846519411\n",
      "  mean_inference_ms: 0.7498249329541824\n",
      "  mean_raw_obs_processing_ms: 0.09081785418909717\n",
      "time_since_restore: 3370.043535709381\n",
      "time_this_iter_s: 6.971232891082764\n",
      "time_total_s: 3370.043535709381\n",
      "timers:\n",
      "  learn_throughput: 1329.192\n",
      "  learn_time_ms: 3009.347\n",
      "  load_throughput: 22489565.684\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 582.32\n",
      "  sample_time_ms: 6869.071\n",
      "  update_time_ms: 2.155\n",
      "timestamp: 1658397324\n",
      "timesteps_since_restore: 1892000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1892000\n",
      "training_iteration: 473\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1896000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-30\n",
      "done: false\n",
      "episode_len_mean: 196.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.92\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10007\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25175192952156067\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036337594501674175\n",
      "        model: {}\n",
      "        policy_loss: 0.0020955167710781097\n",
      "        total_loss: 3.8327412605285645\n",
      "        vf_explained_var: 3.2890868624235736e-06\n",
      "        vf_loss: 3.830645799636841\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1896000\n",
      "  num_agent_steps_trained: 1896000\n",
      "  num_steps_sampled: 1896000\n",
      "  num_steps_trained: 1896000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 474\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.05555555555556\n",
      "  ram_util_percent: 85.76666666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06834551586789792\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07851131378918746\n",
      "  mean_inference_ms: 0.7497849746049562\n",
      "  mean_raw_obs_processing_ms: 0.09081173374179631\n",
      "time_since_restore: 3376.757851600647\n",
      "time_this_iter_s: 6.714315891265869\n",
      "time_total_s: 3376.757851600647\n",
      "timers:\n",
      "  learn_throughput: 1337.564\n",
      "  learn_time_ms: 2990.512\n",
      "  load_throughput: 22040483.447\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 581.067\n",
      "  sample_time_ms: 6883.891\n",
      "  update_time_ms: 2.191\n",
      "timestamp: 1658397330\n",
      "timesteps_since_restore: 1896000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1896000\n",
      "training_iteration: 474\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1900000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-37\n",
      "done: false\n",
      "episode_len_mean: 197.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.55\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10027\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2970830202102661\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00366396177560091\n",
      "        model: {}\n",
      "        policy_loss: 0.000904698739759624\n",
      "        total_loss: 3.4157238006591797\n",
      "        vf_explained_var: 0.004789392929524183\n",
      "        vf_loss: 3.414818525314331\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1900000\n",
      "  num_agent_steps_trained: 1900000\n",
      "  num_steps_sampled: 1900000\n",
      "  num_steps_trained: 1900000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 475\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.1\n",
      "  ram_util_percent: 85.76\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06834092986608502\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07850596589423238\n",
      "  mean_inference_ms: 0.7497410670464584\n",
      "  mean_raw_obs_processing_ms: 0.09080517289765101\n",
      "time_since_restore: 3383.578339099884\n",
      "time_this_iter_s: 6.8204874992370605\n",
      "time_total_s: 3383.578339099884\n",
      "timers:\n",
      "  learn_throughput: 1336.957\n",
      "  learn_time_ms: 2991.869\n",
      "  load_throughput: 22130610.737\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 581.016\n",
      "  sample_time_ms: 6884.494\n",
      "  update_time_ms: 2.191\n",
      "timestamp: 1658397337\n",
      "timesteps_since_restore: 1900000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1900000\n",
      "training_iteration: 475\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1904000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-45\n",
      "done: false\n",
      "episode_len_mean: 199.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.78\n",
      "episode_reward_min: 189.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10047\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23775775730609894\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003038709983229637\n",
      "        model: {}\n",
      "        policy_loss: 0.002227961551398039\n",
      "        total_loss: 3.278437852859497\n",
      "        vf_explained_var: 0.01304272748529911\n",
      "        vf_loss: 3.276209592819214\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1904000\n",
      "  num_agent_steps_trained: 1904000\n",
      "  num_steps_sampled: 1904000\n",
      "  num_steps_trained: 1904000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 476\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.07272727272727\n",
      "  ram_util_percent: 85.73636363636365\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0683370649119333\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0785011839812996\n",
      "  mean_inference_ms: 0.7497051972482712\n",
      "  mean_raw_obs_processing_ms: 0.090799539907478\n",
      "time_since_restore: 3391.0313160419464\n",
      "time_this_iter_s: 7.452976942062378\n",
      "time_total_s: 3391.0313160419464\n",
      "timers:\n",
      "  learn_throughput: 1312.66\n",
      "  learn_time_ms: 3047.247\n",
      "  load_throughput: 22259806.289\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 579.419\n",
      "  sample_time_ms: 6903.467\n",
      "  update_time_ms: 2.179\n",
      "timestamp: 1658397345\n",
      "timesteps_since_restore: 1904000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1904000\n",
      "training_iteration: 476\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1908000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-51\n",
      "done: false\n",
      "episode_len_mean: 198.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.17\n",
      "episode_reward_min: 95.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 10068\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2649928629398346\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003946555778384209\n",
      "        model: {}\n",
      "        policy_loss: 0.002820504829287529\n",
      "        total_loss: 4.513910293579102\n",
      "        vf_explained_var: 4.506431650952436e-06\n",
      "        vf_loss: 4.51108980178833\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1908000\n",
      "  num_agent_steps_trained: 1908000\n",
      "  num_steps_sampled: 1908000\n",
      "  num_steps_trained: 1908000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 477\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.48888888888889\n",
      "  ram_util_percent: 85.69999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06833152788795555\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07849453784933969\n",
      "  mean_inference_ms: 0.7496493424754065\n",
      "  mean_raw_obs_processing_ms: 0.09079213538733366\n",
      "time_since_restore: 3397.6690475940704\n",
      "time_this_iter_s: 6.637731552124023\n",
      "time_total_s: 3397.6690475940704\n",
      "timers:\n",
      "  learn_throughput: 1312.476\n",
      "  learn_time_ms: 3047.675\n",
      "  load_throughput: 22860356.997\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 575.711\n",
      "  sample_time_ms: 6947.933\n",
      "  update_time_ms: 2.208\n",
      "timestamp: 1658397351\n",
      "timesteps_since_restore: 1908000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1908000\n",
      "training_iteration: 477\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1912000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-55-59\n",
      "done: false\n",
      "episode_len_mean: 197.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.41\n",
      "episode_reward_min: 95.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10088\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27212679386138916\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004724384751170874\n",
      "        model: {}\n",
      "        policy_loss: -0.002198585541918874\n",
      "        total_loss: 1.6233065128326416\n",
      "        vf_explained_var: -0.06363637000322342\n",
      "        vf_loss: 1.625504970550537\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1912000\n",
      "  num_agent_steps_trained: 1912000\n",
      "  num_steps_sampled: 1912000\n",
      "  num_steps_trained: 1912000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 478\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.33636363636364\n",
      "  ram_util_percent: 85.70909090909092\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06832660773926481\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07848869504025942\n",
      "  mean_inference_ms: 0.7495972355092636\n",
      "  mean_raw_obs_processing_ms: 0.09078543057919798\n",
      "time_since_restore: 3404.849156856537\n",
      "time_this_iter_s: 7.180109262466431\n",
      "time_total_s: 3404.849156856537\n",
      "timers:\n",
      "  learn_throughput: 1296.995\n",
      "  learn_time_ms: 3084.052\n",
      "  load_throughput: 22638262.043\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 574.8\n",
      "  sample_time_ms: 6958.944\n",
      "  update_time_ms: 2.117\n",
      "timestamp: 1658397359\n",
      "timesteps_since_restore: 1912000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1912000\n",
      "training_iteration: 478\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1916000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-56-06\n",
      "done: false\n",
      "episode_len_mean: 196.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.94\n",
      "episode_reward_min: 95.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 10109\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2779250144958496\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004540469963103533\n",
      "        model: {}\n",
      "        policy_loss: 0.0019991695880889893\n",
      "        total_loss: 6.25200891494751\n",
      "        vf_explained_var: -0.04705597087740898\n",
      "        vf_loss: 6.250009536743164\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1916000\n",
      "  num_agent_steps_trained: 1916000\n",
      "  num_steps_sampled: 1916000\n",
      "  num_steps_trained: 1916000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 479\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.45555555555555\n",
      "  ram_util_percent: 85.57777777777777\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06832212778914125\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07848362529907978\n",
      "  mean_inference_ms: 0.749555963101073\n",
      "  mean_raw_obs_processing_ms: 0.09077973527802527\n",
      "time_since_restore: 3411.7025401592255\n",
      "time_this_iter_s: 6.853383302688599\n",
      "time_total_s: 3411.7025401592255\n",
      "timers:\n",
      "  learn_throughput: 1303.773\n",
      "  learn_time_ms: 3068.02\n",
      "  load_throughput: 23507378.45\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 570.66\n",
      "  sample_time_ms: 7009.422\n",
      "  update_time_ms: 2.128\n",
      "timestamp: 1658397366\n",
      "timesteps_since_restore: 1916000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1916000\n",
      "training_iteration: 479\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1920000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-56-12\n",
      "done: false\n",
      "episode_len_mean: 197.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.05\n",
      "episode_reward_min: 95.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10129\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22682757675647736\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003464542096480727\n",
      "        model: {}\n",
      "        policy_loss: 0.0073534282855689526\n",
      "        total_loss: 8.570860862731934\n",
      "        vf_explained_var: 7.189089501480339e-07\n",
      "        vf_loss: 8.563508033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1920000\n",
      "  num_agent_steps_trained: 1920000\n",
      "  num_steps_sampled: 1920000\n",
      "  num_steps_trained: 1920000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 480\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.62\n",
      "  ram_util_percent: 85.61000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06831734146372417\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07847840330009323\n",
      "  mean_inference_ms: 0.749531451365075\n",
      "  mean_raw_obs_processing_ms: 0.09077410477361413\n",
      "time_since_restore: 3418.598348379135\n",
      "time_this_iter_s: 6.895808219909668\n",
      "time_total_s: 3418.598348379135\n",
      "timers:\n",
      "  learn_throughput: 1319.802\n",
      "  learn_time_ms: 3030.758\n",
      "  load_throughput: 23736864.743\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 571.268\n",
      "  sample_time_ms: 7001.964\n",
      "  update_time_ms: 1.988\n",
      "timestamp: 1658397372\n",
      "timesteps_since_restore: 1920000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1920000\n",
      "training_iteration: 480\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1924000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-56-19\n",
      "done: false\n",
      "episode_len_mean: 197.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.05\n",
      "episode_reward_min: 95.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10149\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23547229170799255\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030953926034271717\n",
      "        model: {}\n",
      "        policy_loss: 0.007680474780499935\n",
      "        total_loss: 8.571187973022461\n",
      "        vf_explained_var: -2.087444386233983e-07\n",
      "        vf_loss: 8.563508033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1924000\n",
      "  num_agent_steps_trained: 1924000\n",
      "  num_steps_sampled: 1924000\n",
      "  num_steps_trained: 1924000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 481\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.589999999999996\n",
      "  ram_util_percent: 85.56000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06831293805885591\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07847368947745621\n",
      "  mean_inference_ms: 0.7495108334265314\n",
      "  mean_raw_obs_processing_ms: 0.09076898273554886\n",
      "time_since_restore: 3425.6272599697113\n",
      "time_this_iter_s: 7.028911590576172\n",
      "time_total_s: 3425.6272599697113\n",
      "timers:\n",
      "  learn_throughput: 1322.693\n",
      "  learn_time_ms: 3024.133\n",
      "  load_throughput: 22653545.774\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 573.351\n",
      "  sample_time_ms: 6976.524\n",
      "  update_time_ms: 2.033\n",
      "timestamp: 1658397379\n",
      "timesteps_since_restore: 1924000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1924000\n",
      "training_iteration: 481\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1928000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-56-27\n",
      "done: false\n",
      "episode_len_mean: 198.77\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.77\n",
      "episode_reward_min: 135.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10169\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2620527446269989\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002733886707574129\n",
      "        model: {}\n",
      "        policy_loss: 0.00854058563709259\n",
      "        total_loss: 8.572049140930176\n",
      "        vf_explained_var: 1.682389125789996e-07\n",
      "        vf_loss: 8.563508033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1928000\n",
      "  num_agent_steps_trained: 1928000\n",
      "  num_steps_sampled: 1928000\n",
      "  num_steps_trained: 1928000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 482\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.279999999999994\n",
      "  ram_util_percent: 85.62\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06831172778433528\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07847253019158533\n",
      "  mean_inference_ms: 0.7495269791893117\n",
      "  mean_raw_obs_processing_ms: 0.09076724371688866\n",
      "time_since_restore: 3432.7459473609924\n",
      "time_this_iter_s: 7.118687391281128\n",
      "time_total_s: 3432.7459473609924\n",
      "timers:\n",
      "  learn_throughput: 1327.165\n",
      "  learn_time_ms: 3013.944\n",
      "  load_throughput: 22619948.766\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 571.702\n",
      "  sample_time_ms: 6996.647\n",
      "  update_time_ms: 2.053\n",
      "timestamp: 1658397387\n",
      "timesteps_since_restore: 1928000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1928000\n",
      "training_iteration: 482\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1932000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-56-34\n",
      "done: false\n",
      "episode_len_mean: 199.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.53\n",
      "episode_reward_min: 166.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10189\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24075819551944733\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0016280997078865767\n",
      "        model: {}\n",
      "        policy_loss: 0.008509866893291473\n",
      "        total_loss: 8.572017669677734\n",
      "        vf_explained_var: -3.3058145731956756e-07\n",
      "        vf_loss: 8.563508033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1932000\n",
      "  num_agent_steps_trained: 1932000\n",
      "  num_steps_sampled: 1932000\n",
      "  num_steps_trained: 1932000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 483\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.336363636363636\n",
      "  ram_util_percent: 85.65454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06831347442654452\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07847437601862028\n",
      "  mean_inference_ms: 0.7495749002199426\n",
      "  mean_raw_obs_processing_ms: 0.0907696224357575\n",
      "time_since_restore: 3440.004390478134\n",
      "time_this_iter_s: 7.258443117141724\n",
      "time_total_s: 3440.004390478134\n",
      "timers:\n",
      "  learn_throughput: 1333.144\n",
      "  learn_time_ms: 3000.426\n",
      "  load_throughput: 22209711.411\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 569.092\n",
      "  sample_time_ms: 7028.741\n",
      "  update_time_ms: 2.061\n",
      "timestamp: 1658397394\n",
      "timesteps_since_restore: 1932000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1932000\n",
      "training_iteration: 483\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1936000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-56-42\n",
      "done: false\n",
      "episode_len_mean: 199.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.7\n",
      "episode_reward_min: 170.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10209\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2632632851600647\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003862095298245549\n",
      "        model: {}\n",
      "        policy_loss: 0.005236539989709854\n",
      "        total_loss: 7.2129011154174805\n",
      "        vf_explained_var: 1.5792667227287893e-06\n",
      "        vf_loss: 7.207664489746094\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1936000\n",
      "  num_agent_steps_trained: 1936000\n",
      "  num_steps_sampled: 1936000\n",
      "  num_steps_trained: 1936000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 484\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.91818181818182\n",
      "  ram_util_percent: 86.00909090909092\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0683196194996892\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07848106990624835\n",
      "  mean_inference_ms: 0.7496651878050149\n",
      "  mean_raw_obs_processing_ms: 0.09077729873286025\n",
      "time_since_restore: 3447.6479449272156\n",
      "time_this_iter_s: 7.643554449081421\n",
      "time_total_s: 3447.6479449272156\n",
      "timers:\n",
      "  learn_throughput: 1323.62\n",
      "  learn_time_ms: 3022.015\n",
      "  load_throughput: 22414450.234\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 564.462\n",
      "  sample_time_ms: 7086.392\n",
      "  update_time_ms: 2.073\n",
      "timestamp: 1658397402\n",
      "timesteps_since_restore: 1936000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1936000\n",
      "training_iteration: 484\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1940000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-56-50\n",
      "done: false\n",
      "episode_len_mean: 197.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.93\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 10230\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2661929130554199\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004454983863979578\n",
      "        model: {}\n",
      "        policy_loss: 0.0043604401871562\n",
      "        total_loss: 6.793676376342773\n",
      "        vf_explained_var: -0.03223593160510063\n",
      "        vf_loss: 6.789316654205322\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1940000\n",
      "  num_agent_steps_trained: 1940000\n",
      "  num_steps_sampled: 1940000\n",
      "  num_steps_trained: 1940000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 485\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.05833333333334\n",
      "  ram_util_percent: 85.75000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06833884437920489\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07850244422143957\n",
      "  mean_inference_ms: 0.7498719119081898\n",
      "  mean_raw_obs_processing_ms: 0.0908013482635303\n",
      "time_since_restore: 3456.0972969532013\n",
      "time_this_iter_s: 8.449352025985718\n",
      "time_total_s: 3456.0972969532013\n",
      "timers:\n",
      "  learn_throughput: 1321.711\n",
      "  learn_time_ms: 3026.379\n",
      "  load_throughput: 22447439.122\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 550.39\n",
      "  sample_time_ms: 7267.568\n",
      "  update_time_ms: 2.087\n",
      "timestamp: 1658397410\n",
      "timesteps_since_restore: 1940000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1940000\n",
      "training_iteration: 485\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1944000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-56-57\n",
      "done: false\n",
      "episode_len_mean: 197.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.93\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10250\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2589185833930969\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003984412644058466\n",
      "        model: {}\n",
      "        policy_loss: 0.008065395057201385\n",
      "        total_loss: 8.223791122436523\n",
      "        vf_explained_var: 5.056140253145713e-07\n",
      "        vf_loss: 8.215725898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1944000\n",
      "  num_agent_steps_trained: 1944000\n",
      "  num_steps_sampled: 1944000\n",
      "  num_steps_trained: 1944000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 486\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.099999999999994\n",
      "  ram_util_percent: 85.85555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0683555930078787\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07852086722319049\n",
      "  mean_inference_ms: 0.7500474161624837\n",
      "  mean_raw_obs_processing_ms: 0.09082169241908805\n",
      "time_since_restore: 3462.7422258853912\n",
      "time_this_iter_s: 6.644928932189941\n",
      "time_total_s: 3462.7422258853912\n",
      "timers:\n",
      "  learn_throughput: 1347.391\n",
      "  learn_time_ms: 2968.7\n",
      "  load_throughput: 22543961.301\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 551.864\n",
      "  sample_time_ms: 7248.166\n",
      "  update_time_ms: 2.105\n",
      "timestamp: 1658397417\n",
      "timesteps_since_restore: 1944000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1944000\n",
      "training_iteration: 486\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1948000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-04\n",
      "done: false\n",
      "episode_len_mean: 197.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.93\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10270\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26986148953437805\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00293059553951025\n",
      "        model: {}\n",
      "        policy_loss: 0.009411916136741638\n",
      "        total_loss: 8.225137710571289\n",
      "        vf_explained_var: 8.2940181300728e-07\n",
      "        vf_loss: 8.215725898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1948000\n",
      "  num_agent_steps_trained: 1948000\n",
      "  num_steps_sampled: 1948000\n",
      "  num_steps_trained: 1948000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 487\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.11\n",
      "  ram_util_percent: 85.77000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06837018414605818\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07853678802999882\n",
      "  mean_inference_ms: 0.7501995256442254\n",
      "  mean_raw_obs_processing_ms: 0.09084010166566742\n",
      "time_since_restore: 3469.600410938263\n",
      "time_this_iter_s: 6.858185052871704\n",
      "time_total_s: 3469.600410938263\n",
      "timers:\n",
      "  learn_throughput: 1346.211\n",
      "  learn_time_ms: 2971.301\n",
      "  load_throughput: 22678042.714\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 554.749\n",
      "  sample_time_ms: 7210.469\n",
      "  update_time_ms: 2.081\n",
      "timestamp: 1658397424\n",
      "timesteps_since_restore: 1948000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1948000\n",
      "training_iteration: 487\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1952000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-10\n",
      "done: false\n",
      "episode_len_mean: 197.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.93\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10290\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24583473801612854\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00413556769490242\n",
      "        model: {}\n",
      "        policy_loss: 0.008642448112368584\n",
      "        total_loss: 8.224369049072266\n",
      "        vf_explained_var: 7.863967965704433e-08\n",
      "        vf_loss: 8.215726852416992\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1952000\n",
      "  num_agent_steps_trained: 1952000\n",
      "  num_steps_sampled: 1952000\n",
      "  num_steps_trained: 1952000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 488\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.51\n",
      "  ram_util_percent: 85.55\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06838116134279026\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07854905907431785\n",
      "  mean_inference_ms: 0.7503145404890543\n",
      "  mean_raw_obs_processing_ms: 0.09085316382097465\n",
      "time_since_restore: 3476.404811143875\n",
      "time_this_iter_s: 6.804400205612183\n",
      "time_total_s: 3476.404811143875\n",
      "timers:\n",
      "  learn_throughput: 1360.482\n",
      "  learn_time_ms: 2940.134\n",
      "  load_throughput: 22696450.216\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 555.066\n",
      "  sample_time_ms: 7206.356\n",
      "  update_time_ms: 2.126\n",
      "timestamp: 1658397430\n",
      "timesteps_since_restore: 1952000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1952000\n",
      "training_iteration: 488\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1956000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-17\n",
      "done: false\n",
      "episode_len_mean: 198.23\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.23\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10310\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2712331712245941\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004139518365263939\n",
      "        model: {}\n",
      "        policy_loss: 0.00861838087439537\n",
      "        total_loss: 8.224346160888672\n",
      "        vf_explained_var: 1.0142402970814146e-06\n",
      "        vf_loss: 8.215726852416992\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1956000\n",
      "  num_agent_steps_trained: 1956000\n",
      "  num_steps_sampled: 1956000\n",
      "  num_steps_trained: 1956000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 489\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.96666666666667\n",
      "  ram_util_percent: 85.57777777777777\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06838676309753909\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07855517107688646\n",
      "  mean_inference_ms: 0.7503719705974129\n",
      "  mean_raw_obs_processing_ms: 0.09085897618015304\n",
      "time_since_restore: 3483.0669956207275\n",
      "time_this_iter_s: 6.662184476852417\n",
      "time_total_s: 3483.0669956207275\n",
      "timers:\n",
      "  learn_throughput: 1363.068\n",
      "  learn_time_ms: 2934.556\n",
      "  load_throughput: 22501630.901\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 558.479\n",
      "  sample_time_ms: 7162.316\n",
      "  update_time_ms: 2.14\n",
      "timestamp: 1658397437\n",
      "timesteps_since_restore: 1956000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1956000\n",
      "training_iteration: 489\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1960000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-24\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10330\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2700430452823639\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003207867732271552\n",
      "        model: {}\n",
      "        policy_loss: 0.010227943770587444\n",
      "        total_loss: 8.225954055786133\n",
      "        vf_explained_var: 1.1380641353753163e-06\n",
      "        vf_loss: 8.215725898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1960000\n",
      "  num_agent_steps_trained: 1960000\n",
      "  num_steps_sampled: 1960000\n",
      "  num_steps_trained: 1960000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 490\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.980000000000004\n",
      "  ram_util_percent: 85.62\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06838045824806166\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07854764483183799\n",
      "  mean_inference_ms: 0.7503077211292214\n",
      "  mean_raw_obs_processing_ms: 0.0908495225929051\n",
      "time_since_restore: 3489.8008704185486\n",
      "time_this_iter_s: 6.733874797821045\n",
      "time_total_s: 3489.8008704185486\n",
      "timers:\n",
      "  learn_throughput: 1360.514\n",
      "  learn_time_ms: 2940.065\n",
      "  load_throughput: 22498613.383\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 560.635\n",
      "  sample_time_ms: 7134.762\n",
      "  update_time_ms: 2.134\n",
      "timestamp: 1658397444\n",
      "timesteps_since_restore: 1960000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1960000\n",
      "training_iteration: 490\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1964000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-31\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10350\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24415312707424164\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028314238879829645\n",
      "        model: {}\n",
      "        policy_loss: 0.008625791408121586\n",
      "        total_loss: 8.22435188293457\n",
      "        vf_explained_var: 4.1909115111593565e-07\n",
      "        vf_loss: 8.215725898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1964000\n",
      "  num_agent_steps_trained: 1964000\n",
      "  num_steps_sampled: 1964000\n",
      "  num_steps_trained: 1964000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 491\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.3\n",
      "  ram_util_percent: 85.47\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06837415993692983\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07854031783068936\n",
      "  mean_inference_ms: 0.7502523999487966\n",
      "  mean_raw_obs_processing_ms: 0.09084059697864434\n",
      "time_since_restore: 3496.516301393509\n",
      "time_this_iter_s: 6.715430974960327\n",
      "time_total_s: 3496.516301393509\n",
      "timers:\n",
      "  learn_throughput: 1367.298\n",
      "  learn_time_ms: 2925.478\n",
      "  load_throughput: 23609929.637\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 561.513\n",
      "  sample_time_ms: 7123.616\n",
      "  update_time_ms: 2.121\n",
      "timestamp: 1658397451\n",
      "timesteps_since_restore: 1964000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1964000\n",
      "training_iteration: 491\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1968000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-37\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10370\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2936294376850128\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005053400062024593\n",
      "        model: {}\n",
      "        policy_loss: 0.007610481232404709\n",
      "        total_loss: 8.223336219787598\n",
      "        vf_explained_var: 2.895119450840866e-06\n",
      "        vf_loss: 8.215725898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1968000\n",
      "  num_agent_steps_trained: 1968000\n",
      "  num_steps_sampled: 1968000\n",
      "  num_steps_trained: 1968000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 492\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.0\n",
      "  ram_util_percent: 85.46666666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06836698469268015\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07853211345428796\n",
      "  mean_inference_ms: 0.7501893993957788\n",
      "  mean_raw_obs_processing_ms: 0.0908299357391628\n",
      "time_since_restore: 3503.1631524562836\n",
      "time_this_iter_s: 6.646851062774658\n",
      "time_total_s: 3503.1631524562836\n",
      "timers:\n",
      "  learn_throughput: 1370.95\n",
      "  learn_time_ms: 2917.685\n",
      "  load_throughput: 23726793.947\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 565.807\n",
      "  sample_time_ms: 7069.554\n",
      "  update_time_ms: 2.115\n",
      "timestamp: 1658397457\n",
      "timesteps_since_restore: 1968000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1968000\n",
      "training_iteration: 492\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1972000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-44\n",
      "done: false\n",
      "episode_len_mean: 199.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.16\n",
      "episode_reward_min: 116.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10390\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24582627415657043\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030335679184645414\n",
      "        model: {}\n",
      "        policy_loss: 0.0033536723349243402\n",
      "        total_loss: 4.620290279388428\n",
      "        vf_explained_var: 9.276533887714322e-07\n",
      "        vf_loss: 4.616936683654785\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1972000\n",
      "  num_agent_steps_trained: 1972000\n",
      "  num_steps_sampled: 1972000\n",
      "  num_steps_trained: 1972000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 493\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.22\n",
      "  ram_util_percent: 85.54\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06836061307964512\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07852424503472655\n",
      "  mean_inference_ms: 0.7501295593593728\n",
      "  mean_raw_obs_processing_ms: 0.09081994522046118\n",
      "time_since_restore: 3509.9733951091766\n",
      "time_this_iter_s: 6.810242652893066\n",
      "time_total_s: 3509.9733951091766\n",
      "timers:\n",
      "  learn_throughput: 1371.868\n",
      "  learn_time_ms: 2915.732\n",
      "  load_throughput: 24318330.193\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 569.925\n",
      "  sample_time_ms: 7018.462\n",
      "  update_time_ms: 2.15\n",
      "timestamp: 1658397464\n",
      "timesteps_since_restore: 1972000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1972000\n",
      "training_iteration: 493\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1976000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-51\n",
      "done: false\n",
      "episode_len_mean: 199.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.16\n",
      "episode_reward_min: 116.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10410\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2405167818069458\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002987660700455308\n",
      "        model: {}\n",
      "        policy_loss: 0.003333059838041663\n",
      "        total_loss: 3.9851877689361572\n",
      "        vf_explained_var: 1.191451929116738e-06\n",
      "        vf_loss: 3.9818549156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1976000\n",
      "  num_agent_steps_trained: 1976000\n",
      "  num_steps_sampled: 1976000\n",
      "  num_steps_trained: 1976000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 494\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.38\n",
      "  ram_util_percent: 85.55\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06835509180489474\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0785175239665627\n",
      "  mean_inference_ms: 0.7500825145212815\n",
      "  mean_raw_obs_processing_ms: 0.0908113269300534\n",
      "time_since_restore: 3517.0135946273804\n",
      "time_this_iter_s: 7.040199518203735\n",
      "time_total_s: 3517.0135946273804\n",
      "timers:\n",
      "  learn_throughput: 1375.025\n",
      "  learn_time_ms: 2909.038\n",
      "  load_throughput: 24625298.694\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 574.457\n",
      "  sample_time_ms: 6963.098\n",
      "  update_time_ms: 2.12\n",
      "timestamp: 1658397471\n",
      "timesteps_since_restore: 1976000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1976000\n",
      "training_iteration: 494\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1980000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-57-58\n",
      "done: false\n",
      "episode_len_mean: 199.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.16\n",
      "episode_reward_min: 116.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10430\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2683091163635254\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034916906151920557\n",
      "        model: {}\n",
      "        policy_loss: 0.0013164804549887776\n",
      "        total_loss: 3.9831717014312744\n",
      "        vf_explained_var: 4.173606953372655e-07\n",
      "        vf_loss: 3.9818551540374756\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1980000\n",
      "  num_agent_steps_trained: 1980000\n",
      "  num_steps_sampled: 1980000\n",
      "  num_steps_trained: 1980000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 495\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.56363636363636\n",
      "  ram_util_percent: 85.48181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06835072777537854\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07851229437695187\n",
      "  mean_inference_ms: 0.7500458097871251\n",
      "  mean_raw_obs_processing_ms: 0.09080423359508631\n",
      "time_since_restore: 3524.339776992798\n",
      "time_this_iter_s: 7.3261823654174805\n",
      "time_total_s: 3524.339776992798\n",
      "timers:\n",
      "  learn_throughput: 1356.278\n",
      "  learn_time_ms: 2949.247\n",
      "  load_throughput: 24825711.749\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 587.871\n",
      "  sample_time_ms: 6804.217\n",
      "  update_time_ms: 2.123\n",
      "timestamp: 1658397478\n",
      "timesteps_since_restore: 1980000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1980000\n",
      "training_iteration: 495\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1984000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-58-05\n",
      "done: false\n",
      "episode_len_mean: 199.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.16\n",
      "episode_reward_min: 116.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10450\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27596351504325867\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034481894690543413\n",
      "        model: {}\n",
      "        policy_loss: 0.0033885727170854807\n",
      "        total_loss: 3.9852445125579834\n",
      "        vf_explained_var: 8.838151188683696e-08\n",
      "        vf_loss: 3.981855869293213\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1984000\n",
      "  num_agent_steps_trained: 1984000\n",
      "  num_steps_sampled: 1984000\n",
      "  num_steps_trained: 1984000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 496\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.24444444444444\n",
      "  ram_util_percent: 85.53333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06834760952441284\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07850859083969099\n",
      "  mean_inference_ms: 0.7500224178799801\n",
      "  mean_raw_obs_processing_ms: 0.09079888972181635\n",
      "time_since_restore: 3531.309135913849\n",
      "time_this_iter_s: 6.969358921051025\n",
      "time_total_s: 3531.309135913849\n",
      "timers:\n",
      "  learn_throughput: 1353.7\n",
      "  learn_time_ms: 2954.864\n",
      "  load_throughput: 24869872.517\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 582.126\n",
      "  sample_time_ms: 6871.36\n",
      "  update_time_ms: 2.132\n",
      "timestamp: 1658397485\n",
      "timesteps_since_restore: 1984000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1984000\n",
      "training_iteration: 496\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1988000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-58-12\n",
      "done: false\n",
      "episode_len_mean: 199.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.16\n",
      "episode_reward_min: 116.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10470\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2517867684364319\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003924434073269367\n",
      "        model: {}\n",
      "        policy_loss: 0.0027030145283788443\n",
      "        total_loss: 3.984557628631592\n",
      "        vf_explained_var: 7.74732200170547e-07\n",
      "        vf_loss: 3.9818549156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1988000\n",
      "  num_agent_steps_trained: 1988000\n",
      "  num_steps_sampled: 1988000\n",
      "  num_steps_trained: 1988000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 497\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.739999999999995\n",
      "  ram_util_percent: 85.55999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06834571867974434\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07850605771237835\n",
      "  mean_inference_ms: 0.7500112344775683\n",
      "  mean_raw_obs_processing_ms: 0.09079506006576019\n",
      "time_since_restore: 3538.133847475052\n",
      "time_this_iter_s: 6.824711561203003\n",
      "time_total_s: 3538.133847475052\n",
      "timers:\n",
      "  learn_throughput: 1357.354\n",
      "  learn_time_ms: 2946.909\n",
      "  load_throughput: 24556814.988\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 581.243\n",
      "  sample_time_ms: 6881.805\n",
      "  update_time_ms: 2.128\n",
      "timestamp: 1658397492\n",
      "timesteps_since_restore: 1988000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1988000\n",
      "training_iteration: 497\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1992000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-58-19\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10490\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2406342476606369\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003994866739958525\n",
      "        model: {}\n",
      "        policy_loss: 0.0032820948399603367\n",
      "        total_loss: 3.985137939453125\n",
      "        vf_explained_var: -6.088646387070185e-08\n",
      "        vf_loss: 3.981855630874634\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1992000\n",
      "  num_agent_steps_trained: 1992000\n",
      "  num_steps_sampled: 1992000\n",
      "  num_steps_trained: 1992000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 498\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.95\n",
      "  ram_util_percent: 85.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06834266474326764\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07850253522348295\n",
      "  mean_inference_ms: 0.7499927530172479\n",
      "  mean_raw_obs_processing_ms: 0.09079080266492146\n",
      "time_since_restore: 3544.791700363159\n",
      "time_this_iter_s: 6.6578528881073\n",
      "time_total_s: 3544.791700363159\n",
      "timers:\n",
      "  learn_throughput: 1361.535\n",
      "  learn_time_ms: 2937.86\n",
      "  load_throughput: 24463715.369\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 582.359\n",
      "  sample_time_ms: 6868.612\n",
      "  update_time_ms: 2.094\n",
      "timestamp: 1658397499\n",
      "timesteps_since_restore: 1992000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1992000\n",
      "training_iteration: 498\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 1996000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-58-26\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10510\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.261240154504776\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004085936117917299\n",
      "        model: {}\n",
      "        policy_loss: 0.0036457874812185764\n",
      "        total_loss: 3.9855010509490967\n",
      "        vf_explained_var: -3.6076832543585624e-07\n",
      "        vf_loss: 3.9818551540374756\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 1996000\n",
      "  num_agent_steps_trained: 1996000\n",
      "  num_steps_sampled: 1996000\n",
      "  num_steps_trained: 1996000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 499\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.33\n",
      "  ram_util_percent: 85.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06833894858247731\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07849809136314423\n",
      "  mean_inference_ms: 0.7499669468937953\n",
      "  mean_raw_obs_processing_ms: 0.09078544436581401\n",
      "time_since_restore: 3551.7293906211853\n",
      "time_this_iter_s: 6.937690258026123\n",
      "time_total_s: 3551.7293906211853\n",
      "timers:\n",
      "  learn_throughput: 1351.4\n",
      "  learn_time_ms: 2959.894\n",
      "  load_throughput: 24803690.124\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 582.694\n",
      "  sample_time_ms: 6864.666\n",
      "  update_time_ms: 2.077\n",
      "timestamp: 1658397506\n",
      "timesteps_since_restore: 1996000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 1996000\n",
      "training_iteration: 499\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2000000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-58-33\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10530\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2664239704608917\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005606515798717737\n",
      "        model: {}\n",
      "        policy_loss: 0.0008366277907043695\n",
      "        total_loss: 3.982691764831543\n",
      "        vf_explained_var: -2.260490106209545e-07\n",
      "        vf_loss: 3.9818551540374756\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2000000\n",
      "  num_agent_steps_trained: 2000000\n",
      "  num_steps_sampled: 2000000\n",
      "  num_steps_trained: 2000000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 500\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.33\n",
      "  ram_util_percent: 85.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06833514259075686\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07849354064381768\n",
      "  mean_inference_ms: 0.7499451040020563\n",
      "  mean_raw_obs_processing_ms: 0.09078032886266751\n",
      "time_since_restore: 3558.7591869831085\n",
      "time_this_iter_s: 7.029796361923218\n",
      "time_total_s: 3558.7591869831085\n",
      "timers:\n",
      "  learn_throughput: 1346.221\n",
      "  learn_time_ms: 2971.281\n",
      "  load_throughput: 24643384.254\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 579.275\n",
      "  sample_time_ms: 6905.186\n",
      "  update_time_ms: 2.059\n",
      "timestamp: 1658397513\n",
      "timesteps_since_restore: 2000000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2000000\n",
      "training_iteration: 500\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2004000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-58-40\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10550\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2715608477592468\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035361337941139936\n",
      "        model: {}\n",
      "        policy_loss: 0.0031846510246396065\n",
      "        total_loss: 3.9850406646728516\n",
      "        vf_explained_var: -3.3314509551019e-07\n",
      "        vf_loss: 3.981856107711792\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2004000\n",
      "  num_agent_steps_trained: 2004000\n",
      "  num_steps_sampled: 2004000\n",
      "  num_steps_trained: 2004000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 501\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.4\n",
      "  ram_util_percent: 85.54444444444444\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06832997441164874\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07848736097504902\n",
      "  mean_inference_ms: 0.7499041629152109\n",
      "  mean_raw_obs_processing_ms: 0.09077354809620335\n",
      "time_since_restore: 3565.4844386577606\n",
      "time_this_iter_s: 6.7252516746521\n",
      "time_total_s: 3565.4844386577606\n",
      "timers:\n",
      "  learn_throughput: 1342.863\n",
      "  learn_time_ms: 2978.711\n",
      "  load_throughput: 24618071.9\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 578.867\n",
      "  sample_time_ms: 6910.053\n",
      "  update_time_ms: 2.048\n",
      "timestamp: 1658397520\n",
      "timesteps_since_restore: 2004000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2004000\n",
      "training_iteration: 501\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000501/checkpoint-501\n",
      "agent_timesteps_total: 2008000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-58-47\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10570\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.279653936624527\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002977586118504405\n",
      "        model: {}\n",
      "        policy_loss: 0.003239753656089306\n",
      "        total_loss: 3.985095262527466\n",
      "        vf_explained_var: 3.375673713890137e-07\n",
      "        vf_loss: 3.981855630874634\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2008000\n",
      "  num_agent_steps_trained: 2008000\n",
      "  num_steps_sampled: 2008000\n",
      "  num_steps_trained: 2008000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 502\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.519999999999996\n",
      "  ram_util_percent: 85.71\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06832469484645592\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07848132684697645\n",
      "  mean_inference_ms: 0.7498599226345906\n",
      "  mean_raw_obs_processing_ms: 0.09076656054841793\n",
      "time_since_restore: 3572.307343006134\n",
      "time_this_iter_s: 6.822904348373413\n",
      "time_total_s: 3572.307343006134\n",
      "timers:\n",
      "  learn_throughput: 1340.322\n",
      "  learn_time_ms: 2984.357\n",
      "  load_throughput: 24343029.6\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 577.195\n",
      "  sample_time_ms: 6930.072\n",
      "  update_time_ms: 2.048\n",
      "timestamp: 1658397527\n",
      "timesteps_since_restore: 2008000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2008000\n",
      "training_iteration: 502\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2012000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-58-54\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10590\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2919829189777374\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002706862986087799\n",
      "        model: {}\n",
      "        policy_loss: 0.0035907647106796503\n",
      "        total_loss: 3.985445499420166\n",
      "        vf_explained_var: 1.2491338452491618e-07\n",
      "        vf_loss: 3.9818549156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2012000\n",
      "  num_agent_steps_trained: 2012000\n",
      "  num_steps_sampled: 2012000\n",
      "  num_steps_trained: 2012000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 503\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.089999999999996\n",
      "  ram_util_percent: 85.67\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06832123749048213\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07847752304036242\n",
      "  mean_inference_ms: 0.7498349536888091\n",
      "  mean_raw_obs_processing_ms: 0.09076172415016473\n",
      "time_since_restore: 3579.259222984314\n",
      "time_this_iter_s: 6.951879978179932\n",
      "time_total_s: 3579.259222984314\n",
      "timers:\n",
      "  learn_throughput: 1341.09\n",
      "  learn_time_ms: 2982.649\n",
      "  load_throughput: 24192092.286\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 575.393\n",
      "  sample_time_ms: 6951.775\n",
      "  update_time_ms: 2.026\n",
      "timestamp: 1658397534\n",
      "timesteps_since_restore: 2012000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2012000\n",
      "training_iteration: 503\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2016000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-00\n",
      "done: false\n",
      "episode_len_mean: 199.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.01\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 10611\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.299164354801178\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0042783101089298725\n",
      "        model: {}\n",
      "        policy_loss: -0.0017344490624964237\n",
      "        total_loss: 8.277017593383789\n",
      "        vf_explained_var: 6.981434239605733e-07\n",
      "        vf_loss: 8.278752326965332\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2016000\n",
      "  num_agent_steps_trained: 2016000\n",
      "  num_steps_sampled: 2016000\n",
      "  num_steps_trained: 2016000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 504\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.49\n",
      "  ram_util_percent: 85.72999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06831701559654364\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0784727870115569\n",
      "  mean_inference_ms: 0.7497989762141877\n",
      "  mean_raw_obs_processing_ms: 0.09075617289451621\n",
      "time_since_restore: 3585.938782453537\n",
      "time_this_iter_s: 6.6795594692230225\n",
      "time_total_s: 3585.938782453537\n",
      "timers:\n",
      "  learn_throughput: 1347.653\n",
      "  learn_time_ms: 2968.123\n",
      "  load_throughput: 24206053.96\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 577.299\n",
      "  sample_time_ms: 6928.821\n",
      "  update_time_ms: 2.006\n",
      "timestamp: 1658397540\n",
      "timesteps_since_restore: 2016000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2016000\n",
      "training_iteration: 504\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2020000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-08\n",
      "done: false\n",
      "episode_len_mean: 199.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.01\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10631\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28504982590675354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005279196426272392\n",
      "        model: {}\n",
      "        policy_loss: -0.0017505214782431722\n",
      "        total_loss: 9.04058837890625\n",
      "        vf_explained_var: -6.978229976084549e-07\n",
      "        vf_loss: 9.042338371276855\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2020000\n",
      "  num_agent_steps_trained: 2020000\n",
      "  num_steps_sampled: 2020000\n",
      "  num_steps_trained: 2020000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 505\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.910000000000004\n",
      "  ram_util_percent: 85.68\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06831485167073541\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0784707760482534\n",
      "  mean_inference_ms: 0.7497865939415701\n",
      "  mean_raw_obs_processing_ms: 0.09075295734015594\n",
      "time_since_restore: 3593.167113304138\n",
      "time_this_iter_s: 7.228330850601196\n",
      "time_total_s: 3593.167113304138\n",
      "timers:\n",
      "  learn_throughput: 1366.587\n",
      "  learn_time_ms: 2926.999\n",
      "  load_throughput: 24146827.864\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 576.021\n",
      "  sample_time_ms: 6944.197\n",
      "  update_time_ms: 1.973\n",
      "timestamp: 1658397548\n",
      "timesteps_since_restore: 2020000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2020000\n",
      "training_iteration: 505\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2024000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-14\n",
      "done: false\n",
      "episode_len_mean: 197.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.7\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10651\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2710832357406616\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00295285158790648\n",
      "        model: {}\n",
      "        policy_loss: 0.004183863755315542\n",
      "        total_loss: 5.729990482330322\n",
      "        vf_explained_var: -0.013383622281253338\n",
      "        vf_loss: 5.72580623626709\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2024000\n",
      "  num_agent_steps_trained: 2024000\n",
      "  num_steps_sampled: 2024000\n",
      "  num_steps_trained: 2024000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 506\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.910000000000004\n",
      "  ram_util_percent: 85.70000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06831357772214945\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07846979835614704\n",
      "  mean_inference_ms: 0.7497815082093539\n",
      "  mean_raw_obs_processing_ms: 0.09075052053485351\n",
      "time_since_restore: 3599.941819667816\n",
      "time_this_iter_s: 6.7747063636779785\n",
      "time_total_s: 3599.941819667816\n",
      "timers:\n",
      "  learn_throughput: 1369.463\n",
      "  learn_time_ms: 2920.852\n",
      "  load_throughput: 23926434.683\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 580.59\n",
      "  sample_time_ms: 6889.541\n",
      "  update_time_ms: 2.021\n",
      "timestamp: 1658397554\n",
      "timesteps_since_restore: 2024000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2024000\n",
      "training_iteration: 506\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2028000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-21\n",
      "done: false\n",
      "episode_len_mean: 197.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.7\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10671\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2774733603000641\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031397645361721516\n",
      "        model: {}\n",
      "        policy_loss: 0.0015590109396725893\n",
      "        total_loss: 2.4713170528411865\n",
      "        vf_explained_var: -0.0003027376369573176\n",
      "        vf_loss: 2.4697580337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2028000\n",
      "  num_agent_steps_trained: 2028000\n",
      "  num_steps_sampled: 2028000\n",
      "  num_steps_trained: 2028000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 507\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.05555555555556\n",
      "  ram_util_percent: 85.63333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06831127808070786\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07846755828713946\n",
      "  mean_inference_ms: 0.7497634564464064\n",
      "  mean_raw_obs_processing_ms: 0.09074691326393626\n",
      "time_since_restore: 3606.7846245765686\n",
      "time_this_iter_s: 6.842804908752441\n",
      "time_total_s: 3606.7846245765686\n",
      "timers:\n",
      "  learn_throughput: 1359.335\n",
      "  learn_time_ms: 2942.616\n",
      "  load_throughput: 24339498.041\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 582.797\n",
      "  sample_time_ms: 6863.454\n",
      "  update_time_ms: 2.0\n",
      "timestamp: 1658397561\n",
      "timesteps_since_restore: 2028000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2028000\n",
      "training_iteration: 507\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2032000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-28\n",
      "done: false\n",
      "episode_len_mean: 197.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.7\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10691\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2734448313713074\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003452498000115156\n",
      "        model: {}\n",
      "        policy_loss: 0.0010187576990574598\n",
      "        total_loss: 2.4707767963409424\n",
      "        vf_explained_var: -0.004100649617612362\n",
      "        vf_loss: 2.4697580337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2032000\n",
      "  num_agent_steps_trained: 2032000\n",
      "  num_steps_sampled: 2032000\n",
      "  num_steps_trained: 2032000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 508\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.45\n",
      "  ram_util_percent: 85.66000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06830775107901019\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07846390566495931\n",
      "  mean_inference_ms: 0.7497326121737309\n",
      "  mean_raw_obs_processing_ms: 0.09074147724436762\n",
      "time_since_restore: 3613.608686208725\n",
      "time_this_iter_s: 6.824061632156372\n",
      "time_total_s: 3613.608686208725\n",
      "timers:\n",
      "  learn_throughput: 1354.413\n",
      "  learn_time_ms: 2953.308\n",
      "  load_throughput: 24553221.133\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 580.463\n",
      "  sample_time_ms: 6891.053\n",
      "  update_time_ms: 1.958\n",
      "timestamp: 1658397568\n",
      "timesteps_since_restore: 2032000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2032000\n",
      "training_iteration: 508\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2036000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-35\n",
      "done: false\n",
      "episode_len_mean: 197.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.9\n",
      "episode_reward_min: 121.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 10712\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27326521277427673\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026582484133541584\n",
      "        model: {}\n",
      "        policy_loss: 0.004173931200057268\n",
      "        total_loss: 6.738062858581543\n",
      "        vf_explained_var: -0.03225782513618469\n",
      "        vf_loss: 6.733888626098633\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2036000\n",
      "  num_agent_steps_trained: 2036000\n",
      "  num_steps_sampled: 2036000\n",
      "  num_steps_trained: 2036000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 509\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.68\n",
      "  ram_util_percent: 85.67000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06830424421454925\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07846037710249694\n",
      "  mean_inference_ms: 0.7497041859611303\n",
      "  mean_raw_obs_processing_ms: 0.09073597369562192\n",
      "time_since_restore: 3620.4603867530823\n",
      "time_this_iter_s: 6.8517005443573\n",
      "time_total_s: 3620.4603867530823\n",
      "timers:\n",
      "  learn_throughput: 1356.555\n",
      "  learn_time_ms: 2948.645\n",
      "  load_throughput: 23402449.435\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 579.916\n",
      "  sample_time_ms: 6897.551\n",
      "  update_time_ms: 2.014\n",
      "timestamp: 1658397575\n",
      "timesteps_since_restore: 2036000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2036000\n",
      "training_iteration: 509\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2040000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-42\n",
      "done: false\n",
      "episode_len_mean: 198.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.45\n",
      "episode_reward_min: 121.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10732\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3098403811454773\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025637985672801733\n",
      "        model: {}\n",
      "        policy_loss: 0.007125557400286198\n",
      "        total_loss: 8.570633888244629\n",
      "        vf_explained_var: 4.02491586726228e-08\n",
      "        vf_loss: 8.563508033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2040000\n",
      "  num_agent_steps_trained: 2040000\n",
      "  num_steps_sampled: 2040000\n",
      "  num_steps_trained: 2040000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 510\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.760000000000005\n",
      "  ram_util_percent: 85.62\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06830071672778437\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07845603202290756\n",
      "  mean_inference_ms: 0.7496656223854464\n",
      "  mean_raw_obs_processing_ms: 0.0907301261327338\n",
      "time_since_restore: 3627.4703238010406\n",
      "time_this_iter_s: 7.009937047958374\n",
      "time_total_s: 3627.4703238010406\n",
      "timers:\n",
      "  learn_throughput: 1363.134\n",
      "  learn_time_ms: 2934.414\n",
      "  load_throughput: 23137796.166\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 579.189\n",
      "  sample_time_ms: 6906.206\n",
      "  update_time_ms: 2.084\n",
      "timestamp: 1658397582\n",
      "timesteps_since_restore: 2040000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2040000\n",
      "training_iteration: 510\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2044000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-49\n",
      "done: false\n",
      "episode_len_mean: 199.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.1\n",
      "episode_reward_min: 121.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10752\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2984258234500885\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002396233379840851\n",
      "        model: {}\n",
      "        policy_loss: 0.00818268395960331\n",
      "        total_loss: 8.18862533569336\n",
      "        vf_explained_var: 1.3365540780796437e-06\n",
      "        vf_loss: 8.18044376373291\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2044000\n",
      "  num_agent_steps_trained: 2044000\n",
      "  num_steps_sampled: 2044000\n",
      "  num_steps_trained: 2044000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 511\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.58\n",
      "  ram_util_percent: 85.63000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06829690684939388\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07845115424523845\n",
      "  mean_inference_ms: 0.7496257951068381\n",
      "  mean_raw_obs_processing_ms: 0.09072384734485577\n",
      "time_since_restore: 3634.3420131206512\n",
      "time_this_iter_s: 6.871689319610596\n",
      "time_total_s: 3634.3420131206512\n",
      "timers:\n",
      "  learn_throughput: 1359.713\n",
      "  learn_time_ms: 2941.798\n",
      "  load_throughput: 23134605.626\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 579.739\n",
      "  sample_time_ms: 6899.653\n",
      "  update_time_ms: 2.112\n",
      "timestamp: 1658397589\n",
      "timesteps_since_restore: 2044000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2044000\n",
      "training_iteration: 511\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2048000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_11-59-56\n",
      "done: false\n",
      "episode_len_mean: 199.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.1\n",
      "episode_reward_min: 121.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10772\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29263022541999817\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038922647945582867\n",
      "        model: {}\n",
      "        policy_loss: 0.00821483600884676\n",
      "        total_loss: 8.022327423095703\n",
      "        vf_explained_var: -7.050011685549862e-09\n",
      "        vf_loss: 8.01411247253418\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2048000\n",
      "  num_agent_steps_trained: 2048000\n",
      "  num_steps_sampled: 2048000\n",
      "  num_steps_trained: 2048000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 512\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.5\n",
      "  ram_util_percent: 85.66666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06829352168762709\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07844658885712512\n",
      "  mean_inference_ms: 0.7495922349123313\n",
      "  mean_raw_obs_processing_ms: 0.09071783766377002\n",
      "time_since_restore: 3641.0691542625427\n",
      "time_this_iter_s: 6.7271411418914795\n",
      "time_total_s: 3641.0691542625427\n",
      "timers:\n",
      "  learn_throughput: 1360.266\n",
      "  learn_time_ms: 2940.602\n",
      "  load_throughput: 23275826.859\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 579.853\n",
      "  sample_time_ms: 6898.304\n",
      "  update_time_ms: 2.114\n",
      "timestamp: 1658397596\n",
      "timesteps_since_restore: 2048000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2048000\n",
      "training_iteration: 512\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2052000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-02\n",
      "done: false\n",
      "episode_len_mean: 199.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.1\n",
      "episode_reward_min: 121.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10792\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2803950607776642\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002798286033794284\n",
      "        model: {}\n",
      "        policy_loss: 0.009306542575359344\n",
      "        total_loss: 8.023419380187988\n",
      "        vf_explained_var: -4.5055983832753554e-08\n",
      "        vf_loss: 8.01411247253418\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2052000\n",
      "  num_agent_steps_trained: 2052000\n",
      "  num_steps_sampled: 2052000\n",
      "  num_steps_trained: 2052000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 513\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.12\n",
      "  ram_util_percent: 85.6\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06829025776186842\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07844204941817251\n",
      "  mean_inference_ms: 0.7495588578076985\n",
      "  mean_raw_obs_processing_ms: 0.0907118867874771\n",
      "time_since_restore: 3647.84077000618\n",
      "time_this_iter_s: 6.771615743637085\n",
      "time_total_s: 3647.84077000618\n",
      "timers:\n",
      "  learn_throughput: 1359.476\n",
      "  learn_time_ms: 2942.309\n",
      "  load_throughput: 23412246.721\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 581.62\n",
      "  sample_time_ms: 6877.34\n",
      "  update_time_ms: 2.123\n",
      "timestamp: 1658397602\n",
      "timesteps_since_restore: 2052000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2052000\n",
      "training_iteration: 513\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2056000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-09\n",
      "done: false\n",
      "episode_len_mean: 199.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.89\n",
      "episode_reward_min: 189.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10812\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2638578414916992\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038761384785175323\n",
      "        model: {}\n",
      "        policy_loss: 0.007802313193678856\n",
      "        total_loss: 8.021916389465332\n",
      "        vf_explained_var: 7.438403031301277e-07\n",
      "        vf_loss: 8.014113426208496\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2056000\n",
      "  num_agent_steps_trained: 2056000\n",
      "  num_steps_sampled: 2056000\n",
      "  num_steps_trained: 2056000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 514\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.07\n",
      "  ram_util_percent: 85.68\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06828656688502754\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07843686145439166\n",
      "  mean_inference_ms: 0.7495178149541715\n",
      "  mean_raw_obs_processing_ms: 0.09070494255800947\n",
      "time_since_restore: 3654.4327783584595\n",
      "time_this_iter_s: 6.592008352279663\n",
      "time_total_s: 3654.4327783584595\n",
      "timers:\n",
      "  learn_throughput: 1362.525\n",
      "  learn_time_ms: 2935.727\n",
      "  load_throughput: 23441687.858\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 581.708\n",
      "  sample_time_ms: 6876.298\n",
      "  update_time_ms: 2.135\n",
      "timestamp: 1658397609\n",
      "timesteps_since_restore: 2056000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2056000\n",
      "training_iteration: 514\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2060000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-16\n",
      "done: false\n",
      "episode_len_mean: 199.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.6\n",
      "episode_reward_min: 171.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10832\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2903030812740326\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005088245961815119\n",
      "        model: {}\n",
      "        policy_loss: 0.006193122360855341\n",
      "        total_loss: 7.874139308929443\n",
      "        vf_explained_var: 7.937031227811531e-07\n",
      "        vf_loss: 7.867946147918701\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2060000\n",
      "  num_agent_steps_trained: 2060000\n",
      "  num_steps_sampled: 2060000\n",
      "  num_steps_trained: 2060000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 515\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.300000000000004\n",
      "  ram_util_percent: 85.64444444444445\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06828127819536853\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07843015759810416\n",
      "  mean_inference_ms: 0.7494670607657828\n",
      "  mean_raw_obs_processing_ms: 0.0906964848451424\n",
      "time_since_restore: 3661.2819652557373\n",
      "time_this_iter_s: 6.849186897277832\n",
      "time_total_s: 3661.2819652557373\n",
      "timers:\n",
      "  learn_throughput: 1366.075\n",
      "  learn_time_ms: 2928.097\n",
      "  load_throughput: 23461356.454\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 584.821\n",
      "  sample_time_ms: 6839.704\n",
      "  update_time_ms: 2.14\n",
      "timestamp: 1658397616\n",
      "timesteps_since_restore: 2060000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2060000\n",
      "training_iteration: 515\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2064000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-23\n",
      "done: false\n",
      "episode_len_mean: 199.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.71\n",
      "episode_reward_min: 171.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10852\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2692810297012329\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030232456047087908\n",
      "        model: {}\n",
      "        policy_loss: 0.006784758064895868\n",
      "        total_loss: 6.559204578399658\n",
      "        vf_explained_var: -4.1152841845359944e-07\n",
      "        vf_loss: 6.552419185638428\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2064000\n",
      "  num_agent_steps_trained: 2064000\n",
      "  num_steps_sampled: 2064000\n",
      "  num_steps_trained: 2064000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 516\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.040000000000006\n",
      "  ram_util_percent: 85.72999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06827599845482388\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07842374509054237\n",
      "  mean_inference_ms: 0.7494176085100501\n",
      "  mean_raw_obs_processing_ms: 0.09068839466043538\n",
      "time_since_restore: 3668.0546498298645\n",
      "time_this_iter_s: 6.772684574127197\n",
      "time_total_s: 3668.0546498298645\n",
      "timers:\n",
      "  learn_throughput: 1365.272\n",
      "  learn_time_ms: 2929.819\n",
      "  load_throughput: 23369850.954\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 585.616\n",
      "  sample_time_ms: 6830.418\n",
      "  update_time_ms: 2.067\n",
      "timestamp: 1658397623\n",
      "timesteps_since_restore: 2064000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2064000\n",
      "training_iteration: 516\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2068000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-29\n",
      "done: false\n",
      "episode_len_mean: 199.22\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.22\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10872\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3055567443370819\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003980641718953848\n",
      "        model: {}\n",
      "        policy_loss: 0.0006344799185171723\n",
      "        total_loss: 4.453760147094727\n",
      "        vf_explained_var: 4.806826154890587e-07\n",
      "        vf_loss: 4.453125953674316\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2068000\n",
      "  num_agent_steps_trained: 2068000\n",
      "  num_steps_sampled: 2068000\n",
      "  num_steps_trained: 2068000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 517\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.93\n",
      "  ram_util_percent: 85.64000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06827045050565957\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07841722968786717\n",
      "  mean_inference_ms: 0.7493659609458904\n",
      "  mean_raw_obs_processing_ms: 0.0906806289290888\n",
      "time_since_restore: 3674.832193136215\n",
      "time_this_iter_s: 6.777543306350708\n",
      "time_total_s: 3674.832193136215\n",
      "timers:\n",
      "  learn_throughput: 1370.727\n",
      "  learn_time_ms: 2918.159\n",
      "  load_throughput: 23415514.306\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 585.045\n",
      "  sample_time_ms: 6837.084\n",
      "  update_time_ms: 2.066\n",
      "timestamp: 1658397629\n",
      "timesteps_since_restore: 2068000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2068000\n",
      "training_iteration: 517\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2072000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-36\n",
      "done: false\n",
      "episode_len_mean: 199.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.12\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10892\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27563604712486267\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0017192617524415255\n",
      "        model: {}\n",
      "        policy_loss: 0.004641252104192972\n",
      "        total_loss: 4.036900043487549\n",
      "        vf_explained_var: -2.1150035056649585e-09\n",
      "        vf_loss: 4.0322585105896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2072000\n",
      "  num_agent_steps_trained: 2072000\n",
      "  num_steps_sampled: 2072000\n",
      "  num_steps_trained: 2072000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 518\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.68\n",
      "  ram_util_percent: 85.72\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06826605597001376\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07841211323155961\n",
      "  mean_inference_ms: 0.7493274149435994\n",
      "  mean_raw_obs_processing_ms: 0.09067436371970806\n",
      "time_since_restore: 3681.7512595653534\n",
      "time_this_iter_s: 6.919066429138184\n",
      "time_total_s: 3681.7512595653534\n",
      "timers:\n",
      "  learn_throughput: 1374.577\n",
      "  learn_time_ms: 2909.985\n",
      "  load_throughput: 23083676.39\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 584.533\n",
      "  sample_time_ms: 6843.068\n",
      "  update_time_ms: 2.079\n",
      "timestamp: 1658397636\n",
      "timesteps_since_restore: 2072000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2072000\n",
      "training_iteration: 518\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2076000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-44\n",
      "done: false\n",
      "episode_len_mean: 199.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.12\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10912\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2761003077030182\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0022463102359324694\n",
      "        model: {}\n",
      "        policy_loss: 0.004568953532725573\n",
      "        total_loss: 3.5831990242004395\n",
      "        vf_explained_var: -0.028855662792921066\n",
      "        vf_loss: 3.578629970550537\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2076000\n",
      "  num_agent_steps_trained: 2076000\n",
      "  num_steps_sampled: 2076000\n",
      "  num_steps_trained: 2076000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 519\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.0\n",
      "  ram_util_percent: 85.69000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06826240706060852\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07840773159487778\n",
      "  mean_inference_ms: 0.7493012955755135\n",
      "  mean_raw_obs_processing_ms: 0.09066954927553429\n",
      "time_since_restore: 3689.0283336639404\n",
      "time_this_iter_s: 7.277074098587036\n",
      "time_total_s: 3689.0283336639404\n",
      "timers:\n",
      "  learn_throughput: 1357.517\n",
      "  learn_time_ms: 2946.557\n",
      "  load_throughput: 23743583.357\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 584.699\n",
      "  sample_time_ms: 6841.13\n",
      "  update_time_ms: 1.994\n",
      "timestamp: 1658397644\n",
      "timesteps_since_restore: 2076000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2076000\n",
      "training_iteration: 519\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2080000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-51\n",
      "done: false\n",
      "episode_len_mean: 199.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.41\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10932\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2447293996810913\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001994641264900565\n",
      "        model: {}\n",
      "        policy_loss: 0.004478965420275927\n",
      "        total_loss: 3.5831081867218018\n",
      "        vf_explained_var: -0.03225832059979439\n",
      "        vf_loss: 3.5786290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2080000\n",
      "  num_agent_steps_trained: 2080000\n",
      "  num_steps_sampled: 2080000\n",
      "  num_steps_trained: 2080000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 520\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.37\n",
      "  ram_util_percent: 85.70000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06825789578649406\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07840242912569623\n",
      "  mean_inference_ms: 0.749262054470326\n",
      "  mean_raw_obs_processing_ms: 0.09066334094559884\n",
      "time_since_restore: 3695.878056049347\n",
      "time_this_iter_s: 6.849722385406494\n",
      "time_total_s: 3695.878056049347\n",
      "timers:\n",
      "  learn_throughput: 1350.035\n",
      "  learn_time_ms: 2962.885\n",
      "  load_throughput: 24005173.845\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 584.474\n",
      "  sample_time_ms: 6843.764\n",
      "  update_time_ms: 1.943\n",
      "timestamp: 1658397651\n",
      "timesteps_since_restore: 2080000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2080000\n",
      "training_iteration: 520\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2084000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-00-57\n",
      "done: false\n",
      "episode_len_mean: 199.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.41\n",
      "episode_reward_min: 151.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10952\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25354623794555664\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030147104989737272\n",
      "        model: {}\n",
      "        policy_loss: 0.0031249779276549816\n",
      "        total_loss: 3.581753969192505\n",
      "        vf_explained_var: 0.016901148483157158\n",
      "        vf_loss: 3.5786290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2084000\n",
      "  num_agent_steps_trained: 2084000\n",
      "  num_steps_sampled: 2084000\n",
      "  num_steps_trained: 2084000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 521\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.940000000000005\n",
      "  ram_util_percent: 85.68\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06825407506553118\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0783977093709571\n",
      "  mean_inference_ms: 0.7492316795714191\n",
      "  mean_raw_obs_processing_ms: 0.09065798542385811\n",
      "time_since_restore: 3702.7459094524384\n",
      "time_this_iter_s: 6.867853403091431\n",
      "time_total_s: 3702.7459094524384\n",
      "timers:\n",
      "  learn_throughput: 1356.161\n",
      "  learn_time_ms: 2949.503\n",
      "  load_throughput: 23824504.402\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 581.945\n",
      "  sample_time_ms: 6873.507\n",
      "  update_time_ms: 1.914\n",
      "timestamp: 1658397657\n",
      "timesteps_since_restore: 2084000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2084000\n",
      "training_iteration: 521\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2088000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-04\n",
      "done: false\n",
      "episode_len_mean: 199.9\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.9\n",
      "episode_reward_min: 190.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10972\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26318463683128357\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004190762992948294\n",
      "        model: {}\n",
      "        policy_loss: 0.001610573148354888\n",
      "        total_loss: 3.58024001121521\n",
      "        vf_explained_var: 0.0010009980760514736\n",
      "        vf_loss: 3.5786292552948\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2088000\n",
      "  num_agent_steps_trained: 2088000\n",
      "  num_steps_sampled: 2088000\n",
      "  num_steps_trained: 2088000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 522\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.75555555555556\n",
      "  ram_util_percent: 85.74444444444444\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06825040858876484\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07839322540130006\n",
      "  mean_inference_ms: 0.7492029904292298\n",
      "  mean_raw_obs_processing_ms: 0.09065286415904669\n",
      "time_since_restore: 3709.5924203395844\n",
      "time_this_iter_s: 6.846510887145996\n",
      "time_total_s: 3709.5924203395844\n",
      "timers:\n",
      "  learn_throughput: 1350.42\n",
      "  learn_time_ms: 2962.041\n",
      "  load_throughput: 23790720.363\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 583.159\n",
      "  sample_time_ms: 6859.192\n",
      "  update_time_ms: 1.894\n",
      "timestamp: 1658397664\n",
      "timesteps_since_restore: 2088000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2088000\n",
      "training_iteration: 522\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2092000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-11\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 10992\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26799145340919495\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034168066922575235\n",
      "        model: {}\n",
      "        policy_loss: 0.0017131335334852338\n",
      "        total_loss: 3.5803427696228027\n",
      "        vf_explained_var: -0.031644463539123535\n",
      "        vf_loss: 3.578629493713379\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2092000\n",
      "  num_agent_steps_trained: 2092000\n",
      "  num_steps_sampled: 2092000\n",
      "  num_steps_trained: 2092000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 523\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.839999999999996\n",
      "  ram_util_percent: 85.82000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06824539624850612\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07838683846620588\n",
      "  mean_inference_ms: 0.7491556629171212\n",
      "  mean_raw_obs_processing_ms: 0.09064603961535507\n",
      "time_since_restore: 3716.279124736786\n",
      "time_this_iter_s: 6.686704397201538\n",
      "time_total_s: 3716.279124736786\n",
      "timers:\n",
      "  learn_throughput: 1350.926\n",
      "  learn_time_ms: 2960.932\n",
      "  load_throughput: 23477772.18\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 582.74\n",
      "  sample_time_ms: 6864.126\n",
      "  update_time_ms: 1.868\n",
      "timestamp: 1658397671\n",
      "timesteps_since_restore: 2092000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2092000\n",
      "training_iteration: 523\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2096000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-18\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11012\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2621023654937744\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002942705061286688\n",
      "        model: {}\n",
      "        policy_loss: 0.003058109898120165\n",
      "        total_loss: 3.581688404083252\n",
      "        vf_explained_var: -0.03225811943411827\n",
      "        vf_loss: 3.578629970550537\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2096000\n",
      "  num_agent_steps_trained: 2096000\n",
      "  num_steps_sampled: 2096000\n",
      "  num_steps_trained: 2096000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 524\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.730000000000004\n",
      "  ram_util_percent: 85.80999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06824054557642704\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0783808642392942\n",
      "  mean_inference_ms: 0.7491092482116162\n",
      "  mean_raw_obs_processing_ms: 0.09063939277622918\n",
      "time_since_restore: 3723.0508313179016\n",
      "time_this_iter_s: 6.771706581115723\n",
      "time_total_s: 3723.0508313179016\n",
      "timers:\n",
      "  learn_throughput: 1350.5\n",
      "  learn_time_ms: 2961.865\n",
      "  load_throughput: 23471203.134\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 581.366\n",
      "  sample_time_ms: 6880.353\n",
      "  update_time_ms: 1.853\n",
      "timestamp: 1658397678\n",
      "timesteps_since_restore: 2096000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2096000\n",
      "training_iteration: 524\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2100000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-25\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11032\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2756250500679016\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004005664959549904\n",
      "        model: {}\n",
      "        policy_loss: 0.0020422725938260555\n",
      "        total_loss: 3.5806713104248047\n",
      "        vf_explained_var: 0.011138347908854485\n",
      "        vf_loss: 3.5786290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2100000\n",
      "  num_agent_steps_trained: 2100000\n",
      "  num_steps_sampled: 2100000\n",
      "  num_steps_trained: 2100000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 525\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.93\n",
      "  ram_util_percent: 85.73\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06823833005258695\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07837756657498492\n",
      "  mean_inference_ms: 0.7490920557469635\n",
      "  mean_raw_obs_processing_ms: 0.09063620986137756\n",
      "time_since_restore: 3730.1766443252563\n",
      "time_this_iter_s: 7.125813007354736\n",
      "time_total_s: 3730.1766443252563\n",
      "timers:\n",
      "  learn_throughput: 1348.408\n",
      "  learn_time_ms: 2966.461\n",
      "  load_throughput: 23298452.993\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 579.401\n",
      "  sample_time_ms: 6903.687\n",
      "  update_time_ms: 1.872\n",
      "timestamp: 1658397685\n",
      "timesteps_since_restore: 2100000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2100000\n",
      "training_iteration: 525\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2104000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-32\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11052\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2737899720668793\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035745236091315746\n",
      "        model: {}\n",
      "        policy_loss: 0.0027410192415118217\n",
      "        total_loss: 3.5813705921173096\n",
      "        vf_explained_var: -0.032257962971925735\n",
      "        vf_loss: 3.578629493713379\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2104000\n",
      "  num_agent_steps_trained: 2104000\n",
      "  num_steps_sampled: 2104000\n",
      "  num_steps_trained: 2104000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 526\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.69\n",
      "  ram_util_percent: 85.76999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06823781983668102\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07837620363025255\n",
      "  mean_inference_ms: 0.7490891741303688\n",
      "  mean_raw_obs_processing_ms: 0.09063506665311738\n",
      "time_since_restore: 3737.3779516220093\n",
      "time_this_iter_s: 7.20130729675293\n",
      "time_total_s: 3737.3779516220093\n",
      "timers:\n",
      "  learn_throughput: 1343.755\n",
      "  learn_time_ms: 2976.732\n",
      "  load_throughput: 23484344.905\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 576.175\n",
      "  sample_time_ms: 6942.331\n",
      "  update_time_ms: 1.903\n",
      "timestamp: 1658397692\n",
      "timesteps_since_restore: 2104000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2104000\n",
      "training_iteration: 526\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2108000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-39\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11072\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28907451033592224\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038150751497596502\n",
      "        model: {}\n",
      "        policy_loss: 0.0028805630281567574\n",
      "        total_loss: 3.581509828567505\n",
      "        vf_explained_var: 0.014637160114943981\n",
      "        vf_loss: 3.5786292552948\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2108000\n",
      "  num_agent_steps_trained: 2108000\n",
      "  num_steps_sampled: 2108000\n",
      "  num_steps_trained: 2108000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 527\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.86\n",
      "  ram_util_percent: 85.77\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0682372039324127\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0783744749869469\n",
      "  mean_inference_ms: 0.7490849715643837\n",
      "  mean_raw_obs_processing_ms: 0.09063328808822448\n",
      "time_since_restore: 3744.105692625046\n",
      "time_this_iter_s: 6.727741003036499\n",
      "time_total_s: 3744.105692625046\n",
      "timers:\n",
      "  learn_throughput: 1345.67\n",
      "  learn_time_ms: 2972.497\n",
      "  load_throughput: 23233923.279\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 575.374\n",
      "  sample_time_ms: 6951.995\n",
      "  update_time_ms: 1.915\n",
      "timestamp: 1658397699\n",
      "timesteps_since_restore: 2108000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2108000\n",
      "training_iteration: 527\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2112000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-46\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11092\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28484484553337097\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026916044298559427\n",
      "        model: {}\n",
      "        policy_loss: 0.0039032038766890764\n",
      "        total_loss: 3.582533121109009\n",
      "        vf_explained_var: -0.002055092714726925\n",
      "        vf_loss: 3.578629970550537\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2112000\n",
      "  num_agent_steps_trained: 2112000\n",
      "  num_steps_sampled: 2112000\n",
      "  num_steps_trained: 2112000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 528\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.03\n",
      "  ram_util_percent: 85.89\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06823702829581761\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07837367006369192\n",
      "  mean_inference_ms: 0.7490881862428274\n",
      "  mean_raw_obs_processing_ms: 0.0906324258765581\n",
      "time_since_restore: 3750.9260218143463\n",
      "time_this_iter_s: 6.820329189300537\n",
      "time_total_s: 3750.9260218143463\n",
      "timers:\n",
      "  learn_throughput: 1343.601\n",
      "  learn_time_ms: 2977.074\n",
      "  load_throughput: 23593328.646\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 576.949\n",
      "  sample_time_ms: 6933.023\n",
      "  update_time_ms: 1.989\n",
      "timestamp: 1658397706\n",
      "timesteps_since_restore: 2112000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2112000\n",
      "training_iteration: 528\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2116000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-52\n",
      "done: false\n",
      "episode_len_mean: 199.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.65\n",
      "episode_reward_min: 165.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11112\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3091295063495636\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003090898273512721\n",
      "        model: {}\n",
      "        policy_loss: 0.0011905714636668563\n",
      "        total_loss: 1.9039124250411987\n",
      "        vf_explained_var: -0.2049763798713684\n",
      "        vf_loss: 1.9027217626571655\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2116000\n",
      "  num_agent_steps_trained: 2116000\n",
      "  num_steps_sampled: 2116000\n",
      "  num_steps_trained: 2116000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 529\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.63333333333333\n",
      "  ram_util_percent: 85.81111111111112\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06823594851236946\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07837183394181718\n",
      "  mean_inference_ms: 0.7490800058251526\n",
      "  mean_raw_obs_processing_ms: 0.0906304256009022\n",
      "time_since_restore: 3757.6553337574005\n",
      "time_this_iter_s: 6.729311943054199\n",
      "time_total_s: 3757.6553337574005\n",
      "timers:\n",
      "  learn_throughput: 1362.23\n",
      "  learn_time_ms: 2936.362\n",
      "  load_throughput: 24060255.27\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 577.689\n",
      "  sample_time_ms: 6924.136\n",
      "  update_time_ms: 2.025\n",
      "timestamp: 1658397712\n",
      "timesteps_since_restore: 2116000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2116000\n",
      "training_iteration: 529\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2120000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-01-59\n",
      "done: false\n",
      "episode_len_mean: 198.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.51\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11133\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2929447591304779\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004155915696173906\n",
      "        model: {}\n",
      "        policy_loss: 0.003651288105174899\n",
      "        total_loss: 5.502647876739502\n",
      "        vf_explained_var: 0.015325174666941166\n",
      "        vf_loss: 5.498996257781982\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2120000\n",
      "  num_agent_steps_trained: 2120000\n",
      "  num_steps_sampled: 2120000\n",
      "  num_steps_trained: 2120000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 530\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.8\n",
      "  ram_util_percent: 85.78\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06823226895684475\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07836749654895651\n",
      "  mean_inference_ms: 0.7490425524703767\n",
      "  mean_raw_obs_processing_ms: 0.09062542165729531\n",
      "time_since_restore: 3764.449192047119\n",
      "time_this_iter_s: 6.793858289718628\n",
      "time_total_s: 3764.449192047119\n",
      "timers:\n",
      "  learn_throughput: 1366.691\n",
      "  learn_time_ms: 2926.777\n",
      "  load_throughput: 24339498.041\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 580.751\n",
      "  sample_time_ms: 6887.631\n",
      "  update_time_ms: 2.069\n",
      "timestamp: 1658397719\n",
      "timesteps_since_restore: 2120000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2120000\n",
      "training_iteration: 530\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2124000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-02-06\n",
      "done: false\n",
      "episode_len_mean: 197.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.75\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11153\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2857253849506378\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032563181594014168\n",
      "        model: {}\n",
      "        policy_loss: 0.0014918091474100947\n",
      "        total_loss: 2.3578426837921143\n",
      "        vf_explained_var: 0.029924757778644562\n",
      "        vf_loss: 2.356350898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2124000\n",
      "  num_agent_steps_trained: 2124000\n",
      "  num_steps_sampled: 2124000\n",
      "  num_steps_trained: 2124000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 531\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.144444444444446\n",
      "  ram_util_percent: 85.72222222222223\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06822603683734316\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07836028481447661\n",
      "  mean_inference_ms: 0.7489790391906707\n",
      "  mean_raw_obs_processing_ms: 0.09061725881530183\n",
      "time_since_restore: 3771.102452993393\n",
      "time_this_iter_s: 6.653260946273804\n",
      "time_total_s: 3771.102452993393\n",
      "timers:\n",
      "  learn_throughput: 1367.276\n",
      "  learn_time_ms: 2925.525\n",
      "  load_throughput: 24647004.554\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 583.341\n",
      "  sample_time_ms: 6857.048\n",
      "  update_time_ms: 2.103\n",
      "timestamp: 1658397726\n",
      "timesteps_since_restore: 2124000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2124000\n",
      "training_iteration: 531\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2128000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-02-13\n",
      "done: false\n",
      "episode_len_mean: 197.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.38\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11173\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3013901710510254\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004366853274405003\n",
      "        model: {}\n",
      "        policy_loss: 0.0018181974301114678\n",
      "        total_loss: 2.227121114730835\n",
      "        vf_explained_var: 0.001540917786769569\n",
      "        vf_loss: 2.2253024578094482\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2128000\n",
      "  num_agent_steps_trained: 2128000\n",
      "  num_steps_sampled: 2128000\n",
      "  num_steps_trained: 2128000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 532\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.2\n",
      "  ram_util_percent: 85.70000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06822007899795335\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07835360354878458\n",
      "  mean_inference_ms: 0.7489203317100035\n",
      "  mean_raw_obs_processing_ms: 0.09060980428637383\n",
      "time_since_restore: 3777.868448495865\n",
      "time_this_iter_s: 6.765995502471924\n",
      "time_total_s: 3777.868448495865\n",
      "timers:\n",
      "  learn_throughput: 1373.015\n",
      "  learn_time_ms: 2913.296\n",
      "  load_throughput: 23573438.246\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 583.095\n",
      "  sample_time_ms: 6859.943\n",
      "  update_time_ms: 2.142\n",
      "timestamp: 1658397733\n",
      "timesteps_since_restore: 2128000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2128000\n",
      "training_iteration: 532\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2132000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-02-20\n",
      "done: false\n",
      "episode_len_mean: 196.13\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.13\n",
      "episode_reward_min: 70.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11194\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27879855036735535\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00688856141641736\n",
      "        model: {}\n",
      "        policy_loss: -0.0019907213281840086\n",
      "        total_loss: 2.492969274520874\n",
      "        vf_explained_var: 0.026372794061899185\n",
      "        vf_loss: 2.494959831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2132000\n",
      "  num_agent_steps_trained: 2132000\n",
      "  num_steps_sampled: 2132000\n",
      "  num_steps_trained: 2132000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 533\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.260000000000005\n",
      "  ram_util_percent: 85.82000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06821332721596372\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07834599535908586\n",
      "  mean_inference_ms: 0.7488569026290641\n",
      "  mean_raw_obs_processing_ms: 0.0906012663954676\n",
      "time_since_restore: 3784.6126306056976\n",
      "time_this_iter_s: 6.744182109832764\n",
      "time_total_s: 3784.6126306056976\n",
      "timers:\n",
      "  learn_throughput: 1372.306\n",
      "  learn_time_ms: 2914.802\n",
      "  load_throughput: 23623227.26\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 583.754\n",
      "  sample_time_ms: 6852.205\n",
      "  update_time_ms: 2.155\n",
      "timestamp: 1658397740\n",
      "timesteps_since_restore: 2132000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2132000\n",
      "training_iteration: 533\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2136000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-02-26\n",
      "done: false\n",
      "episode_len_mean: 196.13\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.13\n",
      "episode_reward_min: 70.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11214\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2669733464717865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003247292945161462\n",
      "        model: {}\n",
      "        policy_loss: 0.001749617513269186\n",
      "        total_loss: 2.471508026123047\n",
      "        vf_explained_var: 0.03829294070601463\n",
      "        vf_loss: 2.4697580337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2136000\n",
      "  num_agent_steps_trained: 2136000\n",
      "  num_steps_sampled: 2136000\n",
      "  num_steps_trained: 2136000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 534\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.34444444444444\n",
      "  ram_util_percent: 85.75555555555556\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06820754416987962\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07833951727174844\n",
      "  mean_inference_ms: 0.7488033439944295\n",
      "  mean_raw_obs_processing_ms: 0.09059415262932942\n",
      "time_since_restore: 3791.322004556656\n",
      "time_this_iter_s: 6.709373950958252\n",
      "time_total_s: 3791.322004556656\n",
      "timers:\n",
      "  learn_throughput: 1373.101\n",
      "  learn_time_ms: 2913.115\n",
      "  load_throughput: 23599966.24\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 583.992\n",
      "  sample_time_ms: 6849.406\n",
      "  update_time_ms: 2.185\n",
      "timestamp: 1658397746\n",
      "timesteps_since_restore: 2136000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2136000\n",
      "training_iteration: 534\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2140000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-02-33\n",
      "done: false\n",
      "episode_len_mean: 198.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.02\n",
      "episode_reward_min: 70.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11234\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3140307068824768\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029976770747452974\n",
      "        model: {}\n",
      "        policy_loss: 0.0018152282573282719\n",
      "        total_loss: 2.471573829650879\n",
      "        vf_explained_var: -0.006173358298838139\n",
      "        vf_loss: 2.4697585105895996\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2140000\n",
      "  num_agent_steps_trained: 2140000\n",
      "  num_steps_sampled: 2140000\n",
      "  num_steps_trained: 2140000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 535\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.809999999999995\n",
      "  ram_util_percent: 85.83\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06820136870712121\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07833258068918282\n",
      "  mean_inference_ms: 0.7487482187957768\n",
      "  mean_raw_obs_processing_ms: 0.09058628496811556\n",
      "time_since_restore: 3798.1962082386017\n",
      "time_this_iter_s: 6.874203681945801\n",
      "time_total_s: 3798.1962082386017\n",
      "timers:\n",
      "  learn_throughput: 1366.147\n",
      "  learn_time_ms: 2927.943\n",
      "  load_throughput: 23780603.827\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 587.513\n",
      "  sample_time_ms: 6808.359\n",
      "  update_time_ms: 2.156\n",
      "timestamp: 1658397753\n",
      "timesteps_since_restore: 2140000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2140000\n",
      "training_iteration: 535\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2144000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-02-40\n",
      "done: false\n",
      "episode_len_mean: 198.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.03\n",
      "episode_reward_min: 70.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11254\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.293994277715683\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024781792890280485\n",
      "        model: {}\n",
      "        policy_loss: 0.002108149928972125\n",
      "        total_loss: 2.4718663692474365\n",
      "        vf_explained_var: -0.017102155834436417\n",
      "        vf_loss: 2.4697580337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2144000\n",
      "  num_agent_steps_trained: 2144000\n",
      "  num_steps_sampled: 2144000\n",
      "  num_steps_trained: 2144000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 536\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.58\n",
      "  ram_util_percent: 85.88\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06819814769868433\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07832879931517545\n",
      "  mean_inference_ms: 0.7487239454227079\n",
      "  mean_raw_obs_processing_ms: 0.09058204124069816\n",
      "time_since_restore: 3805.3256504535675\n",
      "time_this_iter_s: 7.12944221496582\n",
      "time_total_s: 3805.3256504535675\n",
      "timers:\n",
      "  learn_throughput: 1370.679\n",
      "  learn_time_ms: 2918.261\n",
      "  load_throughput: 23730149.929\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 586.181\n",
      "  sample_time_ms: 6823.828\n",
      "  update_time_ms: 2.167\n",
      "timestamp: 1658397760\n",
      "timesteps_since_restore: 2144000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2144000\n",
      "training_iteration: 536\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2148000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-02-47\n",
      "done: false\n",
      "episode_len_mean: 198.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.32\n",
      "episode_reward_min: 70.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11274\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27164438366889954\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031676851212978363\n",
      "        model: {}\n",
      "        policy_loss: 0.0008991050417535007\n",
      "        total_loss: 2.3496897220611572\n",
      "        vf_explained_var: -0.060017336159944534\n",
      "        vf_loss: 2.348790407180786\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2148000\n",
      "  num_agent_steps_trained: 2148000\n",
      "  num_steps_sampled: 2148000\n",
      "  num_steps_trained: 2148000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 537\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.519999999999996\n",
      "  ram_util_percent: 85.95\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06819438042837424\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07832428580589791\n",
      "  mean_inference_ms: 0.7486936486912932\n",
      "  mean_raw_obs_processing_ms: 0.09057690255981125\n",
      "time_since_restore: 3811.961745262146\n",
      "time_this_iter_s: 6.636094808578491\n",
      "time_total_s: 3811.961745262146\n",
      "timers:\n",
      "  learn_throughput: 1373.803\n",
      "  learn_time_ms: 2911.626\n",
      "  load_throughput: 23994874.142\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 587.233\n",
      "  sample_time_ms: 6811.608\n",
      "  update_time_ms: 2.178\n",
      "timestamp: 1658397767\n",
      "timesteps_since_restore: 2148000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2148000\n",
      "training_iteration: 537\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2152000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-02-54\n",
      "done: false\n",
      "episode_len_mean: 197.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.52\n",
      "episode_reward_min: 48.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11295\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26877322793006897\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004040149971842766\n",
      "        model: {}\n",
      "        policy_loss: 0.0011321677593514323\n",
      "        total_loss: 2.9547641277313232\n",
      "        vf_explained_var: -0.1832672655582428\n",
      "        vf_loss: 2.953631639480591\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2152000\n",
      "  num_agent_steps_trained: 2152000\n",
      "  num_steps_sampled: 2152000\n",
      "  num_steps_trained: 2152000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 538\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.61\n",
      "  ram_util_percent: 85.87999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06819122225681\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07832125582007911\n",
      "  mean_inference_ms: 0.7486659845161526\n",
      "  mean_raw_obs_processing_ms: 0.09057224420483063\n",
      "time_since_restore: 3819.0365483760834\n",
      "time_this_iter_s: 7.074803113937378\n",
      "time_total_s: 3819.0365483760834\n",
      "timers:\n",
      "  learn_throughput: 1362.484\n",
      "  learn_time_ms: 2935.815\n",
      "  load_throughput: 23943507.921\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 587.692\n",
      "  sample_time_ms: 6806.291\n",
      "  update_time_ms: 2.149\n",
      "timestamp: 1658397774\n",
      "timesteps_since_restore: 2152000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2152000\n",
      "training_iteration: 538\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2156000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-03-03\n",
      "done: false\n",
      "episode_len_mean: 197.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.52\n",
      "episode_reward_min: 48.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11315\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2790776491165161\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004599368199706078\n",
      "        model: {}\n",
      "        policy_loss: -0.0016780673759058118\n",
      "        total_loss: 0.04872525855898857\n",
      "        vf_explained_var: 0.07603667676448822\n",
      "        vf_loss: 0.05040332302451134\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2156000\n",
      "  num_agent_steps_trained: 2156000\n",
      "  num_steps_sampled: 2156000\n",
      "  num_steps_trained: 2156000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 539\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.0\n",
      "  ram_util_percent: 87.05384615384615\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06819570334973533\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07832649787981126\n",
      "  mean_inference_ms: 0.748714794695095\n",
      "  mean_raw_obs_processing_ms: 0.09057699587505681\n",
      "time_since_restore: 3828.2789113521576\n",
      "time_this_iter_s: 9.242362976074219\n",
      "time_total_s: 3828.2789113521576\n",
      "timers:\n",
      "  learn_throughput: 1304.036\n",
      "  learn_time_ms: 3067.401\n",
      "  load_throughput: 21862413.344\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 575.597\n",
      "  sample_time_ms: 6949.304\n",
      "  update_time_ms: 2.161\n",
      "timestamp: 1658397783\n",
      "timesteps_since_restore: 2156000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2156000\n",
      "training_iteration: 539\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2160000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-03-11\n",
      "done: false\n",
      "episode_len_mean: 195.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.62\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11336\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2741425633430481\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005949912592768669\n",
      "        model: {}\n",
      "        policy_loss: -0.0035396949388086796\n",
      "        total_loss: 0.7273073792457581\n",
      "        vf_explained_var: 0.06732375174760818\n",
      "        vf_loss: 0.7308470606803894\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2160000\n",
      "  num_agent_steps_trained: 2160000\n",
      "  num_steps_sampled: 2160000\n",
      "  num_steps_trained: 2160000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 540\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.41818181818182\n",
      "  ram_util_percent: 87.7090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06820593909603194\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07833802059821864\n",
      "  mean_inference_ms: 0.7488211395342372\n",
      "  mean_raw_obs_processing_ms: 0.09058862567104267\n",
      "time_since_restore: 3835.930423974991\n",
      "time_this_iter_s: 7.651512622833252\n",
      "time_total_s: 3835.930423974991\n",
      "timers:\n",
      "  learn_throughput: 1299.597\n",
      "  learn_time_ms: 3077.878\n",
      "  load_throughput: 21684394.468\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 558.887\n",
      "  sample_time_ms: 7157.084\n",
      "  update_time_ms: 2.152\n",
      "timestamp: 1658397791\n",
      "timesteps_since_restore: 2160000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2160000\n",
      "training_iteration: 540\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2164000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-03-18\n",
      "done: false\n",
      "episode_len_mean: 195.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.52\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11356\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2707255780696869\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.010397039353847504\n",
      "        model: {}\n",
      "        policy_loss: -0.003924224060028791\n",
      "        total_loss: 0.29849717020988464\n",
      "        vf_explained_var: 0.028457410633563995\n",
      "        vf_loss: 0.30242136120796204\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2164000\n",
      "  num_agent_steps_trained: 2164000\n",
      "  num_steps_sampled: 2164000\n",
      "  num_steps_trained: 2164000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 541\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.81\n",
      "  ram_util_percent: 87.08000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0682139015090284\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07834725726347436\n",
      "  mean_inference_ms: 0.7489022558269329\n",
      "  mean_raw_obs_processing_ms: 0.09059753093391552\n",
      "time_since_restore: 3842.7127597332\n",
      "time_this_iter_s: 6.7823357582092285\n",
      "time_total_s: 3842.7127597332\n",
      "timers:\n",
      "  learn_throughput: 1299.089\n",
      "  learn_time_ms: 3079.081\n",
      "  load_throughput: 21614552.95\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 557.144\n",
      "  sample_time_ms: 7179.471\n",
      "  update_time_ms: 2.114\n",
      "timestamp: 1658397798\n",
      "timesteps_since_restore: 2164000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2164000\n",
      "training_iteration: 541\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2168000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-03-25\n",
      "done: false\n",
      "episode_len_mean: 195.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.6\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11376\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2741541564464569\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00630149245262146\n",
      "        model: {}\n",
      "        policy_loss: -0.002197698689997196\n",
      "        total_loss: 0.048205647617578506\n",
      "        vf_explained_var: -0.009307821281254292\n",
      "        vf_loss: 0.05040334165096283\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2168000\n",
      "  num_agent_steps_trained: 2168000\n",
      "  num_steps_sampled: 2168000\n",
      "  num_steps_trained: 2168000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 542\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.41\n",
      "  ram_util_percent: 87.01\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06822341129519975\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07835843634799244\n",
      "  mean_inference_ms: 0.7489964288582933\n",
      "  mean_raw_obs_processing_ms: 0.09060835473162868\n",
      "time_since_restore: 3849.613057613373\n",
      "time_this_iter_s: 6.9002978801727295\n",
      "time_total_s: 3849.613057613373\n",
      "timers:\n",
      "  learn_throughput: 1298.518\n",
      "  learn_time_ms: 3080.436\n",
      "  load_throughput: 22420441.0\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 556.11\n",
      "  sample_time_ms: 7192.827\n",
      "  update_time_ms: 2.078\n",
      "timestamp: 1658397805\n",
      "timesteps_since_restore: 2168000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2168000\n",
      "training_iteration: 542\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2172000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-03-32\n",
      "done: false\n",
      "episode_len_mean: 198.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.0\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11396\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3563121259212494\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.018581697717308998\n",
      "        model: {}\n",
      "        policy_loss: -0.004214628599584103\n",
      "        total_loss: 0.04618897661566734\n",
      "        vf_explained_var: -0.19613611698150635\n",
      "        vf_loss: 0.05040360242128372\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2172000\n",
      "  num_agent_steps_trained: 2172000\n",
      "  num_steps_sampled: 2172000\n",
      "  num_steps_trained: 2172000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 543\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.63636363636364\n",
      "  ram_util_percent: 87.05454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06823418603726497\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07837046367913708\n",
      "  mean_inference_ms: 0.7491098148295339\n",
      "  mean_raw_obs_processing_ms: 0.09062084708264444\n",
      "time_since_restore: 3857.252128601074\n",
      "time_this_iter_s: 7.639070987701416\n",
      "time_total_s: 3857.252128601074\n",
      "timers:\n",
      "  learn_throughput: 1277.414\n",
      "  learn_time_ms: 3131.325\n",
      "  load_throughput: 22510688.313\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 553.053\n",
      "  sample_time_ms: 7232.58\n",
      "  update_time_ms: 2.104\n",
      "timestamp: 1658397812\n",
      "timesteps_since_restore: 2172000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2172000\n",
      "training_iteration: 543\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2176000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-03-41\n",
      "done: false\n",
      "episode_len_mean: 194.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.45\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 11418\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3335130214691162\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004177272319793701\n",
      "        model: {}\n",
      "        policy_loss: -0.002976806601509452\n",
      "        total_loss: 2.817087173461914\n",
      "        vf_explained_var: -0.12048513442277908\n",
      "        vf_loss: 2.820063829421997\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2176000\n",
      "  num_agent_steps_trained: 2176000\n",
      "  num_steps_sampled: 2176000\n",
      "  num_steps_trained: 2176000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 544\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.800000000000004\n",
      "  ram_util_percent: 87.14166666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06824530155283505\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07838300460152292\n",
      "  mean_inference_ms: 0.7492295423689151\n",
      "  mean_raw_obs_processing_ms: 0.09063380429161694\n",
      "time_since_restore: 3865.689429998398\n",
      "time_this_iter_s: 8.437301397323608\n",
      "time_total_s: 3865.689429998398\n",
      "timers:\n",
      "  learn_throughput: 1250.918\n",
      "  learn_time_ms: 3197.652\n",
      "  load_throughput: 21951087.269\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 541.229\n",
      "  sample_time_ms: 7390.586\n",
      "  update_time_ms: 2.088\n",
      "timestamp: 1658397821\n",
      "timesteps_since_restore: 2176000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2176000\n",
      "training_iteration: 544\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2180000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-03-49\n",
      "done: false\n",
      "episode_len_mean: 194.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.49\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11439\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30773505568504333\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005912256892770529\n",
      "        model: {}\n",
      "        policy_loss: -0.0013956790789961815\n",
      "        total_loss: 2.669975519180298\n",
      "        vf_explained_var: -0.0967726856470108\n",
      "        vf_loss: 2.6713709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2180000\n",
      "  num_agent_steps_trained: 2180000\n",
      "  num_steps_sampled: 2180000\n",
      "  num_steps_trained: 2180000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 545\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.60833333333334\n",
      "  ram_util_percent: 86.925\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06825817591501843\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07839787097546852\n",
      "  mean_inference_ms: 0.7493677558693981\n",
      "  mean_raw_obs_processing_ms: 0.09064936489670795\n",
      "time_since_restore: 3874.1752915382385\n",
      "time_this_iter_s: 8.485861539840698\n",
      "time_total_s: 3874.1752915382385\n",
      "timers:\n",
      "  learn_throughput: 1228.988\n",
      "  learn_time_ms: 3254.711\n",
      "  load_throughput: 21673189.51\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 529.0\n",
      "  sample_time_ms: 7561.443\n",
      "  update_time_ms: 2.177\n",
      "timestamp: 1658397829\n",
      "timesteps_since_restore: 2180000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2180000\n",
      "training_iteration: 545\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2184000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-03-59\n",
      "done: false\n",
      "episode_len_mean: 193.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.91\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11460\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33264854550361633\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034040999598801136\n",
      "        model: {}\n",
      "        policy_loss: -0.011673652566969395\n",
      "        total_loss: 5.946008682250977\n",
      "        vf_explained_var: -0.03225651755928993\n",
      "        vf_loss: 5.957682132720947\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2184000\n",
      "  num_agent_steps_trained: 2184000\n",
      "  num_steps_sampled: 2184000\n",
      "  num_steps_trained: 2184000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 546\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 58.54285714285714\n",
      "  ram_util_percent: 87.18571428571428\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06827922628272991\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07842178851534402\n",
      "  mean_inference_ms: 0.7495968207312771\n",
      "  mean_raw_obs_processing_ms: 0.09067526559427783\n",
      "time_since_restore: 3884.2617795467377\n",
      "time_this_iter_s: 10.086488008499146\n",
      "time_total_s: 3884.2617795467377\n",
      "timers:\n",
      "  learn_throughput: 1157.574\n",
      "  learn_time_ms: 3455.502\n",
      "  load_throughput: 21822601.457\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 518.451\n",
      "  sample_time_ms: 7715.291\n",
      "  update_time_ms: 2.189\n",
      "timestamp: 1658397839\n",
      "timesteps_since_restore: 2184000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2184000\n",
      "training_iteration: 546\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2188000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-04-08\n",
      "done: false\n",
      "episode_len_mean: 191.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.08\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11481\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.347949743270874\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00352618470788002\n",
      "        model: {}\n",
      "        policy_loss: 0.0062886690720915794\n",
      "        total_loss: 7.017376899719238\n",
      "        vf_explained_var: 1.3280940720505896e-06\n",
      "        vf_loss: 7.011088848114014\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2188000\n",
      "  num_agent_steps_trained: 2188000\n",
      "  num_steps_sampled: 2188000\n",
      "  num_steps_trained: 2188000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 547\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.98333333333333\n",
      "  ram_util_percent: 88.41666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06830479718883535\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07845076662950118\n",
      "  mean_inference_ms: 0.749876727976\n",
      "  mean_raw_obs_processing_ms: 0.09070716814390137\n",
      "time_since_restore: 3892.3933930397034\n",
      "time_this_iter_s: 8.131613492965698\n",
      "time_total_s: 3892.3933930397034\n",
      "timers:\n",
      "  learn_throughput: 1140.301\n",
      "  learn_time_ms: 3507.845\n",
      "  load_throughput: 21451497.251\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 499.089\n",
      "  sample_time_ms: 8014.604\n",
      "  update_time_ms: 2.214\n",
      "timestamp: 1658397848\n",
      "timesteps_since_restore: 2188000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2188000\n",
      "training_iteration: 547\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2192000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-04-15\n",
      "done: false\n",
      "episode_len_mean: 188.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.59\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11502\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33249714970588684\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006411285605281591\n",
      "        model: {}\n",
      "        policy_loss: 0.004836111329495907\n",
      "        total_loss: 8.185306549072266\n",
      "        vf_explained_var: 2.2203050775715383e-06\n",
      "        vf_loss: 8.180469512939453\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2192000\n",
      "  num_agent_steps_trained: 2192000\n",
      "  num_steps_sampled: 2192000\n",
      "  num_steps_trained: 2192000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 548\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.279999999999994\n",
      "  ram_util_percent: 87.29\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0683287488538185\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07847781236573645\n",
      "  mean_inference_ms: 0.7501318557377776\n",
      "  mean_raw_obs_processing_ms: 0.09073666312378627\n",
      "time_since_restore: 3899.5696144104004\n",
      "time_this_iter_s: 7.1762213706970215\n",
      "time_total_s: 3899.5696144104004\n",
      "timers:\n",
      "  learn_throughput: 1143.59\n",
      "  learn_time_ms: 3497.757\n",
      "  load_throughput: 21290883.249\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 494.547\n",
      "  sample_time_ms: 8088.213\n",
      "  update_time_ms: 2.2\n",
      "timestamp: 1658397855\n",
      "timesteps_since_restore: 2192000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2192000\n",
      "training_iteration: 548\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2196000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-04-23\n",
      "done: false\n",
      "episode_len_mean: 192.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.14\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11522\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3155238926410675\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036534678656607866\n",
      "        model: {}\n",
      "        policy_loss: 0.002406979678198695\n",
      "        total_loss: 3.0266005992889404\n",
      "        vf_explained_var: -0.007196149323135614\n",
      "        vf_loss: 3.024193525314331\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2196000\n",
      "  num_agent_steps_trained: 2196000\n",
      "  num_steps_sampled: 2196000\n",
      "  num_steps_trained: 2196000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 549\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.20833333333333\n",
      "  ram_util_percent: 86.91666666666669\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06835160388071942\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07850399483881235\n",
      "  mean_inference_ms: 0.7503790391189343\n",
      "  mean_raw_obs_processing_ms: 0.09076537366648807\n",
      "time_since_restore: 3907.6161103248596\n",
      "time_this_iter_s: 8.046495914459229\n",
      "time_total_s: 3907.6161103248596\n",
      "timers:\n",
      "  learn_throughput: 1183.09\n",
      "  learn_time_ms: 3380.978\n",
      "  load_throughput: 22005792.235\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 495.328\n",
      "  sample_time_ms: 8075.459\n",
      "  update_time_ms: 2.178\n",
      "timestamp: 1658397863\n",
      "timesteps_since_restore: 2196000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2196000\n",
      "training_iteration: 549\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2200000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-04-32\n",
      "done: false\n",
      "episode_len_mean: 194.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.0\n",
      "episode_reward_min: 19.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11542\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35780012607574463\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006062597036361694\n",
      "        model: {}\n",
      "        policy_loss: 0.0008688353700563312\n",
      "        total_loss: 3.0250625610351562\n",
      "        vf_explained_var: -0.06451594084501266\n",
      "        vf_loss: 3.024193525314331\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2200000\n",
      "  num_agent_steps_trained: 2200000\n",
      "  num_steps_sampled: 2200000\n",
      "  num_steps_trained: 2200000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 550\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.70000000000001\n",
      "  ram_util_percent: 86.64999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06837394872880646\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0785293912224819\n",
      "  mean_inference_ms: 0.7506282796713717\n",
      "  mean_raw_obs_processing_ms: 0.09079325590190773\n",
      "time_since_restore: 3916.337008714676\n",
      "time_this_iter_s: 8.720898389816284\n",
      "time_total_s: 3916.337008714676\n",
      "timers:\n",
      "  learn_throughput: 1155.439\n",
      "  learn_time_ms: 3461.888\n",
      "  load_throughput: 20487502.748\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 500.996\n",
      "  sample_time_ms: 7984.103\n",
      "  update_time_ms: 2.154\n",
      "timestamp: 1658397872\n",
      "timesteps_since_restore: 2200000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2200000\n",
      "training_iteration: 550\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2204000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-04-39\n",
      "done: false\n",
      "episode_len_mean: 194.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.68\n",
      "episode_reward_min: 19.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11562\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32357296347618103\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003571573179215193\n",
      "        model: {}\n",
      "        policy_loss: 0.0025429746601730585\n",
      "        total_loss: 3.026736259460449\n",
      "        vf_explained_var: -0.06451567262411118\n",
      "        vf_loss: 3.024193525314331\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2204000\n",
      "  num_agent_steps_trained: 2204000\n",
      "  num_steps_sampled: 2204000\n",
      "  num_steps_trained: 2204000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 551\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.10909090909091\n",
      "  ram_util_percent: 86.85454545454544\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06839501754613479\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07855343781584209\n",
      "  mean_inference_ms: 0.7508588098248833\n",
      "  mean_raw_obs_processing_ms: 0.09081986285739\n",
      "time_since_restore: 3924.1674642562866\n",
      "time_this_iter_s: 7.830455541610718\n",
      "time_total_s: 3924.1674642562866\n",
      "timers:\n",
      "  learn_throughput: 1151.259\n",
      "  learn_time_ms: 3474.458\n",
      "  load_throughput: 20252554.322\n",
      "  load_time_ms: 0.198\n",
      "  sample_throughput: 490.304\n",
      "  sample_time_ms: 8158.197\n",
      "  update_time_ms: 2.129\n",
      "timestamp: 1658397879\n",
      "timesteps_since_restore: 2204000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2204000\n",
      "training_iteration: 551\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2208000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-04-47\n",
      "done: false\n",
      "episode_len_mean: 197.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.51\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11582\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3220483660697937\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004807546269148588\n",
      "        model: {}\n",
      "        policy_loss: 2.3988370230654255e-05\n",
      "        total_loss: 3.0242176055908203\n",
      "        vf_explained_var: -0.06451597809791565\n",
      "        vf_loss: 3.024193525314331\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2208000\n",
      "  num_agent_steps_trained: 2208000\n",
      "  num_steps_sampled: 2208000\n",
      "  num_steps_trained: 2208000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 552\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.545454545454554\n",
      "  ram_util_percent: 86.05454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06841219170520046\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07857274013864615\n",
      "  mean_inference_ms: 0.7510498824460538\n",
      "  mean_raw_obs_processing_ms: 0.09084133268145436\n",
      "time_since_restore: 3931.361263990402\n",
      "time_this_iter_s: 7.193799734115601\n",
      "time_total_s: 3931.361263990402\n",
      "timers:\n",
      "  learn_throughput: 1144.999\n",
      "  learn_time_ms: 3493.453\n",
      "  load_throughput: 20281934.236\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 488.963\n",
      "  sample_time_ms: 8180.584\n",
      "  update_time_ms: 2.129\n",
      "timestamp: 1658397887\n",
      "timesteps_since_restore: 2208000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2208000\n",
      "training_iteration: 552\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2212000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-04-53\n",
      "done: false\n",
      "episode_len_mean: 198.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.14\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11603\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3220460116863251\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004044797271490097\n",
      "        model: {}\n",
      "        policy_loss: 0.0017125786980614066\n",
      "        total_loss: 3.1670353412628174\n",
      "        vf_explained_var: -0.06384191662073135\n",
      "        vf_loss: 3.1653225421905518\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2212000\n",
      "  num_agent_steps_trained: 2212000\n",
      "  num_steps_sampled: 2212000\n",
      "  num_steps_trained: 2212000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 553\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.666666666666664\n",
      "  ram_util_percent: 85.92222222222222\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0684272461735509\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07858975639387737\n",
      "  mean_inference_ms: 0.7512241589891961\n",
      "  mean_raw_obs_processing_ms: 0.09086106926784883\n",
      "time_since_restore: 3937.9722719192505\n",
      "time_this_iter_s: 6.611007928848267\n",
      "time_total_s: 3937.9722719192505\n",
      "timers:\n",
      "  learn_throughput: 1164.588\n",
      "  learn_time_ms: 3434.691\n",
      "  load_throughput: 20390393.777\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 490.451\n",
      "  sample_time_ms: 8155.756\n",
      "  update_time_ms: 2.116\n",
      "timestamp: 1658397893\n",
      "timesteps_since_restore: 2212000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2212000\n",
      "training_iteration: 553\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2216000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-05-00\n",
      "done: false\n",
      "episode_len_mean: 198.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.14\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11623\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33752453327178955\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002940339734777808\n",
      "        model: {}\n",
      "        policy_loss: 0.0028591263107955456\n",
      "        total_loss: 3.7326979637145996\n",
      "        vf_explained_var: -4.3575482777669095e-07\n",
      "        vf_loss: 3.7298390865325928\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2216000\n",
      "  num_agent_steps_trained: 2216000\n",
      "  num_steps_sampled: 2216000\n",
      "  num_steps_trained: 2216000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 554\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.97\n",
      "  ram_util_percent: 85.71000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06843437919894085\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07859771569491786\n",
      "  mean_inference_ms: 0.7513120759976636\n",
      "  mean_raw_obs_processing_ms: 0.09087004116436201\n",
      "time_since_restore: 3944.686845064163\n",
      "time_this_iter_s: 6.71457314491272\n",
      "time_total_s: 3944.686845064163\n",
      "timers:\n",
      "  learn_throughput: 1184.182\n",
      "  learn_time_ms: 3377.859\n",
      "  load_throughput: 20849031.937\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 501.196\n",
      "  sample_time_ms: 7980.916\n",
      "  update_time_ms: 2.124\n",
      "timestamp: 1658397900\n",
      "timesteps_since_restore: 2216000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2216000\n",
      "training_iteration: 554\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2220000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-05-07\n",
      "done: false\n",
      "episode_len_mean: 195.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.46\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11644\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.304775208234787\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004740214440971613\n",
      "        model: {}\n",
      "        policy_loss: 0.0028033710550516844\n",
      "        total_loss: 4.942325115203857\n",
      "        vf_explained_var: -0.12903037667274475\n",
      "        vf_loss: 4.939521312713623\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2220000\n",
      "  num_agent_steps_trained: 2220000\n",
      "  num_steps_sampled: 2220000\n",
      "  num_steps_trained: 2220000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 555\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.209999999999994\n",
      "  ram_util_percent: 85.46000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06843766794373582\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07860154743681998\n",
      "  mean_inference_ms: 0.7513543394674558\n",
      "  mean_raw_obs_processing_ms: 0.0908744848633315\n",
      "time_since_restore: 3951.8343591690063\n",
      "time_this_iter_s: 7.14751410484314\n",
      "time_total_s: 3951.8343591690063\n",
      "timers:\n",
      "  learn_throughput: 1209.682\n",
      "  learn_time_ms: 3306.655\n",
      "  load_throughput: 21108726.724\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 508.86\n",
      "  sample_time_ms: 7860.709\n",
      "  update_time_ms: 2.107\n",
      "timestamp: 1658397907\n",
      "timesteps_since_restore: 2220000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2220000\n",
      "training_iteration: 555\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2224000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-05-14\n",
      "done: false\n",
      "episode_len_mean: 195.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.01\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11665\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30000773072242737\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005595763213932514\n",
      "        model: {}\n",
      "        policy_loss: -0.002403624588623643\n",
      "        total_loss: 2.253140926361084\n",
      "        vf_explained_var: -0.08661589026451111\n",
      "        vf_loss: 2.255544424057007\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2224000\n",
      "  num_agent_steps_trained: 2224000\n",
      "  num_steps_sampled: 2224000\n",
      "  num_steps_trained: 2224000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 556\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.666666666666664\n",
      "  ram_util_percent: 85.36666666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06843416770512928\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07859780927058609\n",
      "  mean_inference_ms: 0.7513292532270792\n",
      "  mean_raw_obs_processing_ms: 0.09087070658271175\n",
      "time_since_restore: 3958.4879007339478\n",
      "time_this_iter_s: 6.653541564941406\n",
      "time_total_s: 3958.4879007339478\n",
      "timers:\n",
      "  learn_throughput: 1290.4\n",
      "  learn_time_ms: 3099.814\n",
      "  load_throughput: 21124673.886\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 522.773\n",
      "  sample_time_ms: 7651.506\n",
      "  update_time_ms: 2.093\n",
      "timestamp: 1658397914\n",
      "timesteps_since_restore: 2224000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2224000\n",
      "training_iteration: 556\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2228000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-05-21\n",
      "done: false\n",
      "episode_len_mean: 194.74\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.74\n",
      "episode_reward_min: 14.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11685\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2868606448173523\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034730008337646723\n",
      "        model: {}\n",
      "        policy_loss: 0.006618629675358534\n",
      "        total_loss: 7.10087251663208\n",
      "        vf_explained_var: 1.0237898777631926e-06\n",
      "        vf_loss: 7.094254016876221\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2228000\n",
      "  num_agent_steps_trained: 2228000\n",
      "  num_steps_sampled: 2228000\n",
      "  num_steps_trained: 2228000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 557\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.8\n",
      "  ram_util_percent: 85.35\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06842953412364407\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07859286500768844\n",
      "  mean_inference_ms: 0.7512906270730614\n",
      "  mean_raw_obs_processing_ms: 0.09086573016145225\n",
      "time_since_restore: 3965.2703704833984\n",
      "time_this_iter_s: 6.782469749450684\n",
      "time_total_s: 3965.2703704833984\n",
      "timers:\n",
      "  learn_throughput: 1308.914\n",
      "  learn_time_ms: 3055.969\n",
      "  load_throughput: 21342343.213\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 544.033\n",
      "  sample_time_ms: 7352.498\n",
      "  update_time_ms: 2.077\n",
      "timestamp: 1658397921\n",
      "timesteps_since_restore: 2228000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2228000\n",
      "training_iteration: 557\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2232000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-05-28\n",
      "done: false\n",
      "episode_len_mean: 196.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.6\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11705\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3413485884666443\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030516358092427254\n",
      "        model: {}\n",
      "        policy_loss: 0.006215246394276619\n",
      "        total_loss: 6.760248184204102\n",
      "        vf_explained_var: 2.086162567138672e-07\n",
      "        vf_loss: 6.754032611846924\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2232000\n",
      "  num_agent_steps_trained: 2232000\n",
      "  num_steps_sampled: 2232000\n",
      "  num_steps_trained: 2232000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 558\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.660000000000004\n",
      "  ram_util_percent: 85.36999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06842549962090902\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07858850106652311\n",
      "  mean_inference_ms: 0.7512610138648269\n",
      "  mean_raw_obs_processing_ms: 0.09086133634895802\n",
      "time_since_restore: 3972.1454265117645\n",
      "time_this_iter_s: 6.875056028366089\n",
      "time_total_s: 3972.1454265117645\n",
      "timers:\n",
      "  learn_throughput: 1313.145\n",
      "  learn_time_ms: 3046.121\n",
      "  load_throughput: 20674326.556\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 548.879\n",
      "  sample_time_ms: 7287.575\n",
      "  update_time_ms: 2.069\n",
      "timestamp: 1658397928\n",
      "timesteps_since_restore: 2232000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2232000\n",
      "training_iteration: 558\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2236000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-05-35\n",
      "done: false\n",
      "episode_len_mean: 196.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.52\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11725\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3317560851573944\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004166766069829464\n",
      "        model: {}\n",
      "        policy_loss: 0.004324335139244795\n",
      "        total_loss: 6.61722993850708\n",
      "        vf_explained_var: 1.1003786539731664e-06\n",
      "        vf_loss: 6.612905502319336\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2236000\n",
      "  num_agent_steps_trained: 2236000\n",
      "  num_steps_sampled: 2236000\n",
      "  num_steps_trained: 2236000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 559\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.71818181818181\n",
      "  ram_util_percent: 85.45454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06842474957155416\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07858778507732884\n",
      "  mean_inference_ms: 0.7512659599314856\n",
      "  mean_raw_obs_processing_ms: 0.09086150794674125\n",
      "time_since_restore: 3979.619162797928\n",
      "time_this_iter_s: 7.47373628616333\n",
      "time_total_s: 3979.619162797928\n",
      "timers:\n",
      "  learn_throughput: 1312.914\n",
      "  learn_time_ms: 3046.658\n",
      "  load_throughput: 21751868.274\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 553.979\n",
      "  sample_time_ms: 7220.484\n",
      "  update_time_ms: 2.129\n",
      "timestamp: 1658397935\n",
      "timesteps_since_restore: 2236000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2236000\n",
      "training_iteration: 559\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2240000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-05-44\n",
      "done: false\n",
      "episode_len_mean: 198.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.19\n",
      "episode_reward_min: 142.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11745\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33124908804893494\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003497442463412881\n",
      "        model: {}\n",
      "        policy_loss: -0.0009939229348674417\n",
      "        total_loss: 2.352837324142456\n",
      "        vf_explained_var: -0.029732603579759598\n",
      "        vf_loss: 2.3538310527801514\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2240000\n",
      "  num_agent_steps_trained: 2240000\n",
      "  num_steps_sampled: 2240000\n",
      "  num_steps_trained: 2240000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 560\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.208333333333336\n",
      "  ram_util_percent: 85.71666666666668\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0684307023628369\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07859438364876423\n",
      "  mean_inference_ms: 0.7513358686085608\n",
      "  mean_raw_obs_processing_ms: 0.09086952894197055\n",
      "time_since_restore: 3988.1784179210663\n",
      "time_this_iter_s: 8.559255123138428\n",
      "time_total_s: 3988.1784179210663\n",
      "timers:\n",
      "  learn_throughput: 1333.62\n",
      "  learn_time_ms: 2999.356\n",
      "  load_throughput: 23438412.965\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 551.457\n",
      "  sample_time_ms: 7253.51\n",
      "  update_time_ms: 2.115\n",
      "timestamp: 1658397944\n",
      "timesteps_since_restore: 2240000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2240000\n",
      "training_iteration: 560\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2244000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-05-54\n",
      "done: false\n",
      "episode_len_mean: 196.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.76\n",
      "episode_reward_min: 31.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11766\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.34096062183380127\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00390157219953835\n",
      "        model: {}\n",
      "        policy_loss: 0.000575296871829778\n",
      "        total_loss: 2.4930150508880615\n",
      "        vf_explained_var: -0.13915134966373444\n",
      "        vf_loss: 2.4924395084381104\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2244000\n",
      "  num_agent_steps_trained: 2244000\n",
      "  num_steps_sampled: 2244000\n",
      "  num_steps_trained: 2244000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 561\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 57.17142857142857\n",
      "  ram_util_percent: 85.89285714285715\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06845254797618495\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07861953893173518\n",
      "  mean_inference_ms: 0.7515748625298069\n",
      "  mean_raw_obs_processing_ms: 0.09089558655297054\n",
      "time_since_restore: 3998.1913924217224\n",
      "time_this_iter_s: 10.012974500656128\n",
      "time_total_s: 3998.1913924217224\n",
      "timers:\n",
      "  learn_throughput: 1296.583\n",
      "  learn_time_ms: 3085.032\n",
      "  load_throughput: 23494210.895\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 545.18\n",
      "  sample_time_ms: 7337.027\n",
      "  update_time_ms: 2.198\n",
      "timestamp: 1658397954\n",
      "timesteps_since_restore: 2244000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2244000\n",
      "training_iteration: 561\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2248000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-06-02\n",
      "done: false\n",
      "episode_len_mean: 196.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.02\n",
      "episode_reward_min: 31.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11787\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33241069316864014\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038160348776727915\n",
      "        model: {}\n",
      "        policy_loss: 0.0028685324359685183\n",
      "        total_loss: 5.360742092132568\n",
      "        vf_explained_var: -0.03526328131556511\n",
      "        vf_loss: 5.357873916625977\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2248000\n",
      "  num_agent_steps_trained: 2248000\n",
      "  num_steps_sampled: 2248000\n",
      "  num_steps_trained: 2248000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 562\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.81818181818182\n",
      "  ram_util_percent: 86.48181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06847842029110801\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07864906091206827\n",
      "  mean_inference_ms: 0.7518509887015011\n",
      "  mean_raw_obs_processing_ms: 0.09092592245397588\n",
      "time_since_restore: 4006.00759267807\n",
      "time_this_iter_s: 7.816200256347656\n",
      "time_total_s: 4006.00759267807\n",
      "timers:\n",
      "  learn_throughput: 1282.465\n",
      "  learn_time_ms: 3118.995\n",
      "  load_throughput: 23580064.652\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 536.764\n",
      "  sample_time_ms: 7452.061\n",
      "  update_time_ms: 2.251\n",
      "timestamp: 1658397962\n",
      "timesteps_since_restore: 2248000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2248000\n",
      "training_iteration: 562\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2252000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-06-09\n",
      "done: false\n",
      "episode_len_mean: 196.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.02\n",
      "episode_reward_min: 31.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11807\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3476985991001129\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003737536957487464\n",
      "        model: {}\n",
      "        policy_loss: 0.004363784100860357\n",
      "        total_loss: 6.859202861785889\n",
      "        vf_explained_var: 8.431173341705289e-07\n",
      "        vf_loss: 6.854838848114014\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2252000\n",
      "  num_agent_steps_trained: 2252000\n",
      "  num_steps_sampled: 2252000\n",
      "  num_steps_trained: 2252000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 563\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.90909090909091\n",
      "  ram_util_percent: 86.55454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06850676032352024\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07868111282280346\n",
      "  mean_inference_ms: 0.7521483836384448\n",
      "  mean_raw_obs_processing_ms: 0.09095919376041646\n",
      "time_since_restore: 4013.739912748337\n",
      "time_this_iter_s: 7.732320070266724\n",
      "time_total_s: 4013.739912748337\n",
      "timers:\n",
      "  learn_throughput: 1265.504\n",
      "  learn_time_ms: 3160.797\n",
      "  load_throughput: 23240360.161\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 529.331\n",
      "  sample_time_ms: 7556.715\n",
      "  update_time_ms: 2.268\n",
      "timestamp: 1658397969\n",
      "timesteps_since_restore: 2252000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2252000\n",
      "training_iteration: 563\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2256000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-06-16\n",
      "done: false\n",
      "episode_len_mean: 194.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.94\n",
      "episode_reward_min: 31.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11827\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.34313079714775085\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005523451138287783\n",
      "        model: {}\n",
      "        policy_loss: -0.001237187534570694\n",
      "        total_loss: 4.076385498046875\n",
      "        vf_explained_var: -0.10156342387199402\n",
      "        vf_loss: 4.077622413635254\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2256000\n",
      "  num_agent_steps_trained: 2256000\n",
      "  num_steps_sampled: 2256000\n",
      "  num_steps_trained: 2256000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 564\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.25454545454545\n",
      "  ram_util_percent: 86.11818181818181\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06853265563137637\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0787103052510388\n",
      "  mean_inference_ms: 0.7524229656983015\n",
      "  mean_raw_obs_processing_ms: 0.09099037222626671\n",
      "time_since_restore: 4020.883928537369\n",
      "time_this_iter_s: 7.144015789031982\n",
      "time_total_s: 4020.883928537369\n",
      "timers:\n",
      "  learn_throughput: 1261.264\n",
      "  learn_time_ms: 3171.422\n",
      "  load_throughput: 22687242.732\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 524.177\n",
      "  sample_time_ms: 7631.003\n",
      "  update_time_ms: 2.255\n",
      "timestamp: 1658397976\n",
      "timesteps_since_restore: 2256000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2256000\n",
      "training_iteration: 564\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2260000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-06-24\n",
      "done: false\n",
      "episode_len_mean: 195.95\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.95\n",
      "episode_reward_min: 31.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11847\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3241899311542511\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0052137067541480064\n",
      "        model: {}\n",
      "        policy_loss: -0.001831227564252913\n",
      "        total_loss: 1.0062334537506104\n",
      "        vf_explained_var: -0.0568448007106781\n",
      "        vf_loss: 1.0080645084381104\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2260000\n",
      "  num_agent_steps_trained: 2260000\n",
      "  num_steps_sampled: 2260000\n",
      "  num_steps_trained: 2260000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 565\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.76363636363636\n",
      "  ram_util_percent: 86.10909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06855291037705656\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07873333943688009\n",
      "  mean_inference_ms: 0.7526439009760175\n",
      "  mean_raw_obs_processing_ms: 0.0910146212133296\n",
      "time_since_restore: 4028.7879207134247\n",
      "time_this_iter_s: 7.903992176055908\n",
      "time_total_s: 4028.7879207134247\n",
      "timers:\n",
      "  learn_throughput: 1240.888\n",
      "  learn_time_ms: 3223.497\n",
      "  load_throughput: 22274583.112\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 521.839\n",
      "  sample_time_ms: 7665.203\n",
      "  update_time_ms: 2.193\n",
      "timestamp: 1658397984\n",
      "timesteps_since_restore: 2260000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2260000\n",
      "training_iteration: 565\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2264000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-06-32\n",
      "done: false\n",
      "episode_len_mean: 197.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.83\n",
      "episode_reward_min: 99.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11867\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31820935010910034\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005760726984590292\n",
      "        model: {}\n",
      "        policy_loss: -0.002594824181869626\n",
      "        total_loss: 1.005469799041748\n",
      "        vf_explained_var: 0.008878706023097038\n",
      "        vf_loss: 1.0080646276474\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2264000\n",
      "  num_agent_steps_trained: 2264000\n",
      "  num_steps_sampled: 2264000\n",
      "  num_steps_trained: 2264000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 566\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.345454545454544\n",
      "  ram_util_percent: 85.98181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06856348367795854\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07874509762442033\n",
      "  mean_inference_ms: 0.7527609092450731\n",
      "  mean_raw_obs_processing_ms: 0.09102821965576116\n",
      "time_since_restore: 4036.2558438777924\n",
      "time_this_iter_s: 7.467923164367676\n",
      "time_total_s: 4036.2558438777924\n",
      "timers:\n",
      "  learn_throughput: 1233.514\n",
      "  learn_time_ms: 3242.768\n",
      "  load_throughput: 22159841.5\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 514.175\n",
      "  sample_time_ms: 7779.447\n",
      "  update_time_ms: 2.183\n",
      "timestamp: 1658397992\n",
      "timesteps_since_restore: 2264000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2264000\n",
      "training_iteration: 566\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2268000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-06-39\n",
      "done: false\n",
      "episode_len_mean: 197.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.83\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11888\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35034725069999695\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032007163390517235\n",
      "        model: {}\n",
      "        policy_loss: 0.005447104573249817\n",
      "        total_loss: 6.368855953216553\n",
      "        vf_explained_var: 2.3074687760527013e-06\n",
      "        vf_loss: 6.363408088684082\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2268000\n",
      "  num_agent_steps_trained: 2268000\n",
      "  num_steps_sampled: 2268000\n",
      "  num_steps_trained: 2268000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 567\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.449999999999996\n",
      "  ram_util_percent: 86.03\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06857361147781525\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07875649391533762\n",
      "  mean_inference_ms: 0.7528744109253718\n",
      "  mean_raw_obs_processing_ms: 0.09104173275611858\n",
      "time_since_restore: 4043.6131823062897\n",
      "time_this_iter_s: 7.3573384284973145\n",
      "time_total_s: 4043.6131823062897\n",
      "timers:\n",
      "  learn_throughput: 1227.513\n",
      "  learn_time_ms: 3258.622\n",
      "  load_throughput: 21805583.572\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 510.192\n",
      "  sample_time_ms: 7840.186\n",
      "  update_time_ms: 2.169\n",
      "timestamp: 1658397999\n",
      "timesteps_since_restore: 2268000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2268000\n",
      "training_iteration: 567\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2272000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-06-46\n",
      "done: false\n",
      "episode_len_mean: 196.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.16\n",
      "episode_reward_min: 115.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 11909\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3098013401031494\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0052400813437998295\n",
      "        model: {}\n",
      "        policy_loss: 5.5920179875101894e-05\n",
      "        total_loss: 2.8906824588775635\n",
      "        vf_explained_var: -0.0005084762233309448\n",
      "        vf_loss: 2.8906266689300537\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2272000\n",
      "  num_agent_steps_trained: 2272000\n",
      "  num_steps_sampled: 2272000\n",
      "  num_steps_trained: 2272000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 568\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.86\n",
      "  ram_util_percent: 86.01\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06858174408392995\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876598618028627\n",
      "  mean_inference_ms: 0.7529694738775297\n",
      "  mean_raw_obs_processing_ms: 0.09105258923179656\n",
      "time_since_restore: 4050.689938545227\n",
      "time_this_iter_s: 7.076756238937378\n",
      "time_total_s: 4050.689938545227\n",
      "timers:\n",
      "  learn_throughput: 1230.934\n",
      "  learn_time_ms: 3249.566\n",
      "  load_throughput: 22810626.785\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 507.282\n",
      "  sample_time_ms: 7885.162\n",
      "  update_time_ms: 2.179\n",
      "timestamp: 1658398006\n",
      "timesteps_since_restore: 2272000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2272000\n",
      "training_iteration: 568\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2276000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-06-54\n",
      "done: false\n",
      "episode_len_mean: 197.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.32\n",
      "episode_reward_min: 115.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11929\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31086796522140503\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005042757838964462\n",
      "        model: {}\n",
      "        policy_loss: 0.006049623712897301\n",
      "        total_loss: 7.66733980178833\n",
      "        vf_explained_var: 1.196707444250933e-06\n",
      "        vf_loss: 7.661290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2276000\n",
      "  num_agent_steps_trained: 2276000\n",
      "  num_steps_sampled: 2276000\n",
      "  num_steps_trained: 2276000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 569\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.80909090909091\n",
      "  ram_util_percent: 85.98181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06858816879757074\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877343381092738\n",
      "  mean_inference_ms: 0.7530446851339562\n",
      "  mean_raw_obs_processing_ms: 0.09106008018574709\n",
      "time_since_restore: 4057.8304398059845\n",
      "time_this_iter_s: 7.140501260757446\n",
      "time_total_s: 4057.8304398059845\n",
      "timers:\n",
      "  learn_throughput: 1226.766\n",
      "  learn_time_ms: 3260.607\n",
      "  load_throughput: 22659665.046\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 510.773\n",
      "  sample_time_ms: 7831.268\n",
      "  update_time_ms: 2.136\n",
      "timestamp: 1658398014\n",
      "timesteps_since_restore: 2276000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2276000\n",
      "training_iteration: 569\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2280000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-01\n",
      "done: false\n",
      "episode_len_mean: 196.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.28\n",
      "episode_reward_min: 115.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11949\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28736039996147156\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005110634956508875\n",
      "        model: {}\n",
      "        policy_loss: 2.6317437004763633e-05\n",
      "        total_loss: 3.029261350631714\n",
      "        vf_explained_var: -0.004115321207791567\n",
      "        vf_loss: 3.0292348861694336\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2280000\n",
      "  num_agent_steps_trained: 2280000\n",
      "  num_steps_sampled: 2280000\n",
      "  num_steps_trained: 2280000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 570\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.01\n",
      "  ram_util_percent: 85.94999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859230524569482\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877796878510089\n",
      "  mean_inference_ms: 0.7530990208261045\n",
      "  mean_raw_obs_processing_ms: 0.09106539848695544\n",
      "time_since_restore: 4065.3207676410675\n",
      "time_this_iter_s: 7.490327835083008\n",
      "time_total_s: 4065.3207676410675\n",
      "timers:\n",
      "  learn_throughput: 1228.066\n",
      "  learn_time_ms: 3257.153\n",
      "  load_throughput: 22601665.095\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 516.973\n",
      "  sample_time_ms: 7737.342\n",
      "  update_time_ms: 2.133\n",
      "timestamp: 1658398021\n",
      "timesteps_since_restore: 2280000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2280000\n",
      "training_iteration: 570\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2284000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-08\n",
      "done: false\n",
      "episode_len_mean: 196.63\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.63\n",
      "episode_reward_min: 115.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11969\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2956937253475189\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038906922563910484\n",
      "        model: {}\n",
      "        policy_loss: -0.0003669248544611037\n",
      "        total_loss: 2.4189887046813965\n",
      "        vf_explained_var: 0.026553479954600334\n",
      "        vf_loss: 2.4193553924560547\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2284000\n",
      "  num_agent_steps_trained: 2284000\n",
      "  num_steps_sampled: 2284000\n",
      "  num_steps_trained: 2284000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 571\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.69090909090909\n",
      "  ram_util_percent: 86.05454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859463369695253\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07878022099117515\n",
      "  mean_inference_ms: 0.7531361997870379\n",
      "  mean_raw_obs_processing_ms: 0.09106861761300433\n",
      "time_since_restore: 4072.673372030258\n",
      "time_this_iter_s: 7.352604389190674\n",
      "time_total_s: 4072.673372030258\n",
      "timers:\n",
      "  learn_throughput: 1253.392\n",
      "  learn_time_ms: 3191.341\n",
      "  load_throughput: 22644373.06\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 530.895\n",
      "  sample_time_ms: 7534.451\n",
      "  update_time_ms: 2.047\n",
      "timestamp: 1658398028\n",
      "timesteps_since_restore: 2284000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2284000\n",
      "training_iteration: 571\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2288000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-15\n",
      "done: false\n",
      "episode_len_mean: 197.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.2\n",
      "episode_reward_min: 115.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 11989\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3284052312374115\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00448572589084506\n",
      "        model: {}\n",
      "        policy_loss: -0.0008550014463253319\n",
      "        total_loss: 2.214366912841797\n",
      "        vf_explained_var: -0.19353729486465454\n",
      "        vf_loss: 2.215221881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2288000\n",
      "  num_agent_steps_trained: 2288000\n",
      "  num_steps_sampled: 2288000\n",
      "  num_steps_trained: 2288000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 572\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.14\n",
      "  ram_util_percent: 85.95\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859458431049188\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877972196232232\n",
      "  mean_inference_ms: 0.7531489967048393\n",
      "  mean_raw_obs_processing_ms: 0.09106887526683247\n",
      "time_since_restore: 4079.664823770523\n",
      "time_this_iter_s: 6.991451740264893\n",
      "time_total_s: 4079.664823770523\n",
      "timers:\n",
      "  learn_throughput: 1265.852\n",
      "  learn_time_ms: 3159.927\n",
      "  load_throughput: 22671913.514\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 539.323\n",
      "  sample_time_ms: 7416.702\n",
      "  update_time_ms: 1.983\n",
      "timestamp: 1658398035\n",
      "timesteps_since_restore: 2288000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2288000\n",
      "training_iteration: 572\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2292000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-22\n",
      "done: false\n",
      "episode_len_mean: 197.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.16\n",
      "episode_reward_min: 68.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12010\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32041072845458984\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004100184887647629\n",
      "        model: {}\n",
      "        policy_loss: 5.296065137372352e-05\n",
      "        total_loss: 4.879091262817383\n",
      "        vf_explained_var: -0.07092738151550293\n",
      "        vf_loss: 4.879037857055664\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2292000\n",
      "  num_agent_steps_trained: 2292000\n",
      "  num_steps_sampled: 2292000\n",
      "  num_steps_trained: 2292000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 573\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.15\n",
      "  ram_util_percent: 85.97\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859328863782906\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877766402303304\n",
      "  mean_inference_ms: 0.7531481073407379\n",
      "  mean_raw_obs_processing_ms: 0.0910669613921173\n",
      "time_since_restore: 4086.5311300754547\n",
      "time_this_iter_s: 6.866306304931641\n",
      "time_total_s: 4086.5311300754547\n",
      "timers:\n",
      "  learn_throughput: 1280.319\n",
      "  learn_time_ms: 3124.222\n",
      "  load_throughput: 22951047.88\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 545.427\n",
      "  sample_time_ms: 7333.707\n",
      "  update_time_ms: 1.963\n",
      "timestamp: 1658398042\n",
      "timesteps_since_restore: 2292000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2292000\n",
      "training_iteration: 573\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2296000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-29\n",
      "done: false\n",
      "episode_len_mean: 196.64\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.64\n",
      "episode_reward_min: 68.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12030\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3086041212081909\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003514573909342289\n",
      "        model: {}\n",
      "        policy_loss: 0.00017285706417169422\n",
      "        total_loss: 2.1171088218688965\n",
      "        vf_explained_var: -0.02236764132976532\n",
      "        vf_loss: 2.1169357299804688\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2296000\n",
      "  num_agent_steps_trained: 2296000\n",
      "  num_steps_sampled: 2296000\n",
      "  num_steps_trained: 2296000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 574\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.28\n",
      "  ram_util_percent: 85.98999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859260374783611\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877645295187502\n",
      "  mean_inference_ms: 0.7531523114516736\n",
      "  mean_raw_obs_processing_ms: 0.09106616736724499\n",
      "time_since_restore: 4093.6473486423492\n",
      "time_this_iter_s: 7.116218566894531\n",
      "time_total_s: 4093.6473486423492\n",
      "timers:\n",
      "  learn_throughput: 1277.511\n",
      "  learn_time_ms: 3131.087\n",
      "  load_throughput: 23464637.762\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 548.844\n",
      "  sample_time_ms: 7288.049\n",
      "  update_time_ms: 2.03\n",
      "timestamp: 1658398049\n",
      "timesteps_since_restore: 2296000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2296000\n",
      "training_iteration: 574\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2300000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-37\n",
      "done: false\n",
      "episode_len_mean: 195.67\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.67\n",
      "episode_reward_min: 68.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12051\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3343915641307831\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006860620342195034\n",
      "        model: {}\n",
      "        policy_loss: -0.0019430846441537142\n",
      "        total_loss: 3.541405200958252\n",
      "        vf_explained_var: -0.03462284058332443\n",
      "        vf_loss: 3.5433478355407715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2300000\n",
      "  num_agent_steps_trained: 2300000\n",
      "  num_steps_sampled: 2300000\n",
      "  num_steps_trained: 2300000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 575\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.269999999999996\n",
      "  ram_util_percent: 86.00999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685929044056275\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877595337009785\n",
      "  mean_inference_ms: 0.7531634637997281\n",
      "  mean_raw_obs_processing_ms: 0.09106594161530192\n",
      "time_since_restore: 4101.027126550674\n",
      "time_this_iter_s: 7.379777908325195\n",
      "time_total_s: 4101.027126550674\n",
      "timers:\n",
      "  learn_throughput: 1290.206\n",
      "  learn_time_ms: 3100.281\n",
      "  load_throughput: 23760396.544\n",
      "  load_time_ms: 0.168\n",
      "  sample_throughput: 549.811\n",
      "  sample_time_ms: 7275.233\n",
      "  update_time_ms: 2.007\n",
      "timestamp: 1658398057\n",
      "timesteps_since_restore: 2300000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2300000\n",
      "training_iteration: 575\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2304000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-44\n",
      "done: false\n",
      "episode_len_mean: 195.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.41\n",
      "episode_reward_min: 68.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12072\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3175541162490845\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0051399096846580505\n",
      "        model: {}\n",
      "        policy_loss: -0.012043149210512638\n",
      "        total_loss: 9.163887023925781\n",
      "        vf_explained_var: 6.865942395961611e-06\n",
      "        vf_loss: 9.17593002319336\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2304000\n",
      "  num_agent_steps_trained: 2304000\n",
      "  num_steps_sampled: 2304000\n",
      "  num_steps_trained: 2304000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 576\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.17272727272728\n",
      "  ram_util_percent: 85.95454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859215169859503\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877425914734476\n",
      "  mean_inference_ms: 0.7531591397441187\n",
      "  mean_raw_obs_processing_ms: 0.09106377689880515\n",
      "time_since_restore: 4108.247799873352\n",
      "time_this_iter_s: 7.220673322677612\n",
      "time_total_s: 4108.247799873352\n",
      "timers:\n",
      "  learn_throughput: 1278.866\n",
      "  learn_time_ms: 3127.77\n",
      "  load_throughput: 23673227.035\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 556.225\n",
      "  sample_time_ms: 7191.329\n",
      "  update_time_ms: 2.136\n",
      "timestamp: 1658398064\n",
      "timesteps_since_restore: 2304000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2304000\n",
      "training_iteration: 576\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2308000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-51\n",
      "done: false\n",
      "episode_len_mean: 194.74\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.74\n",
      "episode_reward_min: 68.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12092\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3035459816455841\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007074653636664152\n",
      "        model: {}\n",
      "        policy_loss: 0.005218022037297487\n",
      "        total_loss: 8.765298843383789\n",
      "        vf_explained_var: 1.6632259303150931e-06\n",
      "        vf_loss: 8.760080337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2308000\n",
      "  num_agent_steps_trained: 2308000\n",
      "  num_steps_sampled: 2308000\n",
      "  num_steps_trained: 2308000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 577\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.6\n",
      "  ram_util_percent: 85.98\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859190448782668\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877340359751372\n",
      "  mean_inference_ms: 0.7531631087680779\n",
      "  mean_raw_obs_processing_ms: 0.09106250867024045\n",
      "time_since_restore: 4115.383779287338\n",
      "time_this_iter_s: 7.135979413986206\n",
      "time_total_s: 4115.383779287338\n",
      "timers:\n",
      "  learn_throughput: 1277.485\n",
      "  learn_time_ms: 3131.153\n",
      "  load_throughput: 24188604.383\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 555.921\n",
      "  sample_time_ms: 7195.267\n",
      "  update_time_ms: 2.158\n",
      "timestamp: 1658398071\n",
      "timesteps_since_restore: 2308000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2308000\n",
      "training_iteration: 577\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2312000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-07-58\n",
      "done: false\n",
      "episode_len_mean: 196.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.05\n",
      "episode_reward_min: 99.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12112\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3147439956665039\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038226544857025146\n",
      "        model: {}\n",
      "        policy_loss: 0.0010789398802444339\n",
      "        total_loss: 4.592813014984131\n",
      "        vf_explained_var: 3.3301050734735327e-06\n",
      "        vf_loss: 4.591733932495117\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2312000\n",
      "  num_agent_steps_trained: 2312000\n",
      "  num_steps_sampled: 2312000\n",
      "  num_steps_trained: 2312000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 578\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.32000000000001\n",
      "  ram_util_percent: 85.99\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859170295796414\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877279083033432\n",
      "  mean_inference_ms: 0.7531715252314919\n",
      "  mean_raw_obs_processing_ms: 0.09106220916908753\n",
      "time_since_restore: 4122.466479063034\n",
      "time_this_iter_s: 7.082699775695801\n",
      "time_total_s: 4122.466479063034\n",
      "timers:\n",
      "  learn_throughput: 1270.844\n",
      "  learn_time_ms: 3147.516\n",
      "  load_throughput: 23726793.947\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 556.859\n",
      "  sample_time_ms: 7183.151\n",
      "  update_time_ms: 2.193\n",
      "timestamp: 1658398078\n",
      "timesteps_since_restore: 2312000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2312000\n",
      "training_iteration: 578\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2316000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-08-05\n",
      "done: false\n",
      "episode_len_mean: 194.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.46\n",
      "episode_reward_min: 99.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12133\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.289146363735199\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004844265524297953\n",
      "        model: {}\n",
      "        policy_loss: -0.00058321951655671\n",
      "        total_loss: 4.376937389373779\n",
      "        vf_explained_var: -0.0022140005603432655\n",
      "        vf_loss: 4.377520561218262\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2316000\n",
      "  num_agent_steps_trained: 2316000\n",
      "  num_steps_sampled: 2316000\n",
      "  num_steps_trained: 2316000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 579\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.900000000000006\n",
      "  ram_util_percent: 86.02\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859141774799551\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877210384112163\n",
      "  mean_inference_ms: 0.7531779203662542\n",
      "  mean_raw_obs_processing_ms: 0.09106191161395367\n",
      "time_since_restore: 4129.525511264801\n",
      "time_this_iter_s: 7.059032201766968\n",
      "time_total_s: 4129.525511264801\n",
      "timers:\n",
      "  learn_throughput: 1278.723\n",
      "  learn_time_ms: 3128.12\n",
      "  load_throughput: 23636539.87\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 554.707\n",
      "  sample_time_ms: 7211.013\n",
      "  update_time_ms: 2.179\n",
      "timestamp: 1658398085\n",
      "timesteps_since_restore: 2316000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2316000\n",
      "training_iteration: 579\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2320000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-08-13\n",
      "done: false\n",
      "episode_len_mean: 195.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.06\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12154\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32549819350242615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004702544305473566\n",
      "        model: {}\n",
      "        policy_loss: 0.0020874678157269955\n",
      "        total_loss: 6.327704906463623\n",
      "        vf_explained_var: 4.475090918276692e-06\n",
      "        vf_loss: 6.32561731338501\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2320000\n",
      "  num_agent_steps_trained: 2320000\n",
      "  num_steps_sampled: 2320000\n",
      "  num_steps_trained: 2320000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 580\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.56999999999999\n",
      "  ram_util_percent: 85.95000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859016835838466\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877090316300393\n",
      "  mean_inference_ms: 0.7531788774582989\n",
      "  mean_raw_obs_processing_ms: 0.09106099632231784\n",
      "time_since_restore: 4136.767026424408\n",
      "time_this_iter_s: 7.241515159606934\n",
      "time_total_s: 4136.767026424408\n",
      "timers:\n",
      "  learn_throughput: 1287.884\n",
      "  learn_time_ms: 3105.869\n",
      "  load_throughput: 23533757.89\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 556.381\n",
      "  sample_time_ms: 7189.323\n",
      "  update_time_ms: 2.219\n",
      "timestamp: 1658398093\n",
      "timesteps_since_restore: 2320000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2320000\n",
      "training_iteration: 580\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2324000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-08-20\n",
      "done: false\n",
      "episode_len_mean: 194.84\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.84\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12174\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3188764750957489\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005565547849982977\n",
      "        model: {}\n",
      "        policy_loss: -0.003804563544690609\n",
      "        total_loss: 3.675631046295166\n",
      "        vf_explained_var: 3.908782673534006e-06\n",
      "        vf_loss: 3.6794354915618896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2324000\n",
      "  num_agent_steps_trained: 2324000\n",
      "  num_steps_sampled: 2324000\n",
      "  num_steps_trained: 2324000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 581\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.71818181818182\n",
      "  ram_util_percent: 85.74545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859143733462444\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877237247790055\n",
      "  mean_inference_ms: 0.7532083615359594\n",
      "  mean_raw_obs_processing_ms: 0.09106353800523742\n",
      "time_since_restore: 4144.047460794449\n",
      "time_this_iter_s: 7.2804343700408936\n",
      "time_total_s: 4144.047460794449\n",
      "timers:\n",
      "  learn_throughput: 1299.246\n",
      "  learn_time_ms: 3078.708\n",
      "  load_throughput: 23570126.44\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 556.565\n",
      "  sample_time_ms: 7186.944\n",
      "  update_time_ms: 2.233\n",
      "timestamp: 1658398100\n",
      "timesteps_since_restore: 2324000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2324000\n",
      "training_iteration: 581\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2328000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-08-27\n",
      "done: false\n",
      "episode_len_mean: 194.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.71\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12195\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3130289316177368\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004356312565505505\n",
      "        model: {}\n",
      "        policy_loss: -0.01555596198886633\n",
      "        total_loss: 2.129101276397705\n",
      "        vf_explained_var: -0.11113975197076797\n",
      "        vf_loss: 2.1446573734283447\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2328000\n",
      "  num_agent_steps_trained: 2328000\n",
      "  num_steps_sampled: 2328000\n",
      "  num_steps_trained: 2328000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 582\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.559999999999995\n",
      "  ram_util_percent: 85.67999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685913824228973\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877204309144904\n",
      "  mean_inference_ms: 0.7532200658778642\n",
      "  mean_raw_obs_processing_ms: 0.09106438134005074\n",
      "time_since_restore: 4150.823458909988\n",
      "time_this_iter_s: 6.775998115539551\n",
      "time_total_s: 4150.823458909988\n",
      "timers:\n",
      "  learn_throughput: 1302.669\n",
      "  learn_time_ms: 3070.619\n",
      "  load_throughput: 23527157.481\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 559.712\n",
      "  sample_time_ms: 7146.537\n",
      "  update_time_ms: 2.263\n",
      "timestamp: 1658398107\n",
      "timesteps_since_restore: 2328000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2328000\n",
      "training_iteration: 582\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2332000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-08-34\n",
      "done: false\n",
      "episode_len_mean: 194.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.89\n",
      "episode_reward_min: 105.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12215\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3134649991989136\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003977938089519739\n",
      "        model: {}\n",
      "        policy_loss: 0.00737517885863781\n",
      "        total_loss: 8.727133750915527\n",
      "        vf_explained_var: 1.9973324469901854e-06\n",
      "        vf_loss: 8.719758033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2332000\n",
      "  num_agent_steps_trained: 2332000\n",
      "  num_steps_sampled: 2332000\n",
      "  num_steps_trained: 2332000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 583\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.77\n",
      "  ram_util_percent: 85.66000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859194528224453\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0787722327343663\n",
      "  mean_inference_ms: 0.7532371893690865\n",
      "  mean_raw_obs_processing_ms: 0.09106586385010043\n",
      "time_since_restore: 4158.116797685623\n",
      "time_this_iter_s: 7.293338775634766\n",
      "time_total_s: 4158.116797685623\n",
      "timers:\n",
      "  learn_throughput: 1291.24\n",
      "  learn_time_ms: 3097.798\n",
      "  load_throughput: 23201792.283\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 559.014\n",
      "  sample_time_ms: 7155.456\n",
      "  update_time_ms: 2.267\n",
      "timestamp: 1658398114\n",
      "timesteps_since_restore: 2332000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2332000\n",
      "training_iteration: 583\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2336000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-08-41\n",
      "done: false\n",
      "episode_len_mean: 195.82\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.82\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12235\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32058027386665344\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00406472897157073\n",
      "        model: {}\n",
      "        policy_loss: 0.003928270190954208\n",
      "        total_loss: 6.795766830444336\n",
      "        vf_explained_var: 5.906691967538791e-06\n",
      "        vf_loss: 6.791837692260742\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2336000\n",
      "  num_agent_steps_trained: 2336000\n",
      "  num_steps_sampled: 2336000\n",
      "  num_steps_trained: 2336000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 584\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.49999999999999\n",
      "  ram_util_percent: 85.69\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859164144777953\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877147313793692\n",
      "  mean_inference_ms: 0.7532470299200748\n",
      "  mean_raw_obs_processing_ms: 0.09106609286121448\n",
      "time_since_restore: 4164.862763881683\n",
      "time_this_iter_s: 6.745966196060181\n",
      "time_total_s: 4164.862763881683\n",
      "timers:\n",
      "  learn_throughput: 1302.746\n",
      "  learn_time_ms: 3070.438\n",
      "  load_throughput: 23373106.715\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 557.599\n",
      "  sample_time_ms: 7173.613\n",
      "  update_time_ms: 2.194\n",
      "timestamp: 1658398121\n",
      "timesteps_since_restore: 2336000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2336000\n",
      "training_iteration: 584\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2340000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-08-48\n",
      "done: false\n",
      "episode_len_mean: 196.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.08\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12256\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3232034742832184\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00624522939324379\n",
      "        model: {}\n",
      "        policy_loss: 0.001128256437368691\n",
      "        total_loss: 6.9114203453063965\n",
      "        vf_explained_var: 6.683539140794892e-06\n",
      "        vf_loss: 6.91029167175293\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2340000\n",
      "  num_agent_steps_trained: 2340000\n",
      "  num_steps_sampled: 2340000\n",
      "  num_steps_trained: 2340000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 585\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.68\n",
      "  ram_util_percent: 85.75\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06859007795676385\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876881478036121\n",
      "  mean_inference_ms: 0.7532402328438331\n",
      "  mean_raw_obs_processing_ms: 0.09106428865282533\n",
      "time_since_restore: 4171.7661216259\n",
      "time_this_iter_s: 6.903357744216919\n",
      "time_total_s: 4171.7661216259\n",
      "timers:\n",
      "  learn_throughput: 1307.531\n",
      "  learn_time_ms: 3059.202\n",
      "  load_throughput: 23350335.421\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 562.755\n",
      "  sample_time_ms: 7107.884\n",
      "  update_time_ms: 2.223\n",
      "timestamp: 1658398128\n",
      "timesteps_since_restore: 2340000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2340000\n",
      "training_iteration: 585\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2344000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-08-55\n",
      "done: false\n",
      "episode_len_mean: 192.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.36\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 12278\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31872135400772095\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005682078655809164\n",
      "        model: {}\n",
      "        policy_loss: 0.0006712406175211072\n",
      "        total_loss: 5.613070011138916\n",
      "        vf_explained_var: 5.757680355600314e-06\n",
      "        vf_loss: 5.612399101257324\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2344000\n",
      "  num_agent_steps_trained: 2344000\n",
      "  num_steps_sampled: 2344000\n",
      "  num_steps_trained: 2344000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 586\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.17999999999999\n",
      "  ram_util_percent: 85.54\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0685867823749211\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876440798828345\n",
      "  mean_inference_ms: 0.7532145193853224\n",
      "  mean_raw_obs_processing_ms: 0.09106041928046917\n",
      "time_since_restore: 4179.117810249329\n",
      "time_this_iter_s: 7.351688623428345\n",
      "time_total_s: 4179.117810249329\n",
      "timers:\n",
      "  learn_throughput: 1306.333\n",
      "  learn_time_ms: 3062.007\n",
      "  load_throughput: 23334097.357\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 562.774\n",
      "  sample_time_ms: 7107.653\n",
      "  update_time_ms: 2.07\n",
      "timestamp: 1658398135\n",
      "timesteps_since_restore: 2344000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2344000\n",
      "training_iteration: 586\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2348000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-09-02\n",
      "done: false\n",
      "episode_len_mean: 193.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.25\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12298\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29940265417099\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036049478221684694\n",
      "        model: {}\n",
      "        policy_loss: 0.0034401901066303253\n",
      "        total_loss: 5.497392177581787\n",
      "        vf_explained_var: 1.3963509672976215e-06\n",
      "        vf_loss: 5.493951797485352\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2348000\n",
      "  num_agent_steps_trained: 2348000\n",
      "  num_steps_sampled: 2348000\n",
      "  num_steps_trained: 2348000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 587\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.230000000000004\n",
      "  ram_util_percent: 85.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06858396542745815\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876064240237665\n",
      "  mean_inference_ms: 0.7531948305775967\n",
      "  mean_raw_obs_processing_ms: 0.091057312817507\n",
      "time_since_restore: 4186.038069009781\n",
      "time_this_iter_s: 6.9202587604522705\n",
      "time_total_s: 4186.038069009781\n",
      "timers:\n",
      "  learn_throughput: 1309.12\n",
      "  learn_time_ms: 3055.487\n",
      "  load_throughput: 23311401.973\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 563.896\n",
      "  sample_time_ms: 7093.51\n",
      "  update_time_ms: 2.067\n",
      "timestamp: 1658398142\n",
      "timesteps_since_restore: 2348000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2348000\n",
      "training_iteration: 587\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2352000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-09-09\n",
      "done: false\n",
      "episode_len_mean: 190.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.91\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12319\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3363505005836487\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0040143621154129505\n",
      "        model: {}\n",
      "        policy_loss: -0.0005275770090520382\n",
      "        total_loss: 3.0035059452056885\n",
      "        vf_explained_var: -0.11943680793046951\n",
      "        vf_loss: 3.004033327102661\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2352000\n",
      "  num_agent_steps_trained: 2352000\n",
      "  num_steps_sampled: 2352000\n",
      "  num_steps_trained: 2352000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 588\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.78\n",
      "  ram_util_percent: 85.65\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06858096424592634\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0787564715505958\n",
      "  mean_inference_ms: 0.7531676472881892\n",
      "  mean_raw_obs_processing_ms: 0.09105361539654455\n",
      "time_since_restore: 4193.2112782001495\n",
      "time_this_iter_s: 7.173209190368652\n",
      "time_total_s: 4193.2112782001495\n",
      "timers:\n",
      "  learn_throughput: 1303.633\n",
      "  learn_time_ms: 3068.348\n",
      "  load_throughput: 23304925.684\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 564.746\n",
      "  sample_time_ms: 7082.832\n",
      "  update_time_ms: 2.083\n",
      "timestamp: 1658398149\n",
      "timesteps_since_restore: 2352000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2352000\n",
      "training_iteration: 588\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2356000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-09-17\n",
      "done: false\n",
      "episode_len_mean: 191.97\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.97\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12340\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28637269139289856\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005794340744614601\n",
      "        model: {}\n",
      "        policy_loss: -0.01033933274447918\n",
      "        total_loss: 7.678684711456299\n",
      "        vf_explained_var: -0.026176851242780685\n",
      "        vf_loss: 7.689023971557617\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2356000\n",
      "  num_agent_steps_trained: 2356000\n",
      "  num_steps_sampled: 2356000\n",
      "  num_steps_trained: 2356000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 589\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.227272727272734\n",
      "  ram_util_percent: 85.74545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06857789257974109\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07875229802104064\n",
      "  mean_inference_ms: 0.7531390559907075\n",
      "  mean_raw_obs_processing_ms: 0.09104992677771243\n",
      "time_since_restore: 4200.485455274582\n",
      "time_this_iter_s: 7.274177074432373\n",
      "time_total_s: 4200.485455274582\n",
      "timers:\n",
      "  learn_throughput: 1289.415\n",
      "  learn_time_ms: 3102.182\n",
      "  load_throughput: 23192170.307\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 564.729\n",
      "  sample_time_ms: 7083.041\n",
      "  update_time_ms: 2.17\n",
      "timestamp: 1658398157\n",
      "timesteps_since_restore: 2356000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2356000\n",
      "training_iteration: 589\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2360000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-09-26\n",
      "done: false\n",
      "episode_len_mean: 190.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.31\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12361\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3111894130706787\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003108877455815673\n",
      "        model: {}\n",
      "        policy_loss: 0.003528654109686613\n",
      "        total_loss: 6.361896514892578\n",
      "        vf_explained_var: 0.00013147297431714833\n",
      "        vf_loss: 6.358367443084717\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2360000\n",
      "  num_agent_steps_trained: 2360000\n",
      "  num_steps_sampled: 2360000\n",
      "  num_steps_trained: 2360000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 590\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 54.224999999999994\n",
      "  ram_util_percent: 85.97500000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06857598991503629\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07874949005771943\n",
      "  mean_inference_ms: 0.7531219451465211\n",
      "  mean_raw_obs_processing_ms: 0.09104784468338589\n",
      "time_since_restore: 4209.457627773285\n",
      "time_this_iter_s: 8.972172498703003\n",
      "time_total_s: 4209.457627773285\n",
      "timers:\n",
      "  learn_throughput: 1220.34\n",
      "  learn_time_ms: 3277.776\n",
      "  load_throughput: 21245050.019\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 562.246\n",
      "  sample_time_ms: 7114.321\n",
      "  update_time_ms: 2.181\n",
      "timestamp: 1658398166\n",
      "timesteps_since_restore: 2360000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2360000\n",
      "training_iteration: 590\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2364000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-09-36\n",
      "done: false\n",
      "episode_len_mean: 192.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.93\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12381\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.33417922258377075\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0072777182795107365\n",
      "        model: {}\n",
      "        policy_loss: -0.004892886616289616\n",
      "        total_loss: 0.5747453570365906\n",
      "        vf_explained_var: 0.007207317743450403\n",
      "        vf_loss: 0.5796383023262024\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2364000\n",
      "  num_agent_steps_trained: 2364000\n",
      "  num_steps_sampled: 2364000\n",
      "  num_steps_trained: 2364000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 591\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 57.64666666666666\n",
      "  ram_util_percent: 86.61999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06858876738013317\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07876159008419029\n",
      "  mean_inference_ms: 0.7532549902576895\n",
      "  mean_raw_obs_processing_ms: 0.09106236809448941\n",
      "time_since_restore: 4219.569103717804\n",
      "time_this_iter_s: 10.111475944519043\n",
      "time_total_s: 4219.569103717804\n",
      "timers:\n",
      "  learn_throughput: 1189.163\n",
      "  learn_time_ms: 3363.711\n",
      "  load_throughput: 21074257.003\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 534.16\n",
      "  sample_time_ms: 7488.393\n",
      "  update_time_ms: 2.217\n",
      "timestamp: 1658398176\n",
      "timesteps_since_restore: 2364000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2364000\n",
      "training_iteration: 591\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2368000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-09-43\n",
      "done: false\n",
      "episode_len_mean: 193.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.68\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12401\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35213106870651245\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008847560733556747\n",
      "        model: {}\n",
      "        policy_loss: -0.0030188385862857103\n",
      "        total_loss: 0.09778773784637451\n",
      "        vf_explained_var: -0.06821030378341675\n",
      "        vf_loss: 0.10080656409263611\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2368000\n",
      "  num_agent_steps_trained: 2368000\n",
      "  num_steps_sampled: 2368000\n",
      "  num_steps_trained: 2368000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 592\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.090909090909086\n",
      "  ram_util_percent: 87.38181818181819\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06860529094835867\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07877819143026288\n",
      "  mean_inference_ms: 0.7534291307965906\n",
      "  mean_raw_obs_processing_ms: 0.09108136480787862\n",
      "time_since_restore: 4227.20667719841\n",
      "time_this_iter_s: 7.637573480606079\n",
      "time_total_s: 4227.20667719841\n",
      "timers:\n",
      "  learn_throughput: 1186.347\n",
      "  learn_time_ms: 3371.696\n",
      "  load_throughput: 21061029.375\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 522.581\n",
      "  sample_time_ms: 7654.321\n",
      "  update_time_ms: 2.191\n",
      "timestamp: 1658398183\n",
      "timesteps_since_restore: 2368000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2368000\n",
      "training_iteration: 592\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2372000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-09-52\n",
      "done: false\n",
      "episode_len_mean: 195.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.49\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12421\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.299491822719574\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.017216291278600693\n",
      "        model: {}\n",
      "        policy_loss: -0.005344620440155268\n",
      "        total_loss: 0.0954618752002716\n",
      "        vf_explained_var: -0.3140457272529602\n",
      "        vf_loss: 0.10080648213624954\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2372000\n",
      "  num_agent_steps_trained: 2372000\n",
      "  num_steps_sampled: 2372000\n",
      "  num_steps_trained: 2372000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 593\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.050000000000004\n",
      "  ram_util_percent: 87.39999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0686295268461362\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07880305817282308\n",
      "  mean_inference_ms: 0.7536886107387691\n",
      "  mean_raw_obs_processing_ms: 0.0911095522672753\n",
      "time_since_restore: 4235.572878837585\n",
      "time_this_iter_s: 8.366201639175415\n",
      "time_total_s: 4235.572878837585\n",
      "timers:\n",
      "  learn_throughput: 1190.424\n",
      "  learn_time_ms: 3360.149\n",
      "  load_throughput: 21013547.094\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 514.158\n",
      "  sample_time_ms: 7779.715\n",
      "  update_time_ms: 2.181\n",
      "timestamp: 1658398192\n",
      "timesteps_since_restore: 2372000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2372000\n",
      "training_iteration: 593\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2376000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-00\n",
      "done: false\n",
      "episode_len_mean: 196.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.15\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12441\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3278143107891083\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.01077333651483059\n",
      "        model: {}\n",
      "        policy_loss: -0.004366728011518717\n",
      "        total_loss: 0.09643977135419846\n",
      "        vf_explained_var: -0.3118098974227905\n",
      "        vf_loss: 0.10080648213624954\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2376000\n",
      "  num_agent_steps_trained: 2376000\n",
      "  num_steps_sampled: 2376000\n",
      "  num_steps_trained: 2376000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 594\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.02727272727273\n",
      "  ram_util_percent: 87.41818181818181\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0686560248355278\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07883040417199542\n",
      "  mean_inference_ms: 0.7539699790762981\n",
      "  mean_raw_obs_processing_ms: 0.09114039716289561\n",
      "time_since_restore: 4243.6029460430145\n",
      "time_this_iter_s: 8.030067205429077\n",
      "time_total_s: 4243.6029460430145\n",
      "timers:\n",
      "  learn_throughput: 1158.546\n",
      "  learn_time_ms: 3452.604\n",
      "  load_throughput: 20966278.43\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 512.563\n",
      "  sample_time_ms: 7803.912\n",
      "  update_time_ms: 2.254\n",
      "timestamp: 1658398200\n",
      "timesteps_since_restore: 2376000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2376000\n",
      "training_iteration: 594\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2380000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-08\n",
      "done: false\n",
      "episode_len_mean: 198.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.09\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12462\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31414559483528137\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005472760647535324\n",
      "        model: {}\n",
      "        policy_loss: -0.00381034635938704\n",
      "        total_loss: 1.35707688331604\n",
      "        vf_explained_var: -0.2568690776824951\n",
      "        vf_loss: 1.3608871698379517\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2380000\n",
      "  num_agent_steps_trained: 2380000\n",
      "  num_steps_sampled: 2380000\n",
      "  num_steps_trained: 2380000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 595\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.92499999999999\n",
      "  ram_util_percent: 87.04166666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0686874882954948\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07886311749314528\n",
      "  mean_inference_ms: 0.7543000182446248\n",
      "  mean_raw_obs_processing_ms: 0.09117654047288543\n",
      "time_since_restore: 4251.564517021179\n",
      "time_this_iter_s: 7.961570978164673\n",
      "time_total_s: 4251.564517021179\n",
      "timers:\n",
      "  learn_throughput: 1151.329\n",
      "  learn_time_ms: 3474.245\n",
      "  load_throughput: 20704943.848\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 501.096\n",
      "  sample_time_ms: 7982.501\n",
      "  update_time_ms: 2.257\n",
      "timestamp: 1658398208\n",
      "timesteps_since_restore: 2380000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2380000\n",
      "training_iteration: 595\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2384000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-16\n",
      "done: false\n",
      "episode_len_mean: 198.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.09\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12482\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3162393271923065\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005183143075555563\n",
      "        model: {}\n",
      "        policy_loss: -0.002930037910118699\n",
      "        total_loss: 0.7909208536148071\n",
      "        vf_explained_var: -0.3225804567337036\n",
      "        vf_loss: 0.7938508987426758\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2384000\n",
      "  num_agent_steps_trained: 2384000\n",
      "  num_steps_sampled: 2384000\n",
      "  num_steps_trained: 2384000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 596\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.99090909090909\n",
      "  ram_util_percent: 86.80000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06870547962878672\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07888244256407735\n",
      "  mean_inference_ms: 0.7544951200397249\n",
      "  mean_raw_obs_processing_ms: 0.09119805986601186\n",
      "time_since_restore: 4259.60160112381\n",
      "time_this_iter_s: 8.037084102630615\n",
      "time_total_s: 4259.60160112381\n",
      "timers:\n",
      "  learn_throughput: 1141.091\n",
      "  learn_time_ms: 3505.417\n",
      "  load_throughput: 20738215.08\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 497.429\n",
      "  sample_time_ms: 8041.344\n",
      "  update_time_ms: 2.342\n",
      "timestamp: 1658398216\n",
      "timesteps_since_restore: 2384000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2384000\n",
      "training_iteration: 596\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2388000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-23\n",
      "done: false\n",
      "episode_len_mean: 198.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.0\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12502\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3068254292011261\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008114076219499111\n",
      "        model: {}\n",
      "        policy_loss: -0.0037970058619976044\n",
      "        total_loss: 0.3011429011821747\n",
      "        vf_explained_var: -0.27605608105659485\n",
      "        vf_loss: 0.304939866065979\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2388000\n",
      "  num_agent_steps_trained: 2388000\n",
      "  num_steps_sampled: 2388000\n",
      "  num_steps_trained: 2388000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 597\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.519999999999996\n",
      "  ram_util_percent: 85.86\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06871898847297364\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0788967492668989\n",
      "  mean_inference_ms: 0.754641581078835\n",
      "  mean_raw_obs_processing_ms: 0.09121438150498275\n",
      "time_since_restore: 4266.47642993927\n",
      "time_this_iter_s: 6.874828815460205\n",
      "time_total_s: 4266.47642993927\n",
      "timers:\n",
      "  learn_throughput: 1140.991\n",
      "  learn_time_ms: 3505.725\n",
      "  load_throughput: 20681972.387\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 495.74\n",
      "  sample_time_ms: 8068.75\n",
      "  update_time_ms: 2.32\n",
      "timestamp: 1658398223\n",
      "timesteps_since_restore: 2388000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2388000\n",
      "training_iteration: 597\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2392000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-30\n",
      "done: false\n",
      "episode_len_mean: 198.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.0\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12522\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.36201369762420654\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.011378644034266472\n",
      "        model: {}\n",
      "        policy_loss: -0.001859876443631947\n",
      "        total_loss: 0.09894660115242004\n",
      "        vf_explained_var: -0.3519894778728485\n",
      "        vf_loss: 0.10080646723508835\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2392000\n",
      "  num_agent_steps_trained: 2392000\n",
      "  num_steps_sampled: 2392000\n",
      "  num_steps_trained: 2392000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 598\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.470000000000006\n",
      "  ram_util_percent: 85.61\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06872494053477413\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07890303945798145\n",
      "  mean_inference_ms: 0.754705251100233\n",
      "  mean_raw_obs_processing_ms: 0.09122145126449084\n",
      "time_since_restore: 4273.409865140915\n",
      "time_this_iter_s: 6.9334352016448975\n",
      "time_total_s: 4273.409865140915\n",
      "timers:\n",
      "  learn_throughput: 1148.063\n",
      "  learn_time_ms: 3484.129\n",
      "  load_throughput: 21037261.442\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 495.906\n",
      "  sample_time_ms: 8066.037\n",
      "  update_time_ms: 2.315\n",
      "timestamp: 1658398230\n",
      "timesteps_since_restore: 2392000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2392000\n",
      "training_iteration: 598\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2396000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-37\n",
      "done: false\n",
      "episode_len_mean: 193.72\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.72\n",
      "episode_reward_min: 40.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 12545\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3534545600414276\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004865067545324564\n",
      "        model: {}\n",
      "        policy_loss: -0.002775265136733651\n",
      "        total_loss: 4.951864719390869\n",
      "        vf_explained_var: -0.06451372802257538\n",
      "        vf_loss: 4.9546403884887695\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2396000\n",
      "  num_agent_steps_trained: 2396000\n",
      "  num_steps_sampled: 2396000\n",
      "  num_steps_trained: 2396000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 599\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.879999999999995\n",
      "  ram_util_percent: 85.64000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06872779604320318\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07890578139417614\n",
      "  mean_inference_ms: 0.7547369546289481\n",
      "  mean_raw_obs_processing_ms: 0.0912250994535061\n",
      "time_since_restore: 4280.181615591049\n",
      "time_this_iter_s: 6.771750450134277\n",
      "time_total_s: 4280.181615591049\n",
      "timers:\n",
      "  learn_throughput: 1162.277\n",
      "  learn_time_ms: 3441.521\n",
      "  load_throughput: 20316318.721\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 497.69\n",
      "  sample_time_ms: 8037.132\n",
      "  update_time_ms: 2.218\n",
      "timestamp: 1658398237\n",
      "timesteps_since_restore: 2396000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2396000\n",
      "training_iteration: 599\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2400000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-44\n",
      "done: false\n",
      "episode_len_mean: 191.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.55\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 12567\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.338114857673645\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004048520233482122\n",
      "        model: {}\n",
      "        policy_loss: -0.007207826245576143\n",
      "        total_loss: 6.973642349243164\n",
      "        vf_explained_var: 1.801085772967781e-06\n",
      "        vf_loss: 6.980849742889404\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2400000\n",
      "  num_agent_steps_trained: 2400000\n",
      "  num_steps_sampled: 2400000\n",
      "  num_steps_trained: 2400000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 600\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.9\n",
      "  ram_util_percent: 85.7\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0687254586309772\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07890325104965777\n",
      "  mean_inference_ms: 0.754719716613381\n",
      "  mean_raw_obs_processing_ms: 0.09122287644063358\n",
      "time_since_restore: 4287.291962862015\n",
      "time_this_iter_s: 7.110347270965576\n",
      "time_total_s: 4287.291962862015\n",
      "timers:\n",
      "  learn_throughput: 1224.886\n",
      "  learn_time_ms: 3265.611\n",
      "  load_throughput: 22342809.961\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 501.007\n",
      "  sample_time_ms: 7983.914\n",
      "  update_time_ms: 2.214\n",
      "timestamp: 1658398244\n",
      "timesteps_since_restore: 2400000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2400000\n",
      "training_iteration: 600\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2404000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-51\n",
      "done: false\n",
      "episode_len_mean: 189.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.59\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12588\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.34587690234184265\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006013889797031879\n",
      "        model: {}\n",
      "        policy_loss: 0.0012804664438590407\n",
      "        total_loss: 6.251281261444092\n",
      "        vf_explained_var: 3.939931048080325e-06\n",
      "        vf_loss: 6.25\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2404000\n",
      "  num_agent_steps_trained: 2404000\n",
      "  num_steps_sampled: 2404000\n",
      "  num_steps_trained: 2404000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 601\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.08\n",
      "  ram_util_percent: 85.71999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06872268054033785\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07890016800925528\n",
      "  mean_inference_ms: 0.7546992068891353\n",
      "  mean_raw_obs_processing_ms: 0.09121926857195163\n",
      "time_since_restore: 4294.344140529633\n",
      "time_this_iter_s: 7.052177667617798\n",
      "time_total_s: 4294.344140529633\n",
      "timers:\n",
      "  learn_throughput: 1259.725\n",
      "  learn_time_ms: 3175.296\n",
      "  load_throughput: 22644373.06\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 526.956\n",
      "  sample_time_ms: 7590.76\n",
      "  update_time_ms: 2.214\n",
      "timestamp: 1658398251\n",
      "timesteps_since_restore: 2404000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2404000\n",
      "training_iteration: 601\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000601/checkpoint-601\n",
      "agent_timesteps_total: 2408000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-10-58\n",
      "done: false\n",
      "episode_len_mean: 187.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.45\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12609\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3357415199279785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004680099431425333\n",
      "        model: {}\n",
      "        policy_loss: 0.0038343099877238274\n",
      "        total_loss: 6.193370819091797\n",
      "        vf_explained_var: -0.015913084149360657\n",
      "        vf_loss: 6.189536094665527\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2408000\n",
      "  num_agent_steps_trained: 2408000\n",
      "  num_steps_sampled: 2408000\n",
      "  num_steps_trained: 2408000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 602\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.545454545454554\n",
      "  ram_util_percent: 85.5090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06872268433422077\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07889993923132385\n",
      "  mean_inference_ms: 0.7547119863086488\n",
      "  mean_raw_obs_processing_ms: 0.09121986080222565\n",
      "time_since_restore: 4301.817600488663\n",
      "time_this_iter_s: 7.473459959030151\n",
      "time_total_s: 4301.817600488663\n",
      "timers:\n",
      "  learn_throughput: 1259.536\n",
      "  learn_time_ms: 3175.772\n",
      "  load_throughput: 22668850.155\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 534.517\n",
      "  sample_time_ms: 7483.39\n",
      "  update_time_ms: 2.26\n",
      "timestamp: 1658398258\n",
      "timesteps_since_restore: 2408000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2408000\n",
      "training_iteration: 602\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2412000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-11-06\n",
      "done: false\n",
      "episode_len_mean: 186.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.62\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12630\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30267325043678284\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0050839614123106\n",
      "        model: {}\n",
      "        policy_loss: 0.0032164452131837606\n",
      "        total_loss: 7.223478317260742\n",
      "        vf_explained_var: 4.0261977574118646e-07\n",
      "        vf_loss: 7.220262050628662\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2412000\n",
      "  num_agent_steps_trained: 2412000\n",
      "  num_steps_sampled: 2412000\n",
      "  num_steps_trained: 2412000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 603\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.23636363636364\n",
      "  ram_util_percent: 85.64545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0687221869764489\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07889921879940444\n",
      "  mean_inference_ms: 0.7547254436350349\n",
      "  mean_raw_obs_processing_ms: 0.09122077366768458\n",
      "time_since_restore: 4309.82263302803\n",
      "time_this_iter_s: 8.005032539367676\n",
      "time_total_s: 4309.82263302803\n",
      "timers:\n",
      "  learn_throughput: 1219.259\n",
      "  learn_time_ms: 3280.682\n",
      "  load_throughput: 22792033.691\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 544.729\n",
      "  sample_time_ms: 7343.101\n",
      "  update_time_ms: 2.338\n",
      "timestamp: 1658398266\n",
      "timesteps_since_restore: 2412000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2412000\n",
      "training_iteration: 603\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2416000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-11-16\n",
      "done: false\n",
      "episode_len_mean: 188.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.86\n",
      "episode_reward_min: 88.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12650\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.316509872674942\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035911041777580976\n",
      "        model: {}\n",
      "        policy_loss: 0.006694914773106575\n",
      "        total_loss: 7.50669527053833\n",
      "        vf_explained_var: 1.2017065387226467e-07\n",
      "        vf_loss: 7.5\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2416000\n",
      "  num_agent_steps_trained: 2416000\n",
      "  num_steps_sampled: 2416000\n",
      "  num_steps_trained: 2416000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 604\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.646153846153844\n",
      "  ram_util_percent: 85.93846153846154\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06872820378969097\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07890564524466204\n",
      "  mean_inference_ms: 0.7548144392248772\n",
      "  mean_raw_obs_processing_ms: 0.0912296912427278\n",
      "time_since_restore: 4319.163761377335\n",
      "time_this_iter_s: 9.3411283493042\n",
      "time_total_s: 4319.163761377335\n",
      "timers:\n",
      "  learn_throughput: 1201.372\n",
      "  learn_time_ms: 3329.525\n",
      "  load_throughput: 21253123.892\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 531.156\n",
      "  sample_time_ms: 7530.747\n",
      "  update_time_ms: 2.245\n",
      "timestamp: 1658398276\n",
      "timesteps_since_restore: 2416000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2416000\n",
      "training_iteration: 604\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2420000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-11-24\n",
      "done: false\n",
      "episode_len_mean: 193.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.31\n",
      "episode_reward_min: 88.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12670\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3031824827194214\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00301755010150373\n",
      "        model: {}\n",
      "        policy_loss: 0.002445782069116831\n",
      "        total_loss: 2.6334941387176514\n",
      "        vf_explained_var: -0.1290321946144104\n",
      "        vf_loss: 2.6310484409332275\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2420000\n",
      "  num_agent_steps_trained: 2420000\n",
      "  num_steps_sampled: 2420000\n",
      "  num_steps_trained: 2420000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 605\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.03846153846153\n",
      "  ram_util_percent: 86.35384615384616\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06874202044236571\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07892087224149526\n",
      "  mean_inference_ms: 0.7549895912510539\n",
      "  mean_raw_obs_processing_ms: 0.09124866217704755\n",
      "time_since_restore: 4327.688262224197\n",
      "time_this_iter_s: 8.524500846862793\n",
      "time_total_s: 4327.688262224197\n",
      "timers:\n",
      "  learn_throughput: 1205.117\n",
      "  learn_time_ms: 3319.18\n",
      "  load_throughput: 21690001.293\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 523.256\n",
      "  sample_time_ms: 7644.445\n",
      "  update_time_ms: 2.249\n",
      "timestamp: 1658398284\n",
      "timesteps_since_restore: 2420000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2420000\n",
      "training_iteration: 605\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2424000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-11-31\n",
      "done: false\n",
      "episode_len_mean: 194.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.51\n",
      "episode_reward_min: 88.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12690\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29850202798843384\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00676801847293973\n",
      "        model: {}\n",
      "        policy_loss: -0.004058785270899534\n",
      "        total_loss: 1.0544090270996094\n",
      "        vf_explained_var: -0.28999385237693787\n",
      "        vf_loss: 1.0584677457809448\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2424000\n",
      "  num_agent_steps_trained: 2424000\n",
      "  num_steps_sampled: 2424000\n",
      "  num_steps_trained: 2424000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 606\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.455555555555556\n",
      "  ram_util_percent: 86.45555555555556\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06875359610822845\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07893354414570469\n",
      "  mean_inference_ms: 0.7551390710949832\n",
      "  mean_raw_obs_processing_ms: 0.0912649061982538\n",
      "time_since_restore: 4334.619923591614\n",
      "time_this_iter_s: 6.931661367416382\n",
      "time_total_s: 4334.619923591614\n",
      "timers:\n",
      "  learn_throughput: 1223.243\n",
      "  learn_time_ms: 3269.997\n",
      "  load_throughput: 21476210.958\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 528.183\n",
      "  sample_time_ms: 7573.137\n",
      "  update_time_ms: 2.174\n",
      "timestamp: 1658398291\n",
      "timesteps_since_restore: 2424000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2424000\n",
      "training_iteration: 606\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2428000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-11-39\n",
      "done: false\n",
      "episode_len_mean: 196.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.17\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12711\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3030489981174469\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004402090795338154\n",
      "        model: {}\n",
      "        policy_loss: 0.003145516850054264\n",
      "        total_loss: 5.7465996742248535\n",
      "        vf_explained_var: -0.09677256643772125\n",
      "        vf_loss: 5.743454456329346\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2428000\n",
      "  num_agent_steps_trained: 2428000\n",
      "  num_steps_sampled: 2428000\n",
      "  num_steps_trained: 2428000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 607\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.083333333333336\n",
      "  ram_util_percent: 86.33333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06876689658951457\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07894797694120836\n",
      "  mean_inference_ms: 0.7553079076868624\n",
      "  mean_raw_obs_processing_ms: 0.09128261504791674\n",
      "time_since_restore: 4342.439182519913\n",
      "time_this_iter_s: 7.81925892829895\n",
      "time_total_s: 4342.439182519913\n",
      "timers:\n",
      "  learn_throughput: 1213.387\n",
      "  learn_time_ms: 3296.559\n",
      "  load_throughput: 21355926.68\n",
      "  load_time_ms: 0.187\n",
      "  sample_throughput: 526.985\n",
      "  sample_time_ms: 7590.356\n",
      "  update_time_ms: 2.233\n",
      "timestamp: 1658398299\n",
      "timesteps_since_restore: 2428000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2428000\n",
      "training_iteration: 607\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2432000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-11-48\n",
      "done: false\n",
      "episode_len_mean: 197.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.61\n",
      "episode_reward_min: 89.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12731\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29535606503486633\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003948132507503033\n",
      "        model: {}\n",
      "        policy_loss: 0.006065667141228914\n",
      "        total_loss: 7.304453372955322\n",
      "        vf_explained_var: 1.0453885579408961e-06\n",
      "        vf_loss: 7.298387050628662\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2432000\n",
      "  num_agent_steps_trained: 2432000\n",
      "  num_steps_sampled: 2432000\n",
      "  num_steps_trained: 2432000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 608\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.9\n",
      "  ram_util_percent: 86.38333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06878709406350944\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07897034813790205\n",
      "  mean_inference_ms: 0.7555427185807764\n",
      "  mean_raw_obs_processing_ms: 0.09130762409275132\n",
      "time_since_restore: 4350.993942737579\n",
      "time_this_iter_s: 8.554760217666626\n",
      "time_total_s: 4350.993942737579\n",
      "timers:\n",
      "  learn_throughput: 1198.106\n",
      "  learn_time_ms: 3338.604\n",
      "  load_throughput: 20984635.397\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 516.967\n",
      "  sample_time_ms: 7737.432\n",
      "  update_time_ms: 2.235\n",
      "timestamp: 1658398308\n",
      "timesteps_since_restore: 2432000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2432000\n",
      "training_iteration: 608\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2436000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-11-57\n",
      "done: false\n",
      "episode_len_mean: 197.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.55\n",
      "episode_reward_min: 143.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12751\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30412209033966064\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038334159180521965\n",
      "        model: {}\n",
      "        policy_loss: 0.0018967995420098305\n",
      "        total_loss: 4.485267162322998\n",
      "        vf_explained_var: -0.09677281230688095\n",
      "        vf_loss: 4.483370304107666\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2436000\n",
      "  num_agent_steps_trained: 2436000\n",
      "  num_steps_sampled: 2436000\n",
      "  num_steps_trained: 2436000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 609\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.22307692307693\n",
      "  ram_util_percent: 86.33076923076922\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06880672184955011\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07899170523757972\n",
      "  mean_inference_ms: 0.7557623789278438\n",
      "  mean_raw_obs_processing_ms: 0.09133141610072525\n",
      "time_since_restore: 4360.005792379379\n",
      "time_this_iter_s: 9.011849641799927\n",
      "time_total_s: 4360.005792379379\n",
      "timers:\n",
      "  learn_throughput: 1158.044\n",
      "  learn_time_ms: 3454.099\n",
      "  load_throughput: 22072379.95\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 507.073\n",
      "  sample_time_ms: 7888.418\n",
      "  update_time_ms: 2.269\n",
      "timestamp: 1658398317\n",
      "timesteps_since_restore: 2436000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2436000\n",
      "training_iteration: 609\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2440000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-12-05\n",
      "done: false\n",
      "episode_len_mean: 196.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.35\n",
      "episode_reward_min: 88.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12772\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29702889919281006\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005998117383569479\n",
      "        model: {}\n",
      "        policy_loss: -0.0006395288510248065\n",
      "        total_loss: 4.497849464416504\n",
      "        vf_explained_var: 0.006938961800187826\n",
      "        vf_loss: 4.498488903045654\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2440000\n",
      "  num_agent_steps_trained: 2440000\n",
      "  num_steps_sampled: 2440000\n",
      "  num_steps_trained: 2440000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 610\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.90909090909091\n",
      "  ram_util_percent: 86.69090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06882633648689493\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07901206820161516\n",
      "  mean_inference_ms: 0.7559715480279736\n",
      "  mean_raw_obs_processing_ms: 0.0913549391597221\n",
      "time_since_restore: 4368.232880592346\n",
      "time_this_iter_s: 8.227088212966919\n",
      "time_total_s: 4368.232880592346\n",
      "timers:\n",
      "  learn_throughput: 1154.909\n",
      "  learn_time_ms: 3463.475\n",
      "  load_throughput: 21862413.344\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 493.453\n",
      "  sample_time_ms: 8106.134\n",
      "  update_time_ms: 2.245\n",
      "timestamp: 1658398325\n",
      "timesteps_since_restore: 2440000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2440000\n",
      "training_iteration: 610\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2444000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-12-13\n",
      "done: false\n",
      "episode_len_mean: 196.22\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.22\n",
      "episode_reward_min: 88.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12792\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29021283984184265\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033545091282576323\n",
      "        model: {}\n",
      "        policy_loss: -0.0003319574170745909\n",
      "        total_loss: 2.2980587482452393\n",
      "        vf_explained_var: -2.2046411686460488e-05\n",
      "        vf_loss: 2.2983906269073486\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2444000\n",
      "  num_agent_steps_trained: 2444000\n",
      "  num_steps_sampled: 2444000\n",
      "  num_steps_trained: 2444000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 611\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.574999999999996\n",
      "  ram_util_percent: 86.3\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0688501716068704\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0790371275598698\n",
      "  mean_inference_ms: 0.7562208769584581\n",
      "  mean_raw_obs_processing_ms: 0.09138360413297962\n",
      "time_since_restore: 4375.983124494553\n",
      "time_this_iter_s: 7.750243902206421\n",
      "time_total_s: 4375.983124494553\n",
      "timers:\n",
      "  learn_throughput: 1148.691\n",
      "  learn_time_ms: 3482.224\n",
      "  load_throughput: 21729330.398\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 489.774\n",
      "  sample_time_ms: 8167.031\n",
      "  update_time_ms: 2.212\n",
      "timestamp: 1658398333\n",
      "timesteps_since_restore: 2444000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2444000\n",
      "training_iteration: 611\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2448000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-12-20\n",
      "done: false\n",
      "episode_len_mean: 194.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.94\n",
      "episode_reward_min: 88.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12813\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3159879744052887\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004366524983197451\n",
      "        model: {}\n",
      "        policy_loss: 0.00012248652637936175\n",
      "        total_loss: 3.8836913108825684\n",
      "        vf_explained_var: -0.00039385436684824526\n",
      "        vf_loss: 3.88356876373291\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2448000\n",
      "  num_agent_steps_trained: 2448000\n",
      "  num_steps_sampled: 2448000\n",
      "  num_steps_trained: 2448000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 612\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.41\n",
      "  ram_util_percent: 86.27999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06887568449028772\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07906413167821828\n",
      "  mean_inference_ms: 0.7564815856277792\n",
      "  mean_raw_obs_processing_ms: 0.09141422178521803\n",
      "time_since_restore: 4383.541878223419\n",
      "time_this_iter_s: 7.558753728866577\n",
      "time_total_s: 4383.541878223419\n",
      "timers:\n",
      "  learn_throughput: 1152.97\n",
      "  learn_time_ms: 3469.302\n",
      "  load_throughput: 21586742.151\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 487.451\n",
      "  sample_time_ms: 8205.957\n",
      "  update_time_ms: 2.196\n",
      "timestamp: 1658398340\n",
      "timesteps_since_restore: 2448000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2448000\n",
      "training_iteration: 612\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2452000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-12-28\n",
      "done: false\n",
      "episode_len_mean: 191.63\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.63\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 12835\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31053265929222107\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004321245942264795\n",
      "        model: {}\n",
      "        policy_loss: 0.00425073504447937\n",
      "        total_loss: 7.673109531402588\n",
      "        vf_explained_var: 3.5412208490015473e-06\n",
      "        vf_loss: 7.668858528137207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2452000\n",
      "  num_agent_steps_trained: 2452000\n",
      "  num_steps_sampled: 2452000\n",
      "  num_steps_trained: 2452000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 613\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.654545454545456\n",
      "  ram_util_percent: 86.34545454545456\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06889627819125392\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07908559268270787\n",
      "  mean_inference_ms: 0.756691961329687\n",
      "  mean_raw_obs_processing_ms: 0.09143942035251607\n",
      "time_since_restore: 4391.0409598350525\n",
      "time_this_iter_s: 7.499081611633301\n",
      "time_total_s: 4391.0409598350525\n",
      "timers:\n",
      "  learn_throughput: 1183.994\n",
      "  learn_time_ms: 3378.397\n",
      "  load_throughput: 21732145.078\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 485.835\n",
      "  sample_time_ms: 8233.246\n",
      "  update_time_ms: 2.115\n",
      "timestamp: 1658398348\n",
      "timesteps_since_restore: 2452000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2452000\n",
      "training_iteration: 613\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2456000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-12-36\n",
      "done: false\n",
      "episode_len_mean: 192.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.8\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12855\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32175397872924805\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033789542503654957\n",
      "        model: {}\n",
      "        policy_loss: 0.00356575776822865\n",
      "        total_loss: 4.791872501373291\n",
      "        vf_explained_var: -2.566845296314568e-07\n",
      "        vf_loss: 4.78830623626709\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2456000\n",
      "  num_agent_steps_trained: 2456000\n",
      "  num_steps_sampled: 2456000\n",
      "  num_steps_trained: 2456000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 614\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.166666666666664\n",
      "  ram_util_percent: 86.30833333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06891265603632872\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07910275267552723\n",
      "  mean_inference_ms: 0.756864822811367\n",
      "  mean_raw_obs_processing_ms: 0.09145928302524547\n",
      "time_since_restore: 4399.598057985306\n",
      "time_this_iter_s: 8.557098150253296\n",
      "time_total_s: 4399.598057985306\n",
      "timers:\n",
      "  learn_throughput: 1195.888\n",
      "  learn_time_ms: 3344.794\n",
      "  load_throughput: 22730275.03\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 494.062\n",
      "  sample_time_ms: 8096.154\n",
      "  update_time_ms: 2.281\n",
      "timestamp: 1658398356\n",
      "timesteps_since_restore: 2456000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2456000\n",
      "training_iteration: 614\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2460000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-12-45\n",
      "done: false\n",
      "episode_len_mean: 193.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.31\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12876\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3144681751728058\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004287496209144592\n",
      "        model: {}\n",
      "        policy_loss: -0.009493294171988964\n",
      "        total_loss: 6.222870826721191\n",
      "        vf_explained_var: -0.03225777670741081\n",
      "        vf_loss: 6.232364177703857\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2460000\n",
      "  num_agent_steps_trained: 2460000\n",
      "  num_steps_sampled: 2460000\n",
      "  num_steps_trained: 2460000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 615\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.85833333333334\n",
      "  ram_util_percent: 86.61666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06892784004185967\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07911920086399923\n",
      "  mean_inference_ms: 0.7570260997636686\n",
      "  mean_raw_obs_processing_ms: 0.09147739960754266\n",
      "time_since_restore: 4408.040312290192\n",
      "time_this_iter_s: 8.442254304885864\n",
      "time_total_s: 4408.040312290192\n",
      "timers:\n",
      "  learn_throughput: 1172.189\n",
      "  learn_time_ms: 3412.419\n",
      "  load_throughput: 22348762.488\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 500.785\n",
      "  sample_time_ms: 7987.458\n",
      "  update_time_ms: 2.316\n",
      "timestamp: 1658398365\n",
      "timesteps_since_restore: 2460000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2460000\n",
      "training_iteration: 615\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2464000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-12-54\n",
      "done: false\n",
      "episode_len_mean: 192.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.45\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12896\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2712148129940033\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004977930802851915\n",
      "        model: {}\n",
      "        policy_loss: 0.0017944028368219733\n",
      "        total_loss: 6.226597309112549\n",
      "        vf_explained_var: -0.015866324305534363\n",
      "        vf_loss: 6.224802494049072\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2464000\n",
      "  num_agent_steps_trained: 2464000\n",
      "  num_steps_sampled: 2464000\n",
      "  num_steps_trained: 2464000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 616\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.78461538461538\n",
      "  ram_util_percent: 86.73846153846155\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0689483070502039\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07914055366138535\n",
      "  mean_inference_ms: 0.7572401452261847\n",
      "  mean_raw_obs_processing_ms: 0.0915013473013604\n",
      "time_since_restore: 4416.979089975357\n",
      "time_this_iter_s: 8.938777685165405\n",
      "time_total_s: 4416.979089975357\n",
      "timers:\n",
      "  learn_throughput: 1167.812\n",
      "  learn_time_ms: 3425.208\n",
      "  load_throughput: 22405470.085\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 485.21\n",
      "  sample_time_ms: 8243.86\n",
      "  update_time_ms: 2.396\n",
      "timestamp: 1658398374\n",
      "timesteps_since_restore: 2464000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2464000\n",
      "training_iteration: 616\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2468000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-13-02\n",
      "done: false\n",
      "episode_len_mean: 193.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.19\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 12917\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29484352469444275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004245111718773842\n",
      "        model: {}\n",
      "        policy_loss: 0.0017797716427594423\n",
      "        total_loss: 5.508364677429199\n",
      "        vf_explained_var: 0.0013012444833293557\n",
      "        vf_loss: 5.506585121154785\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2468000\n",
      "  num_agent_steps_trained: 2468000\n",
      "  num_steps_sampled: 2468000\n",
      "  num_steps_trained: 2468000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 617\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.55833333333333\n",
      "  ram_util_percent: 86.48333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06897161378164292\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07916515591232626\n",
      "  mean_inference_ms: 0.7574985377213956\n",
      "  mean_raw_obs_processing_ms: 0.09152915420122118\n",
      "time_since_restore: 4425.47234749794\n",
      "time_this_iter_s: 8.493257522583008\n",
      "time_total_s: 4425.47234749794\n",
      "timers:\n",
      "  learn_throughput: 1162.432\n",
      "  learn_time_ms: 3441.063\n",
      "  load_throughput: 21811253.25\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 481.385\n",
      "  sample_time_ms: 8309.358\n",
      "  update_time_ms: 2.39\n",
      "timestamp: 1658398382\n",
      "timesteps_since_restore: 2468000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2468000\n",
      "training_iteration: 617\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2472000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-13-11\n",
      "done: false\n",
      "episode_len_mean: 196.18\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.18\n",
      "episode_reward_min: 117.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12937\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3137936592102051\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004184456076472998\n",
      "        model: {}\n",
      "        policy_loss: 0.0038822353817522526\n",
      "        total_loss: 5.6994476318359375\n",
      "        vf_explained_var: 1.3343749571959052e-07\n",
      "        vf_loss: 5.6955647468566895\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2472000\n",
      "  num_agent_steps_trained: 2472000\n",
      "  num_steps_sampled: 2472000\n",
      "  num_steps_trained: 2472000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 618\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.08461538461539\n",
      "  ram_util_percent: 86.79999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06900065389975112\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07919638776281988\n",
      "  mean_inference_ms: 0.7578132750038037\n",
      "  mean_raw_obs_processing_ms: 0.09156422770712552\n",
      "time_since_restore: 4434.536689519882\n",
      "time_this_iter_s: 9.064342021942139\n",
      "time_total_s: 4434.536689519882\n",
      "timers:\n",
      "  learn_throughput: 1155.028\n",
      "  learn_time_ms: 3463.121\n",
      "  load_throughput: 20560313.725\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 478.718\n",
      "  sample_time_ms: 8355.647\n",
      "  update_time_ms: 2.378\n",
      "timestamp: 1658398391\n",
      "timesteps_since_restore: 2472000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2472000\n",
      "training_iteration: 618\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2476000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-13-20\n",
      "done: false\n",
      "episode_len_mean: 196.18\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.18\n",
      "episode_reward_min: 117.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12957\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3026668429374695\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029859335627406836\n",
      "        model: {}\n",
      "        policy_loss: 0.004810743499547243\n",
      "        total_loss: 5.700375556945801\n",
      "        vf_explained_var: -1.6920028045319668e-08\n",
      "        vf_loss: 5.6955647468566895\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2476000\n",
      "  num_agent_steps_trained: 2476000\n",
      "  num_steps_sampled: 2476000\n",
      "  num_steps_trained: 2476000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 619\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.925000000000004\n",
      "  ram_util_percent: 86.21666666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06903082276863631\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07922927918881002\n",
      "  mean_inference_ms: 0.7581355961234578\n",
      "  mean_raw_obs_processing_ms: 0.0916011556426691\n",
      "time_since_restore: 4442.715065717697\n",
      "time_this_iter_s: 8.178376197814941\n",
      "time_total_s: 4442.715065717697\n",
      "timers:\n",
      "  learn_throughput: 1180.247\n",
      "  learn_time_ms: 3389.122\n",
      "  load_throughput: 20440077.973\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 477.999\n",
      "  sample_time_ms: 8368.211\n",
      "  update_time_ms: 2.347\n",
      "timestamp: 1658398400\n",
      "timesteps_since_restore: 2476000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2476000\n",
      "training_iteration: 619\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2480000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-13-27\n",
      "done: false\n",
      "episode_len_mean: 196.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.15\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 12977\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3188249468803406\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007198070641607046\n",
      "        model: {}\n",
      "        policy_loss: -0.005281310994178057\n",
      "        total_loss: 0.1660904437303543\n",
      "        vf_explained_var: 0.003453601151704788\n",
      "        vf_loss: 0.17137175798416138\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2480000\n",
      "  num_agent_steps_trained: 2480000\n",
      "  num_steps_sampled: 2480000\n",
      "  num_steps_trained: 2480000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 620\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.31818181818182\n",
      "  ram_util_percent: 85.96363636363635\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06905923543449594\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07925990772586305\n",
      "  mean_inference_ms: 0.7584397333774093\n",
      "  mean_raw_obs_processing_ms: 0.09163594724400027\n",
      "time_since_restore: 4450.50691819191\n",
      "time_this_iter_s: 7.7918524742126465\n",
      "time_total_s: 4450.50691819191\n",
      "timers:\n",
      "  learn_throughput: 1172.849\n",
      "  learn_time_ms: 3410.498\n",
      "  load_throughput: 20557794.388\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 486.079\n",
      "  sample_time_ms: 8229.116\n",
      "  update_time_ms: 2.362\n",
      "timestamp: 1658398407\n",
      "timesteps_since_restore: 2480000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2480000\n",
      "training_iteration: 620\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2484000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-13-37\n",
      "done: false\n",
      "episode_len_mean: 195.26\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.26\n",
      "episode_reward_min: 48.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 12999\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.305229127407074\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00451101828366518\n",
      "        model: {}\n",
      "        policy_loss: 0.0021022427827119827\n",
      "        total_loss: 6.027838706970215\n",
      "        vf_explained_var: -0.001076574088074267\n",
      "        vf_loss: 6.025736331939697\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2484000\n",
      "  num_agent_steps_trained: 2484000\n",
      "  num_steps_sampled: 2484000\n",
      "  num_steps_trained: 2484000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 621\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.138461538461534\n",
      "  ram_util_percent: 86.32307692307693\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06908758865976623\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07929153143599597\n",
      "  mean_inference_ms: 0.7587445399560301\n",
      "  mean_raw_obs_processing_ms: 0.09167107071284743\n",
      "time_since_restore: 4459.636149644852\n",
      "time_this_iter_s: 9.129231452941895\n",
      "time_total_s: 4459.636149644852\n",
      "timers:\n",
      "  learn_throughput: 1147.386\n",
      "  learn_time_ms: 3486.185\n",
      "  load_throughput: 20378010.446\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 481.146\n",
      "  sample_time_ms: 8313.486\n",
      "  update_time_ms: 2.404\n",
      "timestamp: 1658398417\n",
      "timesteps_since_restore: 2484000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2484000\n",
      "training_iteration: 621\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2488000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-13-44\n",
      "done: false\n",
      "episode_len_mean: 196.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.42\n",
      "episode_reward_min: 48.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13019\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31953784823417664\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005506587214767933\n",
      "        model: {}\n",
      "        policy_loss: 0.004187423270195723\n",
      "        total_loss: 7.81668758392334\n",
      "        vf_explained_var: -2.461094936734298e-07\n",
      "        vf_loss: 7.8125\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2488000\n",
      "  num_agent_steps_trained: 2488000\n",
      "  num_steps_sampled: 2488000\n",
      "  num_steps_trained: 2488000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 622\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.809090909090905\n",
      "  ram_util_percent: 86.36363636363635\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06911177257511943\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07931821596701383\n",
      "  mean_inference_ms: 0.7589908563680874\n",
      "  mean_raw_obs_processing_ms: 0.09170050452148748\n",
      "time_since_restore: 4467.365987062454\n",
      "time_this_iter_s: 7.729837417602539\n",
      "time_total_s: 4467.365987062454\n",
      "timers:\n",
      "  learn_throughput: 1141.672\n",
      "  learn_time_ms: 3503.632\n",
      "  load_throughput: 19661568.03\n",
      "  load_time_ms: 0.203\n",
      "  sample_throughput: 476.762\n",
      "  sample_time_ms: 8389.933\n",
      "  update_time_ms: 2.425\n",
      "timestamp: 1658398424\n",
      "timesteps_since_restore: 2488000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2488000\n",
      "training_iteration: 622\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2492000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-13-53\n",
      "done: false\n",
      "episode_len_mean: 193.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.09\n",
      "episode_reward_min: 48.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13040\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3175053298473358\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004718375392258167\n",
      "        model: {}\n",
      "        policy_loss: -0.0007144410046748817\n",
      "        total_loss: 3.08396315574646\n",
      "        vf_explained_var: 0.0040022265166044235\n",
      "        vf_loss: 3.0846774578094482\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2492000\n",
      "  num_agent_steps_trained: 2492000\n",
      "  num_steps_sampled: 2492000\n",
      "  num_steps_trained: 2492000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 623\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.5\n",
      "  ram_util_percent: 86.19999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06913453584351521\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07934283651943383\n",
      "  mean_inference_ms: 0.7592256123271973\n",
      "  mean_raw_obs_processing_ms: 0.09172819273940724\n",
      "time_since_restore: 4475.811467409134\n",
      "time_this_iter_s: 8.445480346679688\n",
      "time_total_s: 4475.811467409134\n",
      "timers:\n",
      "  learn_throughput: 1135.239\n",
      "  learn_time_ms: 3523.486\n",
      "  load_throughput: 18741304.736\n",
      "  load_time_ms: 0.213\n",
      "  sample_throughput: 471.573\n",
      "  sample_time_ms: 8482.248\n",
      "  update_time_ms: 2.409\n",
      "timestamp: 1658398433\n",
      "timesteps_since_restore: 2492000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2492000\n",
      "training_iteration: 623\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2496000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-14-02\n",
      "done: false\n",
      "episode_len_mean: 191.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.39\n",
      "episode_reward_min: 48.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 13062\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3211580812931061\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004023064859211445\n",
      "        model: {}\n",
      "        policy_loss: -0.001217521377839148\n",
      "        total_loss: 3.058258295059204\n",
      "        vf_explained_var: -0.019658289849758148\n",
      "        vf_loss: 3.059475898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2496000\n",
      "  num_agent_steps_trained: 2496000\n",
      "  num_steps_sampled: 2496000\n",
      "  num_steps_trained: 2496000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 624\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.861538461538466\n",
      "  ram_util_percent: 86.34615384615384\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06915946202717374\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07937133511751239\n",
      "  mean_inference_ms: 0.7594833366120253\n",
      "  mean_raw_obs_processing_ms: 0.09175851594997841\n",
      "time_since_restore: 4484.844663619995\n",
      "time_this_iter_s: 9.033196210861206\n",
      "time_total_s: 4484.844663619995\n",
      "timers:\n",
      "  learn_throughput: 1130.961\n",
      "  learn_time_ms: 3536.815\n",
      "  load_throughput: 18595894.48\n",
      "  load_time_ms: 0.215\n",
      "  sample_throughput: 468.554\n",
      "  sample_time_ms: 8536.896\n",
      "  update_time_ms: 2.298\n",
      "timestamp: 1658398442\n",
      "timesteps_since_restore: 2496000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2496000\n",
      "training_iteration: 624\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2500000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-14-09\n",
      "done: false\n",
      "episode_len_mean: 190.54\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.54\n",
      "episode_reward_min: 48.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13082\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32222267985343933\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037099493201822042\n",
      "        model: {}\n",
      "        policy_loss: 0.0004125820705667138\n",
      "        total_loss: 4.138519287109375\n",
      "        vf_explained_var: 0.00581709761172533\n",
      "        vf_loss: 4.138106346130371\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2500000\n",
      "  num_agent_steps_trained: 2500000\n",
      "  num_steps_sampled: 2500000\n",
      "  num_steps_trained: 2500000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 625\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.64545454545454\n",
      "  ram_util_percent: 86.2909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0691818912557287\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0793972214505822\n",
      "  mean_inference_ms: 0.7597159858037833\n",
      "  mean_raw_obs_processing_ms: 0.09178548406163031\n",
      "time_since_restore: 4492.519490480423\n",
      "time_this_iter_s: 7.6748268604278564\n",
      "time_total_s: 4492.519490480423\n",
      "timers:\n",
      "  learn_throughput: 1153.917\n",
      "  learn_time_ms: 3466.455\n",
      "  load_throughput: 18814865.986\n",
      "  load_time_ms: 0.213\n",
      "  sample_throughput: 468.152\n",
      "  sample_time_ms: 8544.24\n",
      "  update_time_ms: 2.232\n",
      "timestamp: 1658398449\n",
      "timesteps_since_restore: 2500000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2500000\n",
      "training_iteration: 625\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2504000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-14-18\n",
      "done: false\n",
      "episode_len_mean: 193.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.01\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13102\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3064526915550232\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004320196341723204\n",
      "        model: {}\n",
      "        policy_loss: 0.0013888549292460084\n",
      "        total_loss: 2.8239729404449463\n",
      "        vf_explained_var: 0.0012931384844705462\n",
      "        vf_loss: 2.8225839138031006\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2504000\n",
      "  num_agent_steps_trained: 2504000\n",
      "  num_steps_sampled: 2504000\n",
      "  num_steps_trained: 2504000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 626\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.31666666666667\n",
      "  ram_util_percent: 86.19999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06920301545033976\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07942161010006199\n",
      "  mean_inference_ms: 0.7599395464521682\n",
      "  mean_raw_obs_processing_ms: 0.09181085576171977\n",
      "time_since_restore: 4501.097274541855\n",
      "time_this_iter_s: 8.577784061431885\n",
      "time_total_s: 4501.097274541855\n",
      "timers:\n",
      "  learn_throughput: 1141.033\n",
      "  learn_time_ms: 3505.595\n",
      "  load_throughput: 17669527.12\n",
      "  load_time_ms: 0.226\n",
      "  sample_throughput: 476.342\n",
      "  sample_time_ms: 8397.323\n",
      "  update_time_ms: 2.213\n",
      "timestamp: 1658398458\n",
      "timesteps_since_restore: 2504000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2504000\n",
      "training_iteration: 626\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2508000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-14-27\n",
      "done: false\n",
      "episode_len_mean: 192.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.85\n",
      "episode_reward_min: 86.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13122\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30271825194358826\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004514484666287899\n",
      "        model: {}\n",
      "        policy_loss: -0.0002763295779004693\n",
      "        total_loss: 1.2799674272537231\n",
      "        vf_explained_var: 0.004631777759641409\n",
      "        vf_loss: 1.2802437543869019\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2508000\n",
      "  num_agent_steps_trained: 2508000\n",
      "  num_steps_sampled: 2508000\n",
      "  num_steps_trained: 2508000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 627\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.89999999999999\n",
      "  ram_util_percent: 86.47692307692309\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06922689326028797\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07944928036879012\n",
      "  mean_inference_ms: 0.7601929974397942\n",
      "  mean_raw_obs_processing_ms: 0.09183957065680184\n",
      "time_since_restore: 4509.88165640831\n",
      "time_this_iter_s: 8.784381866455078\n",
      "time_total_s: 4509.88165640831\n",
      "timers:\n",
      "  learn_throughput: 1136.239\n",
      "  learn_time_ms: 3520.387\n",
      "  load_throughput: 18059435.953\n",
      "  load_time_ms: 0.221\n",
      "  sample_throughput: 473.346\n",
      "  sample_time_ms: 8450.475\n",
      "  update_time_ms: 2.168\n",
      "timestamp: 1658398467\n",
      "timesteps_since_restore: 2508000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2508000\n",
      "training_iteration: 627\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2512000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-14-36\n",
      "done: false\n",
      "episode_len_mean: 195.87\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.87\n",
      "episode_reward_min: 101.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13142\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32766881585121155\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037397167179733515\n",
      "        model: {}\n",
      "        policy_loss: -0.0017231116071343422\n",
      "        total_loss: 0.8122897148132324\n",
      "        vf_explained_var: 0.0073057967238128185\n",
      "        vf_loss: 0.8140128254890442\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2512000\n",
      "  num_agent_steps_trained: 2512000\n",
      "  num_steps_sampled: 2512000\n",
      "  num_steps_trained: 2512000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 628\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.32307692307692\n",
      "  ram_util_percent: 86.36153846153844\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06925181197126123\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07947819922143474\n",
      "  mean_inference_ms: 0.7604594466540345\n",
      "  mean_raw_obs_processing_ms: 0.0918694546835152\n",
      "time_since_restore: 4518.932661771774\n",
      "time_this_iter_s: 9.051005363464355\n",
      "time_total_s: 4518.932661771774\n",
      "timers:\n",
      "  learn_throughput: 1128.574\n",
      "  learn_time_ms: 3544.295\n",
      "  load_throughput: 18501561.535\n",
      "  load_time_ms: 0.216\n",
      "  sample_throughput: 473.975\n",
      "  sample_time_ms: 8439.267\n",
      "  update_time_ms: 2.13\n",
      "timestamp: 1658398476\n",
      "timesteps_since_restore: 2512000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2512000\n",
      "training_iteration: 628\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2516000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-14-45\n",
      "done: false\n",
      "episode_len_mean: 197.95\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.95\n",
      "episode_reward_min: 113.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13163\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.340497225522995\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004301571752876043\n",
      "        model: {}\n",
      "        policy_loss: -0.00015048544446472079\n",
      "        total_loss: 4.0295915603637695\n",
      "        vf_explained_var: 0.0006996304146014154\n",
      "        vf_loss: 4.0297417640686035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2516000\n",
      "  num_agent_steps_trained: 2516000\n",
      "  num_steps_sampled: 2516000\n",
      "  num_steps_trained: 2516000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 629\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.815384615384616\n",
      "  ram_util_percent: 86.4076923076923\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06927885340946183\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07950811861642443\n",
      "  mean_inference_ms: 0.7607478695148875\n",
      "  mean_raw_obs_processing_ms: 0.09190172715223476\n",
      "time_since_restore: 4527.845211029053\n",
      "time_this_iter_s: 8.912549257278442\n",
      "time_total_s: 4527.845211029053\n",
      "timers:\n",
      "  learn_throughput: 1113.256\n",
      "  learn_time_ms: 3593.063\n",
      "  load_throughput: 18347786.527\n",
      "  load_time_ms: 0.218\n",
      "  sample_throughput: 471.244\n",
      "  sample_time_ms: 8488.169\n",
      "  update_time_ms: 2.129\n",
      "timestamp: 1658398485\n",
      "timesteps_since_restore: 2516000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2516000\n",
      "training_iteration: 629\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2520000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-14-52\n",
      "done: false\n",
      "episode_len_mean: 198.82\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.82\n",
      "episode_reward_min: 129.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13183\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.35476744174957275\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030192076228559017\n",
      "        model: {}\n",
      "        policy_loss: 0.006929321680217981\n",
      "        total_loss: 6.962574481964111\n",
      "        vf_explained_var: -7.229466802982643e-08\n",
      "        vf_loss: 6.9556450843811035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2520000\n",
      "  num_agent_steps_trained: 2520000\n",
      "  num_steps_sampled: 2520000\n",
      "  num_steps_trained: 2520000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 630\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.41\n",
      "  ram_util_percent: 86.86999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06930155517442119\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07953326030020703\n",
      "  mean_inference_ms: 0.7609912673053162\n",
      "  mean_raw_obs_processing_ms: 0.09192917435645559\n",
      "time_since_restore: 4535.089921236038\n",
      "time_this_iter_s: 7.244710206985474\n",
      "time_total_s: 4535.089921236038\n",
      "timers:\n",
      "  learn_throughput: 1121.528\n",
      "  learn_time_ms: 3566.563\n",
      "  load_throughput: 18261909.22\n",
      "  load_time_ms: 0.219\n",
      "  sample_throughput: 470.067\n",
      "  sample_time_ms: 8509.423\n",
      "  update_time_ms: 2.098\n",
      "timestamp: 1658398492\n",
      "timesteps_since_restore: 2520000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2520000\n",
      "training_iteration: 630\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2524000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-15-01\n",
      "done: false\n",
      "episode_len_mean: 196.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.12\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13204\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3396887481212616\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004193099681288004\n",
      "        model: {}\n",
      "        policy_loss: 0.0014215345727279782\n",
      "        total_loss: 3.532167673110962\n",
      "        vf_explained_var: -0.06451543420553207\n",
      "        vf_loss: 3.5307459831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2524000\n",
      "  num_agent_steps_trained: 2524000\n",
      "  num_steps_sampled: 2524000\n",
      "  num_steps_trained: 2524000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 631\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.300000000000004\n",
      "  ram_util_percent: 86.7\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06932385452917947\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07955795346107533\n",
      "  mean_inference_ms: 0.7612294528022943\n",
      "  mean_raw_obs_processing_ms: 0.09195641495575387\n",
      "time_since_restore: 4543.659861326218\n",
      "time_this_iter_s: 8.569940090179443\n",
      "time_total_s: 4543.659861326218\n",
      "timers:\n",
      "  learn_throughput: 1120.739\n",
      "  learn_time_ms: 3569.073\n",
      "  load_throughput: 18491365.59\n",
      "  load_time_ms: 0.216\n",
      "  sample_throughput: 474.87\n",
      "  sample_time_ms: 8423.355\n",
      "  update_time_ms: 2.19\n",
      "timestamp: 1658398501\n",
      "timesteps_since_restore: 2524000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2524000\n",
      "training_iteration: 631\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2528000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-15-10\n",
      "done: false\n",
      "episode_len_mean: 195.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.4\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13225\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.31961748003959656\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004023637622594833\n",
      "        model: {}\n",
      "        policy_loss: 0.005836883559823036\n",
      "        total_loss: 6.749792098999023\n",
      "        vf_explained_var: 3.940956503356574e-07\n",
      "        vf_loss: 6.743954658508301\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2528000\n",
      "  num_agent_steps_trained: 2528000\n",
      "  num_steps_sampled: 2528000\n",
      "  num_steps_trained: 2528000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 632\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 50.84285714285715\n",
      "  ram_util_percent: 86.85714285714288\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06934655991734597\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07958302332331917\n",
      "  mean_inference_ms: 0.7614762446317722\n",
      "  mean_raw_obs_processing_ms: 0.0919841688356197\n",
      "time_since_restore: 4553.004287958145\n",
      "time_this_iter_s: 9.34442663192749\n",
      "time_total_s: 4553.004287958145\n",
      "timers:\n",
      "  learn_throughput: 1095.111\n",
      "  learn_time_ms: 3652.599\n",
      "  load_throughput: 18749682.611\n",
      "  load_time_ms: 0.213\n",
      "  sample_throughput: 470.393\n",
      "  sample_time_ms: 8503.537\n",
      "  update_time_ms: 2.235\n",
      "timestamp: 1658398510\n",
      "timesteps_since_restore: 2528000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2528000\n",
      "training_iteration: 632\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2532000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-15-20\n",
      "done: false\n",
      "episode_len_mean: 194.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.98\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13245\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3026842474937439\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037445181515067816\n",
      "        model: {}\n",
      "        policy_loss: 0.004959275480359793\n",
      "        total_loss: 6.645584583282471\n",
      "        vf_explained_var: 4.235775179495249e-07\n",
      "        vf_loss: 6.640625\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2532000\n",
      "  num_agent_steps_trained: 2532000\n",
      "  num_steps_sampled: 2532000\n",
      "  num_steps_trained: 2532000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 633\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.0923076923077\n",
      "  ram_util_percent: 87.16153846153846\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06937033045339376\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07960954826521607\n",
      "  mean_inference_ms: 0.7617328204251025\n",
      "  mean_raw_obs_processing_ms: 0.09201336265997082\n",
      "time_since_restore: 4562.401619911194\n",
      "time_this_iter_s: 9.397331953048706\n",
      "time_total_s: 4562.401619911194\n",
      "timers:\n",
      "  learn_throughput: 1082.688\n",
      "  learn_time_ms: 3694.508\n",
      "  load_throughput: 19556144.073\n",
      "  load_time_ms: 0.205\n",
      "  sample_throughput: 462.87\n",
      "  sample_time_ms: 8641.728\n",
      "  update_time_ms: 2.244\n",
      "timestamp: 1658398520\n",
      "timesteps_since_restore: 2532000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2532000\n",
      "training_iteration: 633\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2536000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-15-30\n",
      "done: false\n",
      "episode_len_mean: 194.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.5\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13266\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3255070447921753\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003819934790953994\n",
      "        model: {}\n",
      "        policy_loss: -0.009469875134527683\n",
      "        total_loss: 6.149806499481201\n",
      "        vf_explained_var: 5.919446266489103e-07\n",
      "        vf_loss: 6.159275531768799\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2536000\n",
      "  num_agent_steps_trained: 2536000\n",
      "  num_steps_sampled: 2536000\n",
      "  num_steps_trained: 2536000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 634\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 57.20666666666667\n",
      "  ram_util_percent: 87.17333333333335\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06940136712687392\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07964445799015242\n",
      "  mean_inference_ms: 0.7620726086648838\n",
      "  mean_raw_obs_processing_ms: 0.09205157722576614\n",
      "time_since_restore: 4572.799636363983\n",
      "time_this_iter_s: 10.398016452789307\n",
      "time_total_s: 4572.799636363983\n",
      "timers:\n",
      "  learn_throughput: 1073.773\n",
      "  learn_time_ms: 3725.181\n",
      "  load_throughput: 19951499.584\n",
      "  load_time_ms: 0.2\n",
      "  sample_throughput: 455.061\n",
      "  sample_time_ms: 8790.021\n",
      "  update_time_ms: 2.246\n",
      "timestamp: 1658398530\n",
      "timesteps_since_restore: 2536000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2536000\n",
      "training_iteration: 634\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2540000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-15-39\n",
      "done: false\n",
      "episode_len_mean: 194.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.5\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13286\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3266834616661072\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034753272775560617\n",
      "        model: {}\n",
      "        policy_loss: -0.0072154393419623375\n",
      "        total_loss: 9.418187141418457\n",
      "        vf_explained_var: 6.482806043095479e-07\n",
      "        vf_loss: 9.425403594970703\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2540000\n",
      "  num_agent_steps_trained: 2540000\n",
      "  num_steps_sampled: 2540000\n",
      "  num_steps_trained: 2540000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 635\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.42307692307691\n",
      "  ram_util_percent: 87.44615384615385\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06944061915444778\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0796880200669548\n",
      "  mean_inference_ms: 0.7624974958358252\n",
      "  mean_raw_obs_processing_ms: 0.09209944247575363\n",
      "time_since_restore: 4582.029009580612\n",
      "time_this_iter_s: 9.229373216629028\n",
      "time_total_s: 4582.029009580612\n",
      "timers:\n",
      "  learn_throughput: 1066.818\n",
      "  learn_time_ms: 3749.466\n",
      "  load_throughput: 19737901.176\n",
      "  load_time_ms: 0.203\n",
      "  sample_throughput: 446.872\n",
      "  sample_time_ms: 8951.106\n",
      "  update_time_ms: 2.332\n",
      "timestamp: 1658398539\n",
      "timesteps_since_restore: 2540000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2540000\n",
      "training_iteration: 635\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2544000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-15-49\n",
      "done: false\n",
      "episode_len_mean: 197.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.2\n",
      "episode_reward_min: 81.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13306\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2859649360179901\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005038565956056118\n",
      "        model: {}\n",
      "        policy_loss: -0.008722924627363682\n",
      "        total_loss: 9.416680335998535\n",
      "        vf_explained_var: 4.0710614257477573e-07\n",
      "        vf_loss: 9.425403594970703\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2544000\n",
      "  num_agent_steps_trained: 2544000\n",
      "  num_steps_sampled: 2544000\n",
      "  num_steps_trained: 2544000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 636\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.357142857142854\n",
      "  ram_util_percent: 87.37142857142858\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06948543067482452\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07973759672997897\n",
      "  mean_inference_ms: 0.7629787040677545\n",
      "  mean_raw_obs_processing_ms: 0.09215361282486394\n",
      "time_since_restore: 4591.569815635681\n",
      "time_this_iter_s: 9.54080605506897\n",
      "time_total_s: 4591.569815635681\n",
      "timers:\n",
      "  learn_throughput: 1062.335\n",
      "  learn_time_ms: 3765.291\n",
      "  load_throughput: 20583015.581\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 441.621\n",
      "  sample_time_ms: 9057.541\n",
      "  update_time_ms: 2.3\n",
      "timestamp: 1658398549\n",
      "timesteps_since_restore: 2544000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2544000\n",
      "training_iteration: 636\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2548000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-15-56\n",
      "done: false\n",
      "episode_len_mean: 198.26\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.26\n",
      "episode_reward_min: 81.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13326\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32277393341064453\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003345922799780965\n",
      "        model: {}\n",
      "        policy_loss: -0.007531457114964724\n",
      "        total_loss: 9.417872428894043\n",
      "        vf_explained_var: 4.275511571449897e-07\n",
      "        vf_loss: 9.425403594970703\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2548000\n",
      "  num_agent_steps_trained: 2548000\n",
      "  num_steps_sampled: 2548000\n",
      "  num_steps_trained: 2548000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 637\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.76363636363636\n",
      "  ram_util_percent: 87.20909090909092\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06952102066370242\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07977688009781296\n",
      "  mean_inference_ms: 0.763359644298321\n",
      "  mean_raw_obs_processing_ms: 0.09219667756762845\n",
      "time_since_restore: 4599.156858682632\n",
      "time_this_iter_s: 7.587043046951294\n",
      "time_total_s: 4599.156858682632\n",
      "timers:\n",
      "  learn_throughput: 1053.503\n",
      "  learn_time_ms: 3796.857\n",
      "  load_throughput: 20766451.293\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 448.373\n",
      "  sample_time_ms: 8921.14\n",
      "  update_time_ms: 2.367\n",
      "timestamp: 1658398556\n",
      "timesteps_since_restore: 2548000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2548000\n",
      "training_iteration: 637\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2552000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-16-04\n",
      "done: false\n",
      "episode_len_mean: 198.81\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.81\n",
      "episode_reward_min: 81.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13346\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28520846366882324\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004028487950563431\n",
      "        model: {}\n",
      "        policy_loss: -0.00880558043718338\n",
      "        total_loss: 9.416597366333008\n",
      "        vf_explained_var: -2.896913997574302e-08\n",
      "        vf_loss: 9.425403594970703\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2552000\n",
      "  num_agent_steps_trained: 2552000\n",
      "  num_steps_sampled: 2552000\n",
      "  num_steps_trained: 2552000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 638\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.372727272727275\n",
      "  ram_util_percent: 86.97272727272728\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06954866371432109\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07980680157516018\n",
      "  mean_inference_ms: 0.7636553755243994\n",
      "  mean_raw_obs_processing_ms: 0.09222963771729815\n",
      "time_since_restore: 4606.791979551315\n",
      "time_this_iter_s: 7.635120868682861\n",
      "time_total_s: 4606.791979551315\n",
      "timers:\n",
      "  learn_throughput: 1064.069\n",
      "  learn_time_ms: 3759.153\n",
      "  load_throughput: 21814089.195\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 451.933\n",
      "  sample_time_ms: 8850.871\n",
      "  update_time_ms: 2.341\n",
      "timestamp: 1658398564\n",
      "timesteps_since_restore: 2552000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2552000\n",
      "training_iteration: 638\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2556000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-16-12\n",
      "done: false\n",
      "episode_len_mean: 198.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.71\n",
      "episode_reward_min: 113.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13366\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32033902406692505\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037859550211578608\n",
      "        model: {}\n",
      "        policy_loss: 0.004175199195742607\n",
      "        total_loss: 5.321717262268066\n",
      "        vf_explained_var: 1.3543073009714135e-06\n",
      "        vf_loss: 5.317542552947998\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2556000\n",
      "  num_agent_steps_trained: 2556000\n",
      "  num_steps_sampled: 2556000\n",
      "  num_steps_trained: 2556000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 639\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.39090909090908\n",
      "  ram_util_percent: 86.84545454545456\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06956717953439258\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07982633226128852\n",
      "  mean_inference_ms: 0.7638583787015101\n",
      "  mean_raw_obs_processing_ms: 0.09225119285598643\n",
      "time_since_restore: 4614.744268655777\n",
      "time_this_iter_s: 7.95228910446167\n",
      "time_total_s: 4614.744268655777\n",
      "timers:\n",
      "  learn_throughput: 1071.995\n",
      "  learn_time_ms: 3731.359\n",
      "  load_throughput: 21931001.307\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 457.482\n",
      "  sample_time_ms: 8743.517\n",
      "  update_time_ms: 2.418\n",
      "timestamp: 1658398572\n",
      "timesteps_since_restore: 2556000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2556000\n",
      "training_iteration: 639\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2560000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-16-20\n",
      "done: false\n",
      "episode_len_mean: 196.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.44\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13387\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2838483154773712\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003296098206192255\n",
      "        model: {}\n",
      "        policy_loss: 0.0007702694274485111\n",
      "        total_loss: 3.0249643325805664\n",
      "        vf_explained_var: -0.03780341148376465\n",
      "        vf_loss: 3.0241940021514893\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2560000\n",
      "  num_agent_steps_trained: 2560000\n",
      "  num_steps_sampled: 2560000\n",
      "  num_steps_trained: 2560000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 640\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.699999999999996\n",
      "  ram_util_percent: 87.17272727272729\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06957944236549672\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07983884617455042\n",
      "  mean_inference_ms: 0.763995018468986\n",
      "  mean_raw_obs_processing_ms: 0.09226515598803905\n",
      "time_since_restore: 4622.4700293540955\n",
      "time_this_iter_s: 7.7257606983184814\n",
      "time_total_s: 4622.4700293540955\n",
      "timers:\n",
      "  learn_throughput: 1077.312\n",
      "  learn_time_ms: 3712.945\n",
      "  load_throughput: 21597857.878\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 455.421\n",
      "  sample_time_ms: 8783.087\n",
      "  update_time_ms: 2.419\n",
      "timestamp: 1658398580\n",
      "timesteps_since_restore: 2560000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2560000\n",
      "training_iteration: 640\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2564000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-16-29\n",
      "done: false\n",
      "episode_len_mean: 196.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.44\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13407\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27462366223335266\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004239554516971111\n",
      "        model: {}\n",
      "        policy_loss: 0.00012168913235655054\n",
      "        total_loss: 1.613025188446045\n",
      "        vf_explained_var: -0.06566805392503738\n",
      "        vf_loss: 1.6129032373428345\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2564000\n",
      "  num_agent_steps_trained: 2564000\n",
      "  num_steps_sampled: 2564000\n",
      "  num_steps_trained: 2564000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 641\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.892307692307696\n",
      "  ram_util_percent: 86.98461538461538\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06958502432008258\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07984417981821032\n",
      "  mean_inference_ms: 0.7640677846191969\n",
      "  mean_raw_obs_processing_ms: 0.09227197415052034\n",
      "time_since_restore: 4631.382576704025\n",
      "time_this_iter_s: 8.91254734992981\n",
      "time_total_s: 4631.382576704025\n",
      "timers:\n",
      "  learn_throughput: 1065.233\n",
      "  learn_time_ms: 3755.046\n",
      "  load_throughput: 21484461.519\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 456.761\n",
      "  sample_time_ms: 8757.314\n",
      "  update_time_ms: 2.427\n",
      "timestamp: 1658398589\n",
      "timesteps_since_restore: 2564000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2564000\n",
      "training_iteration: 641\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2568000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-16-39\n",
      "done: false\n",
      "episode_len_mean: 196.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.2\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13427\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30049657821655273\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004077909979969263\n",
      "        model: {}\n",
      "        policy_loss: -0.0017714576097205281\n",
      "        total_loss: 1.0062932968139648\n",
      "        vf_explained_var: 0.00245406455360353\n",
      "        vf_loss: 1.0080646276474\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2568000\n",
      "  num_agent_steps_trained: 2568000\n",
      "  num_steps_sampled: 2568000\n",
      "  num_steps_trained: 2568000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 642\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.9\n",
      "  ram_util_percent: 86.71428571428571\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06960518669829102\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07986651093478665\n",
      "  mean_inference_ms: 0.7642958953401054\n",
      "  mean_raw_obs_processing_ms: 0.09229576078597028\n",
      "time_since_restore: 4641.242671728134\n",
      "time_this_iter_s: 9.860095024108887\n",
      "time_total_s: 4641.242671728134\n",
      "timers:\n",
      "  learn_throughput: 1077.942\n",
      "  learn_time_ms: 3710.775\n",
      "  load_throughput: 21140645.161\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 449.687\n",
      "  sample_time_ms: 8895.083\n",
      "  update_time_ms: 2.388\n",
      "timestamp: 1658398599\n",
      "timesteps_since_restore: 2568000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2568000\n",
      "training_iteration: 642\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2572000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-16-48\n",
      "done: false\n",
      "episode_len_mean: 195.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.11\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13448\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.32798776030540466\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006437783595174551\n",
      "        model: {}\n",
      "        policy_loss: -0.0061560990288853645\n",
      "        total_loss: 1.0850739479064941\n",
      "        vf_explained_var: -0.2137552946805954\n",
      "        vf_loss: 1.0912299156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2572000\n",
      "  num_agent_steps_trained: 2572000\n",
      "  num_steps_sampled: 2572000\n",
      "  num_steps_trained: 2572000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 643\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.16428571428572\n",
      "  ram_util_percent: 86.72857142857143\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.069630792316766\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07989539426504572\n",
      "  mean_inference_ms: 0.7645843701780602\n",
      "  mean_raw_obs_processing_ms: 0.09232637192688689\n",
      "time_since_restore: 4650.751915931702\n",
      "time_this_iter_s: 9.509244203567505\n",
      "time_total_s: 4650.751915931702\n",
      "timers:\n",
      "  learn_throughput: 1058.044\n",
      "  learn_time_ms: 3780.56\n",
      "  load_throughput: 20661596.059\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 455.019\n",
      "  sample_time_ms: 8790.848\n",
      "  update_time_ms: 2.424\n",
      "timestamp: 1658398608\n",
      "timesteps_since_restore: 2572000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2572000\n",
      "training_iteration: 643\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2576000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-16-58\n",
      "done: false\n",
      "episode_len_mean: 193.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.03\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 13470\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30323389172554016\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006110901944339275\n",
      "        model: {}\n",
      "        policy_loss: -0.0008523117867298424\n",
      "        total_loss: 3.4114480018615723\n",
      "        vf_explained_var: -0.10697262734174728\n",
      "        vf_loss: 3.4123001098632812\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2576000\n",
      "  num_agent_steps_trained: 2576000\n",
      "  num_steps_sampled: 2576000\n",
      "  num_steps_trained: 2576000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 644\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.62142857142857\n",
      "  ram_util_percent: 86.47857142857141\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06966310467653915\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07993170308790347\n",
      "  mean_inference_ms: 0.7649406081488581\n",
      "  mean_raw_obs_processing_ms: 0.09236574858975156\n",
      "time_since_restore: 4660.577610492706\n",
      "time_this_iter_s: 9.825694561004639\n",
      "time_total_s: 4660.577610492706\n",
      "timers:\n",
      "  learn_throughput: 1054.433\n",
      "  learn_time_ms: 3793.51\n",
      "  load_throughput: 19878218.009\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 455.028\n",
      "  sample_time_ms: 8790.676\n",
      "  update_time_ms: 2.486\n",
      "timestamp: 1658398618\n",
      "timesteps_since_restore: 2576000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2576000\n",
      "training_iteration: 644\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2580000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-17-06\n",
      "done: false\n",
      "episode_len_mean: 194.6\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.6\n",
      "episode_reward_min: 91.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13490\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3128241300582886\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003706605639308691\n",
      "        model: {}\n",
      "        policy_loss: 0.004318888299167156\n",
      "        total_loss: 6.405529022216797\n",
      "        vf_explained_var: 1.4606342801926075e-06\n",
      "        vf_loss: 6.401209831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2580000\n",
      "  num_agent_steps_trained: 2580000\n",
      "  num_steps_sampled: 2580000\n",
      "  num_steps_trained: 2580000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 645\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.72727272727273\n",
      "  ram_util_percent: 86.16363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06968857600246603\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07996063205147146\n",
      "  mean_inference_ms: 0.7652257869619487\n",
      "  mean_raw_obs_processing_ms: 0.0923969083270606\n",
      "time_since_restore: 4668.838981389999\n",
      "time_this_iter_s: 8.26137089729309\n",
      "time_total_s: 4668.838981389999\n",
      "timers:\n",
      "  learn_throughput: 1030.996\n",
      "  learn_time_ms: 3879.742\n",
      "  load_throughput: 20061241.181\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 463.962\n",
      "  sample_time_ms: 8621.399\n",
      "  update_time_ms: 2.438\n",
      "timestamp: 1658398626\n",
      "timesteps_since_restore: 2580000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2580000\n",
      "training_iteration: 645\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2584000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-17-18\n",
      "done: false\n",
      "episode_len_mean: 193.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.01\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13511\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3093043863773346\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005228463094681501\n",
      "        model: {}\n",
      "        policy_loss: 0.003796440316364169\n",
      "        total_loss: 6.241197109222412\n",
      "        vf_explained_var: 8.22928640786813e-08\n",
      "        vf_loss: 6.237400054931641\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2584000\n",
      "  num_agent_steps_trained: 2584000\n",
      "  num_steps_sampled: 2584000\n",
      "  num_steps_trained: 2584000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 646\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 65.61764705882354\n",
      "  ram_util_percent: 86.53529411764707\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06972648195178646\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08000329726870348\n",
      "  mean_inference_ms: 0.7656466782058134\n",
      "  mean_raw_obs_processing_ms: 0.09244273278176966\n",
      "time_since_restore: 4680.6903467178345\n",
      "time_this_iter_s: 11.851365327835083\n",
      "time_total_s: 4680.6903467178345\n",
      "timers:\n",
      "  learn_throughput: 1003.498\n",
      "  learn_time_ms: 3986.056\n",
      "  load_throughput: 18764361.928\n",
      "  load_time_ms: 0.213\n",
      "  sample_throughput: 452.93\n",
      "  sample_time_ms: 8831.386\n",
      "  update_time_ms: 2.561\n",
      "timestamp: 1658398638\n",
      "timesteps_since_restore: 2584000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2584000\n",
      "training_iteration: 646\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2588000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-17-28\n",
      "done: false\n",
      "episode_len_mean: 193.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.15\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13531\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2945726215839386\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004453685600310564\n",
      "        model: {}\n",
      "        policy_loss: 0.004705843981355429\n",
      "        total_loss: 6.204302787780762\n",
      "        vf_explained_var: 5.236236120254034e-07\n",
      "        vf_loss: 6.199596881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2588000\n",
      "  num_agent_steps_trained: 2588000\n",
      "  num_steps_sampled: 2588000\n",
      "  num_steps_trained: 2588000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 647\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.48571428571429\n",
      "  ram_util_percent: 87.41428571428571\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06975905930687545\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08003938508006544\n",
      "  mean_inference_ms: 0.766006495553454\n",
      "  mean_raw_obs_processing_ms: 0.09248253812932596\n",
      "time_since_restore: 4690.14995598793\n",
      "time_this_iter_s: 9.459609270095825\n",
      "time_total_s: 4690.14995598793\n",
      "timers:\n",
      "  learn_throughput: 1000.861\n",
      "  learn_time_ms: 3996.558\n",
      "  load_throughput: 18471007.376\n",
      "  load_time_ms: 0.217\n",
      "  sample_throughput: 438.802\n",
      "  sample_time_ms: 9115.737\n",
      "  update_time_ms: 2.607\n",
      "timestamp: 1658398648\n",
      "timesteps_since_restore: 2588000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2588000\n",
      "training_iteration: 647\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2592000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-17-38\n",
      "done: false\n",
      "episode_len_mean: 194.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.68\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13551\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2859130799770355\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004908278118818998\n",
      "        model: {}\n",
      "        policy_loss: 0.0033320109359920025\n",
      "        total_loss: 6.1374077796936035\n",
      "        vf_explained_var: 4.918985609947413e-07\n",
      "        vf_loss: 6.13407564163208\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2592000\n",
      "  num_agent_steps_trained: 2592000\n",
      "  num_steps_sampled: 2592000\n",
      "  num_steps_trained: 2592000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 648\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 54.62142857142857\n",
      "  ram_util_percent: 86.95714285714287\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06979882611111399\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08008318281267585\n",
      "  mean_inference_ms: 0.7664405365114578\n",
      "  mean_raw_obs_processing_ms: 0.09253093308834293\n",
      "time_since_restore: 4700.190038442612\n",
      "time_this_iter_s: 10.040082454681396\n",
      "time_total_s: 4700.190038442612\n",
      "timers:\n",
      "  learn_throughput: 993.821\n",
      "  learn_time_ms: 4024.869\n",
      "  load_throughput: 17798871.207\n",
      "  load_time_ms: 0.225\n",
      "  sample_throughput: 428.362\n",
      "  sample_time_ms: 9337.889\n",
      "  update_time_ms: 2.66\n",
      "timestamp: 1658398658\n",
      "timesteps_since_restore: 2592000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2592000\n",
      "training_iteration: 648\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2596000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-17-46\n",
      "done: false\n",
      "episode_len_mean: 197.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.48\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13571\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2970183193683624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004355091135948896\n",
      "        model: {}\n",
      "        policy_loss: 0.0026908142026513815\n",
      "        total_loss: 5.547045707702637\n",
      "        vf_explained_var: 9.871298516372917e-07\n",
      "        vf_loss: 5.5443549156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2596000\n",
      "  num_agent_steps_trained: 2596000\n",
      "  num_steps_sampled: 2596000\n",
      "  num_steps_trained: 2596000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 649\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.07692307692308\n",
      "  ram_util_percent: 87.36923076923078\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06983911897155175\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08012826503275543\n",
      "  mean_inference_ms: 0.7668856547950171\n",
      "  mean_raw_obs_processing_ms: 0.0925802686818599\n",
      "time_since_restore: 4708.747964859009\n",
      "time_this_iter_s: 8.557926416397095\n",
      "time_total_s: 4708.747964859009\n",
      "timers:\n",
      "  learn_throughput: 1003.205\n",
      "  learn_time_ms: 3987.22\n",
      "  load_throughput: 17851900.404\n",
      "  load_time_ms: 0.224\n",
      "  sample_throughput: 422.491\n",
      "  sample_time_ms: 9467.663\n",
      "  update_time_ms: 2.643\n",
      "timestamp: 1658398666\n",
      "timesteps_since_restore: 2596000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2596000\n",
      "training_iteration: 649\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2600000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-17-53\n",
      "done: false\n",
      "episode_len_mean: 197.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.02\n",
      "episode_reward_min: 58.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13592\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30581730604171753\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003272741101682186\n",
      "        model: {}\n",
      "        policy_loss: -0.013046602718532085\n",
      "        total_loss: 4.901269435882568\n",
      "        vf_explained_var: 1.8256325802212814e-06\n",
      "        vf_loss: 4.914315700531006\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2600000\n",
      "  num_agent_steps_trained: 2600000\n",
      "  num_steps_sampled: 2600000\n",
      "  num_steps_trained: 2600000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 650\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.32000000000001\n",
      "  ram_util_percent: 86.8\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06988035371816814\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.080174706372655\n",
      "  mean_inference_ms: 0.7673380286231971\n",
      "  mean_raw_obs_processing_ms: 0.09263067791854906\n",
      "time_since_restore: 4715.814902067184\n",
      "time_this_iter_s: 7.066937208175659\n",
      "time_total_s: 4715.814902067184\n",
      "timers:\n",
      "  learn_throughput: 1003.656\n",
      "  learn_time_ms: 3985.431\n",
      "  load_throughput: 18098399.137\n",
      "  load_time_ms: 0.221\n",
      "  sample_throughput: 427.13\n",
      "  sample_time_ms: 9364.836\n",
      "  update_time_ms: 2.643\n",
      "timestamp: 1658398673\n",
      "timesteps_since_restore: 2600000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2600000\n",
      "training_iteration: 650\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2604000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-18-00\n",
      "done: false\n",
      "episode_len_mean: 198.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.71\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13612\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2977408170700073\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003609755774959922\n",
      "        model: {}\n",
      "        policy_loss: -0.013140992261469364\n",
      "        total_loss: 9.69956111907959\n",
      "        vf_explained_var: 3.355805517912813e-07\n",
      "        vf_loss: 9.712701797485352\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2604000\n",
      "  num_agent_steps_trained: 2604000\n",
      "  num_steps_sampled: 2604000\n",
      "  num_steps_trained: 2604000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 651\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 31.5\n",
      "  ram_util_percent: 86.72222222222223\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06990308196229396\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08020056188118944\n",
      "  mean_inference_ms: 0.76758591183062\n",
      "  mean_raw_obs_processing_ms: 0.092658704600817\n",
      "time_since_restore: 4722.290321826935\n",
      "time_this_iter_s: 6.475419759750366\n",
      "time_total_s: 4722.290321826935\n",
      "timers:\n",
      "  learn_throughput: 1041.493\n",
      "  learn_time_ms: 3840.64\n",
      "  load_throughput: 17882344.916\n",
      "  load_time_ms: 0.224\n",
      "  sample_throughput: 431.772\n",
      "  sample_time_ms: 9264.156\n",
      "  update_time_ms: 2.511\n",
      "timestamp: 1658398680\n",
      "timesteps_since_restore: 2604000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2604000\n",
      "training_iteration: 651\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2608000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-18-07\n",
      "done: false\n",
      "episode_len_mean: 197.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.38\n",
      "episode_reward_min: 112.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13632\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2933969795703888\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005337280221283436\n",
      "        model: {}\n",
      "        policy_loss: 0.002045664470642805\n",
      "        total_loss: 6.3226141929626465\n",
      "        vf_explained_var: 1.7745520608514198e-06\n",
      "        vf_loss: 6.320568561553955\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2608000\n",
      "  num_agent_steps_trained: 2608000\n",
      "  num_steps_sampled: 2608000\n",
      "  num_steps_trained: 2608000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 652\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.01\n",
      "  ram_util_percent: 86.54\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0699172799552551\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08021727266790656\n",
      "  mean_inference_ms: 0.7677504020789914\n",
      "  mean_raw_obs_processing_ms: 0.09267654335865157\n",
      "time_since_restore: 4729.163418531418\n",
      "time_this_iter_s: 6.873096704483032\n",
      "time_total_s: 4729.163418531418\n",
      "timers:\n",
      "  learn_throughput: 1060.144\n",
      "  learn_time_ms: 3773.072\n",
      "  load_throughput: 18442581.071\n",
      "  load_time_ms: 0.217\n",
      "  sample_throughput: 450.085\n",
      "  sample_time_ms: 8887.219\n",
      "  update_time_ms: 2.473\n",
      "timestamp: 1658398687\n",
      "timesteps_since_restore: 2608000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2608000\n",
      "training_iteration: 652\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2612000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-18-14\n",
      "done: false\n",
      "episode_len_mean: 194.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.42\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 13654\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29776671528816223\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00505923293530941\n",
      "        model: {}\n",
      "        policy_loss: 0.00037752967909909785\n",
      "        total_loss: 4.471145153045654\n",
      "        vf_explained_var: -0.06451437622308731\n",
      "        vf_loss: 4.470767498016357\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2612000\n",
      "  num_agent_steps_trained: 2612000\n",
      "  num_steps_sampled: 2612000\n",
      "  num_steps_trained: 2612000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 653\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.166666666666664\n",
      "  ram_util_percent: 86.46666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06991702094383444\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08021799174839157\n",
      "  mean_inference_ms: 0.7677608980029192\n",
      "  mean_raw_obs_processing_ms: 0.09267682296517366\n",
      "time_since_restore: 4735.836016893387\n",
      "time_this_iter_s: 6.672598361968994\n",
      "time_total_s: 4735.836016893387\n",
      "timers:\n",
      "  learn_throughput: 1105.221\n",
      "  learn_time_ms: 3619.185\n",
      "  load_throughput: 18974458.267\n",
      "  load_time_ms: 0.211\n",
      "  sample_throughput: 460.322\n",
      "  sample_time_ms: 8689.567\n",
      "  update_time_ms: 2.501\n",
      "timestamp: 1658398694\n",
      "timesteps_since_restore: 2612000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2612000\n",
      "training_iteration: 653\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2616000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-18-22\n",
      "done: false\n",
      "episode_len_mean: 194.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.7\n",
      "episode_reward_min: 98.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13674\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2836216986179352\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004540650639683008\n",
      "        model: {}\n",
      "        policy_loss: 0.006096952129155397\n",
      "        total_loss: 7.667387008666992\n",
      "        vf_explained_var: -1.390775050680304e-08\n",
      "        vf_loss: 7.661290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2616000\n",
      "  num_agent_steps_trained: 2616000\n",
      "  num_steps_sampled: 2616000\n",
      "  num_steps_trained: 2616000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 654\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.10833333333334\n",
      "  ram_util_percent: 86.63333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06991289371560078\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08021372566270393\n",
      "  mean_inference_ms: 0.7677242345317581\n",
      "  mean_raw_obs_processing_ms: 0.09267152536838663\n",
      "time_since_restore: 4744.268279790878\n",
      "time_this_iter_s: 8.432262897491455\n",
      "time_total_s: 4744.268279790878\n",
      "timers:\n",
      "  learn_throughput: 1119.32\n",
      "  learn_time_ms: 3573.597\n",
      "  load_throughput: 18889006.98\n",
      "  load_time_ms: 0.212\n",
      "  sample_throughput: 473.808\n",
      "  sample_time_ms: 8442.235\n",
      "  update_time_ms: 2.48\n",
      "timestamp: 1658398702\n",
      "timesteps_since_restore: 2616000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2616000\n",
      "training_iteration: 654\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2620000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-18-31\n",
      "done: false\n",
      "episode_len_mean: 194.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.05\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13695\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2927212715148926\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004386001732200384\n",
      "        model: {}\n",
      "        policy_loss: -0.01683560200035572\n",
      "        total_loss: 8.302218437194824\n",
      "        vf_explained_var: 1.3946205399406608e-06\n",
      "        vf_loss: 8.31905460357666\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2620000\n",
      "  num_agent_steps_trained: 2620000\n",
      "  num_steps_sampled: 2620000\n",
      "  num_steps_trained: 2620000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 655\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.58461538461539\n",
      "  ram_util_percent: 87.1846153846154\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06991724930416585\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.080218481871137\n",
      "  mean_inference_ms: 0.7677808573186704\n",
      "  mean_raw_obs_processing_ms: 0.09267681463968368\n",
      "time_since_restore: 4752.92079615593\n",
      "time_this_iter_s: 8.65251636505127\n",
      "time_total_s: 4752.92079615593\n",
      "timers:\n",
      "  learn_throughput: 1156.546\n",
      "  learn_time_ms: 3458.575\n",
      "  load_throughput: 18161091.145\n",
      "  load_time_ms: 0.22\n",
      "  sample_throughput: 467.807\n",
      "  sample_time_ms: 8550.529\n",
      "  update_time_ms: 2.49\n",
      "timestamp: 1658398711\n",
      "timesteps_since_restore: 2620000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2620000\n",
      "training_iteration: 655\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2624000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-18-39\n",
      "done: false\n",
      "episode_len_mean: 193.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.57\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13715\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3007386028766632\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004520902875810862\n",
      "        model: {}\n",
      "        policy_loss: 0.002033010357990861\n",
      "        total_loss: 5.9874420166015625\n",
      "        vf_explained_var: 7.174989491431916e-07\n",
      "        vf_loss: 5.985408782958984\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2624000\n",
      "  num_agent_steps_trained: 2624000\n",
      "  num_steps_sampled: 2624000\n",
      "  num_steps_trained: 2624000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 656\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.945454545454545\n",
      "  ram_util_percent: 86.62727272727274\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06992380491651291\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08022547118222446\n",
      "  mean_inference_ms: 0.7678597706343905\n",
      "  mean_raw_obs_processing_ms: 0.09268460773215445\n",
      "time_since_restore: 4760.859455823898\n",
      "time_this_iter_s: 7.93865966796875\n",
      "time_total_s: 4760.859455823898\n",
      "timers:\n",
      "  learn_throughput: 1193.98\n",
      "  learn_time_ms: 3350.14\n",
      "  load_throughput: 20177048.707\n",
      "  load_time_ms: 0.198\n",
      "  sample_throughput: 490.587\n",
      "  sample_time_ms: 8153.501\n",
      "  update_time_ms: 2.393\n",
      "timestamp: 1658398719\n",
      "timesteps_since_restore: 2624000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2624000\n",
      "training_iteration: 656\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2628000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-18-48\n",
      "done: false\n",
      "episode_len_mean: 194.31\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.31\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13735\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2853119671344757\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031048008240759373\n",
      "        model: {}\n",
      "        policy_loss: 0.0035221418365836143\n",
      "        total_loss: 4.640619277954102\n",
      "        vf_explained_var: 2.5636406331130956e-09\n",
      "        vf_loss: 4.637096881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2628000\n",
      "  num_agent_steps_trained: 2628000\n",
      "  num_steps_sampled: 2628000\n",
      "  num_steps_trained: 2628000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 657\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.29999999999999\n",
      "  ram_util_percent: 87.02307692307691\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06994050952397153\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08024354949479781\n",
      "  mean_inference_ms: 0.7680393595164747\n",
      "  mean_raw_obs_processing_ms: 0.0927044634163648\n",
      "time_since_restore: 4770.223273515701\n",
      "time_this_iter_s: 9.363817691802979\n",
      "time_total_s: 4770.223273515701\n",
      "timers:\n",
      "  learn_throughput: 1209.296\n",
      "  learn_time_ms: 3307.71\n",
      "  load_throughput: 19528827.843\n",
      "  load_time_ms: 0.205\n",
      "  sample_throughput: 495.232\n",
      "  sample_time_ms: 8077.015\n",
      "  update_time_ms: 2.331\n",
      "timestamp: 1658398728\n",
      "timesteps_since_restore: 2628000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2628000\n",
      "training_iteration: 657\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2632000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-18-57\n",
      "done: false\n",
      "episode_len_mean: 197.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.4\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13755\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.250609427690506\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036484634038060904\n",
      "        model: {}\n",
      "        policy_loss: 0.004292801488190889\n",
      "        total_loss: 4.6413893699646\n",
      "        vf_explained_var: 9.54956149712416e-08\n",
      "        vf_loss: 4.637096881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2632000\n",
      "  num_agent_steps_trained: 2632000\n",
      "  num_steps_sampled: 2632000\n",
      "  num_steps_trained: 2632000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 658\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.46923076923077\n",
      "  ram_util_percent: 87.11538461538463\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.06996478113052045\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08027021585716985\n",
      "  mean_inference_ms: 0.768297993150747\n",
      "  mean_raw_obs_processing_ms: 0.09273351361757932\n",
      "time_since_restore: 4779.152951717377\n",
      "time_this_iter_s: 8.929678201675415\n",
      "time_total_s: 4779.152951717377\n",
      "timers:\n",
      "  learn_throughput: 1208.464\n",
      "  learn_time_ms: 3309.986\n",
      "  load_throughput: 19852344.101\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 505.059\n",
      "  sample_time_ms: 7919.86\n",
      "  update_time_ms: 2.348\n",
      "timestamp: 1658398737\n",
      "timesteps_since_restore: 2632000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2632000\n",
      "training_iteration: 658\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2636000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-19-08\n",
      "done: false\n",
      "episode_len_mean: 196.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.98\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13775\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29796120524406433\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004373413510620594\n",
      "        model: {}\n",
      "        policy_loss: -0.00025947773247025907\n",
      "        total_loss: 3.366676092147827\n",
      "        vf_explained_var: -0.06770201027393341\n",
      "        vf_loss: 3.3669354915618896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2636000\n",
      "  num_agent_steps_trained: 2636000\n",
      "  num_steps_sampled: 2636000\n",
      "  num_steps_trained: 2636000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 659\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 60.306250000000006\n",
      "  ram_util_percent: 87.85625\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07000474228899056\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0803144889076054\n",
      "  mean_inference_ms: 0.7687311688972522\n",
      "  mean_raw_obs_processing_ms: 0.09278288919966096\n",
      "time_since_restore: 4790.20437169075\n",
      "time_this_iter_s: 11.051419973373413\n",
      "time_total_s: 4790.20437169075\n",
      "timers:\n",
      "  learn_throughput: 1196.02\n",
      "  learn_time_ms: 3344.425\n",
      "  load_throughput: 19350883.506\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 491.694\n",
      "  sample_time_ms: 8135.137\n",
      "  update_time_ms: 2.324\n",
      "timestamp: 1658398748\n",
      "timesteps_since_restore: 2636000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2636000\n",
      "training_iteration: 659\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2640000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-19-15\n",
      "done: false\n",
      "episode_len_mean: 198.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.5\n",
      "episode_reward_min: 93.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13795\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2993350923061371\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005002746824175119\n",
      "        model: {}\n",
      "        policy_loss: -0.0008319952175952494\n",
      "        total_loss: 2.4890871047973633\n",
      "        vf_explained_var: -0.09353069216012955\n",
      "        vf_loss: 2.489919424057007\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2640000\n",
      "  num_agent_steps_trained: 2640000\n",
      "  num_steps_sampled: 2640000\n",
      "  num_steps_trained: 2640000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 660\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.25454545454545\n",
      "  ram_util_percent: 87.76363636363635\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07003834994508301\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08035207965356736\n",
      "  mean_inference_ms: 0.7690955025106814\n",
      "  mean_raw_obs_processing_ms: 0.09282485776562836\n",
      "time_since_restore: 4797.571158885956\n",
      "time_this_iter_s: 7.3667871952056885\n",
      "time_total_s: 4797.571158885956\n",
      "timers:\n",
      "  learn_throughput: 1194.494\n",
      "  learn_time_ms: 3348.697\n",
      "  load_throughput: 19382181.146\n",
      "  load_time_ms: 0.206\n",
      "  sample_throughput: 488.086\n",
      "  sample_time_ms: 8195.27\n",
      "  update_time_ms: 2.353\n",
      "timestamp: 1658398755\n",
      "timesteps_since_restore: 2640000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2640000\n",
      "training_iteration: 660\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2644000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-19-24\n",
      "done: false\n",
      "episode_len_mean: 199.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.57\n",
      "episode_reward_min: 158.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13815\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30341219902038574\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00545632466673851\n",
      "        model: {}\n",
      "        policy_loss: 0.0005848970031365752\n",
      "        total_loss: 2.470343589782715\n",
      "        vf_explained_var: -0.010823269374668598\n",
      "        vf_loss: 2.4697585105895996\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2644000\n",
      "  num_agent_steps_trained: 2644000\n",
      "  num_steps_sampled: 2644000\n",
      "  num_steps_trained: 2644000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 661\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.650000000000006\n",
      "  ram_util_percent: 88.04166666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07007498480097551\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08039337623442297\n",
      "  mean_inference_ms: 0.7694932585878056\n",
      "  mean_raw_obs_processing_ms: 0.0928709288661814\n",
      "time_since_restore: 4805.9449598789215\n",
      "time_this_iter_s: 8.373800992965698\n",
      "time_total_s: 4805.9449598789215\n",
      "timers:\n",
      "  learn_throughput: 1166.015\n",
      "  learn_time_ms: 3430.487\n",
      "  load_throughput: 19782120.033\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 481.509\n",
      "  sample_time_ms: 8307.218\n",
      "  update_time_ms: 2.388\n",
      "timestamp: 1658398764\n",
      "timesteps_since_restore: 2644000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2644000\n",
      "training_iteration: 661\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2648000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-19-32\n",
      "done: false\n",
      "episode_len_mean: 199.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.57\n",
      "episode_reward_min: 158.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13835\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26990386843681335\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00243971636518836\n",
      "        model: {}\n",
      "        policy_loss: 0.0025234983768314123\n",
      "        total_loss: 2.4722819328308105\n",
      "        vf_explained_var: -0.009818159975111485\n",
      "        vf_loss: 2.4697580337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2648000\n",
      "  num_agent_steps_trained: 2648000\n",
      "  num_steps_sampled: 2648000\n",
      "  num_steps_trained: 2648000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 662\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.71666666666666\n",
      "  ram_util_percent: 88.32499999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07010942430720603\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08043242495589949\n",
      "  mean_inference_ms: 0.7698684193006161\n",
      "  mean_raw_obs_processing_ms: 0.0929145571530738\n",
      "time_since_restore: 4814.4630353450775\n",
      "time_this_iter_s: 8.518075466156006\n",
      "time_total_s: 4814.4630353450775\n",
      "timers:\n",
      "  learn_throughput: 1156.603\n",
      "  learn_time_ms: 3458.404\n",
      "  load_throughput: 19633956.7\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 469.092\n",
      "  sample_time_ms: 8527.112\n",
      "  update_time_ms: 2.381\n",
      "timestamp: 1658398772\n",
      "timesteps_since_restore: 2648000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2648000\n",
      "training_iteration: 662\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2652000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-19-40\n",
      "done: false\n",
      "episode_len_mean: 199.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.57\n",
      "episode_reward_min: 158.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13855\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2795911133289337\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003542061196640134\n",
      "        model: {}\n",
      "        policy_loss: 0.0006186022656038404\n",
      "        total_loss: 2.47037672996521\n",
      "        vf_explained_var: -0.06676638126373291\n",
      "        vf_loss: 2.4697580337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2652000\n",
      "  num_agent_steps_trained: 2652000\n",
      "  num_steps_sampled: 2652000\n",
      "  num_steps_trained: 2652000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 663\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.09090909090909\n",
      "  ram_util_percent: 88.10000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07013926858447529\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08046627749336553\n",
      "  mean_inference_ms: 0.7701940752777406\n",
      "  mean_raw_obs_processing_ms: 0.09295331134387666\n",
      "time_since_restore: 4822.285140752792\n",
      "time_this_iter_s: 7.822105407714844\n",
      "time_total_s: 4822.285140752792\n",
      "timers:\n",
      "  learn_throughput: 1139.13\n",
      "  learn_time_ms: 3511.451\n",
      "  load_throughput: 19447335.111\n",
      "  load_time_ms: 0.206\n",
      "  sample_throughput: 464.165\n",
      "  sample_time_ms: 8617.628\n",
      "  update_time_ms: 2.296\n",
      "timestamp: 1658398780\n",
      "timesteps_since_restore: 2652000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2652000\n",
      "training_iteration: 663\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2656000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-19-48\n",
      "done: false\n",
      "episode_len_mean: 199.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.99\n",
      "episode_reward_min: 199.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13875\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2683427631855011\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003137030638754368\n",
      "        model: {}\n",
      "        policy_loss: 0.0012866389006376266\n",
      "        total_loss: 2.47104549407959\n",
      "        vf_explained_var: 0.0019572919700294733\n",
      "        vf_loss: 2.4697585105895996\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2656000\n",
      "  num_agent_steps_trained: 2656000\n",
      "  num_steps_sampled: 2656000\n",
      "  num_steps_trained: 2656000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 664\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.95454545454545\n",
      "  ram_util_percent: 88.06363636363636\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0701515820421721\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08048054768745161\n",
      "  mean_inference_ms: 0.7703232916901461\n",
      "  mean_raw_obs_processing_ms: 0.0929700778698669\n",
      "time_since_restore: 4829.991104602814\n",
      "time_this_iter_s: 7.705963850021362\n",
      "time_total_s: 4829.991104602814\n",
      "timers:\n",
      "  learn_throughput: 1153.581\n",
      "  learn_time_ms: 3467.465\n",
      "  load_throughput: 19631659.256\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 462.889\n",
      "  sample_time_ms: 8641.376\n",
      "  update_time_ms: 2.249\n",
      "timestamp: 1658398788\n",
      "timesteps_since_restore: 2656000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2656000\n",
      "training_iteration: 664\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2660000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-19-57\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13895\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2622523009777069\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037768473848700523\n",
      "        model: {}\n",
      "        policy_loss: 0.0006800508708693087\n",
      "        total_loss: 2.4704384803771973\n",
      "        vf_explained_var: -0.002832428552210331\n",
      "        vf_loss: 2.4697585105895996\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2660000\n",
      "  num_agent_steps_trained: 2660000\n",
      "  num_steps_sampled: 2660000\n",
      "  num_steps_trained: 2660000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 665\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.4\n",
      "  ram_util_percent: 88.12500000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07016942505283387\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0805005670910684\n",
      "  mean_inference_ms: 0.7705094355159341\n",
      "  mean_raw_obs_processing_ms: 0.09299257503469714\n",
      "time_since_restore: 4838.6228041648865\n",
      "time_this_iter_s: 8.631699562072754\n",
      "time_total_s: 4838.6228041648865\n",
      "timers:\n",
      "  learn_throughput: 1146.141\n",
      "  learn_time_ms: 3489.972\n",
      "  load_throughput: 20135880.941\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 466.581\n",
      "  sample_time_ms: 8573.006\n",
      "  update_time_ms: 2.217\n",
      "timestamp: 1658398797\n",
      "timesteps_since_restore: 2660000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2660000\n",
      "training_iteration: 665\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2664000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-20-06\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13915\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2786715626716614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026153831277042627\n",
      "        model: {}\n",
      "        policy_loss: 0.0010953496675938368\n",
      "        total_loss: 2.470853805541992\n",
      "        vf_explained_var: -0.00041846506064757705\n",
      "        vf_loss: 2.4697580337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2664000\n",
      "  num_agent_steps_trained: 2664000\n",
      "  num_steps_sampled: 2664000\n",
      "  num_steps_trained: 2664000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 666\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.19230769230769\n",
      "  ram_util_percent: 88.14615384615384\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07019489504034046\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08052739632193631\n",
      "  mean_inference_ms: 0.7707598412522296\n",
      "  mean_raw_obs_processing_ms: 0.09302251570608419\n",
      "time_since_restore: 4847.828703403473\n",
      "time_this_iter_s: 9.205899238586426\n",
      "time_total_s: 4847.828703403473\n",
      "timers:\n",
      "  learn_throughput: 1162.745\n",
      "  learn_time_ms: 3440.135\n",
      "  load_throughput: 18424353.174\n",
      "  load_time_ms: 0.217\n",
      "  sample_throughput: 456.049\n",
      "  sample_time_ms: 8770.991\n",
      "  update_time_ms: 2.183\n",
      "timestamp: 1658398806\n",
      "timesteps_since_restore: 2664000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2664000\n",
      "training_iteration: 666\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2668000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-20-15\n",
      "done: false\n",
      "episode_len_mean: 199.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.65\n",
      "episode_reward_min: 165.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13935\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30595916509628296\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004132960457354784\n",
      "        model: {}\n",
      "        policy_loss: -0.0006156411836855114\n",
      "        total_loss: 2.2045257091522217\n",
      "        vf_explained_var: -0.1611519157886505\n",
      "        vf_loss: 2.205141067504883\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2668000\n",
      "  num_agent_steps_trained: 2668000\n",
      "  num_steps_sampled: 2668000\n",
      "  num_steps_trained: 2668000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 667\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.871428571428574\n",
      "  ram_util_percent: 88.24285714285713\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07022552076309255\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08055972549455659\n",
      "  mean_inference_ms: 0.771071245793691\n",
      "  mean_raw_obs_processing_ms: 0.0930592890313918\n",
      "time_since_restore: 4857.4481744766235\n",
      "time_this_iter_s: 9.619471073150635\n",
      "time_total_s: 4857.4481744766235\n",
      "timers:\n",
      "  learn_throughput: 1177.92\n",
      "  learn_time_ms: 3395.816\n",
      "  load_throughput: 18918827.244\n",
      "  load_time_ms: 0.211\n",
      "  sample_throughput: 454.991\n",
      "  sample_time_ms: 8791.38\n",
      "  update_time_ms: 2.129\n",
      "timestamp: 1658398815\n",
      "timesteps_since_restore: 2668000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2668000\n",
      "training_iteration: 667\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2672000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-20-26\n",
      "done: false\n",
      "episode_len_mean: 199.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.65\n",
      "episode_reward_min: 165.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13955\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2870069742202759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005285751074552536\n",
      "        model: {}\n",
      "        policy_loss: -0.0023253217805176973\n",
      "        total_loss: 0.7033200860023499\n",
      "        vf_explained_var: 0.00815940648317337\n",
      "        vf_loss: 0.7056454420089722\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2672000\n",
      "  num_agent_steps_trained: 2672000\n",
      "  num_steps_sampled: 2672000\n",
      "  num_steps_trained: 2672000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 668\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 55.32000000000001\n",
      "  ram_util_percent: 88.09333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07026540434696164\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08060277945873516\n",
      "  mean_inference_ms: 0.7714847062675527\n",
      "  mean_raw_obs_processing_ms: 0.09310647032766878\n",
      "time_since_restore: 4868.078015804291\n",
      "time_this_iter_s: 10.629841327667236\n",
      "time_total_s: 4868.078015804291\n",
      "timers:\n",
      "  learn_throughput: 1152.672\n",
      "  learn_time_ms: 3470.197\n",
      "  load_throughput: 18764361.928\n",
      "  load_time_ms: 0.213\n",
      "  sample_throughput: 452.37\n",
      "  sample_time_ms: 8842.322\n",
      "  update_time_ms: 2.125\n",
      "timestamp: 1658398826\n",
      "timesteps_since_restore: 2672000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2672000\n",
      "training_iteration: 668\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2676000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-20-35\n",
      "done: false\n",
      "episode_len_mean: 199.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.41\n",
      "episode_reward_min: 165.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 13976\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24761132895946503\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034460588358342648\n",
      "        model: {}\n",
      "        policy_loss: -0.019745225086808205\n",
      "        total_loss: 1.074004888534546\n",
      "        vf_explained_var: -0.2721140384674072\n",
      "        vf_loss: 1.0937501192092896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2676000\n",
      "  num_agent_steps_trained: 2676000\n",
      "  num_steps_sampled: 2676000\n",
      "  num_steps_trained: 2676000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 669\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.838461538461544\n",
      "  ram_util_percent: 88.14615384615382\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07031356681822203\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0806553131100466\n",
      "  mean_inference_ms: 0.7719851199047122\n",
      "  mean_raw_obs_processing_ms: 0.09316349719258334\n",
      "time_since_restore: 4877.169902801514\n",
      "time_this_iter_s: 9.0918869972229\n",
      "time_total_s: 4877.169902801514\n",
      "timers:\n",
      "  learn_throughput: 1144.981\n",
      "  learn_time_ms: 3493.506\n",
      "  load_throughput: 18804321.901\n",
      "  load_time_ms: 0.213\n",
      "  sample_throughput: 459.902\n",
      "  sample_time_ms: 8697.502\n",
      "  update_time_ms: 2.121\n",
      "timestamp: 1658398835\n",
      "timesteps_since_restore: 2676000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2676000\n",
      "training_iteration: 669\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2680000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-20-44\n",
      "done: false\n",
      "episode_len_mean: 198.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.89\n",
      "episode_reward_min: 148.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 13996\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27468615770339966\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004216145724058151\n",
      "        model: {}\n",
      "        policy_loss: 0.0055208164267241955\n",
      "        total_loss: 6.9611663818359375\n",
      "        vf_explained_var: 1.1899778655788396e-06\n",
      "        vf_loss: 6.9556450843811035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2680000\n",
      "  num_agent_steps_trained: 2680000\n",
      "  num_steps_sampled: 2680000\n",
      "  num_steps_trained: 2680000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 670\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.57692307692308\n",
      "  ram_util_percent: 88.06153846153846\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07035974600877472\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08070614292235354\n",
      "  mean_inference_ms: 0.7724660979836563\n",
      "  mean_raw_obs_processing_ms: 0.09321935984238834\n",
      "time_since_restore: 4885.965452432632\n",
      "time_this_iter_s: 8.795549631118774\n",
      "time_total_s: 4885.965452432632\n",
      "timers:\n",
      "  learn_throughput: 1135.401\n",
      "  learn_time_ms: 3522.984\n",
      "  load_throughput: 18785372.299\n",
      "  load_time_ms: 0.213\n",
      "  sample_throughput: 452.74\n",
      "  sample_time_ms: 8835.102\n",
      "  update_time_ms: 2.085\n",
      "timestamp: 1658398844\n",
      "timesteps_since_restore: 2680000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2680000\n",
      "training_iteration: 670\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2684000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-20-52\n",
      "done: false\n",
      "episode_len_mean: 198.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.89\n",
      "episode_reward_min: 148.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14016\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2741824984550476\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003830589121207595\n",
      "        model: {}\n",
      "        policy_loss: 0.006143413484096527\n",
      "        total_loss: 6.961792469024658\n",
      "        vf_explained_var: -9.882834461905077e-08\n",
      "        vf_loss: 6.955649375915527\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2684000\n",
      "  num_agent_steps_trained: 2684000\n",
      "  num_steps_sampled: 2684000\n",
      "  num_steps_trained: 2684000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 671\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.28181818181818\n",
      "  ram_util_percent: 88.21818181818182\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07039635033153387\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08074778434808035\n",
      "  mean_inference_ms: 0.7728601668843927\n",
      "  mean_raw_obs_processing_ms: 0.09326506220956172\n",
      "time_since_restore: 4893.918727874756\n",
      "time_this_iter_s: 7.953275442123413\n",
      "time_total_s: 4893.918727874756\n",
      "timers:\n",
      "  learn_throughput: 1137.618\n",
      "  learn_time_ms: 3516.12\n",
      "  load_throughput: 18536312.01\n",
      "  load_time_ms: 0.216\n",
      "  sample_throughput: 453.015\n",
      "  sample_time_ms: 8829.736\n",
      "  update_time_ms: 2.04\n",
      "timestamp: 1658398852\n",
      "timesteps_since_restore: 2684000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2684000\n",
      "training_iteration: 671\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2688000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-21-01\n",
      "done: false\n",
      "episode_len_mean: 198.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.69\n",
      "episode_reward_min: 145.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14036\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2761341333389282\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004260071087628603\n",
      "        model: {}\n",
      "        policy_loss: 0.0028406635392457247\n",
      "        total_loss: 5.572397708892822\n",
      "        vf_explained_var: 3.139178090805217e-07\n",
      "        vf_loss: 5.569557189941406\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2688000\n",
      "  num_agent_steps_trained: 2688000\n",
      "  num_steps_sampled: 2688000\n",
      "  num_steps_trained: 2688000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 672\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.86153846153846\n",
      "  ram_util_percent: 88.15384615384617\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07042623769444885\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08078186427880832\n",
      "  mean_inference_ms: 0.7731792446836857\n",
      "  mean_raw_obs_processing_ms: 0.09330207466697\n",
      "time_since_restore: 4902.448572635651\n",
      "time_this_iter_s: 8.529844760894775\n",
      "time_total_s: 4902.448572635651\n",
      "timers:\n",
      "  learn_throughput: 1129.369\n",
      "  learn_time_ms: 3541.8\n",
      "  load_throughput: 18635139.398\n",
      "  load_time_ms: 0.215\n",
      "  sample_throughput: 454.682\n",
      "  sample_time_ms: 8797.367\n",
      "  update_time_ms: 2.057\n",
      "timestamp: 1658398861\n",
      "timesteps_since_restore: 2688000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2688000\n",
      "training_iteration: 672\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2692000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-21-09\n",
      "done: false\n",
      "episode_len_mean: 198.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.69\n",
      "episode_reward_min: 145.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14056\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27746713161468506\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028994432650506496\n",
      "        model: {}\n",
      "        policy_loss: 0.003433837788179517\n",
      "        total_loss: 4.186901569366455\n",
      "        vf_explained_var: 3.5205195558773994e-07\n",
      "        vf_loss: 4.183467864990234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2692000\n",
      "  num_agent_steps_trained: 2692000\n",
      "  num_steps_sampled: 2692000\n",
      "  num_steps_trained: 2692000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 673\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.40833333333334\n",
      "  ram_util_percent: 88.04166666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.070451125117156\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08081009437806767\n",
      "  mean_inference_ms: 0.7734418283713801\n",
      "  mean_raw_obs_processing_ms: 0.09333390839563788\n",
      "time_since_restore: 4910.834459781647\n",
      "time_this_iter_s: 8.385887145996094\n",
      "time_total_s: 4910.834459781647\n",
      "timers:\n",
      "  learn_throughput: 1136.697\n",
      "  learn_time_ms: 3518.969\n",
      "  load_throughput: 18365863.164\n",
      "  load_time_ms: 0.218\n",
      "  sample_throughput: 449.337\n",
      "  sample_time_ms: 8901.997\n",
      "  update_time_ms: 2.11\n",
      "timestamp: 1658398869\n",
      "timesteps_since_restore: 2692000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2692000\n",
      "training_iteration: 673\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2696000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-21-17\n",
      "done: false\n",
      "episode_len_mean: 198.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.93\n",
      "episode_reward_min: 145.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14076\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24261264503002167\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023786535020917654\n",
      "        model: {}\n",
      "        policy_loss: 0.004718277137726545\n",
      "        total_loss: 4.188187122344971\n",
      "        vf_explained_var: 1.0908291159239525e-07\n",
      "        vf_loss: 4.183468818664551\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2696000\n",
      "  num_agent_steps_trained: 2696000\n",
      "  num_steps_sampled: 2696000\n",
      "  num_steps_trained: 2696000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 674\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.96363636363637\n",
      "  ram_util_percent: 87.93636363636364\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07047323020647848\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.080834986737176\n",
      "  mean_inference_ms: 0.7736746794439938\n",
      "  mean_raw_obs_processing_ms: 0.09336260407956304\n",
      "time_since_restore: 4919.0575087070465\n",
      "time_this_iter_s: 8.22304892539978\n",
      "time_total_s: 4919.0575087070465\n",
      "timers:\n",
      "  learn_throughput: 1140.104\n",
      "  learn_time_ms: 3508.451\n",
      "  load_throughput: 19034735.648\n",
      "  load_time_ms: 0.21\n",
      "  sample_throughput: 447.374\n",
      "  sample_time_ms: 8941.072\n",
      "  update_time_ms: 2.113\n",
      "timestamp: 1658398877\n",
      "timesteps_since_restore: 2696000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2696000\n",
      "training_iteration: 674\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2700000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-21-26\n",
      "done: false\n",
      "episode_len_mean: 199.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.45\n",
      "episode_reward_min: 145.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14096\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24549753963947296\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003545172046869993\n",
      "        model: {}\n",
      "        policy_loss: 0.0027332932222634554\n",
      "        total_loss: 4.186202049255371\n",
      "        vf_explained_var: -7.646058008958789e-08\n",
      "        vf_loss: 4.183468341827393\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2700000\n",
      "  num_agent_steps_trained: 2700000\n",
      "  num_steps_sampled: 2700000\n",
      "  num_steps_trained: 2700000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 675\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.12307692307692\n",
      "  ram_util_percent: 88.13846153846156\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07049172805091157\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08085575413235546\n",
      "  mean_inference_ms: 0.7738691338286162\n",
      "  mean_raw_obs_processing_ms: 0.09338627782599992\n",
      "time_since_restore: 4927.6200132369995\n",
      "time_this_iter_s: 8.562504529953003\n",
      "time_total_s: 4927.6200132369995\n",
      "timers:\n",
      "  learn_throughput: 1125.311\n",
      "  learn_time_ms: 3554.572\n",
      "  load_throughput: 19049864.88\n",
      "  load_time_ms: 0.21\n",
      "  sample_throughput: 450.571\n",
      "  sample_time_ms: 8877.634\n",
      "  update_time_ms: 2.16\n",
      "timestamp: 1658398886\n",
      "timesteps_since_restore: 2700000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2700000\n",
      "training_iteration: 675\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2704000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-21-34\n",
      "done: false\n",
      "episode_len_mean: 199.45\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.45\n",
      "episode_reward_min: 145.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14116\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24112556874752045\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00391361815854907\n",
      "        model: {}\n",
      "        policy_loss: 0.00270903785713017\n",
      "        total_loss: 4.186176776885986\n",
      "        vf_explained_var: 2.6155544219363946e-07\n",
      "        vf_loss: 4.183467864990234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2704000\n",
      "  num_agent_steps_trained: 2704000\n",
      "  num_steps_sampled: 2704000\n",
      "  num_steps_trained: 2704000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 676\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.141666666666666\n",
      "  ram_util_percent: 88.18333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07051466765593695\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08088156867510923\n",
      "  mean_inference_ms: 0.7741079582085567\n",
      "  mean_raw_obs_processing_ms: 0.09341499158628691\n",
      "time_since_restore: 4936.096757173538\n",
      "time_this_iter_s: 8.476743936538696\n",
      "time_total_s: 4936.096757173538\n",
      "timers:\n",
      "  learn_throughput: 1126.161\n",
      "  learn_time_ms: 3551.889\n",
      "  load_throughput: 19824194.73\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 451.751\n",
      "  sample_time_ms: 8854.434\n",
      "  update_time_ms: 2.179\n",
      "timestamp: 1658398894\n",
      "timesteps_since_restore: 2704000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2704000\n",
      "training_iteration: 676\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2708000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-21-43\n",
      "done: false\n",
      "episode_len_mean: 198.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.16\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14137\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2346848100423813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0042176032438874245\n",
      "        model: {}\n",
      "        policy_loss: 0.0016536646289750934\n",
      "        total_loss: 5.006694316864014\n",
      "        vf_explained_var: 3.6877969478155137e-07\n",
      "        vf_loss: 5.005040168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2708000\n",
      "  num_agent_steps_trained: 2708000\n",
      "  num_steps_sampled: 2708000\n",
      "  num_steps_trained: 2708000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 677\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.68181818181818\n",
      "  ram_util_percent: 88.25454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07053759910760916\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08090776904990266\n",
      "  mean_inference_ms: 0.7743405071018139\n",
      "  mean_raw_obs_processing_ms: 0.09344320348221508\n",
      "time_since_restore: 4944.268692493439\n",
      "time_this_iter_s: 8.171935319900513\n",
      "time_total_s: 4944.268692493439\n",
      "timers:\n",
      "  learn_throughput: 1123.135\n",
      "  learn_time_ms: 3561.459\n",
      "  load_throughput: 19906521.12\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 459.9\n",
      "  sample_time_ms: 8697.551\n",
      "  update_time_ms: 2.223\n",
      "timestamp: 1658398903\n",
      "timesteps_since_restore: 2708000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2708000\n",
      "training_iteration: 677\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2712000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-21-51\n",
      "done: false\n",
      "episode_len_mean: 196.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.85\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14158\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24657395482063293\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002677108161151409\n",
      "        model: {}\n",
      "        policy_loss: 0.006827633827924728\n",
      "        total_loss: 7.43122673034668\n",
      "        vf_explained_var: -1.5824072363557207e-07\n",
      "        vf_loss: 7.424399375915527\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2712000\n",
      "  num_agent_steps_trained: 2712000\n",
      "  num_steps_sampled: 2712000\n",
      "  num_steps_trained: 2712000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 678\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.42499999999999\n",
      "  ram_util_percent: 88.25833333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07056084027832603\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0809342148293007\n",
      "  mean_inference_ms: 0.7745756471389916\n",
      "  mean_raw_obs_processing_ms: 0.09347103485663043\n",
      "time_since_restore: 4952.708549499512\n",
      "time_this_iter_s: 8.439857006072998\n",
      "time_total_s: 4952.708549499512\n",
      "timers:\n",
      "  learn_throughput: 1163.633\n",
      "  learn_time_ms: 3437.51\n",
      "  load_throughput: 20500019.55\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 464.449\n",
      "  sample_time_ms: 8612.353\n",
      "  update_time_ms: 2.242\n",
      "timestamp: 1658398911\n",
      "timesteps_since_restore: 2712000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2712000\n",
      "training_iteration: 678\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2716000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-22-00\n",
      "done: false\n",
      "episode_len_mean: 196.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.85\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14178\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23151904344558716\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035206174943596125\n",
      "        model: {}\n",
      "        policy_loss: 0.008580762892961502\n",
      "        total_loss: 8.476322174072266\n",
      "        vf_explained_var: 3.8198244567411166e-08\n",
      "        vf_loss: 8.467741966247559\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2716000\n",
      "  num_agent_steps_trained: 2716000\n",
      "  num_steps_sampled: 2716000\n",
      "  num_steps_trained: 2716000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 679\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.87142857142857\n",
      "  ram_util_percent: 88.35000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07058669745750064\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0809635532294266\n",
      "  mean_inference_ms: 0.7748355272428168\n",
      "  mean_raw_obs_processing_ms: 0.0935016602058634\n",
      "time_since_restore: 4962.136377573013\n",
      "time_this_iter_s: 9.427828073501587\n",
      "time_total_s: 4962.136377573013\n",
      "timers:\n",
      "  learn_throughput: 1156.193\n",
      "  learn_time_ms: 3459.631\n",
      "  load_throughput: 19717024.327\n",
      "  load_time_ms: 0.203\n",
      "  sample_throughput: 470.602\n",
      "  sample_time_ms: 8499.749\n",
      "  update_time_ms: 2.254\n",
      "timestamp: 1658398920\n",
      "timesteps_since_restore: 2716000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2716000\n",
      "training_iteration: 679\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2720000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-22-08\n",
      "done: false\n",
      "episode_len_mean: 196.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.85\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14198\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23711606860160828\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0046594771556556225\n",
      "        model: {}\n",
      "        policy_loss: 0.008111061528325081\n",
      "        total_loss: 8.475852966308594\n",
      "        vf_explained_var: 1.8938895607334416e-07\n",
      "        vf_loss: 8.467741966247559\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2720000\n",
      "  num_agent_steps_trained: 2720000\n",
      "  num_steps_sampled: 2720000\n",
      "  num_steps_trained: 2720000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 680\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.800000000000004\n",
      "  ram_util_percent: 88.29090909090907\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07061057748670757\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08099080104615916\n",
      "  mean_inference_ms: 0.7750744708951879\n",
      "  mean_raw_obs_processing_ms: 0.09352992760955928\n",
      "time_since_restore: 4969.778382301331\n",
      "time_this_iter_s: 7.642004728317261\n",
      "time_total_s: 4969.778382301331\n",
      "timers:\n",
      "  learn_throughput: 1161.111\n",
      "  learn_time_ms: 3444.977\n",
      "  load_throughput: 19737901.176\n",
      "  load_time_ms: 0.203\n",
      "  sample_throughput: 475.014\n",
      "  sample_time_ms: 8420.802\n",
      "  update_time_ms: 2.286\n",
      "timestamp: 1658398928\n",
      "timesteps_since_restore: 2720000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2720000\n",
      "training_iteration: 680\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2724000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-22-16\n",
      "done: false\n",
      "episode_len_mean: 196.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.85\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14218\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23670698702335358\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032589465845376253\n",
      "        model: {}\n",
      "        policy_loss: 0.00868159718811512\n",
      "        total_loss: 8.476424217224121\n",
      "        vf_explained_var: 1.8477439311936905e-07\n",
      "        vf_loss: 8.467741966247559\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2724000\n",
      "  num_agent_steps_trained: 2724000\n",
      "  num_steps_sampled: 2724000\n",
      "  num_steps_trained: 2724000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 681\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.35454545454546\n",
      "  ram_util_percent: 88.24545454545456\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07063222483106286\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08101515443281397\n",
      "  mean_inference_ms: 0.7752905186168308\n",
      "  mean_raw_obs_processing_ms: 0.09355589156973071\n",
      "time_since_restore: 4977.76713848114\n",
      "time_this_iter_s: 7.98875617980957\n",
      "time_total_s: 4977.76713848114\n",
      "timers:\n",
      "  learn_throughput: 1172.828\n",
      "  learn_time_ms: 3410.559\n",
      "  load_throughput: 19897077.799\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 473.715\n",
      "  sample_time_ms: 8443.899\n",
      "  update_time_ms: 2.332\n",
      "timestamp: 1658398936\n",
      "timesteps_since_restore: 2724000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2724000\n",
      "training_iteration: 681\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2728000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-22-24\n",
      "done: false\n",
      "episode_len_mean: 196.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.59\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14239\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22892960906028748\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004012188408523798\n",
      "        model: {}\n",
      "        policy_loss: 0.004717390518635511\n",
      "        total_loss: 7.600491523742676\n",
      "        vf_explained_var: 1.1614573622864555e-06\n",
      "        vf_loss: 7.595773696899414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2728000\n",
      "  num_agent_steps_trained: 2728000\n",
      "  num_steps_sampled: 2728000\n",
      "  num_steps_trained: 2728000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 682\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.29090909090909\n",
      "  ram_util_percent: 88.17272727272729\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07065144453352502\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08103636161445461\n",
      "  mean_inference_ms: 0.7754839136447862\n",
      "  mean_raw_obs_processing_ms: 0.09357932759641624\n",
      "time_since_restore: 4985.2564969062805\n",
      "time_this_iter_s: 7.489358425140381\n",
      "time_total_s: 4985.2564969062805\n",
      "timers:\n",
      "  learn_throughput: 1181.582\n",
      "  learn_time_ms: 3385.293\n",
      "  load_throughput: 19684636.865\n",
      "  load_time_ms: 0.203\n",
      "  sample_throughput: 480.161\n",
      "  sample_time_ms: 8330.545\n",
      "  update_time_ms: 2.319\n",
      "timestamp: 1658398944\n",
      "timesteps_since_restore: 2728000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2728000\n",
      "training_iteration: 682\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2732000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-22-31\n",
      "done: false\n",
      "episode_len_mean: 197.64\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.64\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14259\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2758389413356781\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003455971134826541\n",
      "        model: {}\n",
      "        policy_loss: 0.007426207419484854\n",
      "        total_loss: 7.840087413787842\n",
      "        vf_explained_var: 9.553407380735734e-07\n",
      "        vf_loss: 7.832661151885986\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2732000\n",
      "  num_agent_steps_trained: 2732000\n",
      "  num_steps_sampled: 2732000\n",
      "  num_steps_trained: 2732000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 683\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.04545454545455\n",
      "  ram_util_percent: 88.25454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07066571816315492\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08105226360727506\n",
      "  mean_inference_ms: 0.7756249118662721\n",
      "  mean_raw_obs_processing_ms: 0.09359679421811602\n",
      "time_since_restore: 4992.923231840134\n",
      "time_this_iter_s: 7.666734933853149\n",
      "time_total_s: 4992.923231840134\n",
      "timers:\n",
      "  learn_throughput: 1180.715\n",
      "  learn_time_ms: 3387.778\n",
      "  load_throughput: 19880573.528\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 485.985\n",
      "  sample_time_ms: 8230.703\n",
      "  update_time_ms: 2.279\n",
      "timestamp: 1658398951\n",
      "timesteps_since_restore: 2732000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2732000\n",
      "training_iteration: 683\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2736000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-22-39\n",
      "done: false\n",
      "episode_len_mean: 194.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.53\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14280\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24752692878246307\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005122738890349865\n",
      "        model: {}\n",
      "        policy_loss: 0.0017072418704628944\n",
      "        total_loss: 4.359067916870117\n",
      "        vf_explained_var: -0.0004447204410098493\n",
      "        vf_loss: 4.357360363006592\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2736000\n",
      "  num_agent_steps_trained: 2736000\n",
      "  num_steps_sampled: 2736000\n",
      "  num_steps_trained: 2736000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 684\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.327272727272735\n",
      "  ram_util_percent: 87.99090909090908\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07067476305470582\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08106218140796201\n",
      "  mean_inference_ms: 0.7757130400260972\n",
      "  mean_raw_obs_processing_ms: 0.0936081560193346\n",
      "time_since_restore: 5000.449512243271\n",
      "time_this_iter_s: 7.526280403137207\n",
      "time_total_s: 5000.449512243271\n",
      "timers:\n",
      "  learn_throughput: 1191.841\n",
      "  learn_time_ms: 3356.152\n",
      "  load_throughput: 19522010.705\n",
      "  load_time_ms: 0.205\n",
      "  sample_throughput: 488.08\n",
      "  sample_time_ms: 8195.386\n",
      "  update_time_ms: 2.237\n",
      "timestamp: 1658398959\n",
      "timesteps_since_restore: 2736000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2736000\n",
      "training_iteration: 684\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2740000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-22-47\n",
      "done: false\n",
      "episode_len_mean: 194.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.53\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14300\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23953263461589813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035354308784008026\n",
      "        model: {}\n",
      "        policy_loss: -8.643218279758003e-06\n",
      "        total_loss: 1.0584591627120972\n",
      "        vf_explained_var: -0.052239980548620224\n",
      "        vf_loss: 1.0584677457809448\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2740000\n",
      "  num_agent_steps_trained: 2740000\n",
      "  num_steps_sampled: 2740000\n",
      "  num_steps_trained: 2740000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 685\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.736363636363635\n",
      "  ram_util_percent: 88.06363636363636\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0706822261372148\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08107017630006866\n",
      "  mean_inference_ms: 0.7757832598361121\n",
      "  mean_raw_obs_processing_ms: 0.09361768150545653\n",
      "time_since_restore: 5008.213586807251\n",
      "time_this_iter_s: 7.7640745639801025\n",
      "time_total_s: 5008.213586807251\n",
      "timers:\n",
      "  learn_throughput: 1201.027\n",
      "  learn_time_ms: 3330.483\n",
      "  load_throughput: 19761149.588\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 493.325\n",
      "  sample_time_ms: 8108.251\n",
      "  update_time_ms: 2.203\n",
      "timestamp: 1658398967\n",
      "timesteps_since_restore: 2740000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2740000\n",
      "training_iteration: 685\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2744000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-22-55\n",
      "done: false\n",
      "episode_len_mean: 192.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.2\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 14322\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2789510190486908\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004873764701187611\n",
      "        model: {}\n",
      "        policy_loss: -0.009801792912185192\n",
      "        total_loss: 7.63135290145874\n",
      "        vf_explained_var: 1.61881087024085e-06\n",
      "        vf_loss: 7.641154766082764\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2744000\n",
      "  num_agent_steps_trained: 2744000\n",
      "  num_steps_sampled: 2744000\n",
      "  num_steps_trained: 2744000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 686\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.50833333333333\n",
      "  ram_util_percent: 88.375\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07069160332267545\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08108058432034675\n",
      "  mean_inference_ms: 0.775874344619995\n",
      "  mean_raw_obs_processing_ms: 0.09362911217406467\n",
      "time_since_restore: 5016.618357658386\n",
      "time_this_iter_s: 8.404770851135254\n",
      "time_total_s: 5016.618357658386\n",
      "timers:\n",
      "  learn_throughput: 1195.165\n",
      "  learn_time_ms: 3346.818\n",
      "  load_throughput: 20600707.269\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 496.355\n",
      "  sample_time_ms: 8058.744\n",
      "  update_time_ms: 2.236\n",
      "timestamp: 1658398975\n",
      "timesteps_since_restore: 2744000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2744000\n",
      "training_iteration: 686\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2748000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-23-03\n",
      "done: false\n",
      "episode_len_mean: 192.3\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.3\n",
      "episode_reward_min: 22.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14343\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2746011018753052\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003646630560979247\n",
      "        model: {}\n",
      "        policy_loss: -0.010538848116993904\n",
      "        total_loss: 7.4239373207092285\n",
      "        vf_explained_var: -0.004046331625431776\n",
      "        vf_loss: 7.434475898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2748000\n",
      "  num_agent_steps_trained: 2748000\n",
      "  num_steps_sampled: 2748000\n",
      "  num_steps_trained: 2748000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 687\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.62727272727273\n",
      "  ram_util_percent: 88.23636363636365\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07070184148183943\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0810919577259824\n",
      "  mean_inference_ms: 0.7759766789355266\n",
      "  mean_raw_obs_processing_ms: 0.09364070501830189\n",
      "time_since_restore: 5024.620656251907\n",
      "time_this_iter_s: 8.002298593521118\n",
      "time_total_s: 5024.620656251907\n",
      "timers:\n",
      "  learn_throughput: 1190.858\n",
      "  learn_time_ms: 3358.924\n",
      "  load_throughput: 20823155.02\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 497.171\n",
      "  sample_time_ms: 8045.517\n",
      "  update_time_ms: 2.231\n",
      "timestamp: 1658398983\n",
      "timesteps_since_restore: 2748000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2748000\n",
      "training_iteration: 687\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2752000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-23-12\n",
      "done: false\n",
      "episode_len_mean: 194.34\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.34\n",
      "episode_reward_min: 102.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14363\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2746034562587738\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004681210964918137\n",
      "        model: {}\n",
      "        policy_loss: 0.006991240661591291\n",
      "        total_loss: 8.918281555175781\n",
      "        vf_explained_var: 2.0805866824957775e-06\n",
      "        vf_loss: 8.911290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2752000\n",
      "  num_agent_steps_trained: 2752000\n",
      "  num_steps_sampled: 2752000\n",
      "  num_steps_trained: 2752000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 688\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.77692307692307\n",
      "  ram_util_percent: 88.23846153846154\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07071687687091192\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08110862145690508\n",
      "  mean_inference_ms: 0.7761297237583835\n",
      "  mean_raw_obs_processing_ms: 0.09365787208266134\n",
      "time_since_restore: 5033.8437440395355\n",
      "time_this_iter_s: 9.223087787628174\n",
      "time_total_s: 5033.8437440395355\n",
      "timers:\n",
      "  learn_throughput: 1170.949\n",
      "  learn_time_ms: 3416.033\n",
      "  load_throughput: 19429317.892\n",
      "  load_time_ms: 0.206\n",
      "  sample_throughput: 495.124\n",
      "  sample_time_ms: 8078.789\n",
      "  update_time_ms: 2.241\n",
      "timestamp: 1658398992\n",
      "timesteps_since_restore: 2752000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2752000\n",
      "training_iteration: 688\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2756000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-23-22\n",
      "done: false\n",
      "episode_len_mean: 193.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.2\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14384\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2954981029033661\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034380308352410793\n",
      "        model: {}\n",
      "        policy_loss: 0.002795173553749919\n",
      "        total_loss: 5.2548112869262695\n",
      "        vf_explained_var: 2.5531296614644816e-06\n",
      "        vf_loss: 5.252016067504883\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2756000\n",
      "  num_agent_steps_trained: 2756000\n",
      "  num_steps_sampled: 2756000\n",
      "  num_steps_trained: 2756000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 689\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 50.371428571428574\n",
      "  ram_util_percent: 88.24285714285713\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07073916828364274\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0811337265197744\n",
      "  mean_inference_ms: 0.7763593964651041\n",
      "  mean_raw_obs_processing_ms: 0.09368387156725405\n",
      "time_since_restore: 5043.30193567276\n",
      "time_this_iter_s: 9.458191633224487\n",
      "time_total_s: 5043.30193567276\n",
      "timers:\n",
      "  learn_throughput: 1174.659\n",
      "  learn_time_ms: 3405.243\n",
      "  load_throughput: 20465010.978\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 490.819\n",
      "  sample_time_ms: 8149.642\n",
      "  update_time_ms: 2.222\n",
      "timestamp: 1658399002\n",
      "timesteps_since_restore: 2756000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2756000\n",
      "training_iteration: 689\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2760000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-23-30\n",
      "done: false\n",
      "episode_len_mean: 190.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.1\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 14406\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25572314858436584\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004485886078327894\n",
      "        model: {}\n",
      "        policy_loss: -0.006159970071166754\n",
      "        total_loss: 5.5003981590271\n",
      "        vf_explained_var: -0.06451275944709778\n",
      "        vf_loss: 5.506558418273926\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2760000\n",
      "  num_agent_steps_trained: 2760000\n",
      "  num_steps_sampled: 2760000\n",
      "  num_steps_trained: 2760000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 690\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.38333333333333\n",
      "  ram_util_percent: 88.16666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07076559319394789\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08116339963391311\n",
      "  mean_inference_ms: 0.7766372057077545\n",
      "  mean_raw_obs_processing_ms: 0.09371499409817201\n",
      "time_since_restore: 5051.424471855164\n",
      "time_this_iter_s: 8.122536182403564\n",
      "time_total_s: 5051.424471855164\n",
      "timers:\n",
      "  learn_throughput: 1178.349\n",
      "  learn_time_ms: 3394.581\n",
      "  load_throughput: 20318779.218\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 487.93\n",
      "  sample_time_ms: 8197.901\n",
      "  update_time_ms: 2.199\n",
      "timestamp: 1658399010\n",
      "timesteps_since_restore: 2760000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2760000\n",
      "training_iteration: 690\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2764000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-23-37\n",
      "done: false\n",
      "episode_len_mean: 190.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.14\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14427\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2780323624610901\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00464863795787096\n",
      "        model: {}\n",
      "        policy_loss: -0.006616512313485146\n",
      "        total_loss: 4.2297749519348145\n",
      "        vf_explained_var: 0.0011419247603043914\n",
      "        vf_loss: 4.236391544342041\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2764000\n",
      "  num_agent_steps_trained: 2764000\n",
      "  num_steps_sampled: 2764000\n",
      "  num_steps_trained: 2764000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 691\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.39\n",
      "  ram_util_percent: 87.94\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07078531760121398\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08118554881056593\n",
      "  mean_inference_ms: 0.7768453450885676\n",
      "  mean_raw_obs_processing_ms: 0.09373853831781925\n",
      "time_since_restore: 5058.561121702194\n",
      "time_this_iter_s: 7.13664984703064\n",
      "time_total_s: 5058.561121702194\n",
      "timers:\n",
      "  learn_throughput: 1176.785\n",
      "  learn_time_ms: 3399.092\n",
      "  load_throughput: 20425147.309\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 493.955\n",
      "  sample_time_ms: 8097.903\n",
      "  update_time_ms: 2.238\n",
      "timestamp: 1658399017\n",
      "timesteps_since_restore: 2764000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2764000\n",
      "training_iteration: 691\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2768000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-23-45\n",
      "done: false\n",
      "episode_len_mean: 190.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.92\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14447\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2582007944583893\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002888801973313093\n",
      "        model: {}\n",
      "        policy_loss: 0.006043521221727133\n",
      "        total_loss: 7.216231822967529\n",
      "        vf_explained_var: 2.66298172846291e-07\n",
      "        vf_loss: 7.210187911987305\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2768000\n",
      "  num_agent_steps_trained: 2768000\n",
      "  num_steps_sampled: 2768000\n",
      "  num_steps_trained: 2768000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 692\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.099999999999994\n",
      "  ram_util_percent: 88.13636363636364\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07080417471314515\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08120663471242212\n",
      "  mean_inference_ms: 0.7770453979174985\n",
      "  mean_raw_obs_processing_ms: 0.09376145843370316\n",
      "time_since_restore: 5066.57434463501\n",
      "time_this_iter_s: 8.013222932815552\n",
      "time_total_s: 5066.57434463501\n",
      "timers:\n",
      "  learn_throughput: 1174.296\n",
      "  learn_time_ms: 3406.297\n",
      "  load_throughput: 20702388.944\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 490.957\n",
      "  sample_time_ms: 8147.354\n",
      "  update_time_ms: 2.318\n",
      "timestamp: 1658399025\n",
      "timesteps_since_restore: 2768000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2768000\n",
      "training_iteration: 692\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2772000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-23-52\n",
      "done: false\n",
      "episode_len_mean: 191.04\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.04\n",
      "episode_reward_min: 84.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14468\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3139379024505615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004590424709022045\n",
      "        model: {}\n",
      "        policy_loss: -0.012904921546578407\n",
      "        total_loss: 5.065220355987549\n",
      "        vf_explained_var: 1.5140220739340293e-06\n",
      "        vf_loss: 5.078125\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2772000\n",
      "  num_agent_steps_trained: 2772000\n",
      "  num_steps_sampled: 2772000\n",
      "  num_steps_trained: 2772000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 693\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.58\n",
      "  ram_util_percent: 87.79999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0708156499699851\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08121932355719697\n",
      "  mean_inference_ms: 0.7771693190523916\n",
      "  mean_raw_obs_processing_ms: 0.09377546028209485\n",
      "time_since_restore: 5073.568353891373\n",
      "time_this_iter_s: 6.994009256362915\n",
      "time_total_s: 5073.568353891373\n",
      "timers:\n",
      "  learn_throughput: 1183.5\n",
      "  learn_time_ms: 3379.806\n",
      "  load_throughput: 20807659.68\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 492.966\n",
      "  sample_time_ms: 8114.145\n",
      "  update_time_ms: 2.323\n",
      "timestamp: 1658399032\n",
      "timesteps_since_restore: 2772000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2772000\n",
      "training_iteration: 693\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2776000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-24-01\n",
      "done: false\n",
      "episode_len_mean: 192.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.36\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14488\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3025583028793335\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035788787063211203\n",
      "        model: {}\n",
      "        policy_loss: 0.004576293285936117\n",
      "        total_loss: 7.955696105957031\n",
      "        vf_explained_var: 0.020694857463240623\n",
      "        vf_loss: 7.951119422912598\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2776000\n",
      "  num_agent_steps_trained: 2776000\n",
      "  num_steps_sampled: 2776000\n",
      "  num_steps_trained: 2776000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 694\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.291666666666664\n",
      "  ram_util_percent: 87.92500000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07081956861484538\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08122328754354113\n",
      "  mean_inference_ms: 0.77721489518663\n",
      "  mean_raw_obs_processing_ms: 0.09378016823937665\n",
      "time_since_restore: 5082.101674318314\n",
      "time_this_iter_s: 8.533320426940918\n",
      "time_total_s: 5082.101674318314\n",
      "timers:\n",
      "  learn_throughput: 1140.398\n",
      "  learn_time_ms: 3507.549\n",
      "  load_throughput: 21293585.48\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 496.281\n",
      "  sample_time_ms: 8059.943\n",
      "  update_time_ms: 2.4\n",
      "timestamp: 1658399041\n",
      "timesteps_since_restore: 2776000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2776000\n",
      "training_iteration: 694\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2780000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-24-09\n",
      "done: false\n",
      "episode_len_mean: 193.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.59\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14509\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28442832827568054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00337047316133976\n",
      "        model: {}\n",
      "        policy_loss: 0.001341244438663125\n",
      "        total_loss: 4.222611427307129\n",
      "        vf_explained_var: -0.032257381826639175\n",
      "        vf_loss: 4.2212700843811035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2780000\n",
      "  num_agent_steps_trained: 2780000\n",
      "  num_steps_sampled: 2780000\n",
      "  num_steps_trained: 2780000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 695\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.28333333333334\n",
      "  ram_util_percent: 88.49166666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07082277358532191\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08122660089270477\n",
      "  mean_inference_ms: 0.7772542603742656\n",
      "  mean_raw_obs_processing_ms: 0.09378426316685345\n",
      "time_since_restore: 5090.155180215836\n",
      "time_this_iter_s: 8.053505897521973\n",
      "time_total_s: 5090.155180215836\n",
      "timers:\n",
      "  learn_throughput: 1144.907\n",
      "  learn_time_ms: 3493.733\n",
      "  load_throughput: 20118978.295\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 485.922\n",
      "  sample_time_ms: 8231.771\n",
      "  update_time_ms: 2.385\n",
      "timestamp: 1658399049\n",
      "timesteps_since_restore: 2780000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2780000\n",
      "training_iteration: 695\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2784000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-24-17\n",
      "done: false\n",
      "episode_len_mean: 192.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.92\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14530\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.29079532623291016\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0040195407345891\n",
      "        model: {}\n",
      "        policy_loss: 0.0032782303169369698\n",
      "        total_loss: 6.535536289215088\n",
      "        vf_explained_var: 2.0213665266055614e-06\n",
      "        vf_loss: 6.532258033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2784000\n",
      "  num_agent_steps_trained: 2784000\n",
      "  num_steps_sampled: 2784000\n",
      "  num_steps_trained: 2784000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 696\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.400000000000006\n",
      "  ram_util_percent: 88.08181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07082960736305756\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08123432564066749\n",
      "  mean_inference_ms: 0.7773321062880012\n",
      "  mean_raw_obs_processing_ms: 0.09379327723111812\n",
      "time_since_restore: 5098.201472759247\n",
      "time_this_iter_s: 8.046292543411255\n",
      "time_total_s: 5098.201472759247\n",
      "timers:\n",
      "  learn_throughput: 1147.495\n",
      "  learn_time_ms: 3485.855\n",
      "  load_throughput: 19911246.143\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 488.412\n",
      "  sample_time_ms: 8189.801\n",
      "  update_time_ms: 2.309\n",
      "timestamp: 1658399057\n",
      "timesteps_since_restore: 2784000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2784000\n",
      "training_iteration: 696\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2788000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-24-25\n",
      "done: false\n",
      "episode_len_mean: 191.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.79\n",
      "episode_reward_min: 75.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14551\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28723016381263733\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003990205470472574\n",
      "        model: {}\n",
      "        policy_loss: 0.002458894159644842\n",
      "        total_loss: 5.4132466316223145\n",
      "        vf_explained_var: 1.3212362546255463e-06\n",
      "        vf_loss: 5.410788059234619\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2788000\n",
      "  num_agent_steps_trained: 2788000\n",
      "  num_steps_sampled: 2788000\n",
      "  num_steps_trained: 2788000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 697\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.47272727272727\n",
      "  ram_util_percent: 87.85454545454544\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07083501078710971\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08124069763184007\n",
      "  mean_inference_ms: 0.7773963902340602\n",
      "  mean_raw_obs_processing_ms: 0.09380091529090605\n",
      "time_since_restore: 5105.874453306198\n",
      "time_this_iter_s: 7.672980546951294\n",
      "time_total_s: 5105.874453306198\n",
      "timers:\n",
      "  learn_throughput: 1152.612\n",
      "  learn_time_ms: 3470.38\n",
      "  load_throughput: 19209086.329\n",
      "  load_time_ms: 0.208\n",
      "  sample_throughput: 489.944\n",
      "  sample_time_ms: 8164.192\n",
      "  update_time_ms: 2.328\n",
      "timestamp: 1658399065\n",
      "timesteps_since_restore: 2788000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2788000\n",
      "training_iteration: 697\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2792000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-24-32\n",
      "done: false\n",
      "episode_len_mean: 186.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.12\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 14574\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.28546425700187683\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003236088901758194\n",
      "        model: {}\n",
      "        policy_loss: 0.00329513824544847\n",
      "        total_loss: 6.717023849487305\n",
      "        vf_explained_var: 0.0007858906756155193\n",
      "        vf_loss: 6.713727951049805\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2792000\n",
      "  num_agent_steps_trained: 2792000\n",
      "  num_steps_sampled: 2792000\n",
      "  num_steps_trained: 2792000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 698\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.61818181818182\n",
      "  ram_util_percent: 87.76363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07084288526817821\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08124991457380676\n",
      "  mean_inference_ms: 0.7774896680562762\n",
      "  mean_raw_obs_processing_ms: 0.09381197680922371\n",
      "time_since_restore: 5113.1102776527405\n",
      "time_this_iter_s: 7.235824346542358\n",
      "time_total_s: 5113.1102776527405\n",
      "timers:\n",
      "  learn_throughput: 1184.787\n",
      "  learn_time_ms: 3376.134\n",
      "  load_throughput: 20527610.425\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 497.233\n",
      "  sample_time_ms: 8044.525\n",
      "  update_time_ms: 2.22\n",
      "timestamp: 1658399072\n",
      "timesteps_since_restore: 2792000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2792000\n",
      "training_iteration: 698\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2796000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-24-39\n",
      "done: false\n",
      "episode_len_mean: 184.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.48\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 14597\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.30481377243995667\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037056126166135073\n",
      "        model: {}\n",
      "        policy_loss: 0.0010825092904269695\n",
      "        total_loss: 5.40178918838501\n",
      "        vf_explained_var: -0.0032257982529699802\n",
      "        vf_loss: 5.400706768035889\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2796000\n",
      "  num_agent_steps_trained: 2796000\n",
      "  num_steps_sampled: 2796000\n",
      "  num_steps_trained: 2796000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 699\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.47\n",
      "  ram_util_percent: 87.69000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07084850491671685\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08125670051994394\n",
      "  mean_inference_ms: 0.777558323159634\n",
      "  mean_raw_obs_processing_ms: 0.09382037127610598\n",
      "time_since_restore: 5120.170263290405\n",
      "time_this_iter_s: 7.059985637664795\n",
      "time_total_s: 5120.170263290405\n",
      "timers:\n",
      "  learn_throughput: 1212.992\n",
      "  learn_time_ms: 3297.631\n",
      "  load_throughput: 20830911.348\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 513.634\n",
      "  sample_time_ms: 7787.647\n",
      "  update_time_ms: 2.281\n",
      "timestamp: 1658399079\n",
      "timesteps_since_restore: 2796000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2796000\n",
      "training_iteration: 699\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2800000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-24-46\n",
      "done: false\n",
      "episode_len_mean: 178.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 178.25\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 24\n",
      "episodes_total: 14621\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27981871366500854\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005177561659365892\n",
      "        model: {}\n",
      "        policy_loss: -0.009852126240730286\n",
      "        total_loss: 4.995189666748047\n",
      "        vf_explained_var: -0.0057143098674714565\n",
      "        vf_loss: 5.00504207611084\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2800000\n",
      "  num_agent_steps_trained: 2800000\n",
      "  num_steps_sampled: 2800000\n",
      "  num_steps_trained: 2800000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 700\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.5\n",
      "  ram_util_percent: 87.65\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07085152536951161\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08126035158027049\n",
      "  mean_inference_ms: 0.7775979744517343\n",
      "  mean_raw_obs_processing_ms: 0.0938254124976266\n",
      "time_since_restore: 5127.462236881256\n",
      "time_this_iter_s: 7.29197359085083\n",
      "time_total_s: 5127.462236881256\n",
      "timers:\n",
      "  learn_throughput: 1213.25\n",
      "  learn_time_ms: 3296.931\n",
      "  load_throughput: 20961039.48\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 524.407\n",
      "  sample_time_ms: 7627.669\n",
      "  update_time_ms: 2.285\n",
      "timestamp: 1658399086\n",
      "timesteps_since_restore: 2800000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2800000\n",
      "training_iteration: 700\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2804000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-24-54\n",
      "done: false\n",
      "episode_len_mean: 175.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 175.25\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 14643\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.247884601354599\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038247474003583193\n",
      "        model: {}\n",
      "        policy_loss: 0.0017562517896294594\n",
      "        total_loss: 4.971518039703369\n",
      "        vf_explained_var: -0.043104324489831924\n",
      "        vf_loss: 4.969761371612549\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2804000\n",
      "  num_agent_steps_trained: 2804000\n",
      "  num_steps_sampled: 2804000\n",
      "  num_steps_trained: 2804000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 701\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.10909090909091\n",
      "  ram_util_percent: 87.67272727272729\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0708532804541742\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08126244688157268\n",
      "  mean_inference_ms: 0.7776231727802889\n",
      "  mean_raw_obs_processing_ms: 0.09382860731416105\n",
      "time_since_restore: 5134.9422216415405\n",
      "time_this_iter_s: 7.479984760284424\n",
      "time_total_s: 5134.9422216415405\n",
      "timers:\n",
      "  learn_throughput: 1219.877\n",
      "  learn_time_ms: 3279.02\n",
      "  load_throughput: 20924440.01\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 520.914\n",
      "  sample_time_ms: 7678.811\n",
      "  update_time_ms: 2.239\n",
      "timestamp: 1658399094\n",
      "timesteps_since_restore: 2804000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2804000\n",
      "training_iteration: 701\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000701/checkpoint-701\n",
      "agent_timesteps_total: 2808000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-25-02\n",
      "done: false\n",
      "episode_len_mean: 178.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 178.01\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14663\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2602963447570801\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037413490936160088\n",
      "        model: {}\n",
      "        policy_loss: 0.0016554940957576036\n",
      "        total_loss: 4.185122966766357\n",
      "        vf_explained_var: 3.7179196965553274e-07\n",
      "        vf_loss: 4.183467864990234\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2808000\n",
      "  num_agent_steps_trained: 2808000\n",
      "  num_steps_sampled: 2808000\n",
      "  num_steps_trained: 2808000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 702\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.9\n",
      "  ram_util_percent: 87.58333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07085715419289014\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08126684895417367\n",
      "  mean_inference_ms: 0.7776674027196324\n",
      "  mean_raw_obs_processing_ms: 0.09383438771508476\n",
      "time_since_restore: 5143.33734703064\n",
      "time_this_iter_s: 8.395125389099121\n",
      "time_total_s: 5143.33734703064\n",
      "timers:\n",
      "  learn_throughput: 1206.289\n",
      "  learn_time_ms: 3315.955\n",
      "  load_throughput: 20710055.549\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 522.0\n",
      "  sample_time_ms: 7662.83\n",
      "  update_time_ms: 2.2\n",
      "timestamp: 1658399102\n",
      "timesteps_since_restore: 2808000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2808000\n",
      "training_iteration: 702\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2812000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-25-10\n",
      "done: false\n",
      "episode_len_mean: 182.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 182.19\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14684\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2549237608909607\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00435025105252862\n",
      "        model: {}\n",
      "        policy_loss: 0.004697590600699186\n",
      "        total_loss: 7.272843360900879\n",
      "        vf_explained_var: 1.1645978474916774e-06\n",
      "        vf_loss: 7.2681450843811035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2812000\n",
      "  num_agent_steps_trained: 2812000\n",
      "  num_steps_sampled: 2812000\n",
      "  num_steps_trained: 2812000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 703\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.35454545454545\n",
      "  ram_util_percent: 87.89090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07086268539522082\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08127303674620352\n",
      "  mean_inference_ms: 0.7777277585208127\n",
      "  mean_raw_obs_processing_ms: 0.09384178745919822\n",
      "time_since_restore: 5150.877210140228\n",
      "time_this_iter_s: 7.539863109588623\n",
      "time_total_s: 5150.877210140228\n",
      "timers:\n",
      "  learn_throughput: 1201.172\n",
      "  learn_time_ms: 3330.081\n",
      "  load_throughput: 20092474.251\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 516.756\n",
      "  sample_time_ms: 7740.598\n",
      "  update_time_ms: 2.344\n",
      "timestamp: 1658399110\n",
      "timesteps_since_restore: 2812000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2812000\n",
      "training_iteration: 703\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2816000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-25-17\n",
      "done: false\n",
      "episode_len_mean: 187.81\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.81\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14704\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24469897150993347\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033005299046635628\n",
      "        model: {}\n",
      "        policy_loss: 0.007567711640149355\n",
      "        total_loss: 7.61847448348999\n",
      "        vf_explained_var: -4.3363982626942743e-07\n",
      "        vf_loss: 7.610906600952148\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2816000\n",
      "  num_agent_steps_trained: 2816000\n",
      "  num_steps_sampled: 2816000\n",
      "  num_steps_trained: 2816000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 704\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.7\n",
      "  ram_util_percent: 87.61000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07086700254641473\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08127782017034564\n",
      "  mean_inference_ms: 0.7777751258921972\n",
      "  mean_raw_obs_processing_ms: 0.09384728836926484\n",
      "time_since_restore: 5157.880245685577\n",
      "time_this_iter_s: 7.003035545349121\n",
      "time_total_s: 5157.880245685577\n",
      "timers:\n",
      "  learn_throughput: 1251.928\n",
      "  learn_time_ms: 3195.071\n",
      "  load_throughput: 20172196.706\n",
      "  load_time_ms: 0.198\n",
      "  sample_throughput: 516.976\n",
      "  sample_time_ms: 7737.308\n",
      "  update_time_ms: 2.389\n",
      "timestamp: 1658399117\n",
      "timesteps_since_restore: 2816000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2816000\n",
      "training_iteration: 704\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2820000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-25-24\n",
      "done: false\n",
      "episode_len_mean: 192.73\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.73\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14724\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23403964936733246\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030583797488361597\n",
      "        model: {}\n",
      "        policy_loss: 0.0022131423465907574\n",
      "        total_loss: 4.709874629974365\n",
      "        vf_explained_var: 0.0061566694639623165\n",
      "        vf_loss: 4.707661151885986\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2820000\n",
      "  num_agent_steps_trained: 2820000\n",
      "  num_steps_sampled: 2820000\n",
      "  num_steps_trained: 2820000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 705\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.53\n",
      "  ram_util_percent: 87.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07086923288802496\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08128044281608023\n",
      "  mean_inference_ms: 0.7778040013078339\n",
      "  mean_raw_obs_processing_ms: 0.09385022843946293\n",
      "time_since_restore: 5164.703164339066\n",
      "time_this_iter_s: 6.822918653488159\n",
      "time_total_s: 5164.703164339066\n",
      "timers:\n",
      "  learn_throughput: 1268.218\n",
      "  learn_time_ms: 3154.031\n",
      "  load_throughput: 21517527.254\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 531.861\n",
      "  sample_time_ms: 7520.762\n",
      "  update_time_ms: 2.384\n",
      "timestamp: 1658399124\n",
      "timesteps_since_restore: 2820000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2820000\n",
      "training_iteration: 705\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2824000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-25-31\n",
      "done: false\n",
      "episode_len_mean: 192.13\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.13\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 14747\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25661665201187134\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004719560965895653\n",
      "        model: {}\n",
      "        policy_loss: 0.0008497328381054103\n",
      "        total_loss: 6.328980922698975\n",
      "        vf_explained_var: -0.047685541212558746\n",
      "        vf_loss: 6.328131198883057\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2824000\n",
      "  num_agent_steps_trained: 2824000\n",
      "  num_steps_sampled: 2824000\n",
      "  num_steps_trained: 2824000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 706\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.769999999999996\n",
      "  ram_util_percent: 87.55999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07086989631664325\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0812813069881198\n",
      "  mean_inference_ms: 0.7778157642081337\n",
      "  mean_raw_obs_processing_ms: 0.0938514049268382\n",
      "time_since_restore: 5172.139881849289\n",
      "time_this_iter_s: 7.436717510223389\n",
      "time_total_s: 5172.139881849289\n",
      "timers:\n",
      "  learn_throughput: 1270.46\n",
      "  learn_time_ms: 3148.466\n",
      "  load_throughput: 21785762.888\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 538.847\n",
      "  sample_time_ms: 7423.261\n",
      "  update_time_ms: 2.538\n",
      "timestamp: 1658399131\n",
      "timesteps_since_restore: 2824000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2824000\n",
      "training_iteration: 706\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2828000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-25-38\n",
      "done: false\n",
      "episode_len_mean: 186.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.76\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 14770\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2578743100166321\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003261612029746175\n",
      "        model: {}\n",
      "        policy_loss: 0.00024931097868829966\n",
      "        total_loss: 3.611644744873047\n",
      "        vf_explained_var: -0.002833401784300804\n",
      "        vf_loss: 3.6113955974578857\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2828000\n",
      "  num_agent_steps_trained: 2828000\n",
      "  num_steps_sampled: 2828000\n",
      "  num_steps_trained: 2828000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 707\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.239999999999995\n",
      "  ram_util_percent: 87.67\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07086698123206342\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08127837380814192\n",
      "  mean_inference_ms: 0.7777895827145892\n",
      "  mean_raw_obs_processing_ms: 0.09384853632270908\n",
      "time_since_restore: 5179.267774105072\n",
      "time_this_iter_s: 7.127892255783081\n",
      "time_total_s: 5179.267774105072\n",
      "timers:\n",
      "  learn_throughput: 1280.973\n",
      "  learn_time_ms: 3122.627\n",
      "  load_throughput: 21780106.452\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 541.261\n",
      "  sample_time_ms: 7390.147\n",
      "  update_time_ms: 2.487\n",
      "timestamp: 1658399138\n",
      "timesteps_since_restore: 2828000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2828000\n",
      "training_iteration: 707\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2832000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-25-45\n",
      "done: false\n",
      "episode_len_mean: 184.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.01\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 14792\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2592794895172119\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032212131191045046\n",
      "        model: {}\n",
      "        policy_loss: 0.0029345082584768534\n",
      "        total_loss: 5.973203659057617\n",
      "        vf_explained_var: -0.0016110338037833571\n",
      "        vf_loss: 5.970268726348877\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2832000\n",
      "  num_agent_steps_trained: 2832000\n",
      "  num_steps_sampled: 2832000\n",
      "  num_steps_trained: 2832000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 708\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.50909090909091\n",
      "  ram_util_percent: 87.61818181818181\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07086245979607743\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08127363506201339\n",
      "  mean_inference_ms: 0.7777487075408832\n",
      "  mean_raw_obs_processing_ms: 0.09384389235000949\n",
      "time_since_restore: 5186.341366052628\n",
      "time_this_iter_s: 7.073591947555542\n",
      "time_total_s: 5186.341366052628\n",
      "timers:\n",
      "  learn_throughput: 1270.68\n",
      "  learn_time_ms: 3147.92\n",
      "  load_throughput: 21692805.793\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 546.275\n",
      "  sample_time_ms: 7322.32\n",
      "  update_time_ms: 2.485\n",
      "timestamp: 1658399145\n",
      "timesteps_since_restore: 2832000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2832000\n",
      "training_iteration: 708\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2836000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-25-52\n",
      "done: false\n",
      "episode_len_mean: 184.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.01\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14812\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2778054475784302\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0045339264906942844\n",
      "        model: {}\n",
      "        policy_loss: 0.00551666459068656\n",
      "        total_loss: 7.666807174682617\n",
      "        vf_explained_var: 1.2991889661861933e-06\n",
      "        vf_loss: 7.661290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2836000\n",
      "  num_agent_steps_trained: 2836000\n",
      "  num_steps_sampled: 2836000\n",
      "  num_steps_trained: 2836000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 709\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.93333333333334\n",
      "  ram_util_percent: 87.7\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0708582020890207\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0812690080258241\n",
      "  mean_inference_ms: 0.7777069084641439\n",
      "  mean_raw_obs_processing_ms: 0.09383929639803927\n",
      "time_since_restore: 5193.173677682877\n",
      "time_this_iter_s: 6.832311630249023\n",
      "time_total_s: 5193.173677682877\n",
      "timers:\n",
      "  learn_throughput: 1274.864\n",
      "  learn_time_ms: 3137.591\n",
      "  load_throughput: 21617337.972\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 545.273\n",
      "  sample_time_ms: 7335.769\n",
      "  update_time_ms: 2.421\n",
      "timestamp: 1658399152\n",
      "timesteps_since_restore: 2836000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2836000\n",
      "training_iteration: 709\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2840000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-00\n",
      "done: false\n",
      "episode_len_mean: 183.29\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 183.29\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14833\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2725767493247986\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0041152662597596645\n",
      "        model: {}\n",
      "        policy_loss: -0.0012501657474786043\n",
      "        total_loss: 3.3480451107025146\n",
      "        vf_explained_var: -0.00544518930837512\n",
      "        vf_loss: 3.349294662475586\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2840000\n",
      "  num_agent_steps_trained: 2840000\n",
      "  num_steps_sampled: 2840000\n",
      "  num_steps_trained: 2840000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 710\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.163636363636364\n",
      "  ram_util_percent: 87.56363636363636\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07085457984664681\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08126490014502956\n",
      "  mean_inference_ms: 0.7776722532368983\n",
      "  mean_raw_obs_processing_ms: 0.0938353780024545\n",
      "time_since_restore: 5200.446164608002\n",
      "time_this_iter_s: 7.272486925125122\n",
      "time_total_s: 5200.446164608002\n",
      "timers:\n",
      "  learn_throughput: 1270.725\n",
      "  learn_time_ms: 3147.81\n",
      "  load_throughput: 21164647.408\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 547.07\n",
      "  sample_time_ms: 7311.679\n",
      "  update_time_ms: 2.379\n",
      "timestamp: 1658399160\n",
      "timesteps_since_restore: 2840000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2840000\n",
      "training_iteration: 710\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2844000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-06\n",
      "done: false\n",
      "episode_len_mean: 188.73\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.73\n",
      "episode_reward_min: 60.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14854\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26433518528938293\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003599049523472786\n",
      "        model: {}\n",
      "        policy_loss: -0.0013102091616019607\n",
      "        total_loss: 2.586895704269409\n",
      "        vf_explained_var: -0.17928896844387054\n",
      "        vf_loss: 2.588205575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2844000\n",
      "  num_agent_steps_trained: 2844000\n",
      "  num_steps_sampled: 2844000\n",
      "  num_steps_trained: 2844000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 711\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.160000000000004\n",
      "  ram_util_percent: 87.58\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07084953745130837\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08125895406887486\n",
      "  mean_inference_ms: 0.7776246834341669\n",
      "  mean_raw_obs_processing_ms: 0.09382951626865982\n",
      "time_since_restore: 5207.336744070053\n",
      "time_this_iter_s: 6.890579462051392\n",
      "time_total_s: 5207.336744070053\n",
      "timers:\n",
      "  learn_throughput: 1274.112\n",
      "  learn_time_ms: 3139.442\n",
      "  load_throughput: 21255816.546\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 550.149\n",
      "  sample_time_ms: 7270.761\n",
      "  update_time_ms: 2.358\n",
      "timestamp: 1658399166\n",
      "timesteps_since_restore: 2844000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2844000\n",
      "training_iteration: 711\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2848000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-14\n",
      "done: false\n",
      "episode_len_mean: 189.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.06\n",
      "episode_reward_min: 15.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 14876\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24399718642234802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029006870463490486\n",
      "        model: {}\n",
      "        policy_loss: 0.001818007556721568\n",
      "        total_loss: 3.9206690788269043\n",
      "        vf_explained_var: -0.03225782513618469\n",
      "        vf_loss: 3.918850898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2848000\n",
      "  num_agent_steps_trained: 2848000\n",
      "  num_steps_sampled: 2848000\n",
      "  num_steps_trained: 2848000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 712\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.58\n",
      "  ram_util_percent: 87.55\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07084389537609158\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08125212705836868\n",
      "  mean_inference_ms: 0.7775800408936512\n",
      "  mean_raw_obs_processing_ms: 0.0938225676861068\n",
      "time_since_restore: 5214.800899982452\n",
      "time_this_iter_s: 7.464155912399292\n",
      "time_total_s: 5214.800899982452\n",
      "timers:\n",
      "  learn_throughput: 1284.946\n",
      "  learn_time_ms: 3112.97\n",
      "  load_throughput: 15403246.419\n",
      "  load_time_ms: 0.26\n",
      "  sample_throughput: 555.947\n",
      "  sample_time_ms: 7194.924\n",
      "  update_time_ms: 2.338\n",
      "timestamp: 1658399174\n",
      "timesteps_since_restore: 2848000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2848000\n",
      "training_iteration: 712\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2852000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-22\n",
      "done: false\n",
      "episode_len_mean: 191.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.36\n",
      "episode_reward_min: 15.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14896\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26586174964904785\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004704885650426149\n",
      "        model: {}\n",
      "        policy_loss: 0.002251868136227131\n",
      "        total_loss: 4.4377360343933105\n",
      "        vf_explained_var: -4.620321476522804e-07\n",
      "        vf_loss: 4.435483932495117\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2852000\n",
      "  num_agent_steps_trained: 2852000\n",
      "  num_steps_sampled: 2852000\n",
      "  num_steps_trained: 2852000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 713\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.708333333333336\n",
      "  ram_util_percent: 87.93333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.070840872683203\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08124836912018248\n",
      "  mean_inference_ms: 0.7775615744106463\n",
      "  mean_raw_obs_processing_ms: 0.09381922180652187\n",
      "time_since_restore: 5222.687664270401\n",
      "time_this_iter_s: 7.886764287948608\n",
      "time_total_s: 5222.687664270401\n",
      "timers:\n",
      "  learn_throughput: 1269.691\n",
      "  learn_time_ms: 3150.374\n",
      "  load_throughput: 15913132.884\n",
      "  load_time_ms: 0.251\n",
      "  sample_throughput: 558.221\n",
      "  sample_time_ms: 7165.627\n",
      "  update_time_ms: 2.242\n",
      "timestamp: 1658399182\n",
      "timesteps_since_restore: 2852000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2852000\n",
      "training_iteration: 713\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2856000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-29\n",
      "done: false\n",
      "episode_len_mean: 192.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.35\n",
      "episode_reward_min: 15.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14916\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2890309691429138\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003903200849890709\n",
      "        model: {}\n",
      "        policy_loss: 0.0021124491468071938\n",
      "        total_loss: 4.437597274780273\n",
      "        vf_explained_var: 1.3452704195060505e-07\n",
      "        vf_loss: 4.435484886169434\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2856000\n",
      "  num_agent_steps_trained: 2856000\n",
      "  num_steps_sampled: 2856000\n",
      "  num_steps_trained: 2856000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 714\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.76\n",
      "  ram_util_percent: 87.97\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07084015000424088\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0812473972823647\n",
      "  mean_inference_ms: 0.7775673651203302\n",
      "  mean_raw_obs_processing_ms: 0.09381885118738026\n",
      "time_since_restore: 5230.238524675369\n",
      "time_this_iter_s: 7.550860404968262\n",
      "time_total_s: 5230.238524675369\n",
      "timers:\n",
      "  learn_throughput: 1265.763\n",
      "  learn_time_ms: 3160.149\n",
      "  load_throughput: 15788834.933\n",
      "  load_time_ms: 0.253\n",
      "  sample_throughput: 551.86\n",
      "  sample_time_ms: 7248.216\n",
      "  update_time_ms: 2.144\n",
      "timestamp: 1658399189\n",
      "timesteps_since_restore: 2856000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2856000\n",
      "training_iteration: 714\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2860000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-36\n",
      "done: false\n",
      "episode_len_mean: 192.98\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.98\n",
      "episode_reward_min: 15.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14937\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2690351605415344\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005298971198499203\n",
      "        model: {}\n",
      "        policy_loss: 0.0022529750131070614\n",
      "        total_loss: 5.748230457305908\n",
      "        vf_explained_var: 7.32560295091389e-07\n",
      "        vf_loss: 5.745977401733398\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2860000\n",
      "  num_agent_steps_trained: 2860000\n",
      "  num_steps_sampled: 2860000\n",
      "  num_steps_trained: 2860000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 715\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.96\n",
      "  ram_util_percent: 87.70000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07083823594815197\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.081245294508614\n",
      "  mean_inference_ms: 0.7775602135306262\n",
      "  mean_raw_obs_processing_ms: 0.09381682182258676\n",
      "time_since_restore: 5237.172248601913\n",
      "time_this_iter_s: 6.9337239265441895\n",
      "time_total_s: 5237.172248601913\n",
      "timers:\n",
      "  learn_throughput: 1259.515\n",
      "  learn_time_ms: 3175.826\n",
      "  load_throughput: 15163788.865\n",
      "  load_time_ms: 0.264\n",
      "  sample_throughput: 551.605\n",
      "  sample_time_ms: 7251.569\n",
      "  update_time_ms: 2.129\n",
      "timestamp: 1658399196\n",
      "timesteps_since_restore: 2860000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2860000\n",
      "training_iteration: 715\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2864000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-43\n",
      "done: false\n",
      "episode_len_mean: 197.06\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.06\n",
      "episode_reward_min: 41.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14957\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.259189635515213\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028290546033531427\n",
      "        model: {}\n",
      "        policy_loss: 0.007697399705648422\n",
      "        total_loss: 7.719390392303467\n",
      "        vf_explained_var: 7.428148762755882e-08\n",
      "        vf_loss: 7.71169376373291\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2864000\n",
      "  num_agent_steps_trained: 2864000\n",
      "  num_steps_sampled: 2864000\n",
      "  num_steps_trained: 2864000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 716\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.48\n",
      "  ram_util_percent: 87.61000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07083631717593028\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08124327988779824\n",
      "  mean_inference_ms: 0.7775511120241387\n",
      "  mean_raw_obs_processing_ms: 0.09381456538267542\n",
      "time_since_restore: 5243.931542634964\n",
      "time_this_iter_s: 6.759294033050537\n",
      "time_total_s: 5243.931542634964\n",
      "timers:\n",
      "  learn_throughput: 1277.192\n",
      "  learn_time_ms: 3131.869\n",
      "  load_throughput: 15263114.993\n",
      "  load_time_ms: 0.262\n",
      "  sample_throughput: 552.191\n",
      "  sample_time_ms: 7243.873\n",
      "  update_time_ms: 1.984\n",
      "timestamp: 1658399203\n",
      "timesteps_since_restore: 2864000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2864000\n",
      "training_iteration: 716\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2868000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-50\n",
      "done: false\n",
      "episode_len_mean: 197.43\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.43\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 14977\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23294730484485626\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004021596163511276\n",
      "        model: {}\n",
      "        policy_loss: 0.00169543013907969\n",
      "        total_loss: 4.457342147827148\n",
      "        vf_explained_var: -0.036545369774103165\n",
      "        vf_loss: 4.45564603805542\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2868000\n",
      "  num_agent_steps_trained: 2868000\n",
      "  num_steps_sampled: 2868000\n",
      "  num_steps_trained: 2868000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 717\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.93\n",
      "  ram_util_percent: 87.68\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07083456820315855\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08124143689802173\n",
      "  mean_inference_ms: 0.777536900195486\n",
      "  mean_raw_obs_processing_ms: 0.09381260489092359\n",
      "time_since_restore: 5251.012801885605\n",
      "time_this_iter_s: 7.081259250640869\n",
      "time_total_s: 5251.012801885605\n",
      "timers:\n",
      "  learn_throughput: 1276.545\n",
      "  learn_time_ms: 3133.458\n",
      "  load_throughput: 15750296.658\n",
      "  load_time_ms: 0.254\n",
      "  sample_throughput: 556.1\n",
      "  sample_time_ms: 7192.957\n",
      "  update_time_ms: 2.011\n",
      "timestamp: 1658399210\n",
      "timesteps_since_restore: 2868000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2868000\n",
      "training_iteration: 717\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2872000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-26-57\n",
      "done: false\n",
      "episode_len_mean: 196.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.08\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 14998\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26526153087615967\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0050352104008197784\n",
      "        model: {}\n",
      "        policy_loss: -0.003861378412693739\n",
      "        total_loss: 2.73051381111145\n",
      "        vf_explained_var: -0.001566150225698948\n",
      "        vf_loss: 2.734375\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2872000\n",
      "  num_agent_steps_trained: 2872000\n",
      "  num_steps_sampled: 2872000\n",
      "  num_steps_trained: 2872000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 718\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.44\n",
      "  ram_util_percent: 87.69000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0708317888929923\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08123845519318407\n",
      "  mean_inference_ms: 0.777512437798555\n",
      "  mean_raw_obs_processing_ms: 0.09380919410888651\n",
      "time_since_restore: 5258.101197957993\n",
      "time_this_iter_s: 7.088396072387695\n",
      "time_total_s: 5258.101197957993\n",
      "timers:\n",
      "  learn_throughput: 1286.078\n",
      "  learn_time_ms: 3110.23\n",
      "  load_throughput: 15723726.336\n",
      "  load_time_ms: 0.254\n",
      "  sample_throughput: 554.047\n",
      "  sample_time_ms: 7219.603\n",
      "  update_time_ms: 2.052\n",
      "timestamp: 1658399217\n",
      "timesteps_since_restore: 2872000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2872000\n",
      "training_iteration: 718\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2876000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-27-04\n",
      "done: false\n",
      "episode_len_mean: 194.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.35\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15019\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.251747190952301\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005518923979252577\n",
      "        model: {}\n",
      "        policy_loss: 0.002482929965481162\n",
      "        total_loss: 5.793814182281494\n",
      "        vf_explained_var: 6.714174674016249e-07\n",
      "        vf_loss: 5.791330814361572\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2876000\n",
      "  num_agent_steps_trained: 2876000\n",
      "  num_steps_sampled: 2876000\n",
      "  num_steps_trained: 2876000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 719\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.059999999999995\n",
      "  ram_util_percent: 87.71000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07082633502401504\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08123232826353652\n",
      "  mean_inference_ms: 0.777461555456843\n",
      "  mean_raw_obs_processing_ms: 0.09380259797160692\n",
      "time_since_restore: 5265.051470518112\n",
      "time_this_iter_s: 6.950272560119629\n",
      "time_total_s: 5265.051470518112\n",
      "timers:\n",
      "  learn_throughput: 1280.587\n",
      "  learn_time_ms: 3123.567\n",
      "  load_throughput: 15700183.418\n",
      "  load_time_ms: 0.255\n",
      "  sample_throughput: 555.971\n",
      "  sample_time_ms: 7194.622\n",
      "  update_time_ms: 2.12\n",
      "timestamp: 1658399224\n",
      "timesteps_since_restore: 2876000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2876000\n",
      "training_iteration: 719\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2880000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-27-11\n",
      "done: false\n",
      "episode_len_mean: 195.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.7\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15039\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23296058177947998\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002359874313697219\n",
      "        model: {}\n",
      "        policy_loss: 0.005454723257571459\n",
      "        total_loss: 6.20505952835083\n",
      "        vf_explained_var: 1.2690021478078961e-08\n",
      "        vf_loss: 6.1996049880981445\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2880000\n",
      "  num_agent_steps_trained: 2880000\n",
      "  num_steps_sampled: 2880000\n",
      "  num_steps_trained: 2880000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 720\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.39999999999999\n",
      "  ram_util_percent: 87.72\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0708213544774841\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08122670582883565\n",
      "  mean_inference_ms: 0.7774167285817098\n",
      "  mean_raw_obs_processing_ms: 0.09379669486015967\n",
      "time_since_restore: 5271.9956295490265\n",
      "time_this_iter_s: 6.944159030914307\n",
      "time_total_s: 5271.9956295490265\n",
      "timers:\n",
      "  learn_throughput: 1285.193\n",
      "  learn_time_ms: 3112.372\n",
      "  load_throughput: 16047074.127\n",
      "  load_time_ms: 0.249\n",
      "  sample_throughput: 556.569\n",
      "  sample_time_ms: 7186.89\n",
      "  update_time_ms: 2.177\n",
      "timestamp: 1658399231\n",
      "timesteps_since_restore: 2880000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2880000\n",
      "training_iteration: 720\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2884000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-27-18\n",
      "done: false\n",
      "episode_len_mean: 195.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.78\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15059\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2800493538379669\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004401089157909155\n",
      "        model: {}\n",
      "        policy_loss: 0.0051567889750003815\n",
      "        total_loss: 6.204753875732422\n",
      "        vf_explained_var: -4.146688681316846e-08\n",
      "        vf_loss: 6.199596881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2884000\n",
      "  num_agent_steps_trained: 2884000\n",
      "  num_steps_sampled: 2884000\n",
      "  num_steps_trained: 2884000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 721\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.11\n",
      "  ram_util_percent: 87.7\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07081744559658959\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08122226017617903\n",
      "  mean_inference_ms: 0.7773822484077629\n",
      "  mean_raw_obs_processing_ms: 0.09379228594090032\n",
      "time_since_restore: 5279.156663417816\n",
      "time_this_iter_s: 7.161033868789673\n",
      "time_total_s: 5279.156663417816\n",
      "timers:\n",
      "  learn_throughput: 1283.637\n",
      "  learn_time_ms: 3116.145\n",
      "  load_throughput: 16014906.453\n",
      "  load_time_ms: 0.25\n",
      "  sample_throughput: 555.62\n",
      "  sample_time_ms: 7199.159\n",
      "  update_time_ms: 2.261\n",
      "timestamp: 1658399238\n",
      "timesteps_since_restore: 2884000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2884000\n",
      "training_iteration: 721\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2888000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-27-27\n",
      "done: false\n",
      "episode_len_mean: 195.73\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.73\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15079\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25498610734939575\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034878612495958805\n",
      "        model: {}\n",
      "        policy_loss: 0.0026593904476612806\n",
      "        total_loss: 4.922021865844727\n",
      "        vf_explained_var: -0.050648123025894165\n",
      "        vf_loss: 4.919362545013428\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2888000\n",
      "  num_agent_steps_trained: 2888000\n",
      "  num_steps_sampled: 2888000\n",
      "  num_steps_trained: 2888000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 722\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.01666666666666\n",
      "  ram_util_percent: 87.95833333333336\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07081665725396334\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08122160367413533\n",
      "  mean_inference_ms: 0.7773796578833674\n",
      "  mean_raw_obs_processing_ms: 0.09379165910087398\n",
      "time_since_restore: 5287.248746871948\n",
      "time_this_iter_s: 8.09208345413208\n",
      "time_total_s: 5287.248746871948\n",
      "timers:\n",
      "  learn_throughput: 1281.512\n",
      "  learn_time_ms: 3121.313\n",
      "  load_throughput: 22659665.046\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 550.872\n",
      "  sample_time_ms: 7261.22\n",
      "  update_time_ms: 2.253\n",
      "timestamp: 1658399247\n",
      "timesteps_since_restore: 2888000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2888000\n",
      "training_iteration: 722\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2892000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-27-33\n",
      "done: false\n",
      "episode_len_mean: 195.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.65\n",
      "episode_reward_min: 27.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15100\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21455246210098267\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003951955586671829\n",
      "        model: {}\n",
      "        policy_loss: -0.00205800449475646\n",
      "        total_loss: 2.06447434425354\n",
      "        vf_explained_var: -0.16115358471870422\n",
      "        vf_loss: 2.0665323734283447\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2892000\n",
      "  num_agent_steps_trained: 2892000\n",
      "  num_steps_sampled: 2892000\n",
      "  num_steps_trained: 2892000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 723\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.25555555555556\n",
      "  ram_util_percent: 87.88888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07081413902697953\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.081219041745087\n",
      "  mean_inference_ms: 0.7773596131518871\n",
      "  mean_raw_obs_processing_ms: 0.09378896715287041\n",
      "time_since_restore: 5293.9290409088135\n",
      "time_this_iter_s: 6.680294036865234\n",
      "time_total_s: 5293.9290409088135\n",
      "timers:\n",
      "  learn_throughput: 1310.141\n",
      "  learn_time_ms: 3053.106\n",
      "  load_throughput: 21718078.964\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 554.534\n",
      "  sample_time_ms: 7213.258\n",
      "  update_time_ms: 2.221\n",
      "timestamp: 1658399253\n",
      "timesteps_since_restore: 2892000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2892000\n",
      "training_iteration: 723\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2896000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-27-40\n",
      "done: false\n",
      "episode_len_mean: 197.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.38\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15120\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24151381850242615\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032661291770637035\n",
      "        model: {}\n",
      "        policy_loss: 0.0025859540328383446\n",
      "        total_loss: 3.0771825313568115\n",
      "        vf_explained_var: -0.06451605260372162\n",
      "        vf_loss: 3.074596881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2896000\n",
      "  num_agent_steps_trained: 2896000\n",
      "  num_steps_sampled: 2896000\n",
      "  num_steps_trained: 2896000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 724\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.839999999999996\n",
      "  ram_util_percent: 87.66\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07081184225287515\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08121681153497028\n",
      "  mean_inference_ms: 0.7773406158489083\n",
      "  mean_raw_obs_processing_ms: 0.09378627934724516\n",
      "time_since_restore: 5300.700135231018\n",
      "time_this_iter_s: 6.77109432220459\n",
      "time_total_s: 5300.700135231018\n",
      "timers:\n",
      "  learn_throughput: 1321.256\n",
      "  learn_time_ms: 3027.422\n",
      "  load_throughput: 21899511.813\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 563.996\n",
      "  sample_time_ms: 7092.249\n",
      "  update_time_ms: 2.241\n",
      "timestamp: 1658399260\n",
      "timesteps_since_restore: 2896000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2896000\n",
      "training_iteration: 724\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2900000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-27-47\n",
      "done: false\n",
      "episode_len_mean: 197.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.38\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15140\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25381577014923096\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004936804994940758\n",
      "        model: {}\n",
      "        policy_loss: -0.00010924518574029207\n",
      "        total_loss: 3.0744876861572266\n",
      "        vf_explained_var: -0.04840259253978729\n",
      "        vf_loss: 3.074596881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2900000\n",
      "  num_agent_steps_trained: 2900000\n",
      "  num_steps_sampled: 2900000\n",
      "  num_steps_trained: 2900000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 725\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.309999999999995\n",
      "  ram_util_percent: 87.63000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07080906912696784\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08121393234318754\n",
      "  mean_inference_ms: 0.7773158495966545\n",
      "  mean_raw_obs_processing_ms: 0.09378296716617665\n",
      "time_since_restore: 5307.7975969314575\n",
      "time_this_iter_s: 7.097461700439453\n",
      "time_total_s: 5307.7975969314575\n",
      "timers:\n",
      "  learn_throughput: 1312.928\n",
      "  learn_time_ms: 3046.625\n",
      "  load_throughput: 23266143.392\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 566.276\n",
      "  sample_time_ms: 7063.692\n",
      "  update_time_ms: 2.275\n",
      "timestamp: 1658399267\n",
      "timesteps_since_restore: 2900000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2900000\n",
      "training_iteration: 725\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2904000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-27-54\n",
      "done: false\n",
      "episode_len_mean: 197.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.38\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15160\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23819796741008759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002747095189988613\n",
      "        model: {}\n",
      "        policy_loss: 0.0019278057152405381\n",
      "        total_loss: 3.0765249729156494\n",
      "        vf_explained_var: -0.06451622396707535\n",
      "        vf_loss: 3.074597120285034\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2904000\n",
      "  num_agent_steps_trained: 2904000\n",
      "  num_steps_sampled: 2904000\n",
      "  num_steps_trained: 2904000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 726\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.72\n",
      "  ram_util_percent: 87.57000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07080483833626836\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08120953098932143\n",
      "  mean_inference_ms: 0.7772790090920334\n",
      "  mean_raw_obs_processing_ms: 0.09377789660785439\n",
      "time_since_restore: 5314.715948820114\n",
      "time_this_iter_s: 6.918351888656616\n",
      "time_total_s: 5314.715948820114\n",
      "timers:\n",
      "  learn_throughput: 1306.328\n",
      "  learn_time_ms: 3062.019\n",
      "  load_throughput: 23195376.745\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 564.707\n",
      "  sample_time_ms: 7083.322\n",
      "  update_time_ms: 2.347\n",
      "timestamp: 1658399274\n",
      "timesteps_since_restore: 2904000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2904000\n",
      "training_iteration: 726\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2908000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-01\n",
      "done: false\n",
      "episode_len_mean: 198.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.14\n",
      "episode_reward_min: 65.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15180\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26026421785354614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025692761410027742\n",
      "        model: {}\n",
      "        policy_loss: 0.0011215616250410676\n",
      "        total_loss: 2.261706590652466\n",
      "        vf_explained_var: -0.1612015664577484\n",
      "        vf_loss: 2.260584831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2908000\n",
      "  num_agent_steps_trained: 2908000\n",
      "  num_steps_sampled: 2908000\n",
      "  num_steps_trained: 2908000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 727\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.24999999999999\n",
      "  ram_util_percent: 87.62\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0707966503242154\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08120051227141925\n",
      "  mean_inference_ms: 0.7771999614570595\n",
      "  mean_raw_obs_processing_ms: 0.09376823457338607\n",
      "time_since_restore: 5321.571095943451\n",
      "time_this_iter_s: 6.855147123336792\n",
      "time_total_s: 5321.571095943451\n",
      "timers:\n",
      "  learn_throughput: 1306.475\n",
      "  learn_time_ms: 3061.674\n",
      "  load_throughput: 22919693.989\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 565.223\n",
      "  sample_time_ms: 7076.85\n",
      "  update_time_ms: 2.308\n",
      "timestamp: 1658399281\n",
      "timesteps_since_restore: 2908000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2908000\n",
      "training_iteration: 727\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2912000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-08\n",
      "done: false\n",
      "episode_len_mean: 196.41\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.41\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 15202\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2512609362602234\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004101887345314026\n",
      "        model: {}\n",
      "        policy_loss: 0.00125164317432791\n",
      "        total_loss: 4.4543914794921875\n",
      "        vf_explained_var: -0.161288782954216\n",
      "        vf_loss: 4.4531402587890625\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2912000\n",
      "  num_agent_steps_trained: 2912000\n",
      "  num_steps_sampled: 2912000\n",
      "  num_steps_trained: 2912000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 728\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.23\n",
      "  ram_util_percent: 87.64000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07078796076596015\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0811908726556015\n",
      "  mean_inference_ms: 0.7771153868108766\n",
      "  mean_raw_obs_processing_ms: 0.0937579638989574\n",
      "time_since_restore: 5328.30441403389\n",
      "time_this_iter_s: 6.733318090438843\n",
      "time_total_s: 5328.30441403389\n",
      "timers:\n",
      "  learn_throughput: 1307.5\n",
      "  learn_time_ms: 3059.274\n",
      "  load_throughput: 23140987.586\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 567.921\n",
      "  sample_time_ms: 7043.229\n",
      "  update_time_ms: 2.281\n",
      "timestamp: 1658399288\n",
      "timesteps_since_restore: 2912000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2912000\n",
      "training_iteration: 728\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2916000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-14\n",
      "done: false\n",
      "episode_len_mean: 195.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.61\n",
      "episode_reward_min: 69.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15222\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2657856345176697\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029111176263540983\n",
      "        model: {}\n",
      "        policy_loss: 0.0010355468839406967\n",
      "        total_loss: 3.7258341312408447\n",
      "        vf_explained_var: -0.09677327424287796\n",
      "        vf_loss: 3.7247984409332275\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2916000\n",
      "  num_agent_steps_trained: 2916000\n",
      "  num_steps_sampled: 2916000\n",
      "  num_steps_trained: 2916000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 729\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.166666666666664\n",
      "  ram_util_percent: 87.6888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0707800453110007\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08118212185957234\n",
      "  mean_inference_ms: 0.7770373935808084\n",
      "  mean_raw_obs_processing_ms: 0.0937490453691852\n",
      "time_since_restore: 5334.921830654144\n",
      "time_this_iter_s: 6.617416620254517\n",
      "time_total_s: 5334.921830654144\n",
      "timers:\n",
      "  learn_throughput: 1322.285\n",
      "  learn_time_ms: 3025.065\n",
      "  load_throughput: 23163352.202\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 568.018\n",
      "  sample_time_ms: 7042.025\n",
      "  update_time_ms: 2.218\n",
      "timestamp: 1658399294\n",
      "timesteps_since_restore: 2916000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2916000\n",
      "training_iteration: 729\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2920000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-21\n",
      "done: false\n",
      "episode_len_mean: 192.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.03\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 15244\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25446105003356934\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00445832684636116\n",
      "        model: {}\n",
      "        policy_loss: -0.0006984828505665064\n",
      "        total_loss: 4.109684944152832\n",
      "        vf_explained_var: -0.05851324647665024\n",
      "        vf_loss: 4.110383033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2920000\n",
      "  num_agent_steps_trained: 2920000\n",
      "  num_steps_sampled: 2920000\n",
      "  num_steps_trained: 2920000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 730\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.57\n",
      "  ram_util_percent: 87.72\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07077134381860505\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08117246248063091\n",
      "  mean_inference_ms: 0.7769489724621894\n",
      "  mean_raw_obs_processing_ms: 0.09373943444278172\n",
      "time_since_restore: 5341.550875902176\n",
      "time_this_iter_s: 6.629045248031616\n",
      "time_total_s: 5341.550875902176\n",
      "timers:\n",
      "  learn_throughput: 1329.174\n",
      "  learn_time_ms: 3009.387\n",
      "  load_throughput: 23185760.088\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 572.153\n",
      "  sample_time_ms: 6991.133\n",
      "  update_time_ms: 2.182\n",
      "timestamp: 1658399301\n",
      "timesteps_since_restore: 2920000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2920000\n",
      "training_iteration: 730\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2924000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-28\n",
      "done: false\n",
      "episode_len_mean: 192.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.03\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15264\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23863184452056885\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004313701763749123\n",
      "        model: {}\n",
      "        policy_loss: 0.0015361851546913385\n",
      "        total_loss: 3.2273426055908203\n",
      "        vf_explained_var: -0.0645158514380455\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2924000\n",
      "  num_agent_steps_trained: 2924000\n",
      "  num_steps_sampled: 2924000\n",
      "  num_steps_trained: 2924000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 731\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.233333333333334\n",
      "  ram_util_percent: 87.66666666666669\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07076324961373795\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08116345223132797\n",
      "  mean_inference_ms: 0.7768654900488869\n",
      "  mean_raw_obs_processing_ms: 0.09373057187694885\n",
      "time_since_restore: 5348.357216119766\n",
      "time_this_iter_s: 6.806340217590332\n",
      "time_total_s: 5348.357216119766\n",
      "timers:\n",
      "  learn_throughput: 1331.921\n",
      "  learn_time_ms: 3003.18\n",
      "  load_throughput: 23337343.163\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 575.847\n",
      "  sample_time_ms: 6946.287\n",
      "  update_time_ms: 2.099\n",
      "timestamp: 1658399308\n",
      "timesteps_since_restore: 2924000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2924000\n",
      "training_iteration: 731\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2928000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-35\n",
      "done: false\n",
      "episode_len_mean: 191.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.05\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15285\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24594636261463165\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005245339125394821\n",
      "        model: {}\n",
      "        policy_loss: 0.005101371090859175\n",
      "        total_loss: 7.943614959716797\n",
      "        vf_explained_var: 1.067115363184712e-06\n",
      "        vf_loss: 7.938513278961182\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2928000\n",
      "  num_agent_steps_trained: 2928000\n",
      "  num_steps_sampled: 2928000\n",
      "  num_steps_trained: 2928000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 732\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.0\n",
      "  ram_util_percent: 87.71000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0707546925902594\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08115394438956436\n",
      "  mean_inference_ms: 0.7767773758112091\n",
      "  mean_raw_obs_processing_ms: 0.09372141729374725\n",
      "time_since_restore: 5355.456255674362\n",
      "time_this_iter_s: 7.099039554595947\n",
      "time_total_s: 5355.456255674362\n",
      "timers:\n",
      "  learn_throughput: 1337.035\n",
      "  learn_time_ms: 2991.694\n",
      "  load_throughput: 23566815.564\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 583.781\n",
      "  sample_time_ms: 6851.882\n",
      "  update_time_ms: 2.016\n",
      "timestamp: 1658399315\n",
      "timesteps_since_restore: 2928000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2928000\n",
      "training_iteration: 732\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2932000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-41\n",
      "done: false\n",
      "episode_len_mean: 191.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.92\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15306\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24385476112365723\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004161079414188862\n",
      "        model: {}\n",
      "        policy_loss: 0.002790086902678013\n",
      "        total_loss: 5.907527923583984\n",
      "        vf_explained_var: 1.1163373301315005e-06\n",
      "        vf_loss: 5.904737949371338\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2932000\n",
      "  num_agent_steps_trained: 2932000\n",
      "  num_steps_sampled: 2932000\n",
      "  num_steps_trained: 2932000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 733\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.269999999999996\n",
      "  ram_util_percent: 87.75\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07074477432970352\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08114298934907158\n",
      "  mean_inference_ms: 0.776674294342999\n",
      "  mean_raw_obs_processing_ms: 0.09371051359159602\n",
      "time_since_restore: 5361.900798559189\n",
      "time_this_iter_s: 6.44454288482666\n",
      "time_total_s: 5361.900798559189\n",
      "timers:\n",
      "  learn_throughput: 1336.595\n",
      "  learn_time_ms: 2992.679\n",
      "  load_throughput: 24665122.023\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 586.987\n",
      "  sample_time_ms: 6814.462\n",
      "  update_time_ms: 2.081\n",
      "timestamp: 1658399321\n",
      "timesteps_since_restore: 2932000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2932000\n",
      "training_iteration: 733\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2936000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-48\n",
      "done: false\n",
      "episode_len_mean: 192.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.03\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15326\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22837503254413605\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003369507845491171\n",
      "        model: {}\n",
      "        policy_loss: 0.001103319227695465\n",
      "        total_loss: 4.539915084838867\n",
      "        vf_explained_var: -0.03225696086883545\n",
      "        vf_loss: 4.538811683654785\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2936000\n",
      "  num_agent_steps_trained: 2936000\n",
      "  num_steps_sampled: 2936000\n",
      "  num_steps_trained: 2936000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 734\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.63333333333333\n",
      "  ram_util_percent: 87.85555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07073523921852401\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08113267158370906\n",
      "  mean_inference_ms: 0.7765769317144782\n",
      "  mean_raw_obs_processing_ms: 0.09369997687233603\n",
      "time_since_restore: 5368.577669143677\n",
      "time_this_iter_s: 6.676870584487915\n",
      "time_total_s: 5368.577669143677\n",
      "timers:\n",
      "  learn_throughput: 1340.09\n",
      "  learn_time_ms: 2984.875\n",
      "  load_throughput: 24234025.711\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 586.98\n",
      "  sample_time_ms: 6814.541\n",
      "  update_time_ms: 2.069\n",
      "timestamp: 1658399328\n",
      "timesteps_since_restore: 2936000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2936000\n",
      "training_iteration: 734\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2940000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-28-55\n",
      "done: false\n",
      "episode_len_mean: 194.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.0\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15347\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.26981934905052185\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00395030714571476\n",
      "        model: {}\n",
      "        policy_loss: 0.004130298737436533\n",
      "        total_loss: 7.925010681152344\n",
      "        vf_explained_var: 1.6307958503603004e-06\n",
      "        vf_loss: 7.92087984085083\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2940000\n",
      "  num_agent_steps_trained: 2940000\n",
      "  num_steps_sampled: 2940000\n",
      "  num_steps_trained: 2940000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 735\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.03\n",
      "  ram_util_percent: 87.78\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07072511253275632\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08112180412306069\n",
      "  mean_inference_ms: 0.7764768268943808\n",
      "  mean_raw_obs_processing_ms: 0.09368885894945227\n",
      "time_since_restore: 5375.369344711304\n",
      "time_this_iter_s: 6.791675567626953\n",
      "time_total_s: 5375.369344711304\n",
      "timers:\n",
      "  learn_throughput: 1353.697\n",
      "  learn_time_ms: 2954.871\n",
      "  load_throughput: 24283132.146\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 587.699\n",
      "  sample_time_ms: 6806.205\n",
      "  update_time_ms: 2.082\n",
      "timestamp: 1658399335\n",
      "timesteps_since_restore: 2940000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2940000\n",
      "training_iteration: 735\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2944000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-02\n",
      "done: false\n",
      "episode_len_mean: 192.97\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.97\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15368\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21129409968852997\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0022677266970276833\n",
      "        model: {}\n",
      "        policy_loss: 0.004592313896864653\n",
      "        total_loss: 6.846836090087891\n",
      "        vf_explained_var: -0.06451313942670822\n",
      "        vf_loss: 6.8422441482543945\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2944000\n",
      "  num_agent_steps_trained: 2944000\n",
      "  num_steps_sampled: 2944000\n",
      "  num_steps_trained: 2944000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 736\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.2\n",
      "  ram_util_percent: 87.76666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07071484306303435\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08111080885250559\n",
      "  mean_inference_ms: 0.7763730301377203\n",
      "  mean_raw_obs_processing_ms: 0.09367728753695252\n",
      "time_since_restore: 5382.0356550216675\n",
      "time_this_iter_s: 6.6663103103637695\n",
      "time_total_s: 5382.0356550216675\n",
      "timers:\n",
      "  learn_throughput: 1358.166\n",
      "  learn_time_ms: 2945.149\n",
      "  load_throughput: 24220031.76\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 591.648\n",
      "  sample_time_ms: 6760.782\n",
      "  update_time_ms: 2.013\n",
      "timestamp: 1658399342\n",
      "timesteps_since_restore: 2944000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2944000\n",
      "training_iteration: 736\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2948000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-08\n",
      "done: false\n",
      "episode_len_mean: 194.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.16\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15388\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2268015593290329\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002649121219292283\n",
      "        model: {}\n",
      "        policy_loss: 0.0018880557036027312\n",
      "        total_loss: 4.1021904945373535\n",
      "        vf_explained_var: 7.635803740413394e-07\n",
      "        vf_loss: 4.100302219390869\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2948000\n",
      "  num_agent_steps_trained: 2948000\n",
      "  num_steps_sampled: 2948000\n",
      "  num_steps_trained: 2948000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 737\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.05\n",
      "  ram_util_percent: 87.72000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07070516765433613\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08110045993686626\n",
      "  mean_inference_ms: 0.776275204795561\n",
      "  mean_raw_obs_processing_ms: 0.09366591739696678\n",
      "time_since_restore: 5388.750007867813\n",
      "time_this_iter_s: 6.71435284614563\n",
      "time_total_s: 5388.750007867813\n",
      "timers:\n",
      "  learn_throughput: 1362.854\n",
      "  learn_time_ms: 2935.017\n",
      "  load_throughput: 24538856.223\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 592.923\n",
      "  sample_time_ms: 6746.241\n",
      "  update_time_ms: 2.026\n",
      "timestamp: 1658399348\n",
      "timesteps_since_restore: 2948000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2948000\n",
      "training_iteration: 737\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2952000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-15\n",
      "done: false\n",
      "episode_len_mean: 195.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.86\n",
      "episode_reward_min: 119.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15408\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22364991903305054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004069352522492409\n",
      "        model: {}\n",
      "        policy_loss: 0.0006158108590170741\n",
      "        total_loss: 4.03287410736084\n",
      "        vf_explained_var: -2.3200946941415168e-08\n",
      "        vf_loss: 4.032258033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2952000\n",
      "  num_agent_steps_trained: 2952000\n",
      "  num_steps_sampled: 2952000\n",
      "  num_steps_trained: 2952000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 738\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.83\n",
      "  ram_util_percent: 87.78\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07069676017854637\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08109156628954342\n",
      "  mean_inference_ms: 0.7761923738355613\n",
      "  mean_raw_obs_processing_ms: 0.09365628298323926\n",
      "time_since_restore: 5395.629635095596\n",
      "time_this_iter_s: 6.879627227783203\n",
      "time_total_s: 5395.629635095596\n",
      "timers:\n",
      "  learn_throughput: 1359.069\n",
      "  learn_time_ms: 2943.191\n",
      "  load_throughput: 24564005.857\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 593.252\n",
      "  sample_time_ms: 6742.502\n",
      "  update_time_ms: 2.101\n",
      "timestamp: 1658399355\n",
      "timesteps_since_restore: 2952000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2952000\n",
      "training_iteration: 738\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2956000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-22\n",
      "done: false\n",
      "episode_len_mean: 191.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.2\n",
      "episode_reward_min: 56.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 15431\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23860138654708862\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004962448962032795\n",
      "        model: {}\n",
      "        policy_loss: 0.0024103925097733736\n",
      "        total_loss: 7.114306449890137\n",
      "        vf_explained_var: 1.1930542314075865e-06\n",
      "        vf_loss: 7.11189603805542\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2956000\n",
      "  num_agent_steps_trained: 2956000\n",
      "  num_steps_sampled: 2956000\n",
      "  num_steps_trained: 2956000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 739\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.129999999999995\n",
      "  ram_util_percent: 87.69000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07068755328283742\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08108164489346512\n",
      "  mean_inference_ms: 0.7760973471343467\n",
      "  mean_raw_obs_processing_ms: 0.09364563365468585\n",
      "time_since_restore: 5402.370980262756\n",
      "time_this_iter_s: 6.741345167160034\n",
      "time_total_s: 5402.370980262756\n",
      "timers:\n",
      "  learn_throughput: 1352.315\n",
      "  learn_time_ms: 2957.891\n",
      "  load_throughput: 24770730.843\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 592.691\n",
      "  sample_time_ms: 6748.876\n",
      "  update_time_ms: 2.037\n",
      "timestamp: 1658399362\n",
      "timesteps_since_restore: 2956000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2956000\n",
      "training_iteration: 739\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2960000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-29\n",
      "done: false\n",
      "episode_len_mean: 190.18\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.18\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 15453\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25300708413124084\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00476007629185915\n",
      "        model: {}\n",
      "        policy_loss: -0.011944715864956379\n",
      "        total_loss: 6.235574245452881\n",
      "        vf_explained_var: -0.06451229751110077\n",
      "        vf_loss: 6.247518539428711\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2960000\n",
      "  num_agent_steps_trained: 2960000\n",
      "  num_steps_sampled: 2960000\n",
      "  num_steps_trained: 2960000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 740\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.833333333333336\n",
      "  ram_util_percent: 87.71111111111112\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07067848222715772\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08107169829707202\n",
      "  mean_inference_ms: 0.7760000657411407\n",
      "  mean_raw_obs_processing_ms: 0.09363488791047926\n",
      "time_since_restore: 5408.989284992218\n",
      "time_this_iter_s: 6.61830472946167\n",
      "time_total_s: 5408.989284992218\n",
      "timers:\n",
      "  learn_throughput: 1348.129\n",
      "  learn_time_ms: 2967.075\n",
      "  load_throughput: 24571200.937\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 592.345\n",
      "  sample_time_ms: 6752.821\n",
      "  update_time_ms: 2.052\n",
      "timestamp: 1658399369\n",
      "timesteps_since_restore: 2960000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2960000\n",
      "training_iteration: 740\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2964000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-36\n",
      "done: false\n",
      "episode_len_mean: 188.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.53\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15474\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2255333662033081\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0053442418575286865\n",
      "        model: {}\n",
      "        policy_loss: 0.003911911975592375\n",
      "        total_loss: 7.09060525894165\n",
      "        vf_explained_var: 2.313749746463145e-06\n",
      "        vf_loss: 7.08669376373291\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2964000\n",
      "  num_agent_steps_trained: 2964000\n",
      "  num_steps_sampled: 2964000\n",
      "  num_steps_trained: 2964000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 741\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.980000000000004\n",
      "  ram_util_percent: 87.58000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07067058406247083\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08106311460924191\n",
      "  mean_inference_ms: 0.7759177633606393\n",
      "  mean_raw_obs_processing_ms: 0.09362570913748343\n",
      "time_since_restore: 5416.068903207779\n",
      "time_this_iter_s: 7.079618215560913\n",
      "time_total_s: 5416.068903207779\n",
      "timers:\n",
      "  learn_throughput: 1341.156\n",
      "  learn_time_ms: 2982.502\n",
      "  load_throughput: 24449454.969\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 590.494\n",
      "  sample_time_ms: 6773.993\n",
      "  update_time_ms: 2.087\n",
      "timestamp: 1658399376\n",
      "timesteps_since_restore: 2964000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2964000\n",
      "training_iteration: 741\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2968000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-43\n",
      "done: false\n",
      "episode_len_mean: 188.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.53\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15494\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25158238410949707\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004410846158862114\n",
      "        model: {}\n",
      "        policy_loss: 0.004308861680328846\n",
      "        total_loss: 6.707937240600586\n",
      "        vf_explained_var: 6.493701789622719e-07\n",
      "        vf_loss: 6.703629016876221\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2968000\n",
      "  num_agent_steps_trained: 2968000\n",
      "  num_steps_sampled: 2968000\n",
      "  num_steps_trained: 2968000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 742\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.09090909090909\n",
      "  ram_util_percent: 87.60909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07066473192186043\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08105666395427447\n",
      "  mean_inference_ms: 0.7758569669709581\n",
      "  mean_raw_obs_processing_ms: 0.09361903670035832\n",
      "time_since_restore: 5423.453058719635\n",
      "time_this_iter_s: 7.384155511856079\n",
      "time_total_s: 5423.453058719635\n",
      "timers:\n",
      "  learn_throughput: 1344.209\n",
      "  learn_time_ms: 2975.729\n",
      "  load_throughput: 24300718.424\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 586.067\n",
      "  sample_time_ms: 6825.158\n",
      "  update_time_ms: 2.225\n",
      "timestamp: 1658399383\n",
      "timesteps_since_restore: 2968000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2968000\n",
      "training_iteration: 742\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2972000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-51\n",
      "done: false\n",
      "episode_len_mean: 187.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.42\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15515\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.268381267786026\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00393406767398119\n",
      "        model: {}\n",
      "        policy_loss: 0.0012200719211250544\n",
      "        total_loss: 5.5102925300598145\n",
      "        vf_explained_var: 0.003425210015848279\n",
      "        vf_loss: 5.509072780609131\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2972000\n",
      "  num_agent_steps_trained: 2972000\n",
      "  num_steps_sampled: 2972000\n",
      "  num_steps_trained: 2972000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 743\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.272727272727266\n",
      "  ram_util_percent: 87.58181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07066074469142301\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08105219521780548\n",
      "  mean_inference_ms: 0.7758190417913567\n",
      "  mean_raw_obs_processing_ms: 0.09361485462885287\n",
      "time_since_restore: 5431.118758201599\n",
      "time_this_iter_s: 7.665699481964111\n",
      "time_total_s: 5431.118758201599\n",
      "timers:\n",
      "  learn_throughput: 1323.499\n",
      "  learn_time_ms: 3022.291\n",
      "  load_throughput: 24269081.441\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 580.124\n",
      "  sample_time_ms: 6895.081\n",
      "  update_time_ms: 2.197\n",
      "timestamp: 1658399391\n",
      "timesteps_since_restore: 2972000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2972000\n",
      "training_iteration: 743\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2976000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-29-59\n",
      "done: false\n",
      "episode_len_mean: 189.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.01\n",
      "episode_reward_min: 46.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15536\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2495611608028412\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00371090741828084\n",
      "        model: {}\n",
      "        policy_loss: -0.001424529473297298\n",
      "        total_loss: 5.7672343254089355\n",
      "        vf_explained_var: -0.026267020031809807\n",
      "        vf_loss: 5.768658638000488\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2976000\n",
      "  num_agent_steps_trained: 2976000\n",
      "  num_steps_sampled: 2976000\n",
      "  num_steps_trained: 2976000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 744\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.00909090909091\n",
      "  ram_util_percent: 87.68181818181819\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07065961016722791\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0810505478944759\n",
      "  mean_inference_ms: 0.775811736843854\n",
      "  mean_raw_obs_processing_ms: 0.09361410278669181\n",
      "time_since_restore: 5438.9792602062225\n",
      "time_this_iter_s: 7.860502004623413\n",
      "time_total_s: 5438.9792602062225\n",
      "timers:\n",
      "  learn_throughput: 1296.462\n",
      "  learn_time_ms: 3085.321\n",
      "  load_throughput: 24300718.424\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 571.599\n",
      "  sample_time_ms: 6997.913\n",
      "  update_time_ms: 2.108\n",
      "timestamp: 1658399399\n",
      "timesteps_since_restore: 2976000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2976000\n",
      "training_iteration: 744\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2980000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-30-05\n",
      "done: false\n",
      "episode_len_mean: 180.96\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 180.96\n",
      "episode_reward_min: 30.0\n",
      "episodes_this_iter: 27\n",
      "episodes_total: 15563\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23812918365001678\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005028898827731609\n",
      "        model: {}\n",
      "        policy_loss: -0.007775026839226484\n",
      "        total_loss: 7.3208537101745605\n",
      "        vf_explained_var: 6.070380550227128e-06\n",
      "        vf_loss: 7.328629016876221\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2980000\n",
      "  num_agent_steps_trained: 2980000\n",
      "  num_steps_sampled: 2980000\n",
      "  num_steps_trained: 2980000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 745\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.76666666666667\n",
      "  ram_util_percent: 87.65555555555557\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0706576071844442\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08104796918947604\n",
      "  mean_inference_ms: 0.7757962930976564\n",
      "  mean_raw_obs_processing_ms: 0.09361254040639935\n",
      "time_since_restore: 5445.609952688217\n",
      "time_this_iter_s: 6.630692481994629\n",
      "time_total_s: 5445.609952688217\n",
      "timers:\n",
      "  learn_throughput: 1294.559\n",
      "  learn_time_ms: 3089.855\n",
      "  load_throughput: 23974301.229\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 568.255\n",
      "  sample_time_ms: 7039.095\n",
      "  update_time_ms: 2.083\n",
      "timestamp: 1658399405\n",
      "timesteps_since_restore: 2980000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2980000\n",
      "training_iteration: 745\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2984000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-30-12\n",
      "done: false\n",
      "episode_len_mean: 179.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 179.89\n",
      "episode_reward_min: 30.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15584\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22959448397159576\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003233164083212614\n",
      "        model: {}\n",
      "        policy_loss: 0.004906922113150358\n",
      "        total_loss: 6.889987468719482\n",
      "        vf_explained_var: 6.721865588588116e-07\n",
      "        vf_loss: 6.885080814361572\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2984000\n",
      "  num_agent_steps_trained: 2984000\n",
      "  num_steps_sampled: 2984000\n",
      "  num_steps_trained: 2984000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 746\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.72\n",
      "  ram_util_percent: 87.63000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07065641737385552\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08104625847276838\n",
      "  mean_inference_ms: 0.7757892510638151\n",
      "  mean_raw_obs_processing_ms: 0.0936117524604143\n",
      "time_since_restore: 5452.595593214035\n",
      "time_this_iter_s: 6.985640525817871\n",
      "time_total_s: 5452.595593214035\n",
      "timers:\n",
      "  learn_throughput: 1296.971\n",
      "  learn_time_ms: 3084.11\n",
      "  load_throughput: 24015482.393\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 564.84\n",
      "  sample_time_ms: 7081.651\n",
      "  update_time_ms: 2.071\n",
      "timestamp: 1658399412\n",
      "timesteps_since_restore: 2984000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2984000\n",
      "training_iteration: 746\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2988000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-30-19\n",
      "done: false\n",
      "episode_len_mean: 178.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 178.66\n",
      "episode_reward_min: 30.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15605\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23724225163459778\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00438644690439105\n",
      "        model: {}\n",
      "        policy_loss: -0.00420740619301796\n",
      "        total_loss: 2.1706926822662354\n",
      "        vf_explained_var: -0.024418223649263382\n",
      "        vf_loss: 2.1748998165130615\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2988000\n",
      "  num_agent_steps_trained: 2988000\n",
      "  num_steps_sampled: 2988000\n",
      "  num_steps_trained: 2988000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 747\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.14\n",
      "  ram_util_percent: 87.71000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07065314597715285\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08104235602462513\n",
      "  mean_inference_ms: 0.7757591260455518\n",
      "  mean_raw_obs_processing_ms: 0.09360834922812103\n",
      "time_since_restore: 5459.415178060532\n",
      "time_this_iter_s: 6.819584846496582\n",
      "time_total_s: 5459.415178060532\n",
      "timers:\n",
      "  learn_throughput: 1293.277\n",
      "  learn_time_ms: 3092.919\n",
      "  load_throughput: 24080976.03\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 565.139\n",
      "  sample_time_ms: 7077.901\n",
      "  update_time_ms: 2.155\n",
      "timestamp: 1658399419\n",
      "timesteps_since_restore: 2988000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2988000\n",
      "training_iteration: 747\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2992000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-30-26\n",
      "done: false\n",
      "episode_len_mean: 180.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 180.78\n",
      "episode_reward_min: 30.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15625\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2084282487630844\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031817841809242964\n",
      "        model: {}\n",
      "        policy_loss: 0.0009380985284224153\n",
      "        total_loss: 4.091161251068115\n",
      "        vf_explained_var: 0.0008639887673780322\n",
      "        vf_loss: 4.0902228355407715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2992000\n",
      "  num_agent_steps_trained: 2992000\n",
      "  num_steps_sampled: 2992000\n",
      "  num_steps_trained: 2992000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 748\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.980000000000004\n",
      "  ram_util_percent: 87.62\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07064738442618242\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08103591380737184\n",
      "  mean_inference_ms: 0.775701537164669\n",
      "  mean_raw_obs_processing_ms: 0.09360158488635172\n",
      "time_since_restore: 5466.244312763214\n",
      "time_this_iter_s: 6.829134702682495\n",
      "time_total_s: 5466.244312763214\n",
      "timers:\n",
      "  learn_throughput: 1289.523\n",
      "  learn_time_ms: 3101.923\n",
      "  load_throughput: 23693286.259\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 565.568\n",
      "  sample_time_ms: 7072.53\n",
      "  update_time_ms: 2.084\n",
      "timestamp: 1658399426\n",
      "timesteps_since_restore: 2992000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2992000\n",
      "training_iteration: 748\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 2996000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-30-33\n",
      "done: false\n",
      "episode_len_mean: 184.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 184.51\n",
      "episode_reward_min: 30.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15646\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21411068737506866\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0020814621821045876\n",
      "        model: {}\n",
      "        policy_loss: -0.001825091429054737\n",
      "        total_loss: 1.8454538583755493\n",
      "        vf_explained_var: 0.002715606475248933\n",
      "        vf_loss: 1.8472788333892822\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 2996000\n",
      "  num_agent_steps_trained: 2996000\n",
      "  num_steps_sampled: 2996000\n",
      "  num_steps_trained: 2996000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 749\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.35\n",
      "  ram_util_percent: 87.60000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0706415368023786\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0810296740879905\n",
      "  mean_inference_ms: 0.7756469773012172\n",
      "  mean_raw_obs_processing_ms: 0.09359507772614407\n",
      "time_since_restore: 5473.439828157425\n",
      "time_this_iter_s: 7.195515394210815\n",
      "time_total_s: 5473.439828157425\n",
      "timers:\n",
      "  learn_throughput: 1284.287\n",
      "  learn_time_ms: 3114.57\n",
      "  load_throughput: 23205001.383\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 562.278\n",
      "  sample_time_ms: 7113.922\n",
      "  update_time_ms: 2.128\n",
      "timestamp: 1658399433\n",
      "timesteps_since_restore: 2996000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 2996000\n",
      "training_iteration: 749\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3000000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-30-40\n",
      "done: false\n",
      "episode_len_mean: 188.3\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.3\n",
      "episode_reward_min: 44.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 15669\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23705311119556427\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0021443027071654797\n",
      "        model: {}\n",
      "        policy_loss: -0.00573631701990962\n",
      "        total_loss: 4.389427185058594\n",
      "        vf_explained_var: -0.00030464408337138593\n",
      "        vf_loss: 4.395163536071777\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3000000\n",
      "  num_agent_steps_trained: 3000000\n",
      "  num_steps_sampled: 3000000\n",
      "  num_steps_trained: 3000000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 750\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.43\n",
      "  ram_util_percent: 87.70000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07063553934457305\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08102328864781602\n",
      "  mean_inference_ms: 0.7755919282975889\n",
      "  mean_raw_obs_processing_ms: 0.09358839681265776\n",
      "time_since_restore: 5480.306912899017\n",
      "time_this_iter_s: 6.867084741592407\n",
      "time_total_s: 5480.306912899017\n",
      "timers:\n",
      "  learn_throughput: 1284.672\n",
      "  learn_time_ms: 3113.635\n",
      "  load_throughput: 23347086.001\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 559.214\n",
      "  sample_time_ms: 7152.899\n",
      "  update_time_ms: 2.131\n",
      "timestamp: 1658399440\n",
      "timesteps_since_restore: 3000000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3000000\n",
      "training_iteration: 750\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3004000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-30-47\n",
      "done: false\n",
      "episode_len_mean: 188.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.17\n",
      "episode_reward_min: 42.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15690\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22757785022258759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003619845723733306\n",
      "        model: {}\n",
      "        policy_loss: -0.0003952500701416284\n",
      "        total_loss: 4.389732837677002\n",
      "        vf_explained_var: -0.0085029611364007\n",
      "        vf_loss: 4.390127658843994\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3004000\n",
      "  num_agent_steps_trained: 3004000\n",
      "  num_steps_sampled: 3004000\n",
      "  num_steps_trained: 3004000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 751\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.08\n",
      "  ram_util_percent: 87.6\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.070628914191199\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0810162762273899\n",
      "  mean_inference_ms: 0.7755281001442527\n",
      "  mean_raw_obs_processing_ms: 0.09358101996408985\n",
      "time_since_restore: 5486.975412845612\n",
      "time_this_iter_s: 6.668499946594238\n",
      "time_total_s: 5486.975412845612\n",
      "timers:\n",
      "  learn_throughput: 1295.274\n",
      "  learn_time_ms: 3088.149\n",
      "  load_throughput: 23250022.173\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 560.511\n",
      "  sample_time_ms: 7136.352\n",
      "  update_time_ms: 2.125\n",
      "timestamp: 1658399447\n",
      "timesteps_since_restore: 3004000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3004000\n",
      "training_iteration: 751\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3008000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-30-54\n",
      "done: false\n",
      "episode_len_mean: 189.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.25\n",
      "episode_reward_min: 42.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15710\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19548258185386658\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036480925045907497\n",
      "        model: {}\n",
      "        policy_loss: -0.00034393585519865155\n",
      "        total_loss: 1.0077205896377563\n",
      "        vf_explained_var: -0.012808219529688358\n",
      "        vf_loss: 1.0080645084381104\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3008000\n",
      "  num_agent_steps_trained: 3008000\n",
      "  num_steps_sampled: 3008000\n",
      "  num_steps_trained: 3008000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 752\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.82\n",
      "  ram_util_percent: 87.6\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07062401632845967\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0810111782597219\n",
      "  mean_inference_ms: 0.7754835970845794\n",
      "  mean_raw_obs_processing_ms: 0.09357578767048469\n",
      "time_since_restore: 5494.011599302292\n",
      "time_this_iter_s: 7.036186456680298\n",
      "time_total_s: 5494.011599302292\n",
      "timers:\n",
      "  learn_throughput: 1308.364\n",
      "  learn_time_ms: 3057.253\n",
      "  load_throughput: 23262917.36\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 562.866\n",
      "  sample_time_ms: 7106.485\n",
      "  update_time_ms: 2.039\n",
      "timestamp: 1658399454\n",
      "timesteps_since_restore: 3008000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3008000\n",
      "training_iteration: 752\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3012000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-01\n",
      "done: false\n",
      "episode_len_mean: 188.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 188.8\n",
      "episode_reward_min: 42.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15731\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22244665026664734\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033242374192923307\n",
      "        model: {}\n",
      "        policy_loss: 0.0006641375366598368\n",
      "        total_loss: 4.133729934692383\n",
      "        vf_explained_var: -0.009979719296097755\n",
      "        vf_loss: 4.133065700531006\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3012000\n",
      "  num_agent_steps_trained: 3012000\n",
      "  num_steps_sampled: 3012000\n",
      "  num_steps_trained: 3012000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 753\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.68888888888889\n",
      "  ram_util_percent: 87.61111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07061884035913735\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0810055826358257\n",
      "  mean_inference_ms: 0.7754362579305193\n",
      "  mean_raw_obs_processing_ms: 0.09357078286759435\n",
      "time_since_restore: 5500.704694271088\n",
      "time_this_iter_s: 6.693094968795776\n",
      "time_total_s: 5500.704694271088\n",
      "timers:\n",
      "  learn_throughput: 1329.54\n",
      "  learn_time_ms: 3008.558\n",
      "  load_throughput: 23279056.473\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 569.215\n",
      "  sample_time_ms: 7027.217\n",
      "  update_time_ms: 1.991\n",
      "timestamp: 1658399461\n",
      "timesteps_since_restore: 3012000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3012000\n",
      "training_iteration: 753\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3016000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-08\n",
      "done: false\n",
      "episode_len_mean: 191.52\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.52\n",
      "episode_reward_min: 42.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15751\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23248633742332458\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0062017543241381645\n",
      "        model: {}\n",
      "        policy_loss: 0.0026535331271588802\n",
      "        total_loss: 5.093379497528076\n",
      "        vf_explained_var: 1.0536562911056535e-07\n",
      "        vf_loss: 5.090725898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3016000\n",
      "  num_agent_steps_trained: 3016000\n",
      "  num_steps_sampled: 3016000\n",
      "  num_steps_trained: 3016000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 754\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.13636363636363\n",
      "  ram_util_percent: 87.64545454545456\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07061464731084072\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08100086658287955\n",
      "  mean_inference_ms: 0.7753955763880259\n",
      "  mean_raw_obs_processing_ms: 0.09356674123622753\n",
      "time_since_restore: 5508.038958311081\n",
      "time_this_iter_s: 7.334264039993286\n",
      "time_total_s: 5508.038958311081\n",
      "timers:\n",
      "  learn_throughput: 1344.55\n",
      "  learn_time_ms: 2974.974\n",
      "  load_throughput: 23435138.986\n",
      "  load_time_ms: 0.171\n",
      "  sample_throughput: 574.909\n",
      "  sample_time_ms: 6957.626\n",
      "  update_time_ms: 2.083\n",
      "timestamp: 1658399468\n",
      "timesteps_since_restore: 3016000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3016000\n",
      "training_iteration: 754\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3020000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-15\n",
      "done: false\n",
      "episode_len_mean: 193.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.57\n",
      "episode_reward_min: 42.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15772\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21473249793052673\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029952814802527428\n",
      "        model: {}\n",
      "        policy_loss: 0.003254059934988618\n",
      "        total_loss: 4.224526405334473\n",
      "        vf_explained_var: -0.06451565027236938\n",
      "        vf_loss: 4.2212724685668945\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3020000\n",
      "  num_agent_steps_trained: 3020000\n",
      "  num_steps_sampled: 3020000\n",
      "  num_steps_trained: 3020000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 755\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.760000000000005\n",
      "  ram_util_percent: 87.6\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07060999012948678\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08099548716122364\n",
      "  mean_inference_ms: 0.77535042966594\n",
      "  mean_raw_obs_processing_ms: 0.09356202816634308\n",
      "time_since_restore: 5515.1858632564545\n",
      "time_this_iter_s: 7.146904945373535\n",
      "time_total_s: 5515.1858632564545\n",
      "timers:\n",
      "  learn_throughput: 1333.187\n",
      "  learn_time_ms: 3000.328\n",
      "  load_throughput: 23629881.69\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 575.422\n",
      "  sample_time_ms: 6951.417\n",
      "  update_time_ms: 2.159\n",
      "timestamp: 1658399475\n",
      "timesteps_since_restore: 3020000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3020000\n",
      "training_iteration: 755\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3024000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-22\n",
      "done: false\n",
      "episode_len_mean: 196.77\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.77\n",
      "episode_reward_min: 114.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15792\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21296918392181396\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002960966667160392\n",
      "        model: {}\n",
      "        policy_loss: 0.004398121498525143\n",
      "        total_loss: 6.183833122253418\n",
      "        vf_explained_var: 6.905166287651809e-07\n",
      "        vf_loss: 6.1794352531433105\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3024000\n",
      "  num_agent_steps_trained: 3024000\n",
      "  num_steps_sampled: 3024000\n",
      "  num_steps_trained: 3024000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 756\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.166666666666664\n",
      "  ram_util_percent: 87.63333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07060531615074747\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08098898852779263\n",
      "  mean_inference_ms: 0.7752971198251433\n",
      "  mean_raw_obs_processing_ms: 0.09355667740464928\n",
      "time_since_restore: 5521.807660102844\n",
      "time_this_iter_s: 6.6217968463897705\n",
      "time_total_s: 5521.807660102844\n",
      "timers:\n",
      "  learn_throughput: 1328.081\n",
      "  learn_time_ms: 3011.863\n",
      "  load_throughput: 23560196.602\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 577.298\n",
      "  sample_time_ms: 6928.826\n",
      "  update_time_ms: 2.218\n",
      "timestamp: 1658399482\n",
      "timesteps_since_restore: 3024000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3024000\n",
      "training_iteration: 756\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3028000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-29\n",
      "done: false\n",
      "episode_len_mean: 195.58\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.58\n",
      "episode_reward_min: 81.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15813\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21035315096378326\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004281571134924889\n",
      "        model: {}\n",
      "        policy_loss: -0.0031019835732877254\n",
      "        total_loss: 7.310413837432861\n",
      "        vf_explained_var: 3.965951975715143e-07\n",
      "        vf_loss: 7.313516616821289\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3028000\n",
      "  num_agent_steps_trained: 3028000\n",
      "  num_steps_sampled: 3028000\n",
      "  num_steps_trained: 3028000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 757\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.47\n",
      "  ram_util_percent: 87.7\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07059962822413107\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0809815002288333\n",
      "  mean_inference_ms: 0.775233340666127\n",
      "  mean_raw_obs_processing_ms: 0.09354977718895906\n",
      "time_since_restore: 5528.5731112957\n",
      "time_this_iter_s: 6.765451192855835\n",
      "time_total_s: 5528.5731112957\n",
      "timers:\n",
      "  learn_throughput: 1335.532\n",
      "  learn_time_ms: 2995.06\n",
      "  load_throughput: 23580064.652\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 575.371\n",
      "  sample_time_ms: 6952.038\n",
      "  update_time_ms: 2.149\n",
      "timestamp: 1658399489\n",
      "timesteps_since_restore: 3028000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3028000\n",
      "training_iteration: 757\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3032000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-36\n",
      "done: false\n",
      "episode_len_mean: 194.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.25\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15834\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2184983491897583\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033150692470371723\n",
      "        model: {}\n",
      "        policy_loss: 0.0021667685359716415\n",
      "        total_loss: 5.231501579284668\n",
      "        vf_explained_var: -0.0883529782295227\n",
      "        vf_loss: 5.229334831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3032000\n",
      "  num_agent_steps_trained: 3032000\n",
      "  num_steps_sampled: 3032000\n",
      "  num_steps_trained: 3032000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 758\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.13\n",
      "  ram_util_percent: 87.64\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07059387934492306\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08097362043219386\n",
      "  mean_inference_ms: 0.7751653524737605\n",
      "  mean_raw_obs_processing_ms: 0.09354179489956539\n",
      "time_since_restore: 5535.569509744644\n",
      "time_this_iter_s: 6.996398448944092\n",
      "time_total_s: 5535.569509744644\n",
      "timers:\n",
      "  learn_throughput: 1329.649\n",
      "  learn_time_ms: 3008.312\n",
      "  load_throughput: 24056805.277\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 576.51\n",
      "  sample_time_ms: 6938.303\n",
      "  update_time_ms: 2.222\n",
      "timestamp: 1658399496\n",
      "timesteps_since_restore: 3032000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3032000\n",
      "training_iteration: 758\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3036000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-42\n",
      "done: false\n",
      "episode_len_mean: 194.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.25\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15854\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21598829329013824\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0039004082791507244\n",
      "        model: {}\n",
      "        policy_loss: 0.004869950003921986\n",
      "        total_loss: 6.355676651000977\n",
      "        vf_explained_var: -1.0107153514127276e-07\n",
      "        vf_loss: 6.35080623626709\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3036000\n",
      "  num_agent_steps_trained: 3036000\n",
      "  num_steps_sampled: 3036000\n",
      "  num_steps_trained: 3036000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 759\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.74444444444444\n",
      "  ram_util_percent: 87.57777777777778\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07058603816653633\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.080963500625439\n",
      "  mean_inference_ms: 0.7750766901590008\n",
      "  mean_raw_obs_processing_ms: 0.09353114815198672\n",
      "time_since_restore: 5542.049245834351\n",
      "time_this_iter_s: 6.479736089706421\n",
      "time_total_s: 5542.049245834351\n",
      "timers:\n",
      "  learn_throughput: 1340.419\n",
      "  learn_time_ms: 2984.141\n",
      "  load_throughput: 24524508.113\n",
      "  load_time_ms: 0.163\n",
      "  sample_throughput: 579.345\n",
      "  sample_time_ms: 6904.353\n",
      "  update_time_ms: 2.239\n",
      "timestamp: 1658399502\n",
      "timesteps_since_restore: 3036000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3036000\n",
      "training_iteration: 759\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3040000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-49\n",
      "done: false\n",
      "episode_len_mean: 194.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.71\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15874\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22533446550369263\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003836127230897546\n",
      "        model: {}\n",
      "        policy_loss: 0.0018733696779236197\n",
      "        total_loss: 5.153090476989746\n",
      "        vf_explained_var: -0.03546470031142235\n",
      "        vf_loss: 5.151216506958008\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3040000\n",
      "  num_agent_steps_trained: 3040000\n",
      "  num_steps_sampled: 3040000\n",
      "  num_steps_trained: 3040000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 760\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.28\n",
      "  ram_util_percent: 87.58\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07057761905067192\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08095286955800969\n",
      "  mean_inference_ms: 0.7749819248034132\n",
      "  mean_raw_obs_processing_ms: 0.09351995401393516\n",
      "time_since_restore: 5548.632914304733\n",
      "time_this_iter_s: 6.58366847038269\n",
      "time_total_s: 5548.632914304733\n",
      "timers:\n",
      "  learn_throughput: 1344.69\n",
      "  learn_time_ms: 2974.664\n",
      "  load_throughput: 24129463.541\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 582.968\n",
      "  sample_time_ms: 6861.438\n",
      "  update_time_ms: 2.227\n",
      "timestamp: 1658399509\n",
      "timesteps_since_restore: 3040000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3040000\n",
      "training_iteration: 760\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3044000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-31-56\n",
      "done: false\n",
      "episode_len_mean: 195.1\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.1\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15894\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2115383744239807\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006205632817000151\n",
      "        model: {}\n",
      "        policy_loss: -0.003188116243109107\n",
      "        total_loss: 0.3496345579624176\n",
      "        vf_explained_var: -0.019523298367857933\n",
      "        vf_loss: 0.35282260179519653\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3044000\n",
      "  num_agent_steps_trained: 3044000\n",
      "  num_steps_sampled: 3044000\n",
      "  num_steps_trained: 3044000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 761\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.50909090909091\n",
      "  ram_util_percent: 87.55454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07056960107694935\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08094377307849376\n",
      "  mean_inference_ms: 0.7748992204243086\n",
      "  mean_raw_obs_processing_ms: 0.09350952234287224\n",
      "time_since_restore: 5556.158995628357\n",
      "time_this_iter_s: 7.526081323623657\n",
      "time_total_s: 5556.158995628357\n",
      "timers:\n",
      "  learn_throughput: 1311.482\n",
      "  learn_time_ms: 3049.984\n",
      "  load_throughput: 24290163.602\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 582.882\n",
      "  sample_time_ms: 6862.453\n",
      "  update_time_ms: 2.207\n",
      "timestamp: 1658399516\n",
      "timesteps_since_restore: 3044000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3044000\n",
      "training_iteration: 761\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3048000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-03\n",
      "done: false\n",
      "episode_len_mean: 195.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.08\n",
      "episode_reward_min: 64.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 15916\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2099093794822693\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032258525025099516\n",
      "        model: {}\n",
      "        policy_loss: -0.00018258928321301937\n",
      "        total_loss: 3.1853013038635254\n",
      "        vf_explained_var: 0.0033744717948138714\n",
      "        vf_loss: 3.185483932495117\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3048000\n",
      "  num_agent_steps_trained: 3048000\n",
      "  num_steps_sampled: 3048000\n",
      "  num_steps_trained: 3048000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 762\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.31111111111111\n",
      "  ram_util_percent: 87.60000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07055794841386388\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08093026230817811\n",
      "  mean_inference_ms: 0.774778600723958\n",
      "  mean_raw_obs_processing_ms: 0.09349505452243281\n",
      "time_since_restore: 5562.695937156677\n",
      "time_this_iter_s: 6.5369415283203125\n",
      "time_total_s: 5562.695937156677\n",
      "timers:\n",
      "  learn_throughput: 1299.821\n",
      "  learn_time_ms: 3077.348\n",
      "  load_throughput: 24357166.086\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 583.075\n",
      "  sample_time_ms: 6860.18\n",
      "  update_time_ms: 2.212\n",
      "timestamp: 1658399523\n",
      "timesteps_since_restore: 3048000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3048000\n",
      "training_iteration: 762\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3052000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-10\n",
      "done: false\n",
      "episode_len_mean: 196.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.15\n",
      "episode_reward_min: 64.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15936\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21525676548480988\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032273216638714075\n",
      "        model: {}\n",
      "        policy_loss: 0.006210704334080219\n",
      "        total_loss: 7.113064765930176\n",
      "        vf_explained_var: 1.2811794647404895e-07\n",
      "        vf_loss: 7.1068549156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3052000\n",
      "  num_agent_steps_trained: 3052000\n",
      "  num_steps_sampled: 3052000\n",
      "  num_steps_trained: 3052000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 763\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.199999999999996\n",
      "  ram_util_percent: 87.63\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07054924341712099\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08092035475302853\n",
      "  mean_inference_ms: 0.7746919612488312\n",
      "  mean_raw_obs_processing_ms: 0.09348503401953633\n",
      "time_since_restore: 5570.026660203934\n",
      "time_this_iter_s: 7.33072304725647\n",
      "time_total_s: 5570.026660203934\n",
      "timers:\n",
      "  learn_throughput: 1290.511\n",
      "  learn_time_ms: 3099.547\n",
      "  load_throughput: 22721040.087\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 577.298\n",
      "  sample_time_ms: 6928.826\n",
      "  update_time_ms: 2.231\n",
      "timestamp: 1658399530\n",
      "timesteps_since_restore: 3052000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3052000\n",
      "training_iteration: 763\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3056000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-17\n",
      "done: false\n",
      "episode_len_mean: 196.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.15\n",
      "episode_reward_min: 64.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15956\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22355793416500092\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002919035730883479\n",
      "        model: {}\n",
      "        policy_loss: 0.005392277613282204\n",
      "        total_loss: 7.112247943878174\n",
      "        vf_explained_var: 1.8855577366139187e-07\n",
      "        vf_loss: 7.106855869293213\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3056000\n",
      "  num_agent_steps_trained: 3056000\n",
      "  num_steps_sampled: 3056000\n",
      "  num_steps_trained: 3056000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 764\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.57000000000001\n",
      "  ram_util_percent: 87.67\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07054157526619437\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.080911619538743\n",
      "  mean_inference_ms: 0.774615488223295\n",
      "  mean_raw_obs_processing_ms: 0.0934763993364454\n",
      "time_since_restore: 5576.7724940776825\n",
      "time_this_iter_s: 6.745833873748779\n",
      "time_total_s: 5576.7724940776825\n",
      "timers:\n",
      "  learn_throughput: 1302.06\n",
      "  learn_time_ms: 3072.054\n",
      "  load_throughput: 22687242.732\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 578.041\n",
      "  sample_time_ms: 6919.93\n",
      "  update_time_ms: 2.199\n",
      "timestamp: 1658399537\n",
      "timesteps_since_restore: 3056000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3056000\n",
      "training_iteration: 764\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3060000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-24\n",
      "done: false\n",
      "episode_len_mean: 194.58\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.58\n",
      "episode_reward_min: 41.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 15977\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20618793368339539\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00454060360789299\n",
      "        model: {}\n",
      "        policy_loss: 0.0010769990039989352\n",
      "        total_loss: 4.870029926300049\n",
      "        vf_explained_var: 0.0024729855358600616\n",
      "        vf_loss: 4.868953227996826\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3060000\n",
      "  num_agent_steps_trained: 3060000\n",
      "  num_steps_sampled: 3060000\n",
      "  num_steps_trained: 3060000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 765\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.89\n",
      "  ram_util_percent: 87.53999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07053406830995863\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08090330953241236\n",
      "  mean_inference_ms: 0.7745420331933474\n",
      "  mean_raw_obs_processing_ms: 0.09346844893187642\n",
      "time_since_restore: 5583.541357755661\n",
      "time_this_iter_s: 6.768863677978516\n",
      "time_total_s: 5583.541357755661\n",
      "timers:\n",
      "  learn_throughput: 1318.209\n",
      "  learn_time_ms: 3034.42\n",
      "  load_throughput: 22610803.235\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 580.349\n",
      "  sample_time_ms: 6892.407\n",
      "  update_time_ms: 2.154\n",
      "timestamp: 1658399544\n",
      "timesteps_since_restore: 3060000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3060000\n",
      "training_iteration: 765\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3064000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-30\n",
      "done: false\n",
      "episode_len_mean: 194.58\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.58\n",
      "episode_reward_min: 41.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 15997\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23364342749118805\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029781502671539783\n",
      "        model: {}\n",
      "        policy_loss: 4.0058806916931644e-05\n",
      "        total_loss: 3.2762506008148193\n",
      "        vf_explained_var: 0.0005347492406144738\n",
      "        vf_loss: 3.276210308074951\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3064000\n",
      "  num_agent_steps_trained: 3064000\n",
      "  num_steps_sampled: 3064000\n",
      "  num_steps_trained: 3064000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 766\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.288888888888884\n",
      "  ram_util_percent: 87.55555555555556\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07052747566868758\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08089592236493612\n",
      "  mean_inference_ms: 0.7744776694079499\n",
      "  mean_raw_obs_processing_ms: 0.09346163516926166\n",
      "time_since_restore: 5590.315971851349\n",
      "time_this_iter_s: 6.774614095687866\n",
      "time_total_s: 5590.315971851349\n",
      "timers:\n",
      "  learn_throughput: 1323.789\n",
      "  learn_time_ms: 3021.629\n",
      "  load_throughput: 22432432.143\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 581.149\n",
      "  sample_time_ms: 6882.916\n",
      "  update_time_ms: 2.116\n",
      "timestamp: 1658399550\n",
      "timesteps_since_restore: 3064000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3064000\n",
      "training_iteration: 766\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3068000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-37\n",
      "done: false\n",
      "episode_len_mean: 196.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.08\n",
      "episode_reward_min: 41.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16018\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23899993300437927\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00392678938806057\n",
      "        model: {}\n",
      "        policy_loss: 0.001549531938508153\n",
      "        total_loss: 3.5600180625915527\n",
      "        vf_explained_var: -0.025939205661416054\n",
      "        vf_loss: 3.558468818664551\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3068000\n",
      "  num_agent_steps_trained: 3068000\n",
      "  num_steps_sampled: 3068000\n",
      "  num_steps_trained: 3068000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 767\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.97\n",
      "  ram_util_percent: 87.53\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07052234880075935\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08089017908129122\n",
      "  mean_inference_ms: 0.774426876494178\n",
      "  mean_raw_obs_processing_ms: 0.09345627401843996\n",
      "time_since_restore: 5597.0605664253235\n",
      "time_this_iter_s: 6.744594573974609\n",
      "time_total_s: 5597.0605664253235\n",
      "timers:\n",
      "  learn_throughput: 1319.282\n",
      "  learn_time_ms: 3031.952\n",
      "  load_throughput: 22393507.742\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 583.305\n",
      "  sample_time_ms: 6857.473\n",
      "  update_time_ms: 2.094\n",
      "timestamp: 1658399557\n",
      "timesteps_since_restore: 3068000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3068000\n",
      "training_iteration: 767\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3072000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-44\n",
      "done: false\n",
      "episode_len_mean: 196.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.08\n",
      "episode_reward_min: 41.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16038\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24659322202205658\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004863680340349674\n",
      "        model: {}\n",
      "        policy_loss: 0.006742322351783514\n",
      "        total_loss: 7.5168232917785645\n",
      "        vf_explained_var: 2.710409034989425e-07\n",
      "        vf_loss: 7.510080814361572\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3072000\n",
      "  num_agent_steps_trained: 3072000\n",
      "  num_steps_sampled: 3072000\n",
      "  num_steps_trained: 3072000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 768\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.809999999999995\n",
      "  ram_util_percent: 87.55000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0705172824673076\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08088446292487167\n",
      "  mean_inference_ms: 0.7743745729721625\n",
      "  mean_raw_obs_processing_ms: 0.09345049781592746\n",
      "time_since_restore: 5604.039360284805\n",
      "time_this_iter_s: 6.9787938594818115\n",
      "time_total_s: 5604.039360284805\n",
      "timers:\n",
      "  learn_throughput: 1334.833\n",
      "  learn_time_ms: 2996.63\n",
      "  load_throughput: 22247998.939\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 579.557\n",
      "  sample_time_ms: 6901.821\n",
      "  update_time_ms: 2.02\n",
      "timestamp: 1658399564\n",
      "timesteps_since_restore: 3072000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3072000\n",
      "training_iteration: 768\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3076000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-51\n",
      "done: false\n",
      "episode_len_mean: 195.53\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.53\n",
      "episode_reward_min: 41.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16058\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19661392271518707\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003168797120451927\n",
      "        model: {}\n",
      "        policy_loss: 0.007190329488366842\n",
      "        total_loss: 7.378663063049316\n",
      "        vf_explained_var: -6.729556467632847e-09\n",
      "        vf_loss: 7.3714728355407715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3076000\n",
      "  num_agent_steps_trained: 3076000\n",
      "  num_steps_sampled: 3076000\n",
      "  num_steps_trained: 3076000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 769\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.64\n",
      "  ram_util_percent: 87.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0705119755371145\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08087860039780859\n",
      "  mean_inference_ms: 0.774321335312452\n",
      "  mean_raw_obs_processing_ms: 0.09344443943242489\n",
      "time_since_restore: 5610.9021644592285\n",
      "time_this_iter_s: 6.862804174423218\n",
      "time_total_s: 5610.9021644592285\n",
      "timers:\n",
      "  learn_throughput: 1326.448\n",
      "  learn_time_ms: 3015.572\n",
      "  load_throughput: 22031800.394\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 580.936\n",
      "  sample_time_ms: 6885.44\n",
      "  update_time_ms: 1.992\n",
      "timestamp: 1658399571\n",
      "timesteps_since_restore: 3076000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3076000\n",
      "training_iteration: 769\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3080000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-32-58\n",
      "done: false\n",
      "episode_len_mean: 195.17\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.17\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 16080\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23440226912498474\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030390785541385412\n",
      "        model: {}\n",
      "        policy_loss: -0.006650387309491634\n",
      "        total_loss: 6.313918590545654\n",
      "        vf_explained_var: 6.495624234048591e-07\n",
      "        vf_loss: 6.320568561553955\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3080000\n",
      "  num_agent_steps_trained: 3080000\n",
      "  num_steps_sampled: 3080000\n",
      "  num_steps_trained: 3080000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 770\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.559999999999995\n",
      "  ram_util_percent: 87.58\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07050642632381839\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08087233259328006\n",
      "  mean_inference_ms: 0.7742669031670069\n",
      "  mean_raw_obs_processing_ms: 0.09343768551595222\n",
      "time_since_restore: 5617.859622716904\n",
      "time_this_iter_s: 6.957458257675171\n",
      "time_total_s: 5617.859622716904\n",
      "timers:\n",
      "  learn_throughput: 1318.434\n",
      "  learn_time_ms: 3033.903\n",
      "  load_throughput: 22168625.793\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 577.759\n",
      "  sample_time_ms: 6923.306\n",
      "  update_time_ms: 2.007\n",
      "timestamp: 1658399578\n",
      "timesteps_since_restore: 3080000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3080000\n",
      "training_iteration: 770\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3084000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-33-05\n",
      "done: false\n",
      "episode_len_mean: 194.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.27\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16100\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22430574893951416\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003479760605841875\n",
      "        model: {}\n",
      "        policy_loss: 0.002723987679928541\n",
      "        total_loss: 4.639820575714111\n",
      "        vf_explained_var: 1.7535302276883158e-07\n",
      "        vf_loss: 4.637096881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3084000\n",
      "  num_agent_steps_trained: 3084000\n",
      "  num_steps_sampled: 3084000\n",
      "  num_steps_trained: 3084000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 771\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.63333333333333\n",
      "  ram_util_percent: 87.63333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07050099295828466\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08086624182780895\n",
      "  mean_inference_ms: 0.77421481597905\n",
      "  mean_raw_obs_processing_ms: 0.09343122741754424\n",
      "time_since_restore: 5624.541556358337\n",
      "time_this_iter_s: 6.681933641433716\n",
      "time_total_s: 5624.541556358337\n",
      "timers:\n",
      "  learn_throughput: 1353.972\n",
      "  learn_time_ms: 2954.27\n",
      "  load_throughput: 22159841.5\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 576.62\n",
      "  sample_time_ms: 6936.982\n",
      "  update_time_ms: 1.983\n",
      "timestamp: 1658399585\n",
      "timesteps_since_restore: 3084000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3084000\n",
      "training_iteration: 771\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3088000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-33-11\n",
      "done: false\n",
      "episode_len_mean: 195.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.33\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16120\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21344102919101715\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035983531270176172\n",
      "        model: {}\n",
      "        policy_loss: 0.0015743201365694404\n",
      "        total_loss: 4.613469123840332\n",
      "        vf_explained_var: 8.376695603828921e-08\n",
      "        vf_loss: 4.6118950843811035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3088000\n",
      "  num_agent_steps_trained: 3088000\n",
      "  num_steps_sampled: 3088000\n",
      "  num_steps_trained: 3088000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 772\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.04\n",
      "  ram_util_percent: 87.65\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0704948989013048\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08085953365026102\n",
      "  mean_inference_ms: 0.7741583270204552\n",
      "  mean_raw_obs_processing_ms: 0.09342400628349544\n",
      "time_since_restore: 5631.156695127487\n",
      "time_this_iter_s: 6.61513876914978\n",
      "time_total_s: 5631.156695127487\n",
      "timers:\n",
      "  learn_throughput: 1368.743\n",
      "  learn_time_ms: 2922.39\n",
      "  load_throughput: 21726516.447\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 579.943\n",
      "  sample_time_ms: 6897.231\n",
      "  update_time_ms: 2.014\n",
      "timestamp: 1658399591\n",
      "timesteps_since_restore: 3088000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3088000\n",
      "training_iteration: 772\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3092000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-33-18\n",
      "done: false\n",
      "episode_len_mean: 192.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.19\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 16142\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22420857846736908\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0050332206301391125\n",
      "        model: {}\n",
      "        policy_loss: 0.0012654829770326614\n",
      "        total_loss: 5.563264846801758\n",
      "        vf_explained_var: -0.0011993200751021504\n",
      "        vf_loss: 5.561999320983887\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3092000\n",
      "  num_agent_steps_trained: 3092000\n",
      "  num_steps_sampled: 3092000\n",
      "  num_steps_trained: 3092000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 773\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.077777777777776\n",
      "  ram_util_percent: 87.61111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07048660160295658\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08085050950028155\n",
      "  mean_inference_ms: 0.7740837125471739\n",
      "  mean_raw_obs_processing_ms: 0.09341416503390475\n",
      "time_since_restore: 5637.826983451843\n",
      "time_this_iter_s: 6.670288324356079\n",
      "time_total_s: 5637.826983451843\n",
      "timers:\n",
      "  learn_throughput: 1379.887\n",
      "  learn_time_ms: 2898.788\n",
      "  load_throughput: 23301688.889\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 586.281\n",
      "  sample_time_ms: 6822.669\n",
      "  update_time_ms: 2.011\n",
      "timestamp: 1658399598\n",
      "timesteps_since_restore: 3092000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3092000\n",
      "training_iteration: 773\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3096000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-33-25\n",
      "done: false\n",
      "episode_len_mean: 192.74\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.74\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16162\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2179243564605713\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026882525999099016\n",
      "        model: {}\n",
      "        policy_loss: 0.009440494701266289\n",
      "        total_loss: 8.477182388305664\n",
      "        vf_explained_var: -1.703539140862631e-07\n",
      "        vf_loss: 8.467741966247559\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3096000\n",
      "  num_agent_steps_trained: 3096000\n",
      "  num_steps_sampled: 3096000\n",
      "  num_steps_trained: 3096000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 774\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.599999999999994\n",
      "  ram_util_percent: 87.61\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07047912417772294\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08084236207882847\n",
      "  mean_inference_ms: 0.7740167606277762\n",
      "  mean_raw_obs_processing_ms: 0.09340523604629423\n",
      "time_since_restore: 5644.736866950989\n",
      "time_this_iter_s: 6.909883499145508\n",
      "time_total_s: 5644.736866950989\n",
      "timers:\n",
      "  learn_throughput: 1372.352\n",
      "  learn_time_ms: 2914.704\n",
      "  load_throughput: 23507378.45\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 588.203\n",
      "  sample_time_ms: 6800.372\n",
      "  update_time_ms: 2.022\n",
      "timestamp: 1658399605\n",
      "timesteps_since_restore: 3096000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3096000\n",
      "training_iteration: 774\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3100000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-33-32\n",
      "done: false\n",
      "episode_len_mean: 196.76\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.76\n",
      "episode_reward_min: 76.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16182\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2245473563671112\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004991600289940834\n",
      "        model: {}\n",
      "        policy_loss: 0.006821534596383572\n",
      "        total_loss: 8.474563598632812\n",
      "        vf_explained_var: -8.511286608836599e-08\n",
      "        vf_loss: 8.467741966247559\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3100000\n",
      "  num_agent_steps_trained: 3100000\n",
      "  num_steps_sampled: 3100000\n",
      "  num_steps_trained: 3100000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 775\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.77\n",
      "  ram_util_percent: 87.64\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07047128386771534\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08083380406119774\n",
      "  mean_inference_ms: 0.7739461301911742\n",
      "  mean_raw_obs_processing_ms: 0.09339615315899984\n",
      "time_since_restore: 5651.458496809006\n",
      "time_this_iter_s: 6.721629858016968\n",
      "time_total_s: 5651.458496809006\n",
      "timers:\n",
      "  learn_throughput: 1374.629\n",
      "  learn_time_ms: 2909.876\n",
      "  load_throughput: 23656536.943\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 586.841\n",
      "  sample_time_ms: 6816.154\n",
      "  update_time_ms: 2.024\n",
      "timestamp: 1658399612\n",
      "timesteps_since_restore: 3100000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3100000\n",
      "training_iteration: 775\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3104000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-33-39\n",
      "done: false\n",
      "episode_len_mean: 194.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.85\n",
      "episode_reward_min: 76.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16203\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2302977293729782\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003286964725703001\n",
      "        model: {}\n",
      "        policy_loss: -0.004740922246128321\n",
      "        total_loss: 4.52399206161499\n",
      "        vf_explained_var: -0.0009533546399325132\n",
      "        vf_loss: 4.528732776641846\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3104000\n",
      "  num_agent_steps_trained: 3104000\n",
      "  num_steps_sampled: 3104000\n",
      "  num_steps_trained: 3104000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 776\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.81000000000001\n",
      "  ram_util_percent: 87.71\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07046496183168716\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08082676412533196\n",
      "  mean_inference_ms: 0.7738877479533202\n",
      "  mean_raw_obs_processing_ms: 0.09338951474940849\n",
      "time_since_restore: 5658.552173137665\n",
      "time_this_iter_s: 7.093676328659058\n",
      "time_total_s: 5658.552173137665\n",
      "timers:\n",
      "  learn_throughput: 1370.406\n",
      "  learn_time_ms: 2918.843\n",
      "  load_throughput: 24001739.628\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 585.249\n",
      "  sample_time_ms: 6834.697\n",
      "  update_time_ms: 2.044\n",
      "timestamp: 1658399619\n",
      "timesteps_since_restore: 3104000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3104000\n",
      "training_iteration: 776\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3108000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-33-46\n",
      "done: false\n",
      "episode_len_mean: 193.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.94\n",
      "episode_reward_min: 68.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16223\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22566267848014832\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0022460923064500093\n",
      "        model: {}\n",
      "        policy_loss: 0.005035929381847382\n",
      "        total_loss: 6.265133857727051\n",
      "        vf_explained_var: -0.004007650539278984\n",
      "        vf_loss: 6.260098457336426\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3108000\n",
      "  num_agent_steps_trained: 3108000\n",
      "  num_steps_sampled: 3108000\n",
      "  num_steps_trained: 3108000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 777\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.76\n",
      "  ram_util_percent: 87.61\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07046032935560685\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08082158526862057\n",
      "  mean_inference_ms: 0.773848873254784\n",
      "  mean_raw_obs_processing_ms: 0.09338529301133754\n",
      "time_since_restore: 5665.91446185112\n",
      "time_this_iter_s: 7.3622887134552\n",
      "time_total_s: 5665.91446185112\n",
      "timers:\n",
      "  learn_throughput: 1355.227\n",
      "  learn_time_ms: 2951.535\n",
      "  load_throughput: 23633210.311\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 582.011\n",
      "  sample_time_ms: 6872.717\n",
      "  update_time_ms: 2.062\n",
      "timestamp: 1658399626\n",
      "timesteps_since_restore: 3108000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3108000\n",
      "training_iteration: 777\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3112000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-33-53\n",
      "done: false\n",
      "episode_len_mean: 193.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.01\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 16245\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2197018712759018\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004228890873491764\n",
      "        model: {}\n",
      "        policy_loss: -0.00257062166929245\n",
      "        total_loss: 2.3764617443084717\n",
      "        vf_explained_var: -0.1612892746925354\n",
      "        vf_loss: 2.3790323734283447\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3112000\n",
      "  num_agent_steps_trained: 3112000\n",
      "  num_steps_sampled: 3112000\n",
      "  num_steps_trained: 3112000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 778\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.93\n",
      "  ram_util_percent: 87.69000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07045504495585671\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08081565539385716\n",
      "  mean_inference_ms: 0.7738006544425104\n",
      "  mean_raw_obs_processing_ms: 0.09338062845142052\n",
      "time_since_restore: 5672.7372007369995\n",
      "time_this_iter_s: 6.822738885879517\n",
      "time_total_s: 5672.7372007369995\n",
      "timers:\n",
      "  learn_throughput: 1344.712\n",
      "  learn_time_ms: 2974.615\n",
      "  load_throughput: 23676567.88\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 582.51\n",
      "  sample_time_ms: 6866.841\n",
      "  update_time_ms: 2.125\n",
      "timestamp: 1658399633\n",
      "timesteps_since_restore: 3112000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3112000\n",
      "training_iteration: 778\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3116000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-01\n",
      "done: false\n",
      "episode_len_mean: 192.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.91\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16265\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24566137790679932\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004367953632026911\n",
      "        model: {}\n",
      "        policy_loss: -0.001208402682095766\n",
      "        total_loss: 3.4010093212127686\n",
      "        vf_explained_var: -0.032256923615932465\n",
      "        vf_loss: 3.4022176265716553\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3116000\n",
      "  num_agent_steps_trained: 3116000\n",
      "  num_steps_sampled: 3116000\n",
      "  num_steps_trained: 3116000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 779\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.37272727272727\n",
      "  ram_util_percent: 87.64545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07045284580541704\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.080813135254519\n",
      "  mean_inference_ms: 0.7737856855049802\n",
      "  mean_raw_obs_processing_ms: 0.09337969440725452\n",
      "time_since_restore: 5680.480381727219\n",
      "time_this_iter_s: 7.743180990219116\n",
      "time_total_s: 5680.480381727219\n",
      "timers:\n",
      "  learn_throughput: 1333.151\n",
      "  learn_time_ms: 3000.409\n",
      "  load_throughput: 23646534.179\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 575.274\n",
      "  sample_time_ms: 6953.209\n",
      "  update_time_ms: 2.202\n",
      "timestamp: 1658399641\n",
      "timesteps_since_restore: 3116000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3116000\n",
      "training_iteration: 779\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3120000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-08\n",
      "done: false\n",
      "episode_len_mean: 193.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.15\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16285\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20961473882198334\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026177954860031605\n",
      "        model: {}\n",
      "        policy_loss: -0.00024134792329277843\n",
      "        total_loss: 2.1670970916748047\n",
      "        vf_explained_var: -0.1611376404762268\n",
      "        vf_loss: 2.1673386096954346\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3120000\n",
      "  num_agent_steps_trained: 3120000\n",
      "  num_steps_sampled: 3120000\n",
      "  num_steps_trained: 3120000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 780\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.25\n",
      "  ram_util_percent: 87.72999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07045216309451297\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08081236013701157\n",
      "  mean_inference_ms: 0.773783609389059\n",
      "  mean_raw_obs_processing_ms: 0.09338021849140819\n",
      "time_since_restore: 5687.537630319595\n",
      "time_this_iter_s: 7.057248592376709\n",
      "time_total_s: 5687.537630319595\n",
      "timers:\n",
      "  learn_throughput: 1339.876\n",
      "  learn_time_ms: 2985.35\n",
      "  load_throughput: 22522776.212\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 571.007\n",
      "  sample_time_ms: 7005.172\n",
      "  update_time_ms: 2.193\n",
      "timestamp: 1658399648\n",
      "timesteps_since_restore: 3120000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3120000\n",
      "training_iteration: 780\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3124000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-15\n",
      "done: false\n",
      "episode_len_mean: 191.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.35\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 16307\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2126135230064392\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004714537411928177\n",
      "        model: {}\n",
      "        policy_loss: -0.003874846501275897\n",
      "        total_loss: 2.382718563079834\n",
      "        vf_explained_var: -0.19354701042175293\n",
      "        vf_loss: 2.3865933418273926\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3124000\n",
      "  num_agent_steps_trained: 3124000\n",
      "  num_steps_sampled: 3124000\n",
      "  num_steps_trained: 3124000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 781\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.99090909090909\n",
      "  ram_util_percent: 87.62727272727274\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07045104400916515\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08081132927214614\n",
      "  mean_inference_ms: 0.7737772902420025\n",
      "  mean_raw_obs_processing_ms: 0.09337964341481833\n",
      "time_since_restore: 5694.593610525131\n",
      "time_this_iter_s: 7.055980205535889\n",
      "time_total_s: 5694.593610525131\n",
      "timers:\n",
      "  learn_throughput: 1332.902\n",
      "  learn_time_ms: 3000.971\n",
      "  load_throughput: 22583410.957\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 570.345\n",
      "  sample_time_ms: 7013.294\n",
      "  update_time_ms: 2.171\n",
      "timestamp: 1658399655\n",
      "timesteps_since_restore: 3124000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3124000\n",
      "training_iteration: 781\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3128000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-22\n",
      "done: false\n",
      "episode_len_mean: 192.15\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.15\n",
      "episode_reward_min: 55.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16328\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24261029064655304\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032847176771610975\n",
      "        model: {}\n",
      "        policy_loss: 0.0005288544343784451\n",
      "        total_loss: 4.050438404083252\n",
      "        vf_explained_var: 0.01632688380777836\n",
      "        vf_loss: 4.049909591674805\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3128000\n",
      "  num_agent_steps_trained: 3128000\n",
      "  num_steps_sampled: 3128000\n",
      "  num_steps_trained: 3128000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 782\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.855555555555554\n",
      "  ram_util_percent: 87.64444444444445\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07044913523261777\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08080944093512889\n",
      "  mean_inference_ms: 0.7737583804858258\n",
      "  mean_raw_obs_processing_ms: 0.09337765775014702\n",
      "time_since_restore: 5701.284705162048\n",
      "time_this_iter_s: 6.691094636917114\n",
      "time_total_s: 5701.284705162048\n",
      "timers:\n",
      "  learn_throughput: 1330.327\n",
      "  learn_time_ms: 3006.779\n",
      "  load_throughput: 23061465.292\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 568.977\n",
      "  sample_time_ms: 7030.163\n",
      "  update_time_ms: 2.211\n",
      "timestamp: 1658399662\n",
      "timesteps_since_restore: 3128000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3128000\n",
      "training_iteration: 782\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3132000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-29\n",
      "done: false\n",
      "episode_len_mean: 193.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.09\n",
      "episode_reward_min: 57.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16349\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24146589636802673\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035867795813828707\n",
      "        model: {}\n",
      "        policy_loss: -0.0028744577430188656\n",
      "        total_loss: 7.219907760620117\n",
      "        vf_explained_var: 1.1696610044964473e-06\n",
      "        vf_loss: 7.222782135009766\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3132000\n",
      "  num_agent_steps_trained: 3132000\n",
      "  num_steps_sampled: 3132000\n",
      "  num_steps_trained: 3132000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 783\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.03\n",
      "  ram_util_percent: 87.52\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07044749855746106\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08080791920081118\n",
      "  mean_inference_ms: 0.773744905190664\n",
      "  mean_raw_obs_processing_ms: 0.09337581678402207\n",
      "time_since_restore: 5708.181730747223\n",
      "time_this_iter_s: 6.8970255851745605\n",
      "time_total_s: 5708.181730747223\n",
      "timers:\n",
      "  learn_throughput: 1327.188\n",
      "  learn_time_ms: 3013.89\n",
      "  load_throughput: 22951047.88\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 567.195\n",
      "  sample_time_ms: 7052.247\n",
      "  update_time_ms: 2.214\n",
      "timestamp: 1658399669\n",
      "timesteps_since_restore: 3132000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3132000\n",
      "training_iteration: 783\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3136000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-36\n",
      "done: false\n",
      "episode_len_mean: 192.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.01\n",
      "episode_reward_min: 57.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16369\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21360079944133759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004464061930775642\n",
      "        model: {}\n",
      "        policy_loss: 0.004310561344027519\n",
      "        total_loss: 8.083954811096191\n",
      "        vf_explained_var: 8.377977565032779e-07\n",
      "        vf_loss: 8.079644203186035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3136000\n",
      "  num_agent_steps_trained: 3136000\n",
      "  num_steps_sampled: 3136000\n",
      "  num_steps_trained: 3136000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 784\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.150000000000006\n",
      "  ram_util_percent: 87.67\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07044400001033006\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08080429306379265\n",
      "  mean_inference_ms: 0.7737092202749258\n",
      "  mean_raw_obs_processing_ms: 0.09337142975873419\n",
      "time_since_restore: 5714.987541675568\n",
      "time_this_iter_s: 6.805810928344727\n",
      "time_total_s: 5714.987541675568\n",
      "timers:\n",
      "  learn_throughput: 1335.116\n",
      "  learn_time_ms: 2995.995\n",
      "  load_throughput: 22641317.139\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 566.087\n",
      "  sample_time_ms: 7066.047\n",
      "  update_time_ms: 2.241\n",
      "timestamp: 1658399676\n",
      "timesteps_since_restore: 3136000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3136000\n",
      "training_iteration: 784\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3140000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-42\n",
      "done: false\n",
      "episode_len_mean: 186.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 186.09\n",
      "episode_reward_min: 57.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 16392\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24353477358818054\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004334884695708752\n",
      "        model: {}\n",
      "        policy_loss: -0.004315934143960476\n",
      "        total_loss: 3.949817180633545\n",
      "        vf_explained_var: -0.01685614138841629\n",
      "        vf_loss: 3.9541330337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3140000\n",
      "  num_agent_steps_trained: 3140000\n",
      "  num_steps_sampled: 3140000\n",
      "  num_steps_trained: 3140000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 785\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.61\n",
      "  ram_util_percent: 87.67999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07043898316162268\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08079897847888877\n",
      "  mean_inference_ms: 0.7736601061180576\n",
      "  mean_raw_obs_processing_ms: 0.09336501294388004\n",
      "time_since_restore: 5721.895659208298\n",
      "time_this_iter_s: 6.9081175327301025\n",
      "time_total_s: 5721.895659208298\n",
      "timers:\n",
      "  learn_throughput: 1331.746\n",
      "  learn_time_ms: 3003.576\n",
      "  load_throughput: 22635207.771\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 566.639\n",
      "  sample_time_ms: 7059.174\n",
      "  update_time_ms: 2.27\n",
      "timestamp: 1658399682\n",
      "timesteps_since_restore: 3140000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3140000\n",
      "training_iteration: 785\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3144000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-49\n",
      "done: false\n",
      "episode_len_mean: 189.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.38\n",
      "episode_reward_min: 57.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16413\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23692385852336884\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004102533683180809\n",
      "        model: {}\n",
      "        policy_loss: -0.004161956254392862\n",
      "        total_loss: 2.4681177139282227\n",
      "        vf_explained_var: -0.05068425089120865\n",
      "        vf_loss: 2.4722793102264404\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3144000\n",
      "  num_agent_steps_trained: 3144000\n",
      "  num_steps_sampled: 3144000\n",
      "  num_steps_trained: 3144000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 786\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.74444444444444\n",
      "  ram_util_percent: 87.78888888888889\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07043363898429046\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08079325440871168\n",
      "  mean_inference_ms: 0.7736093080289785\n",
      "  mean_raw_obs_processing_ms: 0.09335819626912023\n",
      "time_since_restore: 5728.598372220993\n",
      "time_this_iter_s: 6.7027130126953125\n",
      "time_total_s: 5728.598372220993\n",
      "timers:\n",
      "  learn_throughput: 1335.944\n",
      "  learn_time_ms: 2994.137\n",
      "  load_throughput: 22522776.212\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 568.318\n",
      "  sample_time_ms: 7038.319\n",
      "  update_time_ms: 2.299\n",
      "timestamp: 1658399689\n",
      "timesteps_since_restore: 3144000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3144000\n",
      "training_iteration: 786\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3148000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-34-56\n",
      "done: false\n",
      "episode_len_mean: 190.22\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.22\n",
      "episode_reward_min: 57.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16433\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21522799134254456\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004844197537750006\n",
      "        model: {}\n",
      "        policy_loss: 0.0064550163224339485\n",
      "        total_loss: 7.491333961486816\n",
      "        vf_explained_var: 6.101464578023297e-07\n",
      "        vf_loss: 7.484879016876221\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3148000\n",
      "  num_agent_steps_trained: 3148000\n",
      "  num_steps_sampled: 3148000\n",
      "  num_steps_trained: 3148000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 787\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.559999999999995\n",
      "  ram_util_percent: 87.66\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07042922845241899\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08078848087630855\n",
      "  mean_inference_ms: 0.7735683911079206\n",
      "  mean_raw_obs_processing_ms: 0.09335276492924383\n",
      "time_since_restore: 5735.576565980911\n",
      "time_this_iter_s: 6.978193759918213\n",
      "time_total_s: 5735.576565980911\n",
      "timers:\n",
      "  learn_throughput: 1348.298\n",
      "  learn_time_ms: 2966.703\n",
      "  load_throughput: 22779655.126\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 569.979\n",
      "  sample_time_ms: 7017.802\n",
      "  update_time_ms: 2.274\n",
      "timestamp: 1658399696\n",
      "timesteps_since_restore: 3148000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3148000\n",
      "training_iteration: 787\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3152000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-03\n",
      "done: false\n",
      "episode_len_mean: 189.87\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 189.87\n",
      "episode_reward_min: 82.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16454\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24724231660366058\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0062537179328501225\n",
      "        model: {}\n",
      "        policy_loss: -0.0007953519816510379\n",
      "        total_loss: 6.687713146209717\n",
      "        vf_explained_var: 1.3129044873494422e-06\n",
      "        vf_loss: 6.688508033752441\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3152000\n",
      "  num_agent_steps_trained: 3152000\n",
      "  num_steps_sampled: 3152000\n",
      "  num_steps_trained: 3152000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 788\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.85\n",
      "  ram_util_percent: 87.69999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0704240339104502\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08078288951249334\n",
      "  mean_inference_ms: 0.7735175492482302\n",
      "  mean_raw_obs_processing_ms: 0.09334644660732729\n",
      "time_since_restore: 5742.54510140419\n",
      "time_this_iter_s: 6.968535423278809\n",
      "time_total_s: 5742.54510140419\n",
      "timers:\n",
      "  learn_throughput: 1345.22\n",
      "  learn_time_ms: 2973.492\n",
      "  load_throughput: 22693380.225\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 571.58\n",
      "  sample_time_ms: 6998.14\n",
      "  update_time_ms: 2.187\n",
      "timestamp: 1658399703\n",
      "timesteps_since_restore: 3152000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3152000\n",
      "training_iteration: 788\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3156000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-10\n",
      "done: false\n",
      "episode_len_mean: 192.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.16\n",
      "episode_reward_min: 85.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16474\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2497849017381668\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004097878001630306\n",
      "        model: {}\n",
      "        policy_loss: 0.00395478680729866\n",
      "        total_loss: 7.1208953857421875\n",
      "        vf_explained_var: 1.8290935486220405e-06\n",
      "        vf_loss: 7.116939544677734\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3156000\n",
      "  num_agent_steps_trained: 3156000\n",
      "  num_steps_sampled: 3156000\n",
      "  num_steps_trained: 3156000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 789\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.559999999999995\n",
      "  ram_util_percent: 87.74\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07041842050085813\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08077679811772373\n",
      "  mean_inference_ms: 0.7734627714634503\n",
      "  mean_raw_obs_processing_ms: 0.09333985625581587\n",
      "time_since_restore: 5749.352603197098\n",
      "time_this_iter_s: 6.807501792907715\n",
      "time_total_s: 5749.352603197098\n",
      "timers:\n",
      "  learn_throughput: 1358.865\n",
      "  learn_time_ms: 2943.633\n",
      "  load_throughput: 22277540.831\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 576.412\n",
      "  sample_time_ms: 6939.485\n",
      "  update_time_ms: 2.162\n",
      "timestamp: 1658399710\n",
      "timesteps_since_restore: 3156000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3156000\n",
      "training_iteration: 789\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3160000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-17\n",
      "done: false\n",
      "episode_len_mean: 195.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.38\n",
      "episode_reward_min: 94.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16495\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.219878688454628\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0039941999129951\n",
      "        model: {}\n",
      "        policy_loss: 0.0015746788121759892\n",
      "        total_loss: 5.414890766143799\n",
      "        vf_explained_var: -0.00013061460049357265\n",
      "        vf_loss: 5.413315773010254\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3160000\n",
      "  num_agent_steps_trained: 3160000\n",
      "  num_steps_sampled: 3160000\n",
      "  num_steps_trained: 3160000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 790\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.67777777777778\n",
      "  ram_util_percent: 87.71111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07041157209320478\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08076919365273155\n",
      "  mean_inference_ms: 0.773394635137312\n",
      "  mean_raw_obs_processing_ms: 0.09333182071846621\n",
      "time_since_restore: 5755.944152355194\n",
      "time_this_iter_s: 6.5915491580963135\n",
      "time_total_s: 5755.944152355194\n",
      "timers:\n",
      "  learn_throughput: 1361.205\n",
      "  learn_time_ms: 2938.574\n",
      "  load_throughput: 23477772.18\n",
      "  load_time_ms: 0.17\n",
      "  sample_throughput: 582.456\n",
      "  sample_time_ms: 6867.475\n",
      "  update_time_ms: 2.177\n",
      "timestamp: 1658399717\n",
      "timesteps_since_restore: 3160000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3160000\n",
      "training_iteration: 790\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3164000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-23\n",
      "done: false\n",
      "episode_len_mean: 196.08\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.08\n",
      "episode_reward_min: 94.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16515\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25177693367004395\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004324279259890318\n",
      "        model: {}\n",
      "        policy_loss: 0.005667747929692268\n",
      "        total_loss: 8.120586395263672\n",
      "        vf_explained_var: 7.815899607521715e-07\n",
      "        vf_loss: 8.114919662475586\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3164000\n",
      "  num_agent_steps_trained: 3164000\n",
      "  num_steps_sampled: 3164000\n",
      "  num_steps_trained: 3164000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 791\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.559999999999995\n",
      "  ram_util_percent: 87.54\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07040522299025061\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08076198569968909\n",
      "  mean_inference_ms: 0.7733305742902236\n",
      "  mean_raw_obs_processing_ms: 0.09332422758589536\n",
      "time_since_restore: 5762.796848535538\n",
      "time_this_iter_s: 6.852696180343628\n",
      "time_total_s: 5762.796848535538\n",
      "timers:\n",
      "  learn_throughput: 1362.83\n",
      "  learn_time_ms: 2935.068\n",
      "  load_throughput: 23304925.684\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 584.453\n",
      "  sample_time_ms: 6844.01\n",
      "  update_time_ms: 2.207\n",
      "timestamp: 1658399723\n",
      "timesteps_since_restore: 3164000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3164000\n",
      "training_iteration: 791\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3168000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-31\n",
      "done: false\n",
      "episode_len_mean: 191.75\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.75\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 16537\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23430238664150238\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003577152267098427\n",
      "        model: {}\n",
      "        policy_loss: 0.0010625912109389901\n",
      "        total_loss: 4.794410705566406\n",
      "        vf_explained_var: -0.002519471338018775\n",
      "        vf_loss: 4.7933478355407715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3168000\n",
      "  num_agent_steps_trained: 3168000\n",
      "  num_steps_sampled: 3168000\n",
      "  num_steps_trained: 3168000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 792\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.63\n",
      "  ram_util_percent: 87.66\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07039833357676167\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0807539438231934\n",
      "  mean_inference_ms: 0.7732602094008122\n",
      "  mean_raw_obs_processing_ms: 0.09331625881188405\n",
      "time_since_restore: 5769.825796365738\n",
      "time_this_iter_s: 7.028947830200195\n",
      "time_total_s: 5769.825796365738\n",
      "timers:\n",
      "  learn_throughput: 1355.642\n",
      "  learn_time_ms: 2950.632\n",
      "  load_throughput: 23288750.694\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 583.167\n",
      "  sample_time_ms: 6859.093\n",
      "  update_time_ms: 2.195\n",
      "timestamp: 1658399731\n",
      "timesteps_since_restore: 3168000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3168000\n",
      "training_iteration: 792\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3172000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-37\n",
      "done: false\n",
      "episode_len_mean: 192.02\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.02\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16558\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24061374366283417\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004587934352457523\n",
      "        model: {}\n",
      "        policy_loss: 0.002080577192828059\n",
      "        total_loss: 6.168918132781982\n",
      "        vf_explained_var: 0.0020056769717484713\n",
      "        vf_loss: 6.166836738586426\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3172000\n",
      "  num_agent_steps_trained: 3172000\n",
      "  num_steps_sampled: 3172000\n",
      "  num_steps_trained: 3172000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 793\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.290000000000006\n",
      "  ram_util_percent: 87.69\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07039219700649037\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0807464553428983\n",
      "  mean_inference_ms: 0.7731970346840515\n",
      "  mean_raw_obs_processing_ms: 0.09330906990831571\n",
      "time_since_restore: 5776.606258869171\n",
      "time_this_iter_s: 6.7804625034332275\n",
      "time_total_s: 5776.606258869171\n",
      "timers:\n",
      "  learn_throughput: 1356.545\n",
      "  learn_time_ms: 2948.667\n",
      "  load_throughput: 23314641.467\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 582.663\n",
      "  sample_time_ms: 6865.03\n",
      "  update_time_ms: 2.16\n",
      "timestamp: 1658399737\n",
      "timesteps_since_restore: 3172000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3172000\n",
      "training_iteration: 793\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3176000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-44\n",
      "done: false\n",
      "episode_len_mean: 190.7\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.7\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16579\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24308918416500092\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0043148440308868885\n",
      "        model: {}\n",
      "        policy_loss: -0.0008129728958010674\n",
      "        total_loss: 4.207866668701172\n",
      "        vf_explained_var: -0.013455581851303577\n",
      "        vf_loss: 4.208679676055908\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3176000\n",
      "  num_agent_steps_trained: 3176000\n",
      "  num_steps_sampled: 3176000\n",
      "  num_steps_trained: 3176000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 794\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 32.922222222222224\n",
      "  ram_util_percent: 87.75555555555555\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07038614691868654\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08073921920781559\n",
      "  mean_inference_ms: 0.7731350379269923\n",
      "  mean_raw_obs_processing_ms: 0.09330223992598834\n",
      "time_since_restore: 5783.321080684662\n",
      "time_this_iter_s: 6.714821815490723\n",
      "time_total_s: 5783.321080684662\n",
      "timers:\n",
      "  learn_throughput: 1355.232\n",
      "  learn_time_ms: 2951.525\n",
      "  load_throughput: 23699980.223\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 583.87\n",
      "  sample_time_ms: 6850.839\n",
      "  update_time_ms: 2.125\n",
      "timestamp: 1658399744\n",
      "timesteps_since_restore: 3176000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3176000\n",
      "training_iteration: 794\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3180000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-51\n",
      "done: false\n",
      "episode_len_mean: 191.24\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.24\n",
      "episode_reward_min: 62.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16599\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23321765661239624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004207251593470573\n",
      "        model: {}\n",
      "        policy_loss: 0.0017801536014303565\n",
      "        total_loss: 5.057223320007324\n",
      "        vf_explained_var: 1.3032907872911892e-06\n",
      "        vf_loss: 5.05544376373291\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3180000\n",
      "  num_agent_steps_trained: 3180000\n",
      "  num_steps_sampled: 3180000\n",
      "  num_steps_trained: 3180000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 795\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.33\n",
      "  ram_util_percent: 87.71\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0703803110124397\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08073246723404157\n",
      "  mean_inference_ms: 0.7730778953246435\n",
      "  mean_raw_obs_processing_ms: 0.09329608609576132\n",
      "time_since_restore: 5790.28985953331\n",
      "time_this_iter_s: 6.968778848648071\n",
      "time_total_s: 5790.28985953331\n",
      "timers:\n",
      "  learn_throughput: 1345.659\n",
      "  learn_time_ms: 2972.521\n",
      "  load_throughput: 23696632.768\n",
      "  load_time_ms: 0.169\n",
      "  sample_throughput: 584.909\n",
      "  sample_time_ms: 6838.672\n",
      "  update_time_ms: 2.143\n",
      "timestamp: 1658399751\n",
      "timesteps_since_restore: 3180000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3180000\n",
      "training_iteration: 795\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3184000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-35-58\n",
      "done: false\n",
      "episode_len_mean: 192.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.27\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16620\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24058903753757477\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003849456552416086\n",
      "        model: {}\n",
      "        policy_loss: 0.00312581704929471\n",
      "        total_loss: 6.127118110656738\n",
      "        vf_explained_var: -0.03225632384419441\n",
      "        vf_loss: 6.123991966247559\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3184000\n",
      "  num_agent_steps_trained: 3184000\n",
      "  num_steps_sampled: 3184000\n",
      "  num_steps_trained: 3184000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 796\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.129999999999995\n",
      "  ram_util_percent: 87.72999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0703729519264447\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08072411767905592\n",
      "  mean_inference_ms: 0.7730043896408278\n",
      "  mean_raw_obs_processing_ms: 0.09328828838313197\n",
      "time_since_restore: 5796.8172652721405\n",
      "time_this_iter_s: 6.527405738830566\n",
      "time_total_s: 5796.8172652721405\n",
      "timers:\n",
      "  learn_throughput: 1343.715\n",
      "  learn_time_ms: 2976.821\n",
      "  load_throughput: 23020329.308\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 585.077\n",
      "  sample_time_ms: 6836.704\n",
      "  update_time_ms: 2.163\n",
      "timestamp: 1658399758\n",
      "timesteps_since_restore: 3184000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3184000\n",
      "training_iteration: 796\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3188000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-04\n",
      "done: false\n",
      "episode_len_mean: 191.81\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.81\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16641\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21387459337711334\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031640639062970877\n",
      "        model: {}\n",
      "        policy_loss: 0.0006350596668198705\n",
      "        total_loss: 4.141260623931885\n",
      "        vf_explained_var: -0.07530258595943451\n",
      "        vf_loss: 4.140625476837158\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3188000\n",
      "  num_agent_steps_trained: 3188000\n",
      "  num_steps_sampled: 3188000\n",
      "  num_steps_trained: 3188000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 797\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.077777777777776\n",
      "  ram_util_percent: 87.76666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07036449451362993\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08071477409746683\n",
      "  mean_inference_ms: 0.7729218863823278\n",
      "  mean_raw_obs_processing_ms: 0.09327906689385074\n",
      "time_since_restore: 5803.447136163712\n",
      "time_this_iter_s: 6.629870891571045\n",
      "time_total_s: 5803.447136163712\n",
      "timers:\n",
      "  learn_throughput: 1348.745\n",
      "  learn_time_ms: 2965.72\n",
      "  load_throughput: 23153762.076\n",
      "  load_time_ms: 0.173\n",
      "  sample_throughput: 586.738\n",
      "  sample_time_ms: 6817.354\n",
      "  update_time_ms: 2.182\n",
      "timestamp: 1658399764\n",
      "timesteps_since_restore: 3188000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3188000\n",
      "training_iteration: 797\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3192000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-11\n",
      "done: false\n",
      "episode_len_mean: 192.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 192.79\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16661\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.193768709897995\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030736715998500586\n",
      "        model: {}\n",
      "        policy_loss: 0.0014156800461933017\n",
      "        total_loss: 3.517040967941284\n",
      "        vf_explained_var: -0.06175915524363518\n",
      "        vf_loss: 3.515625238418579\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3192000\n",
      "  num_agent_steps_trained: 3192000\n",
      "  num_steps_sampled: 3192000\n",
      "  num_steps_trained: 3192000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 798\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.05\n",
      "  ram_util_percent: 87.72999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0703562294364717\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0807058745387974\n",
      "  mean_inference_ms: 0.7728509071403376\n",
      "  mean_raw_obs_processing_ms: 0.09327016802162541\n",
      "time_since_restore: 5810.485705137253\n",
      "time_this_iter_s: 7.03856897354126\n",
      "time_total_s: 5810.485705137253\n",
      "timers:\n",
      "  learn_throughput: 1353.543\n",
      "  learn_time_ms: 2955.207\n",
      "  load_throughput: 23285518.39\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 586.2\n",
      "  sample_time_ms: 6823.612\n",
      "  update_time_ms: 2.206\n",
      "timestamp: 1658399771\n",
      "timesteps_since_restore: 3192000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3192000\n",
      "training_iteration: 798\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3196000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-18\n",
      "done: false\n",
      "episode_len_mean: 194.89\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.89\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16681\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2427826225757599\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002853129990398884\n",
      "        model: {}\n",
      "        policy_loss: -0.0008706455701030791\n",
      "        total_loss: 1.7128390073776245\n",
      "        vf_explained_var: -0.18371859192848206\n",
      "        vf_loss: 1.7137097120285034\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3196000\n",
      "  num_agent_steps_trained: 3196000\n",
      "  num_steps_sampled: 3196000\n",
      "  num_steps_trained: 3196000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 799\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.59\n",
      "  ram_util_percent: 87.63\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07034767289354717\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08069657722176193\n",
      "  mean_inference_ms: 0.7727769639283342\n",
      "  mean_raw_obs_processing_ms: 0.09326074237561033\n",
      "time_since_restore: 5817.118540287018\n",
      "time_this_iter_s: 6.632835149765015\n",
      "time_total_s: 5817.118540287018\n",
      "timers:\n",
      "  learn_throughput: 1359.424\n",
      "  learn_time_ms: 2942.422\n",
      "  load_throughput: 23994874.142\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 587.46\n",
      "  sample_time_ms: 6808.971\n",
      "  update_time_ms: 2.15\n",
      "timestamp: 1658399778\n",
      "timesteps_since_restore: 3196000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3196000\n",
      "training_iteration: 799\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3200000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-25\n",
      "done: false\n",
      "episode_len_mean: 194.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.83\n",
      "episode_reward_min: 72.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16702\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21823960542678833\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002941165352240205\n",
      "        model: {}\n",
      "        policy_loss: 0.0010025517549365759\n",
      "        total_loss: 3.0655205249786377\n",
      "        vf_explained_var: -0.00117828871589154\n",
      "        vf_loss: 3.0645179748535156\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3200000\n",
      "  num_agent_steps_trained: 3200000\n",
      "  num_steps_sampled: 3200000\n",
      "  num_steps_trained: 3200000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 800\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.08888888888889\n",
      "  ram_util_percent: 87.74444444444445\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07033905669788851\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08068709480620923\n",
      "  mean_inference_ms: 0.7727007667347513\n",
      "  mean_raw_obs_processing_ms: 0.09325119760187864\n",
      "time_since_restore: 5823.874425172806\n",
      "time_this_iter_s: 6.755884885787964\n",
      "time_total_s: 5823.874425172806\n",
      "timers:\n",
      "  learn_throughput: 1354.592\n",
      "  learn_time_ms: 2952.919\n",
      "  load_throughput: 24122524.802\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 588.092\n",
      "  sample_time_ms: 6801.661\n",
      "  update_time_ms: 2.132\n",
      "timestamp: 1658399785\n",
      "timesteps_since_restore: 3200000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3200000\n",
      "training_iteration: 800\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3204000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-32\n",
      "done: false\n",
      "episode_len_mean: 197.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.28\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16722\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2250278890132904\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003925511613488197\n",
      "        model: {}\n",
      "        policy_loss: 0.007745554205030203\n",
      "        total_loss: 8.47548770904541\n",
      "        vf_explained_var: 2.934727660885983e-07\n",
      "        vf_loss: 8.467741966247559\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3204000\n",
      "  num_agent_steps_trained: 3204000\n",
      "  num_steps_sampled: 3204000\n",
      "  num_steps_trained: 3204000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 801\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.36\n",
      "  ram_util_percent: 87.83\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07033174085187455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08067911706325816\n",
      "  mean_inference_ms: 0.772638326226844\n",
      "  mean_raw_obs_processing_ms: 0.09324317621711245\n",
      "time_since_restore: 5830.692713260651\n",
      "time_this_iter_s: 6.818288087844849\n",
      "time_total_s: 5830.692713260651\n",
      "timers:\n",
      "  learn_throughput: 1355.417\n",
      "  learn_time_ms: 2951.122\n",
      "  load_throughput: 24195581.194\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 587.319\n",
      "  sample_time_ms: 6810.604\n",
      "  update_time_ms: 2.145\n",
      "timestamp: 1658399792\n",
      "timesteps_since_restore: 3204000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3204000\n",
      "training_iteration: 801\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000801/checkpoint-801\n",
      "agent_timesteps_total: 3208000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-39\n",
      "done: false\n",
      "episode_len_mean: 198.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.28\n",
      "episode_reward_min: 134.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16742\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25718021392822266\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00555783323943615\n",
      "        model: {}\n",
      "        policy_loss: 0.003011547727510333\n",
      "        total_loss: 7.230835914611816\n",
      "        vf_explained_var: 6.657774633822555e-07\n",
      "        vf_loss: 7.227823734283447\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3208000\n",
      "  num_agent_steps_trained: 3208000\n",
      "  num_steps_sampled: 3208000\n",
      "  num_steps_trained: 3208000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 802\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.64\n",
      "  ram_util_percent: 87.67999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07032560124480798\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0806726509611883\n",
      "  mean_inference_ms: 0.772586234214652\n",
      "  mean_raw_obs_processing_ms: 0.09323657547380262\n",
      "time_since_restore: 5837.586233854294\n",
      "time_this_iter_s: 6.8935205936431885\n",
      "time_total_s: 5837.586233854294\n",
      "timers:\n",
      "  learn_throughput: 1364.453\n",
      "  learn_time_ms: 2931.578\n",
      "  load_throughput: 24339498.041\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 586.859\n",
      "  sample_time_ms: 6815.948\n",
      "  update_time_ms: 2.108\n",
      "timestamp: 1658399799\n",
      "timesteps_since_restore: 3208000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3208000\n",
      "training_iteration: 802\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3212000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-45\n",
      "done: false\n",
      "episode_len_mean: 198.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.93\n",
      "episode_reward_min: 134.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16762\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22915078699588776\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0043691410683095455\n",
      "        model: {}\n",
      "        policy_loss: 0.00399318803101778\n",
      "        total_loss: 6.4052042961120605\n",
      "        vf_explained_var: 6.985920464330775e-08\n",
      "        vf_loss: 6.401211261749268\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3212000\n",
      "  num_agent_steps_trained: 3212000\n",
      "  num_steps_sampled: 3212000\n",
      "  num_steps_trained: 3212000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 803\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.68\n",
      "  ram_util_percent: 87.69\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07031999814699223\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08066653956835111\n",
      "  mean_inference_ms: 0.7725311052966083\n",
      "  mean_raw_obs_processing_ms: 0.09323042648256542\n",
      "time_since_restore: 5844.486758947372\n",
      "time_this_iter_s: 6.900525093078613\n",
      "time_total_s: 5844.486758947372\n",
      "timers:\n",
      "  learn_throughput: 1362.067\n",
      "  learn_time_ms: 2936.713\n",
      "  load_throughput: 24157258.459\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 587.965\n",
      "  sample_time_ms: 6803.131\n",
      "  update_time_ms: 2.102\n",
      "timestamp: 1658399805\n",
      "timesteps_since_restore: 3212000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3212000\n",
      "training_iteration: 803\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3216000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-52\n",
      "done: false\n",
      "episode_len_mean: 198.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.93\n",
      "episode_reward_min: 134.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16782\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24445277452468872\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003494927193969488\n",
      "        model: {}\n",
      "        policy_loss: 0.004045423585921526\n",
      "        total_loss: 6.405256748199463\n",
      "        vf_explained_var: 2.2842037594728026e-07\n",
      "        vf_loss: 6.401210784912109\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3216000\n",
      "  num_agent_steps_trained: 3216000\n",
      "  num_steps_sampled: 3216000\n",
      "  num_steps_trained: 3216000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 804\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.769999999999996\n",
      "  ram_util_percent: 87.72999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07031478557418348\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08066070044949045\n",
      "  mean_inference_ms: 0.7724789569858728\n",
      "  mean_raw_obs_processing_ms: 0.09322450600805271\n",
      "time_since_restore: 5851.177934646606\n",
      "time_this_iter_s: 6.691175699234009\n",
      "time_total_s: 5851.177934646606\n",
      "timers:\n",
      "  learn_throughput: 1363.716\n",
      "  learn_time_ms: 2933.161\n",
      "  load_throughput: 24262062.184\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 587.429\n",
      "  sample_time_ms: 6809.337\n",
      "  update_time_ms: 2.097\n",
      "timestamp: 1658399812\n",
      "timesteps_since_restore: 3216000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3216000\n",
      "training_iteration: 804\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3220000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-36-59\n",
      "done: false\n",
      "episode_len_mean: 198.85\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.85\n",
      "episode_reward_min: 149.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16802\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2765538990497589\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033207505475729704\n",
      "        model: {}\n",
      "        policy_loss: 0.0018629694823175669\n",
      "        total_loss: 5.200958728790283\n",
      "        vf_explained_var: -0.004251930397003889\n",
      "        vf_loss: 5.199095726013184\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3220000\n",
      "  num_agent_steps_trained: 3220000\n",
      "  num_steps_sampled: 3220000\n",
      "  num_steps_trained: 3220000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 805\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.44444444444444\n",
      "  ram_util_percent: 87.73333333333332\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07030925656352789\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08065462957923025\n",
      "  mean_inference_ms: 0.7724242985013775\n",
      "  mean_raw_obs_processing_ms: 0.09321843715469628\n",
      "time_since_restore: 5857.859803676605\n",
      "time_this_iter_s: 6.681869029998779\n",
      "time_total_s: 5857.859803676605\n",
      "timers:\n",
      "  learn_throughput: 1374.674\n",
      "  learn_time_ms: 2909.781\n",
      "  load_throughput: 24084432.96\n",
      "  load_time_ms: 0.166\n",
      "  sample_throughput: 588.159\n",
      "  sample_time_ms: 6800.881\n",
      "  update_time_ms: 2.023\n",
      "timestamp: 1658399819\n",
      "timesteps_since_restore: 3220000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3220000\n",
      "training_iteration: 805\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3224000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-37-06\n",
      "done: false\n",
      "episode_len_mean: 193.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.12\n",
      "episode_reward_min: 33.0\n",
      "episodes_this_iter: 23\n",
      "episodes_total: 16825\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21755166351795197\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004106251522898674\n",
      "        model: {}\n",
      "        policy_loss: -0.0003873375244438648\n",
      "        total_loss: 3.427032470703125\n",
      "        vf_explained_var: -0.08413084596395493\n",
      "        vf_loss: 3.427419424057007\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3224000\n",
      "  num_agent_steps_trained: 3224000\n",
      "  num_steps_sampled: 3224000\n",
      "  num_steps_trained: 3224000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 806\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.85\n",
      "  ram_util_percent: 87.74999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07030275379792811\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08064748527231677\n",
      "  mean_inference_ms: 0.772360147011178\n",
      "  mean_raw_obs_processing_ms: 0.09321142713393168\n",
      "time_since_restore: 5864.5090045928955\n",
      "time_this_iter_s: 6.649200916290283\n",
      "time_total_s: 5864.5090045928955\n",
      "timers:\n",
      "  learn_throughput: 1378.401\n",
      "  learn_time_ms: 2901.912\n",
      "  load_throughput: 24895705.594\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 588.509\n",
      "  sample_time_ms: 6796.832\n",
      "  update_time_ms: 1.929\n",
      "timestamp: 1658399826\n",
      "timesteps_since_restore: 3224000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3224000\n",
      "training_iteration: 806\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3228000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-37-12\n",
      "done: false\n",
      "episode_len_mean: 191.56\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.56\n",
      "episode_reward_min: 33.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16846\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22326940298080444\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0039559463039040565\n",
      "        model: {}\n",
      "        policy_loss: 0.00016089748532976955\n",
      "        total_loss: 4.581813812255859\n",
      "        vf_explained_var: 3.4513013247305935e-07\n",
      "        vf_loss: 4.581653118133545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3228000\n",
      "  num_agent_steps_trained: 3228000\n",
      "  num_steps_sampled: 3228000\n",
      "  num_steps_trained: 3228000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 807\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.44444444444444\n",
      "  ram_util_percent: 87.6111111111111\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07029652449637887\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08064058566554372\n",
      "  mean_inference_ms: 0.7722984138354636\n",
      "  mean_raw_obs_processing_ms: 0.09320465186298266\n",
      "time_since_restore: 5871.390941143036\n",
      "time_this_iter_s: 6.881936550140381\n",
      "time_total_s: 5871.390941143036\n",
      "timers:\n",
      "  learn_throughput: 1374.908\n",
      "  learn_time_ms: 2909.286\n",
      "  load_throughput: 24774388.659\n",
      "  load_time_ms: 0.161\n",
      "  sample_throughput: 587.675\n",
      "  sample_time_ms: 6806.486\n",
      "  update_time_ms: 1.946\n",
      "timestamp: 1658399832\n",
      "timesteps_since_restore: 3228000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3228000\n",
      "training_iteration: 807\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3232000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-37-19\n",
      "done: false\n",
      "episode_len_mean: 191.56\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.56\n",
      "episode_reward_min: 33.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16866\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22199919819831848\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032457157503813505\n",
      "        model: {}\n",
      "        policy_loss: 0.0025092109572142363\n",
      "        total_loss: 4.185977458953857\n",
      "        vf_explained_var: -7.171784943693638e-08\n",
      "        vf_loss: 4.183468341827393\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3232000\n",
      "  num_agent_steps_trained: 3232000\n",
      "  num_steps_sampled: 3232000\n",
      "  num_steps_trained: 3232000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 808\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.58\n",
      "  ram_util_percent: 87.62\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07029000858300415\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08063334208053334\n",
      "  mean_inference_ms: 0.772233820914357\n",
      "  mean_raw_obs_processing_ms: 0.09319782844022406\n",
      "time_since_restore: 5878.1671414375305\n",
      "time_this_iter_s: 6.776200294494629\n",
      "time_total_s: 5878.1671414375305\n",
      "timers:\n",
      "  learn_throughput: 1378.169\n",
      "  learn_time_ms: 2902.402\n",
      "  load_throughput: 24639765.017\n",
      "  load_time_ms: 0.162\n",
      "  sample_throughput: 588.582\n",
      "  sample_time_ms: 6795.999\n",
      "  update_time_ms: 1.942\n",
      "timestamp: 1658399839\n",
      "timesteps_since_restore: 3232000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3232000\n",
      "training_iteration: 808\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3236000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-37-26\n",
      "done: false\n",
      "episode_len_mean: 190.65\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 190.65\n",
      "episode_reward_min: 33.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 16887\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2356320470571518\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001978532411158085\n",
      "        model: {}\n",
      "        policy_loss: -0.01148893591016531\n",
      "        total_loss: 6.03439474105835\n",
      "        vf_explained_var: 2.961004952339863e-07\n",
      "        vf_loss: 6.045883655548096\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3236000\n",
      "  num_agent_steps_trained: 3236000\n",
      "  num_steps_sampled: 3236000\n",
      "  num_steps_trained: 3236000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 809\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.83\n",
      "  ram_util_percent: 87.59\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07028472330593277\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08062764594270957\n",
      "  mean_inference_ms: 0.7721844166484426\n",
      "  mean_raw_obs_processing_ms: 0.09319269170244315\n",
      "time_since_restore: 5885.250155687332\n",
      "time_this_iter_s: 7.083014249801636\n",
      "time_total_s: 5885.250155687332\n",
      "timers:\n",
      "  learn_throughput: 1376.257\n",
      "  learn_time_ms: 2906.435\n",
      "  load_throughput: 24399674.229\n",
      "  load_time_ms: 0.164\n",
      "  sample_throughput: 585.631\n",
      "  sample_time_ms: 6830.242\n",
      "  update_time_ms: 1.957\n",
      "timestamp: 1658399846\n",
      "timesteps_since_restore: 3236000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3236000\n",
      "training_iteration: 809\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3240000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-37-33\n",
      "done: false\n",
      "episode_len_mean: 191.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.39\n",
      "episode_reward_min: 33.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16907\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2084035575389862\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036184322088956833\n",
      "        model: {}\n",
      "        policy_loss: -0.012894408777356148\n",
      "        total_loss: 9.60404109954834\n",
      "        vf_explained_var: 8.735605661058798e-08\n",
      "        vf_loss: 9.616935729980469\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3240000\n",
      "  num_agent_steps_trained: 3240000\n",
      "  num_steps_sampled: 3240000\n",
      "  num_steps_trained: 3240000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 810\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 35.660000000000004\n",
      "  ram_util_percent: 87.63000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07028037088140106\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08062299913036368\n",
      "  mean_inference_ms: 0.772143605335288\n",
      "  mean_raw_obs_processing_ms: 0.09318810632970881\n",
      "time_since_restore: 5892.160470485687\n",
      "time_this_iter_s: 6.9103147983551025\n",
      "time_total_s: 5892.160470485687\n",
      "timers:\n",
      "  learn_throughput: 1373.407\n",
      "  learn_time_ms: 2912.466\n",
      "  load_throughput: 24241028.753\n",
      "  load_time_ms: 0.165\n",
      "  sample_throughput: 584.481\n",
      "  sample_time_ms: 6843.68\n",
      "  update_time_ms: 1.983\n",
      "timestamp: 1658399853\n",
      "timesteps_since_restore: 3240000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3240000\n",
      "training_iteration: 810\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3244000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-37-40\n",
      "done: false\n",
      "episode_len_mean: 197.12\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.12\n",
      "episode_reward_min: 100.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16927\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2131294459104538\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033587589859962463\n",
      "        model: {}\n",
      "        policy_loss: -0.010796980001032352\n",
      "        total_loss: 9.606138229370117\n",
      "        vf_explained_var: 5.024735472147768e-08\n",
      "        vf_loss: 9.616935729980469\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3244000\n",
      "  num_agent_steps_trained: 3244000\n",
      "  num_steps_sampled: 3244000\n",
      "  num_steps_trained: 3244000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 811\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.470000000000006\n",
      "  ram_util_percent: 87.62\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07027593440198446\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08061824416085672\n",
      "  mean_inference_ms: 0.7721028410261858\n",
      "  mean_raw_obs_processing_ms: 0.09318333201383944\n",
      "time_since_restore: 5898.997029781342\n",
      "time_this_iter_s: 6.836559295654297\n",
      "time_total_s: 5898.997029781342\n",
      "timers:\n",
      "  learn_throughput: 1372.781\n",
      "  learn_time_ms: 2913.794\n",
      "  load_throughput: 23960605.541\n",
      "  load_time_ms: 0.167\n",
      "  sample_throughput: 583.901\n",
      "  sample_time_ms: 6850.475\n",
      "  update_time_ms: 1.945\n",
      "timestamp: 1658399860\n",
      "timesteps_since_restore: 3244000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3244000\n",
      "training_iteration: 811\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3248000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-37-47\n",
      "done: false\n",
      "episode_len_mean: 199.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.09\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16947\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21626074612140656\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003941412549465895\n",
      "        model: {}\n",
      "        policy_loss: -0.012941003777086735\n",
      "        total_loss: 9.603994369506836\n",
      "        vf_explained_var: 7.037193228143224e-08\n",
      "        vf_loss: 9.616935729980469\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3248000\n",
      "  num_agent_steps_trained: 3248000\n",
      "  num_steps_sampled: 3248000\n",
      "  num_steps_trained: 3248000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 812\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.63333333333333\n",
      "  ram_util_percent: 87.69999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07027072026878764\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08061268448776449\n",
      "  mean_inference_ms: 0.7720540235514411\n",
      "  mean_raw_obs_processing_ms: 0.09317738129967233\n",
      "time_since_restore: 5905.625624895096\n",
      "time_this_iter_s: 6.6285951137542725\n",
      "time_total_s: 5905.625624895096\n",
      "timers:\n",
      "  learn_throughput: 1373.067\n",
      "  learn_time_ms: 2913.187\n",
      "  load_throughput: 23217846.665\n",
      "  load_time_ms: 0.172\n",
      "  sample_throughput: 586.126\n",
      "  sample_time_ms: 6824.471\n",
      "  update_time_ms: 1.918\n",
      "timestamp: 1658399867\n",
      "timesteps_since_restore: 3248000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3248000\n",
      "training_iteration: 812\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3252000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-37-54\n",
      "done: false\n",
      "episode_len_mean: 199.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.09\n",
      "episode_reward_min: 109.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16967\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21245917677879333\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00359804998151958\n",
      "        model: {}\n",
      "        policy_loss: -0.011866762302815914\n",
      "        total_loss: 9.605067253112793\n",
      "        vf_explained_var: -9.43419777854615e-08\n",
      "        vf_loss: 9.616935729980469\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3252000\n",
      "  num_agent_steps_trained: 3252000\n",
      "  num_steps_sampled: 3252000\n",
      "  num_steps_trained: 3252000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 813\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.75000000000001\n",
      "  ram_util_percent: 87.63000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07026551429015085\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08060721736364339\n",
      "  mean_inference_ms: 0.7720051799374488\n",
      "  mean_raw_obs_processing_ms: 0.09317135721430145\n",
      "time_since_restore: 5912.368698120117\n",
      "time_this_iter_s: 6.743073225021362\n",
      "time_total_s: 5912.368698120117\n",
      "timers:\n",
      "  learn_throughput: 1374.063\n",
      "  learn_time_ms: 2911.075\n",
      "  load_throughput: 22271626.178\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 587.378\n",
      "  sample_time_ms: 6809.925\n",
      "  update_time_ms: 1.975\n",
      "timestamp: 1658399874\n",
      "timesteps_since_restore: 3252000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3252000\n",
      "training_iteration: 813\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3256000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-38-00\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 16987\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2067384421825409\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002082302700728178\n",
      "        model: {}\n",
      "        policy_loss: -0.01153272483497858\n",
      "        total_loss: 9.605402946472168\n",
      "        vf_explained_var: -1.8201848206444993e-07\n",
      "        vf_loss: 9.616935729980469\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3256000\n",
      "  num_agent_steps_trained: 3256000\n",
      "  num_steps_sampled: 3256000\n",
      "  num_steps_trained: 3256000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 814\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.589999999999996\n",
      "  ram_util_percent: 87.69\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07025886193149429\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08060000133436727\n",
      "  mean_inference_ms: 0.7719380987343059\n",
      "  mean_raw_obs_processing_ms: 0.09316357397917428\n",
      "time_since_restore: 5918.985812664032\n",
      "time_this_iter_s: 6.617114543914795\n",
      "time_total_s: 5918.985812664032\n",
      "timers:\n",
      "  learn_throughput: 1376.009\n",
      "  learn_time_ms: 2906.958\n",
      "  load_throughput: 21183353.535\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 587.763\n",
      "  sample_time_ms: 6805.467\n",
      "  update_time_ms: 1.982\n",
      "timestamp: 1658399880\n",
      "timesteps_since_restore: 3256000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3256000\n",
      "training_iteration: 814\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3260000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-38-07\n",
      "done: false\n",
      "episode_len_mean: 199.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.33\n",
      "episode_reward_min: 163.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17007\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.213152676820755\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002280189422890544\n",
      "        model: {}\n",
      "        policy_loss: 0.0078077116049826145\n",
      "        total_loss: 7.641382694244385\n",
      "        vf_explained_var: 7.395462375825446e-07\n",
      "        vf_loss: 7.633574962615967\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3260000\n",
      "  num_agent_steps_trained: 3260000\n",
      "  num_steps_sampled: 3260000\n",
      "  num_steps_trained: 3260000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 815\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 33.53333333333333\n",
      "  ram_util_percent: 87.67777777777778\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07025157408764972\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08059208829432052\n",
      "  mean_inference_ms: 0.7718641386455485\n",
      "  mean_raw_obs_processing_ms: 0.09315521015837987\n",
      "time_since_restore: 5925.590215921402\n",
      "time_this_iter_s: 6.604403257369995\n",
      "time_total_s: 5925.590215921402\n",
      "timers:\n",
      "  learn_throughput: 1379.105\n",
      "  learn_time_ms: 2900.431\n",
      "  load_throughput: 20583015.581\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 588.244\n",
      "  sample_time_ms: 6799.903\n",
      "  update_time_ms: 1.958\n",
      "timestamp: 1658399887\n",
      "timesteps_since_restore: 3260000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3260000\n",
      "training_iteration: 815\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3264000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-38-14\n",
      "done: false\n",
      "episode_len_mean: 199.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.33\n",
      "episode_reward_min: 163.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17027\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2144748419523239\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002797946333885193\n",
      "        model: {}\n",
      "        policy_loss: 0.00613994337618351\n",
      "        total_loss: 6.306542873382568\n",
      "        vf_explained_var: 1.1818383427453227e-07\n",
      "        vf_loss: 6.300403118133545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3264000\n",
      "  num_agent_steps_trained: 3264000\n",
      "  num_steps_sampled: 3264000\n",
      "  num_steps_trained: 3264000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 816\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 34.26\n",
      "  ram_util_percent: 87.70000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07024408744650092\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08058394836264554\n",
      "  mean_inference_ms: 0.7717870874463776\n",
      "  mean_raw_obs_processing_ms: 0.09314657436697617\n",
      "time_since_restore: 5932.3407208919525\n",
      "time_this_iter_s: 6.750504970550537\n",
      "time_total_s: 5932.3407208919525\n",
      "timers:\n",
      "  learn_throughput: 1373.659\n",
      "  learn_time_ms: 2911.93\n",
      "  load_throughput: 20613362.821\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 588.948\n",
      "  sample_time_ms: 6791.773\n",
      "  update_time_ms: 2.07\n",
      "timestamp: 1658399894\n",
      "timesteps_since_restore: 3264000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3264000\n",
      "training_iteration: 816\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3268000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-38-21\n",
      "done: false\n",
      "episode_len_mean: 199.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.33\n",
      "episode_reward_min: 163.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17047\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2316417694091797\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004860887303948402\n",
      "        model: {}\n",
      "        policy_loss: 0.00418342649936676\n",
      "        total_loss: 6.3045878410339355\n",
      "        vf_explained_var: 2.5777407586247136e-07\n",
      "        vf_loss: 6.300404071807861\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3268000\n",
      "  num_agent_steps_trained: 3268000\n",
      "  num_steps_sampled: 3268000\n",
      "  num_steps_trained: 3268000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 817\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.57000000000001\n",
      "  ram_util_percent: 87.65\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07023795524633339\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08057707941885538\n",
      "  mean_inference_ms: 0.771725837329864\n",
      "  mean_raw_obs_processing_ms: 0.09313977131855967\n",
      "time_since_restore: 5939.634390830994\n",
      "time_this_iter_s: 7.293669939041138\n",
      "time_total_s: 5939.634390830994\n",
      "timers:\n",
      "  learn_throughput: 1361.558\n",
      "  learn_time_ms: 2937.81\n",
      "  load_throughput: 20636182.042\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 586.589\n",
      "  sample_time_ms: 6819.079\n",
      "  update_time_ms: 2.1\n",
      "timestamp: 1658399901\n",
      "timesteps_since_restore: 3268000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3268000\n",
      "training_iteration: 817\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3272000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-38-28\n",
      "done: false\n",
      "episode_len_mean: 199.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.33\n",
      "episode_reward_min: 163.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17067\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21439096331596375\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0020888890139758587\n",
      "        model: {}\n",
      "        policy_loss: 0.0059583233669400215\n",
      "        total_loss: 6.306362152099609\n",
      "        vf_explained_var: -4.864508085233865e-08\n",
      "        vf_loss: 6.300404071807861\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3272000\n",
      "  num_agent_steps_trained: 3272000\n",
      "  num_steps_sampled: 3272000\n",
      "  num_steps_trained: 3272000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 818\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.054545454545455\n",
      "  ram_util_percent: 87.72727272727272\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07023385835418428\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08057251683303548\n",
      "  mean_inference_ms: 0.7716852923574248\n",
      "  mean_raw_obs_processing_ms: 0.09313532084589987\n",
      "time_since_restore: 5947.030754566193\n",
      "time_this_iter_s: 7.396363735198975\n",
      "time_total_s: 5947.030754566193\n",
      "timers:\n",
      "  learn_throughput: 1354.34\n",
      "  learn_time_ms: 2953.469\n",
      "  load_throughput: 20720286.526\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 580.545\n",
      "  sample_time_ms: 6890.074\n",
      "  update_time_ms: 2.15\n",
      "timestamp: 1658399908\n",
      "timesteps_since_restore: 3272000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3272000\n",
      "training_iteration: 818\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3276000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-38-36\n",
      "done: false\n",
      "episode_len_mean: 199.33\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.33\n",
      "episode_reward_min: 163.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17087\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23071013391017914\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002776107518002391\n",
      "        model: {}\n",
      "        policy_loss: 0.005599903874099255\n",
      "        total_loss: 6.306003570556641\n",
      "        vf_explained_var: 1.5317752399823803e-07\n",
      "        vf_loss: 6.300403118133545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3276000\n",
      "  num_agent_steps_trained: 3276000\n",
      "  num_steps_sampled: 3276000\n",
      "  num_steps_trained: 3276000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 819\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.1\n",
      "  ram_util_percent: 87.75999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07023097682732382\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08056949403281977\n",
      "  mean_inference_ms: 0.7716599766007037\n",
      "  mean_raw_obs_processing_ms: 0.09313225655128235\n",
      "time_since_restore: 5954.557674407959\n",
      "time_this_iter_s: 7.526919841766357\n",
      "time_total_s: 5954.557674407959\n",
      "timers:\n",
      "  learn_throughput: 1331.371\n",
      "  learn_time_ms: 3004.421\n",
      "  load_throughput: 20710055.549\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 579.789\n",
      "  sample_time_ms: 6899.066\n",
      "  update_time_ms: 2.198\n",
      "timestamp: 1658399916\n",
      "timesteps_since_restore: 3276000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3276000\n",
      "training_iteration: 819\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3280000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-38-44\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17107\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2357521653175354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003288119798526168\n",
      "        model: {}\n",
      "        policy_loss: 0.005124262534081936\n",
      "        total_loss: 6.305529594421387\n",
      "        vf_explained_var: 9.594425165460052e-08\n",
      "        vf_loss: 6.300405502319336\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3280000\n",
      "  num_agent_steps_trained: 3280000\n",
      "  num_steps_sampled: 3280000\n",
      "  num_steps_trained: 3280000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 820\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.50833333333333\n",
      "  ram_util_percent: 87.84999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07023432534894317\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08057335936038677\n",
      "  mean_inference_ms: 0.7717024504460861\n",
      "  mean_raw_obs_processing_ms: 0.09313675538101684\n",
      "time_since_restore: 5962.851551532745\n",
      "time_this_iter_s: 8.293877124786377\n",
      "time_total_s: 5962.851551532745\n",
      "timers:\n",
      "  learn_throughput: 1328.126\n",
      "  learn_time_ms: 3011.764\n",
      "  load_throughput: 20653965.284\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 564.828\n",
      "  sample_time_ms: 7081.805\n",
      "  update_time_ms: 2.175\n",
      "timestamp: 1658399924\n",
      "timesteps_since_restore: 3280000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3280000\n",
      "training_iteration: 820\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3284000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-38-51\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17127\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22643226385116577\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00282255164347589\n",
      "        model: {}\n",
      "        policy_loss: 0.00562836742028594\n",
      "        total_loss: 6.306031703948975\n",
      "        vf_explained_var: -1.2875885602170456e-07\n",
      "        vf_loss: 6.300403118133545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3284000\n",
      "  num_agent_steps_trained: 3284000\n",
      "  num_steps_sampled: 3284000\n",
      "  num_steps_trained: 3284000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 821\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.14000000000001\n",
      "  ram_util_percent: 87.64\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0702379905265227\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08057754054385019\n",
      "  mean_inference_ms: 0.7717480831991459\n",
      "  mean_raw_obs_processing_ms: 0.09314157149319652\n",
      "time_since_restore: 5969.948531389236\n",
      "time_this_iter_s: 7.096979856491089\n",
      "time_total_s: 5969.948531389236\n",
      "timers:\n",
      "  learn_throughput: 1316.898\n",
      "  learn_time_ms: 3037.44\n",
      "  load_throughput: 20720286.526\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 564.244\n",
      "  sample_time_ms: 7089.126\n",
      "  update_time_ms: 2.282\n",
      "timestamp: 1658399931\n",
      "timesteps_since_restore: 3284000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3284000\n",
      "training_iteration: 821\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3288000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-39-00\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17147\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20523297786712646\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033385837450623512\n",
      "        model: {}\n",
      "        policy_loss: 0.005716625135391951\n",
      "        total_loss: 6.3061203956604\n",
      "        vf_explained_var: -9.338061346397808e-08\n",
      "        vf_loss: 6.300403594970703\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3288000\n",
      "  num_agent_steps_trained: 3288000\n",
      "  num_steps_sampled: 3288000\n",
      "  num_steps_trained: 3288000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 822\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.775\n",
      "  ram_util_percent: 87.875\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0702442994806099\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08058483696715714\n",
      "  mean_inference_ms: 0.7718206444589572\n",
      "  mean_raw_obs_processing_ms: 0.0931497015763603\n",
      "time_since_restore: 5978.371730089188\n",
      "time_this_iter_s: 8.423198699951172\n",
      "time_total_s: 5978.371730089188\n",
      "timers:\n",
      "  learn_throughput: 1280.401\n",
      "  learn_time_ms: 3124.022\n",
      "  load_throughput: 19317462.291\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 554.92\n",
      "  sample_time_ms: 7208.242\n",
      "  update_time_ms: 2.351\n",
      "timestamp: 1658399940\n",
      "timesteps_since_restore: 3288000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3288000\n",
      "training_iteration: 822\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3292000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-39-07\n",
      "done: false\n",
      "episode_len_mean: 198.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.27\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 17168\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23372432589530945\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031537071336060762\n",
      "        model: {}\n",
      "        policy_loss: 0.0023837632033973932\n",
      "        total_loss: 5.559340476989746\n",
      "        vf_explained_var: 3.79995640287234e-07\n",
      "        vf_loss: 5.556956768035889\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3292000\n",
      "  num_agent_steps_trained: 3292000\n",
      "  num_steps_sampled: 3292000\n",
      "  num_steps_trained: 3292000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 823\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.32727272727272\n",
      "  ram_util_percent: 87.83636363636361\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07025099267927314\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0805925989681001\n",
      "  mean_inference_ms: 0.7718991212709453\n",
      "  mean_raw_obs_processing_ms: 0.0931582639528036\n",
      "time_since_restore: 5986.063397169113\n",
      "time_this_iter_s: 7.691667079925537\n",
      "time_total_s: 5986.063397169113\n",
      "timers:\n",
      "  learn_throughput: 1261.76\n",
      "  learn_time_ms: 3170.174\n",
      "  load_throughput: 19805472.79\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 544.643\n",
      "  sample_time_ms: 7344.263\n",
      "  update_time_ms: 2.31\n",
      "timestamp: 1658399947\n",
      "timesteps_since_restore: 3292000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3292000\n",
      "training_iteration: 823\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3296000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-39-16\n",
      "done: false\n",
      "episode_len_mean: 198.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.27\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17188\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20881770551204681\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003512754337862134\n",
      "        model: {}\n",
      "        policy_loss: 0.006079523824155331\n",
      "        total_loss: 7.667370319366455\n",
      "        vf_explained_var: 2.0688580093519704e-07\n",
      "        vf_loss: 7.661290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3296000\n",
      "  num_agent_steps_trained: 3296000\n",
      "  num_steps_sampled: 3296000\n",
      "  num_steps_trained: 3296000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 824\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.61666666666667\n",
      "  ram_util_percent: 88.03333333333335\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0702619219633183\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08060496493159208\n",
      "  mean_inference_ms: 0.7720189617719408\n",
      "  mean_raw_obs_processing_ms: 0.09317187962805207\n",
      "time_since_restore: 5994.272990465164\n",
      "time_this_iter_s: 8.209593296051025\n",
      "time_total_s: 5994.272990465164\n",
      "timers:\n",
      "  learn_throughput: 1253.116\n",
      "  learn_time_ms: 3192.043\n",
      "  load_throughput: 20267233.631\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 531.419\n",
      "  sample_time_ms: 7527.016\n",
      "  update_time_ms: 2.295\n",
      "timestamp: 1658399956\n",
      "timesteps_since_restore: 3296000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3296000\n",
      "training_iteration: 824\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3300000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-39-22\n",
      "done: false\n",
      "episode_len_mean: 198.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.27\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17208\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19409684836864471\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002109327120706439\n",
      "        model: {}\n",
      "        policy_loss: 0.008615058846771717\n",
      "        total_loss: 7.6699066162109375\n",
      "        vf_explained_var: 2.3072765920062466e-09\n",
      "        vf_loss: 7.661291599273682\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3300000\n",
      "  num_agent_steps_trained: 3300000\n",
      "  num_steps_sampled: 3300000\n",
      "  num_steps_trained: 3300000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 825\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.00000000000001\n",
      "  ram_util_percent: 87.86999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07026737635671455\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0806110499370426\n",
      "  mean_inference_ms: 0.7720789132386742\n",
      "  mean_raw_obs_processing_ms: 0.09317874117743909\n",
      "time_since_restore: 6001.104882955551\n",
      "time_this_iter_s: 6.831892490386963\n",
      "time_total_s: 6001.104882955551\n",
      "timers:\n",
      "  learn_throughput: 1248.025\n",
      "  learn_time_ms: 3205.063\n",
      "  load_throughput: 20984635.397\n",
      "  load_time_ms: 0.191\n",
      "  sample_throughput: 529.202\n",
      "  sample_time_ms: 7558.549\n",
      "  update_time_ms: 2.376\n",
      "timestamp: 1658399962\n",
      "timesteps_since_restore: 3300000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3300000\n",
      "training_iteration: 825\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3304000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-39-30\n",
      "done: false\n",
      "episode_len_mean: 198.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.27\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17228\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2143622636795044\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034816511906683445\n",
      "        model: {}\n",
      "        policy_loss: 0.006716645322740078\n",
      "        total_loss: 7.668008327484131\n",
      "        vf_explained_var: -1.7887802528093744e-07\n",
      "        vf_loss: 7.661291599273682\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3304000\n",
      "  num_agent_steps_trained: 3304000\n",
      "  num_steps_sampled: 3304000\n",
      "  num_steps_trained: 3304000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 826\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.910000000000004\n",
      "  ram_util_percent: 87.78000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07027358953993751\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08061806475110835\n",
      "  mean_inference_ms: 0.7721487599455827\n",
      "  mean_raw_obs_processing_ms: 0.09318650848102916\n",
      "time_since_restore: 6008.137832403183\n",
      "time_this_iter_s: 7.032949447631836\n",
      "time_total_s: 6008.137832403183\n",
      "timers:\n",
      "  learn_throughput: 1249.114\n",
      "  learn_time_ms: 3202.269\n",
      "  load_throughput: 20789610.905\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 526.091\n",
      "  sample_time_ms: 7603.252\n",
      "  update_time_ms: 2.264\n",
      "timestamp: 1658399970\n",
      "timesteps_since_restore: 3304000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3304000\n",
      "training_iteration: 826\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3308000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-39-37\n",
      "done: false\n",
      "episode_len_mean: 198.27\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.27\n",
      "episode_reward_min: 74.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17248\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22250917553901672\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0021369413007050753\n",
      "        model: {}\n",
      "        policy_loss: 0.007625857833772898\n",
      "        total_loss: 7.668918132781982\n",
      "        vf_explained_var: 5.954696007393068e-07\n",
      "        vf_loss: 7.661292552947998\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3308000\n",
      "  num_agent_steps_trained: 3308000\n",
      "  num_steps_sampled: 3308000\n",
      "  num_steps_trained: 3308000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 827\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.27272727272727\n",
      "  ram_util_percent: 87.75454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07027937488958293\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08062456531849602\n",
      "  mean_inference_ms: 0.772212965125444\n",
      "  mean_raw_obs_processing_ms: 0.09319361407002619\n",
      "time_since_restore: 6015.968784332275\n",
      "time_this_iter_s: 7.830951929092407\n",
      "time_total_s: 6015.968784332275\n",
      "timers:\n",
      "  learn_throughput: 1246.283\n",
      "  learn_time_ms: 3209.544\n",
      "  load_throughput: 20615895.797\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 523.118\n",
      "  sample_time_ms: 7646.465\n",
      "  update_time_ms: 2.248\n",
      "timestamp: 1658399977\n",
      "timesteps_since_restore: 3308000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3308000\n",
      "training_iteration: 827\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3312000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-39-45\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17268\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23466552793979645\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003321229014545679\n",
      "        model: {}\n",
      "        policy_loss: 0.006957611069083214\n",
      "        total_loss: 7.668248176574707\n",
      "        vf_explained_var: 1.904785023043587e-07\n",
      "        vf_loss: 7.661290168762207\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3312000\n",
      "  num_agent_steps_trained: 3312000\n",
      "  num_steps_sampled: 3312000\n",
      "  num_steps_trained: 3312000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 828\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.74166666666667\n",
      "  ram_util_percent: 87.80833333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07028572978364231\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08063166051381966\n",
      "  mean_inference_ms: 0.7722836928287927\n",
      "  mean_raw_obs_processing_ms: 0.09320135782566841\n",
      "time_since_restore: 6024.0145082473755\n",
      "time_this_iter_s: 8.045723915100098\n",
      "time_total_s: 6024.0145082473755\n",
      "timers:\n",
      "  learn_throughput: 1228.098\n",
      "  learn_time_ms: 3257.069\n",
      "  load_throughput: 20380485.909\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 521.407\n",
      "  sample_time_ms: 7671.546\n",
      "  update_time_ms: 2.249\n",
      "timestamp: 1658399985\n",
      "timesteps_since_restore: 3312000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3312000\n",
      "training_iteration: 828\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3316000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-39-56\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17288\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22946488857269287\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030575941782444715\n",
      "        model: {}\n",
      "        policy_loss: 0.006996272597461939\n",
      "        total_loss: 7.668287754058838\n",
      "        vf_explained_var: 1.922730447079246e-10\n",
      "        vf_loss: 7.661291599273682\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3316000\n",
      "  num_agent_steps_trained: 3316000\n",
      "  num_steps_sampled: 3316000\n",
      "  num_steps_trained: 3316000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 829\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.95714285714286\n",
      "  ram_util_percent: 88.12142857142858\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07029607360144512\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08064316096353405\n",
      "  mean_inference_ms: 0.772396674823108\n",
      "  mean_raw_obs_processing_ms: 0.09321348265096134\n",
      "time_since_restore: 6034.041655302048\n",
      "time_this_iter_s: 10.027147054672241\n",
      "time_total_s: 6034.041655302048\n",
      "timers:\n",
      "  learn_throughput: 1209.151\n",
      "  learn_time_ms: 3308.107\n",
      "  load_throughput: 19290808.325\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 505.137\n",
      "  sample_time_ms: 7918.647\n",
      "  update_time_ms: 2.296\n",
      "timestamp: 1658399996\n",
      "timesteps_since_restore: 3316000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3316000\n",
      "training_iteration: 829\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3320000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-40-05\n",
      "done: false\n",
      "episode_len_mean: 199.16\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.16\n",
      "episode_reward_min: 116.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17308\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2258632928133011\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028290655463933945\n",
      "        model: {}\n",
      "        policy_loss: 0.005704853218048811\n",
      "        total_loss: 6.608534812927246\n",
      "        vf_explained_var: -0.026073863729834557\n",
      "        vf_loss: 6.602829933166504\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3320000\n",
      "  num_agent_steps_trained: 3320000\n",
      "  num_steps_sampled: 3320000\n",
      "  num_steps_trained: 3320000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 830\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 53.114285714285714\n",
      "  ram_util_percent: 88.16428571428573\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07031579148553907\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08066510617694649\n",
      "  mean_inference_ms: 0.7726029736326105\n",
      "  mean_raw_obs_processing_ms: 0.0932368387351571\n",
      "time_since_restore: 6043.86167883873\n",
      "time_this_iter_s: 9.820023536682129\n",
      "time_total_s: 6043.86167883873\n",
      "timers:\n",
      "  learn_throughput: 1180.559\n",
      "  learn_time_ms: 3388.224\n",
      "  load_throughput: 19095397.223\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 497.328\n",
      "  sample_time_ms: 8042.976\n",
      "  update_time_ms: 2.32\n",
      "timestamp: 1658400005\n",
      "timesteps_since_restore: 3320000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3320000\n",
      "training_iteration: 830\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3324000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-40-15\n",
      "done: false\n",
      "episode_len_mean: 195.67\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.67\n",
      "episode_reward_min: 34.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 17330\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23367761075496674\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0041170488111674786\n",
      "        model: {}\n",
      "        policy_loss: 0.0014674420235678554\n",
      "        total_loss: 4.729290008544922\n",
      "        vf_explained_var: 0.0007437742315232754\n",
      "        vf_loss: 4.727822780609131\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3324000\n",
      "  num_agent_steps_trained: 3324000\n",
      "  num_steps_sampled: 3324000\n",
      "  num_steps_trained: 3324000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 831\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.707692307692305\n",
      "  ram_util_percent: 88.08461538461538\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07034390556848445\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08069658303731381\n",
      "  mean_inference_ms: 0.7728911807337429\n",
      "  mean_raw_obs_processing_ms: 0.09327077245444598\n",
      "time_since_restore: 6053.040370941162\n",
      "time_this_iter_s: 9.178692102432251\n",
      "time_total_s: 6053.040370941162\n",
      "timers:\n",
      "  learn_throughput: 1163.011\n",
      "  learn_time_ms: 3439.348\n",
      "  load_throughput: 19017474.496\n",
      "  load_time_ms: 0.21\n",
      "  sample_throughput: 483.057\n",
      "  sample_time_ms: 8280.603\n",
      "  update_time_ms: 2.404\n",
      "timestamp: 1658400015\n",
      "timesteps_since_restore: 3324000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3324000\n",
      "training_iteration: 831\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3328000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-40-25\n",
      "done: false\n",
      "episode_len_mean: 193.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.21\n",
      "episode_reward_min: 34.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 17351\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24140119552612305\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.005036078859120607\n",
      "        model: {}\n",
      "        policy_loss: 0.0021586697548627853\n",
      "        total_loss: 7.008227348327637\n",
      "        vf_explained_var: 7.013479716988513e-07\n",
      "        vf_loss: 7.006068229675293\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3328000\n",
      "  num_agent_steps_trained: 3328000\n",
      "  num_steps_sampled: 3328000\n",
      "  num_steps_trained: 3328000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 832\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 54.99333333333334\n",
      "  ram_util_percent: 88.09333333333335\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07037663290755831\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08073311847553442\n",
      "  mean_inference_ms: 0.773227104474841\n",
      "  mean_raw_obs_processing_ms: 0.09331028522202837\n",
      "time_since_restore: 6063.081075191498\n",
      "time_this_iter_s: 10.040704250335693\n",
      "time_total_s: 6063.081075191498\n",
      "timers:\n",
      "  learn_throughput: 1148.026\n",
      "  learn_time_ms: 3484.242\n",
      "  load_throughput: 19297464.918\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 473.322\n",
      "  sample_time_ms: 8450.901\n",
      "  update_time_ms: 2.366\n",
      "timestamp: 1658400025\n",
      "timesteps_since_restore: 3328000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3328000\n",
      "training_iteration: 832\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3332000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-40-34\n",
      "done: false\n",
      "episode_len_mean: 193.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.21\n",
      "episode_reward_min: 34.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17371\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2335270196199417\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00304694683291018\n",
      "        model: {}\n",
      "        policy_loss: 0.001592237502336502\n",
      "        total_loss: 3.681027889251709\n",
      "        vf_explained_var: -1.1574837799344095e-07\n",
      "        vf_loss: 3.6794354915618896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3332000\n",
      "  num_agent_steps_trained: 3332000\n",
      "  num_steps_sampled: 3332000\n",
      "  num_steps_trained: 3332000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 833\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.06923076923078\n",
      "  ram_util_percent: 88.01538461538462\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07041061794374141\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08077124078112075\n",
      "  mean_inference_ms: 0.7735759248853559\n",
      "  mean_raw_obs_processing_ms: 0.09335136198069655\n",
      "time_since_restore: 6072.336351633072\n",
      "time_this_iter_s: 9.255276441574097\n",
      "time_total_s: 6072.336351633072\n",
      "timers:\n",
      "  learn_throughput: 1131.028\n",
      "  learn_time_ms: 3536.606\n",
      "  load_throughput: 19321911.782\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 465.11\n",
      "  sample_time_ms: 8600.116\n",
      "  update_time_ms: 2.409\n",
      "timestamp: 1658400034\n",
      "timesteps_since_restore: 3332000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3332000\n",
      "training_iteration: 833\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3336000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-40-43\n",
      "done: false\n",
      "episode_len_mean: 193.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.21\n",
      "episode_reward_min: 34.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17391\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25007832050323486\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032448761630803347\n",
      "        model: {}\n",
      "        policy_loss: 0.0018135756254196167\n",
      "        total_loss: 3.6812491416931152\n",
      "        vf_explained_var: 1.1087745832583096e-08\n",
      "        vf_loss: 3.6794354915618896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3336000\n",
      "  num_agent_steps_trained: 3336000\n",
      "  num_steps_sampled: 3336000\n",
      "  num_steps_trained: 3336000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 834\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.49230769230769\n",
      "  ram_util_percent: 88.13076923076923\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07044247369117423\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08080708432964684\n",
      "  mean_inference_ms: 0.7739030736252235\n",
      "  mean_raw_obs_processing_ms: 0.09339028437904734\n",
      "time_since_restore: 6081.6653480529785\n",
      "time_this_iter_s: 9.328996419906616\n",
      "time_total_s: 6081.6653480529785\n",
      "timers:\n",
      "  learn_throughput: 1110.178\n",
      "  learn_time_ms: 3603.026\n",
      "  load_throughput: 19427068.087\n",
      "  load_time_ms: 0.206\n",
      "  sample_throughput: 459.832\n",
      "  sample_time_ms: 8698.82\n",
      "  update_time_ms: 2.445\n",
      "timestamp: 1658400043\n",
      "timesteps_since_restore: 3336000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3336000\n",
      "training_iteration: 834\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3340000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-40-51\n",
      "done: false\n",
      "episode_len_mean: 194.05\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.05\n",
      "episode_reward_min: 34.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17411\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23741649091243744\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031773457303643227\n",
      "        model: {}\n",
      "        policy_loss: 0.0011143613373860717\n",
      "        total_loss: 3.6805496215820312\n",
      "        vf_explained_var: 4.869635290560836e-07\n",
      "        vf_loss: 3.6794354915618896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3340000\n",
      "  num_agent_steps_trained: 3340000\n",
      "  num_steps_sampled: 3340000\n",
      "  num_steps_trained: 3340000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 835\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.91666666666667\n",
      "  ram_util_percent: 88.16666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07046929402842965\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08083746283578941\n",
      "  mean_inference_ms: 0.7741829910022673\n",
      "  mean_raw_obs_processing_ms: 0.09342330083122238\n",
      "time_since_restore: 6089.715281009674\n",
      "time_this_iter_s: 8.049932956695557\n",
      "time_total_s: 6089.715281009674\n",
      "timers:\n",
      "  learn_throughput: 1102.076\n",
      "  learn_time_ms: 3629.515\n",
      "  load_throughput: 19304126.107\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 451.405\n",
      "  sample_time_ms: 8861.225\n",
      "  update_time_ms: 2.379\n",
      "timestamp: 1658400051\n",
      "timesteps_since_restore: 3340000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3340000\n",
      "training_iteration: 835\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3344000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-41-00\n",
      "done: false\n",
      "episode_len_mean: 197.49\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.49\n",
      "episode_reward_min: 87.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 17432\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21752800047397614\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004000652581453323\n",
      "        model: {}\n",
      "        policy_loss: 0.0007479494670405984\n",
      "        total_loss: 3.765869379043579\n",
      "        vf_explained_var: -0.0013754506362602115\n",
      "        vf_loss: 3.7651214599609375\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3344000\n",
      "  num_agent_steps_trained: 3344000\n",
      "  num_steps_sampled: 3344000\n",
      "  num_steps_trained: 3344000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 836\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.24166666666667\n",
      "  ram_util_percent: 88.24999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07049635599198523\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08086828326066248\n",
      "  mean_inference_ms: 0.7744649982057916\n",
      "  mean_raw_obs_processing_ms: 0.09345644336726502\n",
      "time_since_restore: 6098.626289606094\n",
      "time_this_iter_s: 8.911008596420288\n",
      "time_total_s: 6098.626289606094\n",
      "timers:\n",
      "  learn_throughput: 1077.686\n",
      "  learn_time_ms: 3711.658\n",
      "  load_throughput: 19163010.851\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 444.794\n",
      "  sample_time_ms: 8992.923\n",
      "  update_time_ms: 2.432\n",
      "timestamp: 1658400060\n",
      "timesteps_since_restore: 3344000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3344000\n",
      "training_iteration: 836\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3348000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-41-09\n",
      "done: false\n",
      "episode_len_mean: 198.59\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.59\n",
      "episode_reward_min: 87.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17452\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20485608279705048\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029389290139079094\n",
      "        model: {}\n",
      "        policy_loss: 0.006403657142072916\n",
      "        total_loss: 6.659629821777344\n",
      "        vf_explained_var: -2.3072765920062466e-09\n",
      "        vf_loss: 6.653225898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3348000\n",
      "  num_agent_steps_trained: 3348000\n",
      "  num_steps_sampled: 3348000\n",
      "  num_steps_trained: 3348000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 837\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.19230769230769\n",
      "  ram_util_percent: 88.22307692307692\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07051934633122657\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08089454547005027\n",
      "  mean_inference_ms: 0.7747026996316301\n",
      "  mean_raw_obs_processing_ms: 0.0934845700100783\n",
      "time_since_restore: 6107.245204925537\n",
      "time_this_iter_s: 8.618915319442749\n",
      "time_total_s: 6107.245204925537\n",
      "timers:\n",
      "  learn_throughput: 1070.545\n",
      "  learn_time_ms: 3736.415\n",
      "  load_throughput: 19176152.703\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 438.132\n",
      "  sample_time_ms: 9129.678\n",
      "  update_time_ms: 2.823\n",
      "timestamp: 1658400069\n",
      "timesteps_since_restore: 3348000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3348000\n",
      "training_iteration: 837\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3352000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-41-19\n",
      "done: false\n",
      "episode_len_mean: 197.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.91\n",
      "episode_reward_min: 87.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17472\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20827466249465942\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003941026516258717\n",
      "        model: {}\n",
      "        policy_loss: 0.000941038248129189\n",
      "        total_loss: 3.9122354984283447\n",
      "        vf_explained_var: -0.06451594829559326\n",
      "        vf_loss: 3.9112939834594727\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3352000\n",
      "  num_agent_steps_trained: 3352000\n",
      "  num_steps_sampled: 3352000\n",
      "  num_steps_trained: 3352000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 838\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.207142857142856\n",
      "  ram_util_percent: 88.21428571428571\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07054295864054526\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0809213509056549\n",
      "  mean_inference_ms: 0.7749462571612304\n",
      "  mean_raw_obs_processing_ms: 0.09351351507256062\n",
      "time_since_restore: 6116.849369049072\n",
      "time_this_iter_s: 9.604164123535156\n",
      "time_total_s: 6116.849369049072\n",
      "timers:\n",
      "  learn_throughput: 1056.664\n",
      "  learn_time_ms: 3785.497\n",
      "  load_throughput: 18416263.447\n",
      "  load_time_ms: 0.217\n",
      "  sample_throughput: 431.85\n",
      "  sample_time_ms: 9262.482\n",
      "  update_time_ms: 2.838\n",
      "timestamp: 1658400079\n",
      "timesteps_since_restore: 3352000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3352000\n",
      "training_iteration: 838\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3356000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-41-29\n",
      "done: false\n",
      "episode_len_mean: 197.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.91\n",
      "episode_reward_min: 87.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17492\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20202869176864624\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003292157780379057\n",
      "        model: {}\n",
      "        policy_loss: 0.0012296532513573766\n",
      "        total_loss: 3.2270359992980957\n",
      "        vf_explained_var: -0.06225854903459549\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3356000\n",
      "  num_agent_steps_trained: 3356000\n",
      "  num_steps_sampled: 3356000\n",
      "  num_steps_trained: 3356000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 839\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 50.67142857142857\n",
      "  ram_util_percent: 88.22857142857141\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07056825287950703\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08095007616142143\n",
      "  mean_inference_ms: 0.7752089259810205\n",
      "  mean_raw_obs_processing_ms: 0.09354493484986744\n",
      "time_since_restore: 6126.753464221954\n",
      "time_this_iter_s: 9.90409517288208\n",
      "time_total_s: 6126.753464221954\n",
      "timers:\n",
      "  learn_throughput: 1057.932\n",
      "  learn_time_ms: 3780.96\n",
      "  load_throughput: 19097570.859\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 429.915\n",
      "  sample_time_ms: 9304.168\n",
      "  update_time_ms: 2.76\n",
      "timestamp: 1658400089\n",
      "timesteps_since_restore: 3356000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3356000\n",
      "training_iteration: 839\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3360000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-41-38\n",
      "done: false\n",
      "episode_len_mean: 197.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.91\n",
      "episode_reward_min: 87.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17512\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18432003259658813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002599513391032815\n",
      "        model: {}\n",
      "        policy_loss: 0.001591877662576735\n",
      "        total_loss: 3.22739839553833\n",
      "        vf_explained_var: -0.06177868694067001\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3360000\n",
      "  num_agent_steps_trained: 3360000\n",
      "  num_steps_sampled: 3360000\n",
      "  num_steps_trained: 3360000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 840\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.13846153846154\n",
      "  ram_util_percent: 88.16923076923078\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07059644116558549\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08098252688557463\n",
      "  mean_inference_ms: 0.7754978178189862\n",
      "  mean_raw_obs_processing_ms: 0.09357935266202326\n",
      "time_since_restore: 6135.910731077194\n",
      "time_this_iter_s: 9.157266855239868\n",
      "time_total_s: 6135.910731077194\n",
      "timers:\n",
      "  learn_throughput: 1062.627\n",
      "  learn_time_ms: 3764.256\n",
      "  load_throughput: 19178344.765\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 432.469\n",
      "  sample_time_ms: 9249.211\n",
      "  update_time_ms: 2.883\n",
      "timestamp: 1658400098\n",
      "timesteps_since_restore: 3360000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3360000\n",
      "training_iteration: 840\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3364000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-41-47\n",
      "done: false\n",
      "episode_len_mean: 199.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.32\n",
      "episode_reward_min: 132.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17532\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1979760229587555\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025804596953094006\n",
      "        model: {}\n",
      "        policy_loss: 0.0022446427028626204\n",
      "        total_loss: 3.22805118560791\n",
      "        vf_explained_var: -0.06451614201068878\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3364000\n",
      "  num_agent_steps_trained: 3364000\n",
      "  num_steps_sampled: 3364000\n",
      "  num_steps_trained: 3364000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 841\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.407692307692315\n",
      "  ram_util_percent: 88.17692307692307\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07062600008932605\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0810164261609663\n",
      "  mean_inference_ms: 0.7758038486768274\n",
      "  mean_raw_obs_processing_ms: 0.0936154646755462\n",
      "time_since_restore: 6145.064409017563\n",
      "time_this_iter_s: 9.153677940368652\n",
      "time_total_s: 6145.064409017563\n",
      "timers:\n",
      "  learn_throughput: 1064.863\n",
      "  learn_time_ms: 3756.351\n",
      "  load_throughput: 18361843.056\n",
      "  load_time_ms: 0.218\n",
      "  sample_throughput: 432.975\n",
      "  sample_time_ms: 9238.416\n",
      "  update_time_ms: 2.753\n",
      "timestamp: 1658400107\n",
      "timesteps_since_restore: 3364000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3364000\n",
      "training_iteration: 841\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3368000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-41-55\n",
      "done: false\n",
      "episode_len_mean: 199.32\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.32\n",
      "episode_reward_min: 132.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17552\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18998859822750092\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035622185096144676\n",
      "        model: {}\n",
      "        policy_loss: 0.0013809524243697524\n",
      "        total_loss: 3.2271878719329834\n",
      "        vf_explained_var: -0.06090521812438965\n",
      "        vf_loss: 3.225806951522827\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3368000\n",
      "  num_agent_steps_trained: 3368000\n",
      "  num_steps_sampled: 3368000\n",
      "  num_steps_trained: 3368000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 842\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.900000000000006\n",
      "  ram_util_percent: 88.24545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07065261553589197\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08104700794559762\n",
      "  mean_inference_ms: 0.7760806358195624\n",
      "  mean_raw_obs_processing_ms: 0.0936479722086543\n",
      "time_since_restore: 6153.081534385681\n",
      "time_this_iter_s: 8.017125368118286\n",
      "time_total_s: 6153.081534385681\n",
      "timers:\n",
      "  learn_throughput: 1082.31\n",
      "  learn_time_ms: 3695.799\n",
      "  load_throughput: 19857043.437\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 440.191\n",
      "  sample_time_ms: 9086.974\n",
      "  update_time_ms: 2.763\n",
      "timestamp: 1658400115\n",
      "timesteps_since_restore: 3368000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3368000\n",
      "training_iteration: 842\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3372000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-42-04\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17572\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18339550495147705\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002387919230386615\n",
      "        model: {}\n",
      "        policy_loss: 0.00245260470546782\n",
      "        total_loss: 3.2282590866088867\n",
      "        vf_explained_var: -0.0645160973072052\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3372000\n",
      "  num_agent_steps_trained: 3372000\n",
      "  num_steps_sampled: 3372000\n",
      "  num_steps_trained: 3372000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 843\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.35000000000001\n",
      "  ram_util_percent: 88.20714285714284\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07067883382364423\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0810774039854749\n",
      "  mean_inference_ms: 0.7763535418851287\n",
      "  mean_raw_obs_processing_ms: 0.09368029935011292\n",
      "time_since_restore: 6162.316513299942\n",
      "time_this_iter_s: 9.234978914260864\n",
      "time_total_s: 6162.316513299942\n",
      "timers:\n",
      "  learn_throughput: 1085.743\n",
      "  learn_time_ms: 3684.115\n",
      "  load_throughput: 19835913.928\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 442.686\n",
      "  sample_time_ms: 9035.744\n",
      "  update_time_ms: 2.757\n",
      "timestamp: 1658400124\n",
      "timesteps_since_restore: 3372000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3372000\n",
      "training_iteration: 843\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3376000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-42-13\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17592\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18053030967712402\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002086993772536516\n",
      "        model: {}\n",
      "        policy_loss: 0.003218525554984808\n",
      "        total_loss: 3.229025363922119\n",
      "        vf_explained_var: -0.0018577735172584653\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3376000\n",
      "  num_agent_steps_trained: 3376000\n",
      "  num_steps_sampled: 3376000\n",
      "  num_steps_trained: 3376000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 844\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.49230769230769\n",
      "  ram_util_percent: 88.21538461538461\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07070280437325571\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0811052640862064\n",
      "  mean_inference_ms: 0.7766010933403328\n",
      "  mean_raw_obs_processing_ms: 0.09370950931858606\n",
      "time_since_restore: 6171.430436372757\n",
      "time_this_iter_s: 9.113923072814941\n",
      "time_total_s: 6171.430436372757\n",
      "timers:\n",
      "  learn_throughput: 1087.954\n",
      "  learn_time_ms: 3676.626\n",
      "  load_throughput: 18825421.903\n",
      "  load_time_ms: 0.212\n",
      "  sample_throughput: 443.966\n",
      "  sample_time_ms: 9009.692\n",
      "  update_time_ms: 2.764\n",
      "timestamp: 1658400133\n",
      "timesteps_since_restore: 3376000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3376000\n",
      "training_iteration: 844\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3380000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-42-22\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17612\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20162248611450195\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033073939848691225\n",
      "        model: {}\n",
      "        policy_loss: 0.0013187492731958628\n",
      "        total_loss: 3.227125644683838\n",
      "        vf_explained_var: -0.000642982660792768\n",
      "        vf_loss: 3.225806951522827\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3380000\n",
      "  num_agent_steps_trained: 3380000\n",
      "  num_steps_sampled: 3380000\n",
      "  num_steps_trained: 3380000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 845\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.775\n",
      "  ram_util_percent: 88.16666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07072578084011343\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08113156566567857\n",
      "  mean_inference_ms: 0.7768426288283998\n",
      "  mean_raw_obs_processing_ms: 0.09373788579826464\n",
      "time_since_restore: 6180.339917421341\n",
      "time_this_iter_s: 8.909481048583984\n",
      "time_total_s: 6180.339917421341\n",
      "timers:\n",
      "  learn_throughput: 1077.094\n",
      "  learn_time_ms: 3713.695\n",
      "  load_throughput: 18562974.109\n",
      "  load_time_ms: 0.215\n",
      "  sample_throughput: 441.907\n",
      "  sample_time_ms: 9051.678\n",
      "  update_time_ms: 2.814\n",
      "timestamp: 1658400142\n",
      "timesteps_since_restore: 3380000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3380000\n",
      "training_iteration: 845\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3384000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-42-31\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17632\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18640221655368805\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027208072133362293\n",
      "        model: {}\n",
      "        policy_loss: 0.001696677994914353\n",
      "        total_loss: 3.2275032997131348\n",
      "        vf_explained_var: 0.0024522212333977222\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3384000\n",
      "  num_agent_steps_trained: 3384000\n",
      "  num_steps_sampled: 3384000\n",
      "  num_steps_trained: 3384000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 846\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.96923076923077\n",
      "  ram_util_percent: 88.17692307692309\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07074886818339406\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08115800158539774\n",
      "  mean_inference_ms: 0.7770849562998259\n",
      "  mean_raw_obs_processing_ms: 0.09376643966391338\n",
      "time_since_restore: 6189.460786342621\n",
      "time_this_iter_s: 9.120868921279907\n",
      "time_total_s: 6189.460786342621\n",
      "timers:\n",
      "  learn_throughput: 1081.321\n",
      "  learn_time_ms: 3699.179\n",
      "  load_throughput: 17317522.709\n",
      "  load_time_ms: 0.231\n",
      "  sample_throughput: 438.329\n",
      "  sample_time_ms: 9125.56\n",
      "  update_time_ms: 2.786\n",
      "timestamp: 1658400151\n",
      "timesteps_since_restore: 3384000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3384000\n",
      "training_iteration: 846\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3388000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-42-40\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17652\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2000841647386551\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00311807612888515\n",
      "        model: {}\n",
      "        policy_loss: 0.0014734555734321475\n",
      "        total_loss: 3.2272801399230957\n",
      "        vf_explained_var: -0.06434548646211624\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3388000\n",
      "  num_agent_steps_trained: 3388000\n",
      "  num_steps_sampled: 3388000\n",
      "  num_steps_trained: 3388000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 847\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.75384615384616\n",
      "  ram_util_percent: 88.14615384615385\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07077564820551635\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08118865826130335\n",
      "  mean_inference_ms: 0.7773660017197984\n",
      "  mean_raw_obs_processing_ms: 0.09379985578694364\n",
      "time_since_restore: 6198.342247724533\n",
      "time_this_iter_s: 8.881461381912231\n",
      "time_total_s: 6198.342247724533\n",
      "timers:\n",
      "  learn_throughput: 1080.404\n",
      "  learn_time_ms: 3702.319\n",
      "  load_throughput: 17175692.056\n",
      "  load_time_ms: 0.233\n",
      "  sample_throughput: 437.911\n",
      "  sample_time_ms: 9134.273\n",
      "  update_time_ms: 2.441\n",
      "timestamp: 1658400160\n",
      "timesteps_since_restore: 3388000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3388000\n",
      "training_iteration: 847\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3392000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-42-48\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17672\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20972196757793427\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038580705877393484\n",
      "        model: {}\n",
      "        policy_loss: 0.001264965976588428\n",
      "        total_loss: 3.22707200050354\n",
      "        vf_explained_var: -0.057050496339797974\n",
      "        vf_loss: 3.2258071899414062\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3392000\n",
      "  num_agent_steps_trained: 3392000\n",
      "  num_steps_sampled: 3392000\n",
      "  num_steps_trained: 3392000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 848\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.22727272727272\n",
      "  ram_util_percent: 88.27272727272727\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07079836172018913\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08121452978918993\n",
      "  mean_inference_ms: 0.7776054298174664\n",
      "  mean_raw_obs_processing_ms: 0.09382806781971426\n",
      "time_since_restore: 6206.12073135376\n",
      "time_this_iter_s: 7.778483629226685\n",
      "time_total_s: 6206.12073135376\n",
      "timers:\n",
      "  learn_throughput: 1104.876\n",
      "  learn_time_ms: 3620.316\n",
      "  load_throughput: 17978156.88\n",
      "  load_time_ms: 0.222\n",
      "  sample_throughput: 442.702\n",
      "  sample_time_ms: 9035.43\n",
      "  update_time_ms: 2.355\n",
      "timestamp: 1658400168\n",
      "timesteps_since_restore: 3392000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3392000\n",
      "training_iteration: 848\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3396000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-42-56\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17692\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1865680068731308\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0021233486477285624\n",
      "        model: {}\n",
      "        policy_loss: 0.0030894398223608732\n",
      "        total_loss: 3.228895902633667\n",
      "        vf_explained_var: -0.06024149805307388\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3396000\n",
      "  num_agent_steps_trained: 3396000\n",
      "  num_steps_sampled: 3396000\n",
      "  num_steps_trained: 3396000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 849\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.97272727272727\n",
      "  ram_util_percent: 88.1909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07081629347221399\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08123482176267921\n",
      "  mean_inference_ms: 0.7777932966360731\n",
      "  mean_raw_obs_processing_ms: 0.09385070771408492\n",
      "time_since_restore: 6213.71711730957\n",
      "time_this_iter_s: 7.596385955810547\n",
      "time_total_s: 6213.71711730957\n",
      "timers:\n",
      "  learn_throughput: 1124.067\n",
      "  learn_time_ms: 3558.506\n",
      "  load_throughput: 18129690.944\n",
      "  load_time_ms: 0.221\n",
      "  sample_throughput: 455.4\n",
      "  sample_time_ms: 8783.482\n",
      "  update_time_ms: 2.363\n",
      "timestamp: 1658400176\n",
      "timesteps_since_restore: 3396000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3396000\n",
      "training_iteration: 849\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3400000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-43-04\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17712\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18243443965911865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0015851660864427686\n",
      "        model: {}\n",
      "        policy_loss: 0.003376346779987216\n",
      "        total_loss: 3.2291829586029053\n",
      "        vf_explained_var: -0.06451619416475296\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3400000\n",
      "  num_agent_steps_trained: 3400000\n",
      "  num_steps_sampled: 3400000\n",
      "  num_steps_trained: 3400000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 850\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.38181818181818\n",
      "  ram_util_percent: 88.2181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07083161886392007\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0812520336594409\n",
      "  mean_inference_ms: 0.7779478429201202\n",
      "  mean_raw_obs_processing_ms: 0.09386987563064146\n",
      "time_since_restore: 6221.698781013489\n",
      "time_this_iter_s: 7.981663703918457\n",
      "time_total_s: 6221.698781013489\n",
      "timers:\n",
      "  learn_throughput: 1133.96\n",
      "  learn_time_ms: 3527.46\n",
      "  load_throughput: 17378512.534\n",
      "  load_time_ms: 0.23\n",
      "  sample_throughput: 463.235\n",
      "  sample_time_ms: 8634.926\n",
      "  update_time_ms: 2.214\n",
      "timestamp: 1658400184\n",
      "timesteps_since_restore: 3400000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3400000\n",
      "training_iteration: 850\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3404000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-43-11\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17732\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1775626242160797\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003073186846449971\n",
      "        model: {}\n",
      "        policy_loss: 0.001899241702631116\n",
      "        total_loss: 3.227705955505371\n",
      "        vf_explained_var: -0.0645161122083664\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3404000\n",
      "  num_agent_steps_trained: 3404000\n",
      "  num_steps_sampled: 3404000\n",
      "  num_steps_trained: 3404000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 851\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.14545454545454\n",
      "  ram_util_percent: 88.26363636363635\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07084221736287402\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08126350104240472\n",
      "  mean_inference_ms: 0.7780508204880883\n",
      "  mean_raw_obs_processing_ms: 0.09388304347973495\n",
      "time_since_restore: 6229.322496652603\n",
      "time_this_iter_s: 7.62371563911438\n",
      "time_total_s: 6229.322496652603\n",
      "timers:\n",
      "  learn_throughput: 1147.201\n",
      "  learn_time_ms: 3486.749\n",
      "  load_throughput: 18041957.2\n",
      "  load_time_ms: 0.222\n",
      "  sample_throughput: 471.119\n",
      "  sample_time_ms: 8490.416\n",
      "  update_time_ms: 2.164\n",
      "timestamp: 1658400191\n",
      "timesteps_since_restore: 3404000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3404000\n",
      "training_iteration: 851\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3408000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-43-19\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17752\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18539822101593018\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025289494078606367\n",
      "        model: {}\n",
      "        policy_loss: 0.0024204181972891092\n",
      "        total_loss: 3.228227376937866\n",
      "        vf_explained_var: -0.0590827651321888\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3408000\n",
      "  num_agent_steps_trained: 3408000\n",
      "  num_steps_sampled: 3408000\n",
      "  num_steps_trained: 3408000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 852\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.83636363636364\n",
      "  ram_util_percent: 88.23636363636363\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07084894304840858\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0812707661945753\n",
      "  mean_inference_ms: 0.7781111863098562\n",
      "  mean_raw_obs_processing_ms: 0.0938912020373551\n",
      "time_since_restore: 6236.956813573837\n",
      "time_this_iter_s: 7.634316921234131\n",
      "time_total_s: 6236.956813573837\n",
      "timers:\n",
      "  learn_throughput: 1158.043\n",
      "  learn_time_ms: 3454.102\n",
      "  load_throughput: 17972379.218\n",
      "  load_time_ms: 0.223\n",
      "  sample_throughput: 473.731\n",
      "  sample_time_ms: 8443.61\n",
      "  update_time_ms: 2.18\n",
      "timestamp: 1658400199\n",
      "timesteps_since_restore: 3408000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3408000\n",
      "training_iteration: 852\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3412000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-43-27\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17772\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18689803779125214\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0016231986228376627\n",
      "        model: {}\n",
      "        policy_loss: 0.0027783308178186417\n",
      "        total_loss: 3.228585720062256\n",
      "        vf_explained_var: -0.06451620161533356\n",
      "        vf_loss: 3.2258074283599854\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3412000\n",
      "  num_agent_steps_trained: 3412000\n",
      "  num_steps_sampled: 3412000\n",
      "  num_steps_trained: 3412000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 853\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.13636363636363\n",
      "  ram_util_percent: 88.22727272727272\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07085521391072533\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08127755774865458\n",
      "  mean_inference_ms: 0.7781643730784612\n",
      "  mean_raw_obs_processing_ms: 0.09389869625678181\n",
      "time_since_restore: 6244.5473437309265\n",
      "time_this_iter_s: 7.590530157089233\n",
      "time_total_s: 6244.5473437309265\n",
      "timers:\n",
      "  learn_throughput: 1177.159\n",
      "  learn_time_ms: 3398.012\n",
      "  load_throughput: 18067215.163\n",
      "  load_time_ms: 0.221\n",
      "  sample_throughput: 481.803\n",
      "  sample_time_ms: 8302.15\n",
      "  update_time_ms: 2.204\n",
      "timestamp: 1658400207\n",
      "timesteps_since_restore: 3412000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3412000\n",
      "training_iteration: 853\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3416000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-43-36\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17792\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1821158081293106\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003218461060896516\n",
      "        model: {}\n",
      "        policy_loss: 0.00195184291806072\n",
      "        total_loss: 3.2277579307556152\n",
      "        vf_explained_var: -0.06451619416475296\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3416000\n",
      "  num_agent_steps_trained: 3416000\n",
      "  num_steps_sampled: 3416000\n",
      "  num_steps_trained: 3416000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 854\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.97692307692308\n",
      "  ram_util_percent: 88.26153846153846\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07086548220726144\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08128954883359105\n",
      "  mean_inference_ms: 0.7782639376083609\n",
      "  mean_raw_obs_processing_ms: 0.09391081309071762\n",
      "time_since_restore: 6253.4996881484985\n",
      "time_this_iter_s: 8.952344417572021\n",
      "time_total_s: 6253.4996881484985\n",
      "timers:\n",
      "  learn_throughput: 1179.467\n",
      "  learn_time_ms: 3391.364\n",
      "  load_throughput: 19171770.083\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 485.569\n",
      "  sample_time_ms: 8237.766\n",
      "  update_time_ms: 2.291\n",
      "timestamp: 1658400216\n",
      "timesteps_since_restore: 3416000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3416000\n",
      "training_iteration: 854\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3420000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-43-44\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17812\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1897144615650177\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002411717316135764\n",
      "        model: {}\n",
      "        policy_loss: 0.002990731969475746\n",
      "        total_loss: 3.228797197341919\n",
      "        vf_explained_var: -0.06451613456010818\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3420000\n",
      "  num_agent_steps_trained: 3420000\n",
      "  num_steps_sampled: 3420000\n",
      "  num_steps_trained: 3420000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 855\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.17272727272727\n",
      "  ram_util_percent: 87.97272727272727\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07087534145908331\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08130118270784058\n",
      "  mean_inference_ms: 0.7783650150027727\n",
      "  mean_raw_obs_processing_ms: 0.09392287687167122\n",
      "time_since_restore: 6261.453747749329\n",
      "time_this_iter_s: 7.954059600830078\n",
      "time_total_s: 6261.453747749329\n",
      "timers:\n",
      "  learn_throughput: 1188.472\n",
      "  learn_time_ms: 3365.667\n",
      "  load_throughput: 18682868.597\n",
      "  load_time_ms: 0.214\n",
      "  sample_throughput: 490.138\n",
      "  sample_time_ms: 8160.974\n",
      "  update_time_ms: 2.276\n",
      "timestamp: 1658400224\n",
      "timesteps_since_restore: 3420000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3420000\n",
      "training_iteration: 855\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3424000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-43-55\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17832\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17820672690868378\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002866168273612857\n",
      "        model: {}\n",
      "        policy_loss: 0.0023344887886196375\n",
      "        total_loss: 3.2281413078308105\n",
      "        vf_explained_var: -0.0642809197306633\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3424000\n",
      "  num_agent_steps_trained: 3424000\n",
      "  num_steps_sampled: 3424000\n",
      "  num_steps_trained: 3424000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 856\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.962500000000006\n",
      "  ram_util_percent: 87.99375\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07089590068973131\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08132463772975912\n",
      "  mean_inference_ms: 0.7785830938293664\n",
      "  mean_raw_obs_processing_ms: 0.0939473508831029\n",
      "time_since_restore: 6272.490910053253\n",
      "time_this_iter_s: 11.03716230392456\n",
      "time_total_s: 6272.490910053253\n",
      "timers:\n",
      "  learn_throughput: 1173.003\n",
      "  learn_time_ms: 3410.05\n",
      "  load_throughput: 19560704.209\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 482.955\n",
      "  sample_time_ms: 8282.348\n",
      "  update_time_ms: 2.285\n",
      "timestamp: 1658400235\n",
      "timesteps_since_restore: 3424000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3424000\n",
      "training_iteration: 856\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3428000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-44-04\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17852\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19190430641174316\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002503439784049988\n",
      "        model: {}\n",
      "        policy_loss: 0.0025974370073527098\n",
      "        total_loss: 3.2284040451049805\n",
      "        vf_explained_var: -0.05980604141950607\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3428000\n",
      "  num_agent_steps_trained: 3428000\n",
      "  num_steps_sampled: 3428000\n",
      "  num_steps_trained: 3428000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 857\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.52307692307693\n",
      "  ram_util_percent: 88.03076923076922\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07092104906093828\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08135296941831063\n",
      "  mean_inference_ms: 0.7788540983631494\n",
      "  mean_raw_obs_processing_ms: 0.09397722828343019\n",
      "time_since_restore: 6281.570925474167\n",
      "time_this_iter_s: 9.080015420913696\n",
      "time_total_s: 6281.570925474167\n",
      "timers:\n",
      "  learn_throughput: 1174.195\n",
      "  learn_time_ms: 3406.59\n",
      "  load_throughput: 19445081.131\n",
      "  load_time_ms: 0.206\n",
      "  sample_throughput: 479.039\n",
      "  sample_time_ms: 8350.043\n",
      "  update_time_ms: 2.254\n",
      "timestamp: 1658400244\n",
      "timesteps_since_restore: 3428000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3428000\n",
      "training_iteration: 857\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3432000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-44-13\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17872\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21085861325263977\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004464348312467337\n",
      "        model: {}\n",
      "        policy_loss: 0.000832662801258266\n",
      "        total_loss: 3.226639747619629\n",
      "        vf_explained_var: -0.06451603025197983\n",
      "        vf_loss: 3.225806951522827\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3432000\n",
      "  num_agent_steps_trained: 3432000\n",
      "  num_steps_sampled: 3432000\n",
      "  num_steps_trained: 3432000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 858\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.528571428571425\n",
      "  ram_util_percent: 88.13571428571429\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07095264299255011\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0813888378162425\n",
      "  mean_inference_ms: 0.7791934627550424\n",
      "  mean_raw_obs_processing_ms: 0.09401525983460982\n",
      "time_since_restore: 6291.023013830185\n",
      "time_this_iter_s: 9.452088356018066\n",
      "time_total_s: 6291.023013830185\n",
      "timers:\n",
      "  learn_throughput: 1165.92\n",
      "  learn_time_ms: 3430.768\n",
      "  load_throughput: 19237720.445\n",
      "  load_time_ms: 0.208\n",
      "  sample_throughput: 471.151\n",
      "  sample_time_ms: 8489.839\n",
      "  update_time_ms: 2.321\n",
      "timestamp: 1658400253\n",
      "timesteps_since_restore: 3432000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3432000\n",
      "training_iteration: 858\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3436000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-44-21\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17892\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1720428168773651\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003174958750605583\n",
      "        model: {}\n",
      "        policy_loss: 0.0018111802637577057\n",
      "        total_loss: 3.2276175022125244\n",
      "        vf_explained_var: 0.0002036702207988128\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3436000\n",
      "  num_agent_steps_trained: 3436000\n",
      "  num_steps_sampled: 3436000\n",
      "  num_steps_trained: 3436000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 859\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.027272727272724\n",
      "  ram_util_percent: 88.09090909090908\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07098241324773405\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08142211361161739\n",
      "  mean_inference_ms: 0.7795130630367084\n",
      "  mean_raw_obs_processing_ms: 0.09405098357962752\n",
      "time_since_restore: 6299.17042350769\n",
      "time_this_iter_s: 8.147409677505493\n",
      "time_total_s: 6299.17042350769\n",
      "timers:\n",
      "  learn_throughput: 1167.566\n",
      "  learn_time_ms: 3425.93\n",
      "  load_throughput: 18460845.07\n",
      "  load_time_ms: 0.217\n",
      "  sample_throughput: 466.488\n",
      "  sample_time_ms: 8574.713\n",
      "  update_time_ms: 2.333\n",
      "timestamp: 1658400261\n",
      "timesteps_since_restore: 3436000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3436000\n",
      "training_iteration: 859\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3440000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-44-29\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17912\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19945983588695526\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002097398042678833\n",
      "        model: {}\n",
      "        policy_loss: 0.0031946967355906963\n",
      "        total_loss: 3.229001760482788\n",
      "        vf_explained_var: -0.06451597809791565\n",
      "        vf_loss: 3.225806951522827\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3440000\n",
      "  num_agent_steps_trained: 3440000\n",
      "  num_steps_sampled: 3440000\n",
      "  num_steps_trained: 3440000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 860\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.53636363636364\n",
      "  ram_util_percent: 88.05454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07101137523456964\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0814544243422033\n",
      "  mean_inference_ms: 0.7798241924213827\n",
      "  mean_raw_obs_processing_ms: 0.09408598681367815\n",
      "time_since_restore: 6306.867880582809\n",
      "time_this_iter_s: 7.6974570751190186\n",
      "time_total_s: 6306.867880582809\n",
      "timers:\n",
      "  learn_throughput: 1171.794\n",
      "  learn_time_ms: 3413.57\n",
      "  load_throughput: 18337759.318\n",
      "  load_time_ms: 0.218\n",
      "  sample_throughput: 467.635\n",
      "  sample_time_ms: 8553.676\n",
      "  update_time_ms: 2.385\n",
      "timestamp: 1658400269\n",
      "timesteps_since_restore: 3440000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3440000\n",
      "training_iteration: 860\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3444000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-44-37\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17932\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20030729472637177\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036024749279022217\n",
      "        model: {}\n",
      "        policy_loss: 0.0015981345204636455\n",
      "        total_loss: 3.227404832839966\n",
      "        vf_explained_var: -0.04791276156902313\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3444000\n",
      "  num_agent_steps_trained: 3444000\n",
      "  num_steps_sampled: 3444000\n",
      "  num_steps_trained: 3444000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 861\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.78181818181818\n",
      "  ram_util_percent: 88.05454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07102996329889087\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08147609527511099\n",
      "  mean_inference_ms: 0.7800242837651752\n",
      "  mean_raw_obs_processing_ms: 0.0941091817238047\n",
      "time_since_restore: 6314.677809715271\n",
      "time_this_iter_s: 7.809929132461548\n",
      "time_total_s: 6314.677809715271\n",
      "timers:\n",
      "  learn_throughput: 1170.718\n",
      "  learn_time_ms: 3416.708\n",
      "  load_throughput: 18481180.877\n",
      "  load_time_ms: 0.216\n",
      "  sample_throughput: 467.417\n",
      "  sample_time_ms: 8557.662\n",
      "  update_time_ms: 2.411\n",
      "timestamp: 1658400277\n",
      "timesteps_since_restore: 3444000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3444000\n",
      "training_iteration: 861\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3448000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-44-45\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17952\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.219192773103714\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003621451323851943\n",
      "        model: {}\n",
      "        policy_loss: 0.0008051518234424293\n",
      "        total_loss: 3.226611852645874\n",
      "        vf_explained_var: -0.032367218285799026\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3448000\n",
      "  num_agent_steps_trained: 3448000\n",
      "  num_steps_sampled: 3448000\n",
      "  num_steps_trained: 3448000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 862\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.07272727272727\n",
      "  ram_util_percent: 88.05454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07104392890182115\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08149256249878058\n",
      "  mean_inference_ms: 0.7801718776495928\n",
      "  mean_raw_obs_processing_ms: 0.09412694342592479\n",
      "time_since_restore: 6322.313819169998\n",
      "time_this_iter_s: 7.636009454727173\n",
      "time_total_s: 6322.313819169998\n",
      "timers:\n",
      "  learn_throughput: 1171.072\n",
      "  learn_time_ms: 3415.674\n",
      "  load_throughput: 18373908.663\n",
      "  load_time_ms: 0.218\n",
      "  sample_throughput: 467.185\n",
      "  sample_time_ms: 8561.924\n",
      "  update_time_ms: 2.41\n",
      "timestamp: 1658400285\n",
      "timesteps_since_restore: 3448000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3448000\n",
      "training_iteration: 862\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3452000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-44-53\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17972\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1891375184059143\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003144284011796117\n",
      "        model: {}\n",
      "        policy_loss: 0.0019819068256765604\n",
      "        total_loss: 3.2277886867523193\n",
      "        vf_explained_var: -0.06451622396707535\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3452000\n",
      "  num_agent_steps_trained: 3452000\n",
      "  num_steps_sampled: 3452000\n",
      "  num_steps_trained: 3452000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 863\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.65833333333334\n",
      "  ram_util_percent: 88.04166666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07105174120989083\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08150184433766125\n",
      "  mean_inference_ms: 0.7802564052056337\n",
      "  mean_raw_obs_processing_ms: 0.09413712574499809\n",
      "time_since_restore: 6330.283297300339\n",
      "time_this_iter_s: 7.969478130340576\n",
      "time_total_s: 6330.283297300339\n",
      "timers:\n",
      "  learn_throughput: 1162.613\n",
      "  learn_time_ms: 3440.525\n",
      "  load_throughput: 18236104.348\n",
      "  load_time_ms: 0.219\n",
      "  sample_throughput: 466.534\n",
      "  sample_time_ms: 8573.873\n",
      "  update_time_ms: 2.476\n",
      "timestamp: 1658400293\n",
      "timesteps_since_restore: 3452000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3452000\n",
      "training_iteration: 863\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3456000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-45-01\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 17992\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19926905632019043\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001828244305215776\n",
      "        model: {}\n",
      "        policy_loss: 0.003026882652193308\n",
      "        total_loss: 3.2288339138031006\n",
      "        vf_explained_var: -3.0260829589678906e-05\n",
      "        vf_loss: 3.225806951522827\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3456000\n",
      "  num_agent_steps_trained: 3456000\n",
      "  num_steps_sampled: 3456000\n",
      "  num_steps_trained: 3456000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 864\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.9\n",
      "  ram_util_percent: 88.15000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07106037782895902\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08151203098691719\n",
      "  mean_inference_ms: 0.7803483882994681\n",
      "  mean_raw_obs_processing_ms: 0.09414814365820988\n",
      "time_since_restore: 6338.88060259819\n",
      "time_this_iter_s: 8.597305297851562\n",
      "time_total_s: 6338.88060259819\n",
      "timers:\n",
      "  learn_throughput: 1165.546\n",
      "  learn_time_ms: 3431.867\n",
      "  load_throughput: 18208395.919\n",
      "  load_time_ms: 0.22\n",
      "  sample_throughput: 466.708\n",
      "  sample_time_ms: 8570.664\n",
      "  update_time_ms: 2.437\n",
      "timestamp: 1658400301\n",
      "timesteps_since_restore: 3456000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3456000\n",
      "training_iteration: 864\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3460000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-45-09\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18012\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19611576199531555\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035853427834808826\n",
      "        model: {}\n",
      "        policy_loss: 0.0010866911616176367\n",
      "        total_loss: 3.226893424987793\n",
      "        vf_explained_var: -0.0016656495863571763\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3460000\n",
      "  num_agent_steps_trained: 3460000\n",
      "  num_steps_sampled: 3460000\n",
      "  num_steps_trained: 3460000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 865\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.60909090909091\n",
      "  ram_util_percent: 88.26363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07106991522478412\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08152319126409889\n",
      "  mean_inference_ms: 0.7804478942138343\n",
      "  mean_raw_obs_processing_ms: 0.09416011125631468\n",
      "time_since_restore: 6346.834426403046\n",
      "time_this_iter_s: 7.953823804855347\n",
      "time_total_s: 6346.834426403046\n",
      "timers:\n",
      "  learn_throughput: 1165.682\n",
      "  learn_time_ms: 3431.467\n",
      "  load_throughput: 18895389.12\n",
      "  load_time_ms: 0.212\n",
      "  sample_throughput: 467.066\n",
      "  sample_time_ms: 8564.108\n",
      "  update_time_ms: 2.413\n",
      "timestamp: 1658400309\n",
      "timesteps_since_restore: 3460000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3460000\n",
      "training_iteration: 865\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3464000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-45-17\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18032\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1838047355413437\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025736589450389147\n",
      "        model: {}\n",
      "        policy_loss: 0.002323353895917535\n",
      "        total_loss: 3.22813081741333\n",
      "        vf_explained_var: 0.0007226066663861275\n",
      "        vf_loss: 3.2258074283599854\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3464000\n",
      "  num_agent_steps_trained: 3464000\n",
      "  num_steps_sampled: 3464000\n",
      "  num_steps_trained: 3464000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 866\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.59166666666667\n",
      "  ram_util_percent: 88.20833333333331\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07108045589628909\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08153492748357122\n",
      "  mean_inference_ms: 0.7805585959087088\n",
      "  mean_raw_obs_processing_ms: 0.0941731245631398\n",
      "time_since_restore: 6354.951111316681\n",
      "time_this_iter_s: 8.116684913635254\n",
      "time_total_s: 6354.951111316681\n",
      "timers:\n",
      "  learn_throughput: 1189.848\n",
      "  learn_time_ms: 3361.775\n",
      "  load_throughput: 19707759.897\n",
      "  load_time_ms: 0.203\n",
      "  sample_throughput: 479.608\n",
      "  sample_time_ms: 8340.148\n",
      "  update_time_ms: 2.439\n",
      "timestamp: 1658400317\n",
      "timesteps_since_restore: 3464000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3464000\n",
      "training_iteration: 866\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3468000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-45-25\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18052\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20500513911247253\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0043055652640759945\n",
      "        model: {}\n",
      "        policy_loss: 0.001428018556907773\n",
      "        total_loss: 3.2272353172302246\n",
      "        vf_explained_var: -0.0005776782054454088\n",
      "        vf_loss: 3.225806951522827\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3468000\n",
      "  num_agent_steps_trained: 3468000\n",
      "  num_steps_sampled: 3468000\n",
      "  num_steps_trained: 3468000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 867\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.5\n",
      "  ram_util_percent: 88.22727272727272\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07109157821140573\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08154702550642774\n",
      "  mean_inference_ms: 0.7806741019378393\n",
      "  mean_raw_obs_processing_ms: 0.09418648732555684\n",
      "time_since_restore: 6362.688041687012\n",
      "time_this_iter_s: 7.7369303703308105\n",
      "time_total_s: 6362.688041687012\n",
      "timers:\n",
      "  learn_throughput: 1200.26\n",
      "  learn_time_ms: 3332.61\n",
      "  load_throughput: 19604131.806\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 489.81\n",
      "  sample_time_ms: 8166.432\n",
      "  update_time_ms: 2.401\n",
      "timestamp: 1658400325\n",
      "timesteps_since_restore: 3468000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3468000\n",
      "training_iteration: 867\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3472000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-45-33\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18072\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21406690776348114\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025955354794859886\n",
      "        model: {}\n",
      "        policy_loss: 0.0017105869483202696\n",
      "        total_loss: 3.227518081665039\n",
      "        vf_explained_var: 0.0005027535953558981\n",
      "        vf_loss: 3.2258071899414062\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3472000\n",
      "  num_agent_steps_trained: 3472000\n",
      "  num_steps_sampled: 3472000\n",
      "  num_steps_trained: 3472000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 868\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.68181818181818\n",
      "  ram_util_percent: 88.1909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07110253336657688\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08155877813331644\n",
      "  mean_inference_ms: 0.7807839755397583\n",
      "  mean_raw_obs_processing_ms: 0.09419942321982351\n",
      "time_since_restore: 6370.44038772583\n",
      "time_this_iter_s: 7.752346038818359\n",
      "time_total_s: 6370.44038772583\n",
      "timers:\n",
      "  learn_throughput: 1205.432\n",
      "  learn_time_ms: 3318.312\n",
      "  load_throughput: 19645451.991\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 501.185\n",
      "  sample_time_ms: 7981.091\n",
      "  update_time_ms: 2.382\n",
      "timestamp: 1658400333\n",
      "timesteps_since_restore: 3472000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3472000\n",
      "training_iteration: 868\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3476000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-45-41\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18092\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21101845800876617\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036240608897060156\n",
      "        model: {}\n",
      "        policy_loss: 0.0018446875037625432\n",
      "        total_loss: 3.2276511192321777\n",
      "        vf_explained_var: -0.06451615691184998\n",
      "        vf_loss: 3.225806474685669\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3476000\n",
      "  num_agent_steps_trained: 3476000\n",
      "  num_steps_sampled: 3476000\n",
      "  num_steps_trained: 3476000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 869\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.27272727272727\n",
      "  ram_util_percent: 88.10909090909092\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07111140682766899\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08156832506948299\n",
      "  mean_inference_ms: 0.780872275629882\n",
      "  mean_raw_obs_processing_ms: 0.09421044300560151\n",
      "time_since_restore: 6378.222846031189\n",
      "time_this_iter_s: 7.782458305358887\n",
      "time_total_s: 6378.222846031189\n",
      "timers:\n",
      "  learn_throughput: 1207.804\n",
      "  learn_time_ms: 3311.795\n",
      "  load_throughput: 20776738.08\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 504.004\n",
      "  sample_time_ms: 7936.437\n",
      "  update_time_ms: 2.375\n",
      "timestamp: 1658400341\n",
      "timesteps_since_restore: 3476000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3476000\n",
      "training_iteration: 869\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3480000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-45-49\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18112\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22374500334262848\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030282686930149794\n",
      "        model: {}\n",
      "        policy_loss: 0.002012736164033413\n",
      "        total_loss: 3.2278196811676025\n",
      "        vf_explained_var: -0.0645160973072052\n",
      "        vf_loss: 3.225806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3480000\n",
      "  num_agent_steps_trained: 3480000\n",
      "  num_steps_sampled: 3480000\n",
      "  num_steps_trained: 3480000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 870\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.23333333333334\n",
      "  ram_util_percent: 88.13333333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07112018971732172\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08157780013997047\n",
      "  mean_inference_ms: 0.7809597295075715\n",
      "  mean_raw_obs_processing_ms: 0.09422106434551156\n",
      "time_since_restore: 6386.0327072143555\n",
      "time_this_iter_s: 7.809861183166504\n",
      "time_total_s: 6386.0327072143555\n",
      "timers:\n",
      "  learn_throughput: 1209.677\n",
      "  learn_time_ms: 3306.667\n",
      "  load_throughput: 22060770.546\n",
      "  load_time_ms: 0.181\n",
      "  sample_throughput: 503.372\n",
      "  sample_time_ms: 7946.412\n",
      "  update_time_ms: 2.343\n",
      "timestamp: 1658400349\n",
      "timesteps_since_restore: 3480000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3480000\n",
      "training_iteration: 870\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3484000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-45-56\n",
      "done: false\n",
      "episode_len_mean: 199.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.38\n",
      "episode_reward_min: 138.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18132\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21721287071704865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003546865424141288\n",
      "        model: {}\n",
      "        policy_loss: -3.2355706935049966e-05\n",
      "        total_loss: 1.3507744073867798\n",
      "        vf_explained_var: -0.22580614686012268\n",
      "        vf_loss: 1.350806713104248\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3484000\n",
      "  num_agent_steps_trained: 3484000\n",
      "  num_steps_sampled: 3484000\n",
      "  num_steps_trained: 3484000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 871\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.481818181818184\n",
      "  ram_util_percent: 88.12727272727274\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0711281836061809\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08158615854870814\n",
      "  mean_inference_ms: 0.7810353100301455\n",
      "  mean_raw_obs_processing_ms: 0.09423093736640567\n",
      "time_since_restore: 6393.825369119644\n",
      "time_this_iter_s: 7.792661905288696\n",
      "time_total_s: 6393.825369119644\n",
      "timers:\n",
      "  learn_throughput: 1210.361\n",
      "  learn_time_ms: 3304.799\n",
      "  load_throughput: 21825440.354\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 503.724\n",
      "  sample_time_ms: 7940.864\n",
      "  update_time_ms: 2.34\n",
      "timestamp: 1658400356\n",
      "timesteps_since_restore: 3484000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3484000\n",
      "training_iteration: 871\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3488000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-46-05\n",
      "done: false\n",
      "episode_len_mean: 199.38\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.38\n",
      "episode_reward_min: 138.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18152\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21294565498828888\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.009440278634428978\n",
      "        model: {}\n",
      "        policy_loss: -0.004025578033179045\n",
      "        total_loss: 0.09678089618682861\n",
      "        vf_explained_var: -0.2350853979587555\n",
      "        vf_loss: 0.10080645978450775\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3488000\n",
      "  num_agent_steps_trained: 3488000\n",
      "  num_steps_sampled: 3488000\n",
      "  num_steps_trained: 3488000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 872\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.61666666666667\n",
      "  ram_util_percent: 88.09166666666668\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07113776732798385\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08159675131469576\n",
      "  mean_inference_ms: 0.781131346173739\n",
      "  mean_raw_obs_processing_ms: 0.09424306878063973\n",
      "time_since_restore: 6402.3639669418335\n",
      "time_this_iter_s: 8.538597822189331\n",
      "time_total_s: 6402.3639669418335\n",
      "timers:\n",
      "  learn_throughput: 1198.652\n",
      "  learn_time_ms: 3337.081\n",
      "  load_throughput: 21910952.07\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 500.195\n",
      "  sample_time_ms: 7996.88\n",
      "  update_time_ms: 2.401\n",
      "timestamp: 1658400365\n",
      "timesteps_since_restore: 3488000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3488000\n",
      "training_iteration: 872\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3492000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-46-16\n",
      "done: false\n",
      "episode_len_mean: 199.29\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.29\n",
      "episode_reward_min: 138.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 18173\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21808090806007385\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0045119039714336395\n",
      "        model: {}\n",
      "        policy_loss: -0.02046838216483593\n",
      "        total_loss: 3.3868191242218018\n",
      "        vf_explained_var: -0.19888071715831757\n",
      "        vf_loss: 3.407287359237671\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3492000\n",
      "  num_agent_steps_trained: 3492000\n",
      "  num_steps_sampled: 3492000\n",
      "  num_steps_trained: 3492000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 873\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 55.99375\n",
      "  ram_util_percent: 88.4875\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07115707597278599\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0816180122711689\n",
      "  mean_inference_ms: 0.7813409257265005\n",
      "  mean_raw_obs_processing_ms: 0.09426649238495496\n",
      "time_since_restore: 6413.408205509186\n",
      "time_this_iter_s: 11.044238567352295\n",
      "time_total_s: 6413.408205509186\n",
      "timers:\n",
      "  learn_throughput: 1169.39\n",
      "  learn_time_ms: 3420.587\n",
      "  load_throughput: 21873814.863\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 484.612\n",
      "  sample_time_ms: 8254.03\n",
      "  update_time_ms: 2.325\n",
      "timestamp: 1658400376\n",
      "timesteps_since_restore: 3492000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3492000\n",
      "training_iteration: 873\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3496000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-46-28\n",
      "done: false\n",
      "episode_len_mean: 199.29\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.29\n",
      "episode_reward_min: 138.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18193\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21435293555259705\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002827609423547983\n",
      "        model: {}\n",
      "        policy_loss: -0.011180595494806767\n",
      "        total_loss: 9.653637886047363\n",
      "        vf_explained_var: 2.579022577720025e-07\n",
      "        vf_loss: 9.66481876373291\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3496000\n",
      "  num_agent_steps_trained: 3496000\n",
      "  num_steps_sampled: 3496000\n",
      "  num_steps_trained: 3496000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 874\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 59.7875\n",
      "  ram_util_percent: 88.78125\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07118592182107099\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0816498127003509\n",
      "  mean_inference_ms: 0.7816568384600394\n",
      "  mean_raw_obs_processing_ms: 0.09430241328773559\n",
      "time_since_restore: 6424.907956361771\n",
      "time_this_iter_s: 11.499750852584839\n",
      "time_total_s: 6424.907956361771\n",
      "timers:\n",
      "  learn_throughput: 1146.144\n",
      "  learn_time_ms: 3489.963\n",
      "  load_throughput: 20487502.748\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 467.378\n",
      "  sample_time_ms: 8558.389\n",
      "  update_time_ms: 2.349\n",
      "timestamp: 1658400388\n",
      "timesteps_since_restore: 3496000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3496000\n",
      "training_iteration: 874\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3500000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-46-36\n",
      "done: false\n",
      "episode_len_mean: 199.01\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.01\n",
      "episode_reward_min: 138.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18213\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24131163954734802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004305989947170019\n",
      "        model: {}\n",
      "        policy_loss: 0.007471410557627678\n",
      "        total_loss: 9.311906814575195\n",
      "        vf_explained_var: 2.2901642751094187e-06\n",
      "        vf_loss: 9.304435729980469\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3500000\n",
      "  num_agent_steps_trained: 3500000\n",
      "  num_steps_sampled: 3500000\n",
      "  num_steps_trained: 3500000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 875\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.083333333333336\n",
      "  ram_util_percent: 88.94999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07121772314049508\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08168484557887522\n",
      "  mean_inference_ms: 0.7820049418116437\n",
      "  mean_raw_obs_processing_ms: 0.09434222352223984\n",
      "time_since_restore: 6433.480021715164\n",
      "time_this_iter_s: 8.572065353393555\n",
      "time_total_s: 6433.480021715164\n",
      "timers:\n",
      "  learn_throughput: 1149.975\n",
      "  learn_time_ms: 3478.338\n",
      "  load_throughput: 20430121.773\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 459.754\n",
      "  sample_time_ms: 8700.31\n",
      "  update_time_ms: 2.34\n",
      "timestamp: 1658400396\n",
      "timesteps_since_restore: 3500000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3500000\n",
      "training_iteration: 875\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3504000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-46-44\n",
      "done: false\n",
      "episode_len_mean: 196.4\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.4\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 18234\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20166409015655518\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033211016561836004\n",
      "        model: {}\n",
      "        policy_loss: 0.004968731198459864\n",
      "        total_loss: 6.796802997589111\n",
      "        vf_explained_var: 1.0139839332623524e-06\n",
      "        vf_loss: 6.791834831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3504000\n",
      "  num_agent_steps_trained: 3504000\n",
      "  num_steps_sampled: 3504000\n",
      "  num_steps_trained: 3504000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 876\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.31666666666666\n",
      "  ram_util_percent: 88.7\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07125106731266329\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08172262400001742\n",
      "  mean_inference_ms: 0.7823731803163682\n",
      "  mean_raw_obs_processing_ms: 0.09438374223115593\n",
      "time_since_restore: 6441.385409116745\n",
      "time_this_iter_s: 7.9053874015808105\n",
      "time_total_s: 6441.385409116745\n",
      "timers:\n",
      "  learn_throughput: 1152.872\n",
      "  learn_time_ms: 3469.595\n",
      "  load_throughput: 20254999.396\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 461.03\n",
      "  sample_time_ms: 8676.229\n",
      "  update_time_ms: 2.361\n",
      "timestamp: 1658400404\n",
      "timesteps_since_restore: 3504000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3504000\n",
      "training_iteration: 876\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3508000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-46-52\n",
      "done: false\n",
      "episode_len_mean: 194.69\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.69\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 18255\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21307115256786346\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026985635049641132\n",
      "        model: {}\n",
      "        policy_loss: -0.0009199088672176003\n",
      "        total_loss: 2.6654107570648193\n",
      "        vf_explained_var: -0.12435618042945862\n",
      "        vf_loss: 2.666330575942993\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3508000\n",
      "  num_agent_steps_trained: 3508000\n",
      "  num_steps_sampled: 3508000\n",
      "  num_steps_trained: 3508000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 877\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.7\n",
      "  ram_util_percent: 88.73636363636362\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07128219676276219\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08175785823501418\n",
      "  mean_inference_ms: 0.7827151073071766\n",
      "  mean_raw_obs_processing_ms: 0.09442295270409698\n",
      "time_since_restore: 6449.550742864609\n",
      "time_this_iter_s: 8.16533374786377\n",
      "time_total_s: 6449.550742864609\n",
      "timers:\n",
      "  learn_throughput: 1145.669\n",
      "  learn_time_ms: 3491.411\n",
      "  load_throughput: 20355758.311\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 460.44\n",
      "  sample_time_ms: 8687.341\n",
      "  update_time_ms: 2.434\n",
      "timestamp: 1658400412\n",
      "timesteps_since_restore: 3508000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3508000\n",
      "training_iteration: 877\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3512000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-47-00\n",
      "done: false\n",
      "episode_len_mean: 194.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.36\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18275\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23554615676403046\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004492254462093115\n",
      "        model: {}\n",
      "        policy_loss: -0.0020574727095663548\n",
      "        total_loss: 2.7297983169555664\n",
      "        vf_explained_var: -0.120075523853302\n",
      "        vf_loss: 2.7318553924560547\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3512000\n",
      "  num_agent_steps_trained: 3512000\n",
      "  num_steps_sampled: 3512000\n",
      "  num_steps_trained: 3512000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 878\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.525\n",
      "  ram_util_percent: 88.74166666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07130437824430519\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08178342956368173\n",
      "  mean_inference_ms: 0.7829543442882904\n",
      "  mean_raw_obs_processing_ms: 0.09445208933202473\n",
      "time_since_restore: 6457.611389160156\n",
      "time_this_iter_s: 8.060646295547485\n",
      "time_total_s: 6457.611389160156\n",
      "timers:\n",
      "  learn_throughput: 1147.829\n",
      "  learn_time_ms: 3484.84\n",
      "  load_throughput: 20437588.013\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 457.325\n",
      "  sample_time_ms: 8746.514\n",
      "  update_time_ms: 2.474\n",
      "timestamp: 1658400420\n",
      "timesteps_since_restore: 3512000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3512000\n",
      "training_iteration: 878\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3516000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-47-09\n",
      "done: false\n",
      "episode_len_mean: 194.36\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.36\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18295\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21056289970874786\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002763081807643175\n",
      "        model: {}\n",
      "        policy_loss: 0.0008335831807926297\n",
      "        total_loss: 1.4625270366668701\n",
      "        vf_explained_var: -0.23334790766239166\n",
      "        vf_loss: 1.461693525314331\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3516000\n",
      "  num_agent_steps_trained: 3516000\n",
      "  num_steps_sampled: 3516000\n",
      "  num_steps_trained: 3516000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 879\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.32500000000001\n",
      "  ram_util_percent: 88.74166666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07131676971981768\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0817980365570382\n",
      "  mean_inference_ms: 0.7830831680182261\n",
      "  mean_raw_obs_processing_ms: 0.09446808650605383\n",
      "time_since_restore: 6465.859930753708\n",
      "time_this_iter_s: 8.248541593551636\n",
      "time_total_s: 6465.859930753708\n",
      "timers:\n",
      "  learn_throughput: 1131.319\n",
      "  learn_time_ms: 3535.697\n",
      "  load_throughput: 20412721.742\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 457.914\n",
      "  sample_time_ms: 8735.268\n",
      "  update_time_ms: 2.513\n",
      "timestamp: 1658400429\n",
      "timesteps_since_restore: 3516000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3516000\n",
      "training_iteration: 879\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3520000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-47-19\n",
      "done: false\n",
      "episode_len_mean: 194.64\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.64\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18315\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20379051566123962\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002939211903139949\n",
      "        model: {}\n",
      "        policy_loss: 8.148499910021201e-05\n",
      "        total_loss: 1.4617751836776733\n",
      "        vf_explained_var: -0.25794661045074463\n",
      "        vf_loss: 1.4616937637329102\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3520000\n",
      "  num_agent_steps_trained: 3520000\n",
      "  num_steps_sampled: 3520000\n",
      "  num_steps_trained: 3520000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 880\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.607142857142854\n",
      "  ram_util_percent: 88.90714285714284\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07132995791158599\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08181341938016098\n",
      "  mean_inference_ms: 0.7832293060251473\n",
      "  mean_raw_obs_processing_ms: 0.0944850498867364\n",
      "time_since_restore: 6475.9919583797455\n",
      "time_this_iter_s: 10.132027626037598\n",
      "time_total_s: 6475.9919583797455\n",
      "timers:\n",
      "  learn_throughput: 1092.076\n",
      "  learn_time_ms: 3662.747\n",
      "  load_throughput: 20542691.319\n",
      "  load_time_ms: 0.195\n",
      "  sample_throughput: 449.822\n",
      "  sample_time_ms: 8892.402\n",
      "  update_time_ms: 2.583\n",
      "timestamp: 1658400439\n",
      "timesteps_since_restore: 3520000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3520000\n",
      "training_iteration: 880\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3524000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-47-27\n",
      "done: false\n",
      "episode_len_mean: 196.5\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.5\n",
      "episode_reward_min: 87.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 18336\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20688122510910034\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026112995110452175\n",
      "        model: {}\n",
      "        policy_loss: 0.0002976885298267007\n",
      "        total_loss: 3.1076576709747314\n",
      "        vf_explained_var: -0.12903158366680145\n",
      "        vf_loss: 3.1073598861694336\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3524000\n",
      "  num_agent_steps_trained: 3524000\n",
      "  num_steps_sampled: 3524000\n",
      "  num_steps_trained: 3524000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 881\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.258333333333326\n",
      "  ram_util_percent: 88.98333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07134565048715819\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08183099131285726\n",
      "  mean_inference_ms: 0.78340199211725\n",
      "  mean_raw_obs_processing_ms: 0.09450561106763519\n",
      "time_since_restore: 6484.419712305069\n",
      "time_this_iter_s: 8.427753925323486\n",
      "time_total_s: 6484.419712305069\n",
      "timers:\n",
      "  learn_throughput: 1089.84\n",
      "  learn_time_ms: 3670.263\n",
      "  load_throughput: 20615895.797\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 440.718\n",
      "  sample_time_ms: 9076.099\n",
      "  update_time_ms: 2.594\n",
      "timestamp: 1658400447\n",
      "timesteps_since_restore: 3524000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3524000\n",
      "training_iteration: 881\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3528000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-47-37\n",
      "done: false\n",
      "episode_len_mean: 198.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.21\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18356\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1977822631597519\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002588327042758465\n",
      "        model: {}\n",
      "        policy_loss: 0.0038263832684606314\n",
      "        total_loss: 4.640923023223877\n",
      "        vf_explained_var: 1.2177292507686843e-09\n",
      "        vf_loss: 4.637096881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3528000\n",
      "  num_agent_steps_trained: 3528000\n",
      "  num_steps_sampled: 3528000\n",
      "  num_steps_trained: 3528000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 882\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.24285714285714\n",
      "  ram_util_percent: 88.94285714285715\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07136576236107178\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08185342334361316\n",
      "  mean_inference_ms: 0.7836231504301466\n",
      "  mean_raw_obs_processing_ms: 0.09453124307993921\n",
      "time_since_restore: 6494.148559808731\n",
      "time_this_iter_s: 9.72884750366211\n",
      "time_total_s: 6494.148559808731\n",
      "timers:\n",
      "  learn_throughput: 1085.299\n",
      "  learn_time_ms: 3685.619\n",
      "  load_throughput: 20049254.302\n",
      "  load_time_ms: 0.2\n",
      "  sample_throughput: 435.373\n",
      "  sample_time_ms: 9187.517\n",
      "  update_time_ms: 2.534\n",
      "timestamp: 1658400457\n",
      "timesteps_since_restore: 3528000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3528000\n",
      "training_iteration: 882\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3532000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-47-47\n",
      "done: false\n",
      "episode_len_mean: 198.63\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.63\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18376\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21317130327224731\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002079445170238614\n",
      "        model: {}\n",
      "        policy_loss: 0.004735388793051243\n",
      "        total_loss: 4.64183235168457\n",
      "        vf_explained_var: 7.171784943693638e-08\n",
      "        vf_loss: 4.637096881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3532000\n",
      "  num_agent_steps_trained: 3532000\n",
      "  num_steps_sampled: 3532000\n",
      "  num_steps_trained: 3532000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 883\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 55.50666666666667\n",
      "  ram_util_percent: 88.93333333333332\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07138939112249665\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08187915292597231\n",
      "  mean_inference_ms: 0.783879720551543\n",
      "  mean_raw_obs_processing_ms: 0.0945599175570344\n",
      "time_since_restore: 6504.275747537613\n",
      "time_this_iter_s: 10.127187728881836\n",
      "time_total_s: 6504.275747537613\n",
      "timers:\n",
      "  learn_throughput: 1077.976\n",
      "  learn_time_ms: 3710.659\n",
      "  load_throughput: 20269682.252\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 440.217\n",
      "  sample_time_ms: 9086.426\n",
      "  update_time_ms: 2.575\n",
      "timestamp: 1658400467\n",
      "timesteps_since_restore: 3532000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3532000\n",
      "training_iteration: 883\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3536000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-47-57\n",
      "done: false\n",
      "episode_len_mean: 198.63\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.63\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18396\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1934049278497696\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036882110871374607\n",
      "        model: {}\n",
      "        policy_loss: 0.003447083756327629\n",
      "        total_loss: 4.6405439376831055\n",
      "        vf_explained_var: 6.601374735737409e-08\n",
      "        vf_loss: 4.637096881866455\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3536000\n",
      "  num_agent_steps_trained: 3536000\n",
      "  num_steps_sampled: 3536000\n",
      "  num_steps_trained: 3536000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 884\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.55384615384616\n",
      "  ram_util_percent: 89.24615384615385\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07141842624873952\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08191064930479193\n",
      "  mean_inference_ms: 0.7841978087458205\n",
      "  mean_raw_obs_processing_ms: 0.0945956935228717\n",
      "time_since_restore: 6513.845761299133\n",
      "time_this_iter_s: 9.570013761520386\n",
      "time_total_s: 6513.845761299133\n",
      "timers:\n",
      "  learn_throughput: 1098.073\n",
      "  learn_time_ms: 3642.744\n",
      "  load_throughput: 21636853.237\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 445.078\n",
      "  sample_time_ms: 8987.194\n",
      "  update_time_ms: 2.499\n",
      "timestamp: 1658400477\n",
      "timesteps_since_restore: 3536000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3536000\n",
      "training_iteration: 884\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3540000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-48-05\n",
      "done: false\n",
      "episode_len_mean: 198.63\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.63\n",
      "episode_reward_min: 92.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18416\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1817871779203415\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004175668582320213\n",
      "        model: {}\n",
      "        policy_loss: 0.0021589351817965508\n",
      "        total_loss: 4.639256954193115\n",
      "        vf_explained_var: -1.9163213238471144e-08\n",
      "        vf_loss: 4.6370978355407715\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3540000\n",
      "  num_agent_steps_trained: 3540000\n",
      "  num_steps_sampled: 3540000\n",
      "  num_steps_trained: 3540000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 885\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.525000000000006\n",
      "  ram_util_percent: 88.875\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07144575098302354\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08194052076109468\n",
      "  mean_inference_ms: 0.7844909323808372\n",
      "  mean_raw_obs_processing_ms: 0.09462910272938871\n",
      "time_since_restore: 6522.278034210205\n",
      "time_this_iter_s: 8.432272911071777\n",
      "time_total_s: 6522.278034210205\n",
      "timers:\n",
      "  learn_throughput: 1094.188\n",
      "  learn_time_ms: 3655.679\n",
      "  load_throughput: 21586742.151\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 449.868\n",
      "  sample_time_ms: 8891.497\n",
      "  update_time_ms: 2.498\n",
      "timestamp: 1658400485\n",
      "timesteps_since_restore: 3540000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3540000\n",
      "training_iteration: 885\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3544000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-48-16\n",
      "done: false\n",
      "episode_len_mean: 198.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.66\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 18437\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18130171298980713\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032382914796471596\n",
      "        model: {}\n",
      "        policy_loss: 0.006379200145602226\n",
      "        total_loss: 7.579465389251709\n",
      "        vf_explained_var: 6.880811724840896e-07\n",
      "        vf_loss: 7.573085784912109\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3544000\n",
      "  num_agent_steps_trained: 3544000\n",
      "  num_steps_sampled: 3544000\n",
      "  num_steps_trained: 3544000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 886\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 55.76\n",
      "  ram_util_percent: 88.86666666666665\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07147576457413328\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08197360564482128\n",
      "  mean_inference_ms: 0.7848103357641898\n",
      "  mean_raw_obs_processing_ms: 0.09466505354419809\n",
      "time_since_restore: 6532.756560087204\n",
      "time_this_iter_s: 10.478525876998901\n",
      "time_total_s: 6532.756560087204\n",
      "timers:\n",
      "  learn_throughput: 1042.711\n",
      "  learn_time_ms: 3836.155\n",
      "  load_throughput: 20378010.446\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 445.44\n",
      "  sample_time_ms: 8979.89\n",
      "  update_time_ms: 3.267\n",
      "timestamp: 1658400496\n",
      "timesteps_since_restore: 3544000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3544000\n",
      "training_iteration: 886\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3548000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-48-27\n",
      "done: false\n",
      "episode_len_mean: 198.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.66\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18457\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22010980546474457\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006891756784170866\n",
      "        model: {}\n",
      "        policy_loss: 0.005956787150353193\n",
      "        total_loss: 7.969666481018066\n",
      "        vf_explained_var: 3.067395937250694e-07\n",
      "        vf_loss: 7.963709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3548000\n",
      "  num_agent_steps_trained: 3548000\n",
      "  num_steps_sampled: 3548000\n",
      "  num_steps_trained: 3548000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 887\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 58.91875\n",
      "  ram_util_percent: 89.275\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07150945101515827\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0820105229910609\n",
      "  mean_inference_ms: 0.7851771075835374\n",
      "  mean_raw_obs_processing_ms: 0.09470687149798263\n",
      "time_since_restore: 6543.736013174057\n",
      "time_this_iter_s: 10.979453086853027\n",
      "time_total_s: 6543.736013174057\n",
      "timers:\n",
      "  learn_throughput: 1040.842\n",
      "  learn_time_ms: 3843.044\n",
      "  load_throughput: 18908166.347\n",
      "  load_time_ms: 0.212\n",
      "  sample_throughput: 423.75\n",
      "  sample_time_ms: 9439.533\n",
      "  update_time_ms: 3.263\n",
      "timestamp: 1658400507\n",
      "timesteps_since_restore: 3548000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3548000\n",
      "training_iteration: 887\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3552000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-48-35\n",
      "done: false\n",
      "episode_len_mean: 198.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.66\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18477\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1617257297039032\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003497221739962697\n",
      "        model: {}\n",
      "        policy_loss: 0.006546541582792997\n",
      "        total_loss: 7.97025728225708\n",
      "        vf_explained_var: 2.147049116274502e-08\n",
      "        vf_loss: 7.963710784912109\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3552000\n",
      "  num_agent_steps_trained: 3552000\n",
      "  num_steps_sampled: 3552000\n",
      "  num_steps_trained: 3552000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 888\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.224999999999994\n",
      "  ram_util_percent: 89.3\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07153930883356244\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0820440724027529\n",
      "  mean_inference_ms: 0.7855045239078011\n",
      "  mean_raw_obs_processing_ms: 0.09474455084906924\n",
      "time_since_restore: 6552.248433113098\n",
      "time_this_iter_s: 8.512419939041138\n",
      "time_total_s: 6552.248433113098\n",
      "timers:\n",
      "  learn_throughput: 1027.149\n",
      "  learn_time_ms: 3894.275\n",
      "  load_throughput: 18558867.257\n",
      "  load_time_ms: 0.216\n",
      "  sample_throughput: 423.651\n",
      "  sample_time_ms: 9441.733\n",
      "  update_time_ms: 3.195\n",
      "timestamp: 1658400515\n",
      "timesteps_since_restore: 3552000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3552000\n",
      "training_iteration: 888\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3556000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-48-43\n",
      "done: false\n",
      "episode_len_mean: 198.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.66\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18497\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18885257840156555\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034295665100216866\n",
      "        model: {}\n",
      "        policy_loss: 0.007708912715315819\n",
      "        total_loss: 7.971418380737305\n",
      "        vf_explained_var: 2.1380762404987763e-07\n",
      "        vf_loss: 7.963709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3556000\n",
      "  num_agent_steps_trained: 3556000\n",
      "  num_steps_sampled: 3556000\n",
      "  num_steps_trained: 3556000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 889\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.445454545454545\n",
      "  ram_util_percent: 88.95454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07156343604388614\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08207147981163172\n",
      "  mean_inference_ms: 0.7857672641780421\n",
      "  mean_raw_obs_processing_ms: 0.09477490329076506\n",
      "time_since_restore: 6559.973830699921\n",
      "time_this_iter_s: 7.72539758682251\n",
      "time_total_s: 6559.973830699921\n",
      "timers:\n",
      "  learn_throughput: 1039.785\n",
      "  learn_time_ms: 3846.948\n",
      "  load_throughput: 18489327.75\n",
      "  load_time_ms: 0.216\n",
      "  sample_throughput: 421.574\n",
      "  sample_time_ms: 9488.25\n",
      "  update_time_ms: 3.151\n",
      "timestamp: 1658400523\n",
      "timesteps_since_restore: 3556000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3556000\n",
      "training_iteration: 889\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3560000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-48-52\n",
      "done: false\n",
      "episode_len_mean: 199.55\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.55\n",
      "episode_reward_min: 155.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18517\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18743516504764557\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036132480017840862\n",
      "        model: {}\n",
      "        policy_loss: 0.007292902562767267\n",
      "        total_loss: 7.971007347106934\n",
      "        vf_explained_var: 9.229106368024986e-09\n",
      "        vf_loss: 7.963713645935059\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3560000\n",
      "  num_agent_steps_trained: 3560000\n",
      "  num_steps_sampled: 3560000\n",
      "  num_steps_trained: 3560000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 890\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.34615384615385\n",
      "  ram_util_percent: 88.95384615384614\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07158762026109568\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08209878957722355\n",
      "  mean_inference_ms: 0.7860326682394339\n",
      "  mean_raw_obs_processing_ms: 0.09480624021807962\n",
      "time_since_restore: 6568.8500463962555\n",
      "time_this_iter_s: 8.876215696334839\n",
      "time_total_s: 6568.8500463962555\n",
      "timers:\n",
      "  learn_throughput: 1061.479\n",
      "  learn_time_ms: 3768.325\n",
      "  load_throughput: 18313738.675\n",
      "  load_time_ms: 0.218\n",
      "  sample_throughput: 425.88\n",
      "  sample_time_ms: 9392.32\n",
      "  update_time_ms: 3.148\n",
      "timestamp: 1658400532\n",
      "timesteps_since_restore: 3560000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3560000\n",
      "training_iteration: 890\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3564000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-49-03\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18537\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17774493992328644\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004447947256267071\n",
      "        model: {}\n",
      "        policy_loss: 0.006811455357819796\n",
      "        total_loss: 7.970521450042725\n",
      "        vf_explained_var: 2.237417362493943e-07\n",
      "        vf_loss: 7.963709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3564000\n",
      "  num_agent_steps_trained: 3564000\n",
      "  num_steps_sampled: 3564000\n",
      "  num_steps_trained: 3564000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 891\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 55.27333333333333\n",
      "  ram_util_percent: 89.11333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07161701139143667\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08213132127593896\n",
      "  mean_inference_ms: 0.7863585773888456\n",
      "  mean_raw_obs_processing_ms: 0.0948439309592562\n",
      "time_since_restore: 6579.632862567902\n",
      "time_this_iter_s: 10.782816171646118\n",
      "time_total_s: 6579.632862567902\n",
      "timers:\n",
      "  learn_throughput: 1042.356\n",
      "  learn_time_ms: 3837.461\n",
      "  load_throughput: 18251975.631\n",
      "  load_time_ms: 0.219\n",
      "  sample_throughput: 421.942\n",
      "  sample_time_ms: 9479.972\n",
      "  update_time_ms: 3.17\n",
      "timestamp: 1658400543\n",
      "timesteps_since_restore: 3564000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3564000\n",
      "training_iteration: 891\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3568000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-49-11\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18557\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18477733433246613\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023159494157880545\n",
      "        model: {}\n",
      "        policy_loss: 0.007944682613015175\n",
      "        total_loss: 7.9716572761535645\n",
      "        vf_explained_var: 1.0152017182463169e-07\n",
      "        vf_loss: 7.963711738586426\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3568000\n",
      "  num_agent_steps_trained: 3568000\n",
      "  num_steps_sampled: 3568000\n",
      "  num_steps_trained: 3568000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 892\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.49230769230769\n",
      "  ram_util_percent: 89.22307692307693\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07163907689695595\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08215612633293182\n",
      "  mean_inference_ms: 0.7866016967345988\n",
      "  mean_raw_obs_processing_ms: 0.0948710576663466\n",
      "time_since_restore: 6588.375726699829\n",
      "time_this_iter_s: 8.74286413192749\n",
      "time_total_s: 6588.375726699829\n",
      "timers:\n",
      "  learn_throughput: 1056.225\n",
      "  learn_time_ms: 3787.072\n",
      "  load_throughput: 18317737.744\n",
      "  load_time_ms: 0.218\n",
      "  sample_throughput: 421.007\n",
      "  sample_time_ms: 9501.032\n",
      "  update_time_ms: 3.189\n",
      "timestamp: 1658400551\n",
      "timesteps_since_restore: 3568000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3568000\n",
      "training_iteration: 892\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3572000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-49-21\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18577\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.16330604255199432\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026035821065306664\n",
      "        model: {}\n",
      "        policy_loss: 0.008502600714564323\n",
      "        total_loss: 7.972212791442871\n",
      "        vf_explained_var: -5.255463175757313e-09\n",
      "        vf_loss: 7.963709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3572000\n",
      "  num_agent_steps_trained: 3572000\n",
      "  num_steps_sampled: 3572000\n",
      "  num_steps_trained: 3572000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 893\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.8\n",
      "  ram_util_percent: 89.11428571428571\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07166726409487337\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08218802665290062\n",
      "  mean_inference_ms: 0.7869089445970472\n",
      "  mean_raw_obs_processing_ms: 0.09490566135367974\n",
      "time_since_restore: 6598.053256511688\n",
      "time_this_iter_s: 9.67752981185913\n",
      "time_total_s: 6598.053256511688\n",
      "timers:\n",
      "  learn_throughput: 1088.373\n",
      "  learn_time_ms: 3675.211\n",
      "  load_throughput: 18261909.22\n",
      "  load_time_ms: 0.219\n",
      "  sample_throughput: 420.272\n",
      "  sample_time_ms: 9517.651\n",
      "  update_time_ms: 3.126\n",
      "timestamp: 1658400561\n",
      "timesteps_since_restore: 3572000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3572000\n",
      "training_iteration: 893\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3576000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-49-31\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18597\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19025678932666779\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026612484361976385\n",
      "        model: {}\n",
      "        policy_loss: 0.006441332399845123\n",
      "        total_loss: 7.970151424407959\n",
      "        vf_explained_var: 7.33201233060754e-08\n",
      "        vf_loss: 7.963709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3576000\n",
      "  num_agent_steps_trained: 3576000\n",
      "  num_steps_sampled: 3576000\n",
      "  num_steps_trained: 3576000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 894\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.76923076923077\n",
      "  ram_util_percent: 89.02307692307691\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07169718130319742\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0822219450153132\n",
      "  mean_inference_ms: 0.7872321569703595\n",
      "  mean_raw_obs_processing_ms: 0.0949422409264093\n",
      "time_since_restore: 6607.646837711334\n",
      "time_this_iter_s: 9.593581199645996\n",
      "time_total_s: 6607.646837711334\n",
      "timers:\n",
      "  learn_throughput: 1055.392\n",
      "  learn_time_ms: 3790.06\n",
      "  load_throughput: 17172176.049\n",
      "  load_time_ms: 0.233\n",
      "  sample_throughput: 430.484\n",
      "  sample_time_ms: 9291.859\n",
      "  update_time_ms: 3.178\n",
      "timestamp: 1658400571\n",
      "timesteps_since_restore: 3576000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3576000\n",
      "training_iteration: 894\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3580000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-49-42\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18617\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19760417938232422\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032738777808845043\n",
      "        model: {}\n",
      "        policy_loss: 0.007601045072078705\n",
      "        total_loss: 7.971311569213867\n",
      "        vf_explained_var: 2.9289594749570824e-08\n",
      "        vf_loss: 7.963710784912109\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3580000\n",
      "  num_agent_steps_trained: 3580000\n",
      "  num_steps_sampled: 3580000\n",
      "  num_steps_trained: 3580000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 895\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 60.58235294117646\n",
      "  ram_util_percent: 89.19999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07173634783975079\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08226622829241274\n",
      "  mean_inference_ms: 0.7876659301398399\n",
      "  mean_raw_obs_processing_ms: 0.09498935600314072\n",
      "time_since_restore: 6618.994171380997\n",
      "time_this_iter_s: 11.347333669662476\n",
      "time_total_s: 6618.994171380997\n",
      "timers:\n",
      "  learn_throughput: 1048.063\n",
      "  learn_time_ms: 3816.563\n",
      "  load_throughput: 17225067.762\n",
      "  load_time_ms: 0.232\n",
      "  sample_throughput: 413.351\n",
      "  sample_time_ms: 9677.015\n",
      "  update_time_ms: 3.17\n",
      "timestamp: 1658400582\n",
      "timesteps_since_restore: 3580000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3580000\n",
      "training_iteration: 895\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3584000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-49-50\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18637\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18370750546455383\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0015659424243494868\n",
      "        model: {}\n",
      "        policy_loss: 0.009354003705084324\n",
      "        total_loss: 7.973064422607422\n",
      "        vf_explained_var: -7.107693988928077e-08\n",
      "        vf_loss: 7.963710308074951\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3584000\n",
      "  num_agent_steps_trained: 3584000\n",
      "  num_steps_sampled: 3584000\n",
      "  num_steps_trained: 3584000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 896\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.02727272727273\n",
      "  ram_util_percent: 88.96363636363637\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07176823404820316\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08230233707285653\n",
      "  mean_inference_ms: 0.7880165500454726\n",
      "  mean_raw_obs_processing_ms: 0.0950272621952868\n",
      "time_since_restore: 6627.1659989356995\n",
      "time_this_iter_s: 8.171827554702759\n",
      "time_total_s: 6627.1659989356995\n",
      "timers:\n",
      "  learn_throughput: 1097.188\n",
      "  learn_time_ms: 3645.682\n",
      "  load_throughput: 18168958.198\n",
      "  load_time_ms: 0.22\n",
      "  sample_throughput: 414.693\n",
      "  sample_time_ms: 9645.686\n",
      "  update_time_ms: 2.349\n",
      "timestamp: 1658400590\n",
      "timesteps_since_restore: 3584000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3584000\n",
      "training_iteration: 896\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3588000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-49-59\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18657\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19717532396316528\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028290455229580402\n",
      "        model: {}\n",
      "        policy_loss: 0.007494394201785326\n",
      "        total_loss: 7.971206188201904\n",
      "        vf_explained_var: 1.2497747547968174e-07\n",
      "        vf_loss: 7.963711261749268\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3588000\n",
      "  num_agent_steps_trained: 3588000\n",
      "  num_steps_sampled: 3588000\n",
      "  num_steps_trained: 3588000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 897\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.625\n",
      "  ram_util_percent: 88.81666666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0717969886962402\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08233490707806386\n",
      "  mean_inference_ms: 0.7883332202493014\n",
      "  mean_raw_obs_processing_ms: 0.09506187667191021\n",
      "time_since_restore: 6635.291427373886\n",
      "time_this_iter_s: 8.125428438186646\n",
      "time_total_s: 6635.291427373886\n",
      "timers:\n",
      "  learn_throughput: 1101.602\n",
      "  learn_time_ms: 3631.075\n",
      "  load_throughput: 19821852.552\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 434.827\n",
      "  sample_time_ms: 9199.054\n",
      "  update_time_ms: 2.283\n",
      "timestamp: 1658400599\n",
      "timesteps_since_restore: 3588000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3588000\n",
      "training_iteration: 897\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3592000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-50-08\n",
      "done: false\n",
      "episode_len_mean: 199.57\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.57\n",
      "episode_reward_min: 157.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18677\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17596137523651123\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030345008708536625\n",
      "        model: {}\n",
      "        policy_loss: 0.005671107675880194\n",
      "        total_loss: 6.018778324127197\n",
      "        vf_explained_var: 1.466402466121508e-07\n",
      "        vf_loss: 6.013106822967529\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3592000\n",
      "  num_agent_steps_trained: 3592000\n",
      "  num_steps_sampled: 3592000\n",
      "  num_steps_trained: 3592000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 898\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.284615384615385\n",
      "  ram_util_percent: 89.05384615384614\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07182374203599073\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08236478988188775\n",
      "  mean_inference_ms: 0.7886361437735715\n",
      "  mean_raw_obs_processing_ms: 0.09509476823718249\n",
      "time_since_restore: 6644.481814146042\n",
      "time_this_iter_s: 9.190386772155762\n",
      "time_total_s: 6644.481814146042\n",
      "timers:\n",
      "  learn_throughput: 1117.399\n",
      "  learn_time_ms: 3579.743\n",
      "  load_throughput: 19849995.267\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 429.979\n",
      "  sample_time_ms: 9302.782\n",
      "  update_time_ms: 2.299\n",
      "timestamp: 1658400608\n",
      "timesteps_since_restore: 3592000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3592000\n",
      "training_iteration: 898\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3596000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-50-19\n",
      "done: false\n",
      "episode_len_mean: 198.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.68\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18697\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.17668524384498596\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002992127323523164\n",
      "        model: {}\n",
      "        policy_loss: 0.0014270838582888246\n",
      "        total_loss: 3.106266736984253\n",
      "        vf_explained_var: 0.0038227392360568047\n",
      "        vf_loss: 3.104839563369751\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3596000\n",
      "  num_agent_steps_trained: 3596000\n",
      "  num_steps_sampled: 3596000\n",
      "  num_steps_trained: 3596000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 899\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 59.06875\n",
      "  ram_util_percent: 88.8\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0718560715361304\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0824006658116606\n",
      "  mean_inference_ms: 0.789008401431447\n",
      "  mean_raw_obs_processing_ms: 0.09513439513571735\n",
      "time_since_restore: 6655.670875310898\n",
      "time_this_iter_s: 11.189061164855957\n",
      "time_total_s: 6655.670875310898\n",
      "timers:\n",
      "  learn_throughput: 1073.723\n",
      "  learn_time_ms: 3725.355\n",
      "  load_throughput: 19901798.339\n",
      "  load_time_ms: 0.201\n",
      "  sample_throughput: 423.173\n",
      "  sample_time_ms: 9452.4\n",
      "  update_time_ms: 2.336\n",
      "timestamp: 1658400619\n",
      "timesteps_since_restore: 3596000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3596000\n",
      "training_iteration: 899\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3600000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-50-30\n",
      "done: false\n",
      "episode_len_mean: 198.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.68\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18717\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19565781950950623\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002853162121027708\n",
      "        model: {}\n",
      "        policy_loss: -0.0008544934098608792\n",
      "        total_loss: 1.3096295595169067\n",
      "        vf_explained_var: -0.014525060541927814\n",
      "        vf_loss: 1.3104838132858276\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3600000\n",
      "  num_agent_steps_trained: 3600000\n",
      "  num_steps_sampled: 3600000\n",
      "  num_steps_trained: 3600000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 900\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 59.38125\n",
      "  ram_util_percent: 89.39375000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07188453905155881\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08243213598110344\n",
      "  mean_inference_ms: 0.7893252887155735\n",
      "  mean_raw_obs_processing_ms: 0.09516913916601798\n",
      "time_since_restore: 6666.520136356354\n",
      "time_this_iter_s: 10.849261045455933\n",
      "time_total_s: 6666.520136356354\n",
      "timers:\n",
      "  learn_throughput: 1056.06\n",
      "  learn_time_ms: 3787.664\n",
      "  load_throughput: 20068440.191\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 410.941\n",
      "  sample_time_ms: 9733.763\n",
      "  update_time_ms: 2.398\n",
      "timestamp: 1658400630\n",
      "timesteps_since_restore: 3600000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3600000\n",
      "training_iteration: 900\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3604000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-50-40\n",
      "done: false\n",
      "episode_len_mean: 198.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.68\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18737\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20475375652313232\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030581289902329445\n",
      "        model: {}\n",
      "        policy_loss: 0.0007958316709846258\n",
      "        total_loss: 1.3112796545028687\n",
      "        vf_explained_var: -0.2260027378797531\n",
      "        vf_loss: 1.3104838132858276\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3604000\n",
      "  num_agent_steps_trained: 3604000\n",
      "  num_steps_sampled: 3604000\n",
      "  num_steps_trained: 3604000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 901\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 57.42666666666666\n",
      "  ram_util_percent: 89.39999999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07191465580181909\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08246577164921723\n",
      "  mean_inference_ms: 0.7896605085278354\n",
      "  mean_raw_obs_processing_ms: 0.09520629322821643\n",
      "time_since_restore: 6677.014904022217\n",
      "time_this_iter_s: 10.494767665863037\n",
      "time_total_s: 6677.014904022217\n",
      "timers:\n",
      "  learn_throughput: 1024.168\n",
      "  learn_time_ms: 3905.609\n",
      "  load_throughput: 19132416.467\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 414.524\n",
      "  sample_time_ms: 9649.613\n",
      "  update_time_ms: 2.381\n",
      "timestamp: 1658400640\n",
      "timesteps_since_restore: 3604000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3604000\n",
      "training_iteration: 901\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "checkpoint save at /home/dufek/ray_results/PPOTrainer_CartPole-v0_2022-07-21_10-58-5909c0rqvt/checkpoint_000901/checkpoint-901\n",
      "agent_timesteps_total: 3608000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-50-48\n",
      "done: false\n",
      "episode_len_mean: 198.68\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.68\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18757\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18023619055747986\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004186033736914396\n",
      "        model: {}\n",
      "        policy_loss: -0.0006685502012260258\n",
      "        total_loss: 1.3098154067993164\n",
      "        vf_explained_var: -0.23949496448040009\n",
      "        vf_loss: 1.3104840517044067\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3608000\n",
      "  num_agent_steps_trained: 3608000\n",
      "  num_steps_sampled: 3608000\n",
      "  num_steps_trained: 3608000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 902\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.57272727272727\n",
      "  ram_util_percent: 89.2909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07194479360569075\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08249917887212632\n",
      "  mean_inference_ms: 0.7899898818230733\n",
      "  mean_raw_obs_processing_ms: 0.09524318045538328\n",
      "time_since_restore: 6685.043500185013\n",
      "time_this_iter_s: 8.02859616279602\n",
      "time_total_s: 6685.043500185013\n",
      "timers:\n",
      "  learn_throughput: 1019.835\n",
      "  learn_time_ms: 3922.204\n",
      "  load_throughput: 19485732.869\n",
      "  load_time_ms: 0.205\n",
      "  sample_throughput: 413.193\n",
      "  sample_time_ms: 9680.706\n",
      "  update_time_ms: 2.362\n",
      "timestamp: 1658400648\n",
      "timesteps_since_restore: 3608000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3608000\n",
      "training_iteration: 902\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3612000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-50-57\n",
      "done: false\n",
      "episode_len_mean: 199.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.11\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18777\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19438695907592773\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0022577543277293444\n",
      "        model: {}\n",
      "        policy_loss: 0.0004741438606288284\n",
      "        total_loss: 1.3109582662582397\n",
      "        vf_explained_var: -0.19922301173210144\n",
      "        vf_loss: 1.3104838132858276\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3612000\n",
      "  num_agent_steps_trained: 3612000\n",
      "  num_steps_sampled: 3612000\n",
      "  num_steps_trained: 3612000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 903\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.18333333333334\n",
      "  ram_util_percent: 89.075\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07197036719191856\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08252736118808127\n",
      "  mean_inference_ms: 0.79026301028517\n",
      "  mean_raw_obs_processing_ms: 0.09527382706553673\n",
      "time_since_restore: 6693.145543575287\n",
      "time_this_iter_s: 8.102043390274048\n",
      "time_total_s: 6693.145543575287\n",
      "timers:\n",
      "  learn_throughput: 1018.186\n",
      "  learn_time_ms: 3928.556\n",
      "  load_throughput: 19319686.78\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 419.648\n",
      "  sample_time_ms: 9531.801\n",
      "  update_time_ms: 2.426\n",
      "timestamp: 1658400657\n",
      "timesteps_since_restore: 3612000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3612000\n",
      "training_iteration: 903\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3616000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-51-05\n",
      "done: false\n",
      "episode_len_mean: 197.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.66\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 18799\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21728335320949554\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002569460077211261\n",
      "        model: {}\n",
      "        policy_loss: -0.013493606820702553\n",
      "        total_loss: 5.132708549499512\n",
      "        vf_explained_var: -0.003743306268006563\n",
      "        vf_loss: 5.146202087402344\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3616000\n",
      "  num_agent_steps_trained: 3616000\n",
      "  num_steps_sampled: 3616000\n",
      "  num_steps_trained: 3616000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 904\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.75454545454545\n",
      "  ram_util_percent: 89.00909090909092\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07199083281781402\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08255006443166367\n",
      "  mean_inference_ms: 0.7904759462049148\n",
      "  mean_raw_obs_processing_ms: 0.09529815189290611\n",
      "time_since_restore: 6701.343444824219\n",
      "time_this_iter_s: 8.197901248931885\n",
      "time_total_s: 6701.343444824219\n",
      "timers:\n",
      "  learn_throughput: 1054.462\n",
      "  learn_time_ms: 3793.402\n",
      "  load_throughput: 20259891.317\n",
      "  load_time_ms: 0.197\n",
      "  sample_throughput: 419.423\n",
      "  sample_time_ms: 9536.906\n",
      "  update_time_ms: 2.355\n",
      "timestamp: 1658400665\n",
      "timesteps_since_restore: 3616000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3616000\n",
      "training_iteration: 904\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3620000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-51-13\n",
      "done: false\n",
      "episode_len_mean: 196.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.91\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18819\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.18990881741046906\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035940748639404774\n",
      "        model: {}\n",
      "        policy_loss: 0.007855295203626156\n",
      "        total_loss: 9.496261596679688\n",
      "        vf_explained_var: 1.550361616864393e-07\n",
      "        vf_loss: 9.488407135009766\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3620000\n",
      "  num_agent_steps_trained: 3620000\n",
      "  num_steps_sampled: 3620000\n",
      "  num_steps_trained: 3620000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 905\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.12307692307692\n",
      "  ram_util_percent: 89.0076923076923\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07200344052637953\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08256407939113557\n",
      "  mean_inference_ms: 0.7906053155007229\n",
      "  mean_raw_obs_processing_ms: 0.09531285198822684\n",
      "time_since_restore: 6709.800384044647\n",
      "time_this_iter_s: 8.456939220428467\n",
      "time_total_s: 6709.800384044647\n",
      "timers:\n",
      "  learn_throughput: 1055.886\n",
      "  learn_time_ms: 3788.286\n",
      "  load_throughput: 20104512.882\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 438.981\n",
      "  sample_time_ms: 9112.016\n",
      "  update_time_ms: 2.374\n",
      "timestamp: 1658400673\n",
      "timesteps_since_restore: 3620000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3620000\n",
      "training_iteration: 905\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3624000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-51-21\n",
      "done: false\n",
      "episode_len_mean: 195.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.91\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18839\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20215697586536407\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036226450465619564\n",
      "        model: {}\n",
      "        policy_loss: -0.00035052106250077486\n",
      "        total_loss: 2.620616912841797\n",
      "        vf_explained_var: -0.19277219474315643\n",
      "        vf_loss: 2.6209676265716553\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3624000\n",
      "  num_agent_steps_trained: 3624000\n",
      "  num_steps_sampled: 3624000\n",
      "  num_steps_trained: 3624000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 906\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.690909090909095\n",
      "  ram_util_percent: 89.04545454545455\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0720130843858987\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0825747630222631\n",
      "  mean_inference_ms: 0.7907065190268847\n",
      "  mean_raw_obs_processing_ms: 0.09532418209017951\n",
      "time_since_restore: 6717.856937408447\n",
      "time_this_iter_s: 8.056553363800049\n",
      "time_total_s: 6717.856937408447\n",
      "timers:\n",
      "  learn_throughput: 1051.189\n",
      "  learn_time_ms: 3805.215\n",
      "  load_throughput: 20135880.941\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 440.599\n",
      "  sample_time_ms: 9078.544\n",
      "  update_time_ms: 2.365\n",
      "timestamp: 1658400681\n",
      "timesteps_since_restore: 3624000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3624000\n",
      "training_iteration: 906\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3628000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-51-29\n",
      "done: false\n",
      "episode_len_mean: 195.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.91\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18859\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1957702338695526\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004832916893064976\n",
      "        model: {}\n",
      "        policy_loss: -0.003199344500899315\n",
      "        total_loss: 0.8536555171012878\n",
      "        vf_explained_var: -0.27661922574043274\n",
      "        vf_loss: 0.8568548560142517\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3628000\n",
      "  num_agent_steps_trained: 3628000\n",
      "  num_steps_sampled: 3628000\n",
      "  num_steps_trained: 3628000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 907\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.918181818181814\n",
      "  ram_util_percent: 89.16363636363636\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07202227559435842\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08258531213743378\n",
      "  mean_inference_ms: 0.7908057605268408\n",
      "  mean_raw_obs_processing_ms: 0.09533511319479014\n",
      "time_since_restore: 6725.7334570884705\n",
      "time_this_iter_s: 7.876519680023193\n",
      "time_total_s: 6725.7334570884705\n",
      "timers:\n",
      "  learn_throughput: 1053.775\n",
      "  learn_time_ms: 3795.877\n",
      "  load_throughput: 20090068.255\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 440.547\n",
      "  sample_time_ms: 9079.615\n",
      "  update_time_ms: 2.467\n",
      "timestamp: 1658400689\n",
      "timesteps_since_restore: 3628000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3628000\n",
      "training_iteration: 907\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3632000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-51-37\n",
      "done: false\n",
      "episode_len_mean: 195.84\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.84\n",
      "episode_reward_min: 78.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18879\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20685513317584991\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006750170607119799\n",
      "        model: {}\n",
      "        policy_loss: -0.002780849812552333\n",
      "        total_loss: 0.7835094928741455\n",
      "        vf_explained_var: -0.23633639514446259\n",
      "        vf_loss: 0.7862903475761414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3632000\n",
      "  num_agent_steps_trained: 3632000\n",
      "  num_steps_sampled: 3632000\n",
      "  num_steps_trained: 3632000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 908\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.44166666666667\n",
      "  ram_util_percent: 89.11666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07203106406359022\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08259508987382917\n",
      "  mean_inference_ms: 0.790897235982228\n",
      "  mean_raw_obs_processing_ms: 0.09534562355958727\n",
      "time_since_restore: 6733.732323169708\n",
      "time_this_iter_s: 7.998866081237793\n",
      "time_total_s: 6733.732323169708\n",
      "timers:\n",
      "  learn_throughput: 1047.37\n",
      "  learn_time_ms: 3819.089\n",
      "  load_throughput: 19215686.634\n",
      "  load_time_ms: 0.208\n",
      "  sample_throughput: 448.014\n",
      "  sample_time_ms: 8928.293\n",
      "  update_time_ms: 2.519\n",
      "timestamp: 1658400697\n",
      "timesteps_since_restore: 3632000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3632000\n",
      "training_iteration: 908\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3636000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-51-46\n",
      "done: false\n",
      "episode_len_mean: 198.18\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.18\n",
      "episode_reward_min: 100.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18899\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2165435254573822\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004512308165431023\n",
      "        model: {}\n",
      "        policy_loss: -0.0014672963880002499\n",
      "        total_loss: 0.5025649666786194\n",
      "        vf_explained_var: -0.27220720052719116\n",
      "        vf_loss: 0.5040322542190552\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3636000\n",
      "  num_agent_steps_trained: 3636000\n",
      "  num_steps_sampled: 3636000\n",
      "  num_steps_trained: 3636000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 909\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.59166666666667\n",
      "  ram_util_percent: 88.98333333333335\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07203981739609197\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08260476082300702\n",
      "  mean_inference_ms: 0.7909883960964582\n",
      "  mean_raw_obs_processing_ms: 0.09535616169244218\n",
      "time_since_restore: 6742.138121843338\n",
      "time_this_iter_s: 8.40579867362976\n",
      "time_total_s: 6742.138121843338\n",
      "timers:\n",
      "  learn_throughput: 1077.542\n",
      "  learn_time_ms: 3712.152\n",
      "  load_throughput: 19270866.069\n",
      "  load_time_ms: 0.208\n",
      "  sample_throughput: 455.46\n",
      "  sample_time_ms: 8782.33\n",
      "  update_time_ms: 2.576\n",
      "timestamp: 1658400706\n",
      "timesteps_since_restore: 3636000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3636000\n",
      "training_iteration: 909\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3640000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-51-54\n",
      "done: false\n",
      "episode_len_mean: 198.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.93\n",
      "episode_reward_min: 100.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18919\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23683053255081177\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.008206821046769619\n",
      "        model: {}\n",
      "        policy_loss: -0.005312251392751932\n",
      "        total_loss: 0.4987201392650604\n",
      "        vf_explained_var: -0.28828638792037964\n",
      "        vf_loss: 0.5040323734283447\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3640000\n",
      "  num_agent_steps_trained: 3640000\n",
      "  num_steps_sampled: 3640000\n",
      "  num_steps_trained: 3640000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 910\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.56666666666666\n",
      "  ram_util_percent: 88.71666666666668\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0720497631844881\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08261590446701658\n",
      "  mean_inference_ms: 0.7910966397145915\n",
      "  mean_raw_obs_processing_ms: 0.09536894467314866\n",
      "time_since_restore: 6750.647127628326\n",
      "time_this_iter_s: 8.509005784988403\n",
      "time_total_s: 6750.647127628326\n",
      "timers:\n",
      "  learn_throughput: 1111.181\n",
      "  learn_time_ms: 3599.775\n",
      "  load_throughput: 19224494.099\n",
      "  load_time_ms: 0.208\n",
      "  sample_throughput: 467.635\n",
      "  sample_time_ms: 8553.679\n",
      "  update_time_ms: 2.447\n",
      "timestamp: 1658400714\n",
      "timesteps_since_restore: 3640000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3640000\n",
      "training_iteration: 910\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3644000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-52-03\n",
      "done: false\n",
      "episode_len_mean: 199.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.93\n",
      "episode_reward_min: 193.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18939\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24000433087348938\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004378098528832197\n",
      "        model: {}\n",
      "        policy_loss: -0.0012202844955027103\n",
      "        total_loss: 0.5028123259544373\n",
      "        vf_explained_var: -0.008921063505113125\n",
      "        vf_loss: 0.5040326118469238\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3644000\n",
      "  num_agent_steps_trained: 3644000\n",
      "  num_steps_sampled: 3644000\n",
      "  num_steps_trained: 3644000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 911\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.800000000000004\n",
      "  ram_util_percent: 88.85833333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07206205285889702\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08262980067858873\n",
      "  mean_inference_ms: 0.7912263755937536\n",
      "  mean_raw_obs_processing_ms: 0.09538439210928137\n",
      "time_since_restore: 6759.158612251282\n",
      "time_this_iter_s: 8.511484622955322\n",
      "time_total_s: 6759.158612251282\n",
      "timers:\n",
      "  learn_throughput: 1168.874\n",
      "  learn_time_ms: 3422.096\n",
      "  load_throughput: 20104512.882\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 475.042\n",
      "  sample_time_ms: 8420.307\n",
      "  update_time_ms: 2.403\n",
      "timestamp: 1658400723\n",
      "timesteps_since_restore: 3644000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3644000\n",
      "training_iteration: 911\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3648000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-52-11\n",
      "done: false\n",
      "episode_len_mean: 197.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.44\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 18961\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2284959852695465\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036958479322493076\n",
      "        model: {}\n",
      "        policy_loss: 0.0019515656167641282\n",
      "        total_loss: 5.0422821044921875\n",
      "        vf_explained_var: 0.0023713274858891964\n",
      "        vf_loss: 5.040329933166504\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3648000\n",
      "  num_agent_steps_trained: 3648000\n",
      "  num_steps_sampled: 3648000\n",
      "  num_steps_trained: 3648000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 912\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.36666666666667\n",
      "  ram_util_percent: 88.70833333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07207787553645804\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08264766666276287\n",
      "  mean_inference_ms: 0.7913962288589935\n",
      "  mean_raw_obs_processing_ms: 0.0954042632045428\n",
      "time_since_restore: 6767.7264766693115\n",
      "time_this_iter_s: 8.567864418029785\n",
      "time_total_s: 6767.7264766693115\n",
      "timers:\n",
      "  learn_throughput: 1169.471\n",
      "  learn_time_ms: 3420.35\n",
      "  load_throughput: 19819510.927\n",
      "  load_time_ms: 0.202\n",
      "  sample_throughput: 482.113\n",
      "  sample_time_ms: 8296.819\n",
      "  update_time_ms: 2.377\n",
      "timestamp: 1658400731\n",
      "timesteps_since_restore: 3648000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3648000\n",
      "training_iteration: 912\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3652000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-52-20\n",
      "done: false\n",
      "episode_len_mean: 197.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.37\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 18981\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21972675621509552\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003883928991854191\n",
      "        model: {}\n",
      "        policy_loss: 0.006543302908539772\n",
      "        total_loss: 7.698075294494629\n",
      "        vf_explained_var: 1.1106973119012764e-07\n",
      "        vf_loss: 7.691532135009766\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3652000\n",
      "  num_agent_steps_trained: 3652000\n",
      "  num_steps_sampled: 3652000\n",
      "  num_steps_trained: 3652000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 913\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.800000000000004\n",
      "  ram_util_percent: 88.84615384615384\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07209636033999285\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08266872434271016\n",
      "  mean_inference_ms: 0.7916025999278888\n",
      "  mean_raw_obs_processing_ms: 0.09542759416111578\n",
      "time_since_restore: 6776.8019506931305\n",
      "time_this_iter_s: 9.07547402381897\n",
      "time_total_s: 6776.8019506931305\n",
      "timers:\n",
      "  learn_throughput: 1174.573\n",
      "  learn_time_ms: 3405.493\n",
      "  load_throughput: 19953872.502\n",
      "  load_time_ms: 0.2\n",
      "  sample_throughput: 475.747\n",
      "  sample_time_ms: 8407.829\n",
      "  update_time_ms: 2.368\n",
      "timestamp: 1658400740\n",
      "timesteps_since_restore: 3652000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3652000\n",
      "training_iteration: 913\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3656000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-52-29\n",
      "done: false\n",
      "episode_len_mean: 197.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.37\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19001\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2403068244457245\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002993400674313307\n",
      "        model: {}\n",
      "        policy_loss: 0.006618183571845293\n",
      "        total_loss: 7.415892124176025\n",
      "        vf_explained_var: 6.671874785979526e-08\n",
      "        vf_loss: 7.409274101257324\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3656000\n",
      "  num_agent_steps_trained: 3656000\n",
      "  num_steps_sampled: 3656000\n",
      "  num_steps_trained: 3656000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 914\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.650000000000006\n",
      "  ram_util_percent: 89.00833333333334\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0721150188539866\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08268991124036872\n",
      "  mean_inference_ms: 0.7918083581425341\n",
      "  mean_raw_obs_processing_ms: 0.09545084288104183\n",
      "time_since_restore: 6785.257485628128\n",
      "time_this_iter_s: 8.455534934997559\n",
      "time_total_s: 6785.257485628128\n",
      "timers:\n",
      "  learn_throughput: 1164.925\n",
      "  learn_time_ms: 3433.696\n",
      "  load_throughput: 20380485.909\n",
      "  load_time_ms: 0.196\n",
      "  sample_throughput: 476.871\n",
      "  sample_time_ms: 8388.021\n",
      "  update_time_ms: 2.387\n",
      "timestamp: 1658400749\n",
      "timesteps_since_restore: 3656000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3656000\n",
      "training_iteration: 914\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3660000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-52-37\n",
      "done: false\n",
      "episode_len_mean: 196.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.37\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19021\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23223748803138733\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004091187845915556\n",
      "        model: {}\n",
      "        policy_loss: 0.0027359798550605774\n",
      "        total_loss: 5.899914741516113\n",
      "        vf_explained_var: -0.014918097294867039\n",
      "        vf_loss: 5.897179126739502\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3660000\n",
      "  num_agent_steps_trained: 3660000\n",
      "  num_steps_sampled: 3660000\n",
      "  num_steps_trained: 3660000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 915\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.25000000000001\n",
      "  ram_util_percent: 88.74166666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07213161840775281\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08270873052146044\n",
      "  mean_inference_ms: 0.7919897445354129\n",
      "  mean_raw_obs_processing_ms: 0.09547137362017884\n",
      "time_since_restore: 6793.396331310272\n",
      "time_this_iter_s: 8.138845682144165\n",
      "time_total_s: 6793.396331310272\n",
      "timers:\n",
      "  learn_throughput: 1169.517\n",
      "  learn_time_ms: 3420.215\n",
      "  load_throughput: 20593121.394\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 476.313\n",
      "  sample_time_ms: 8397.843\n",
      "  update_time_ms: 2.465\n",
      "timestamp: 1658400757\n",
      "timesteps_since_restore: 3660000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3660000\n",
      "training_iteration: 915\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3664000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-52-45\n",
      "done: false\n",
      "episode_len_mean: 196.37\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.37\n",
      "episode_reward_min: 49.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19041\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23362667858600616\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00369644770398736\n",
      "        model: {}\n",
      "        policy_loss: 0.0009226777474395931\n",
      "        total_loss: 2.36987566947937\n",
      "        vf_explained_var: -0.0013641592813655734\n",
      "        vf_loss: 2.368952751159668\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3664000\n",
      "  num_agent_steps_trained: 3664000\n",
      "  num_steps_sampled: 3664000\n",
      "  num_steps_trained: 3664000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 916\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.708333333333336\n",
      "  ram_util_percent: 88.90833333333332\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0721459977245247\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08272509011215139\n",
      "  mean_inference_ms: 0.7921494013859939\n",
      "  mean_raw_obs_processing_ms: 0.09548940715620212\n",
      "time_since_restore: 6801.472245454788\n",
      "time_this_iter_s: 8.075914144515991\n",
      "time_total_s: 6801.472245454788\n",
      "timers:\n",
      "  learn_throughput: 1169.958\n",
      "  learn_time_ms: 3418.927\n",
      "  load_throughput: 19002396.647\n",
      "  load_time_ms: 0.21\n",
      "  sample_throughput: 476.91\n",
      "  sample_time_ms: 8387.335\n",
      "  update_time_ms: 2.502\n",
      "timestamp: 1658400765\n",
      "timesteps_since_restore: 3664000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3664000\n",
      "training_iteration: 916\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3668000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-52-55\n",
      "done: false\n",
      "episode_len_mean: 198.86\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.86\n",
      "episode_reward_min: 100.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19061\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.27018260955810547\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003089477540925145\n",
      "        model: {}\n",
      "        policy_loss: 0.00027921609580516815\n",
      "        total_loss: 2.3692314624786377\n",
      "        vf_explained_var: 0.001761200837790966\n",
      "        vf_loss: 2.3689520359039307\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3668000\n",
      "  num_agent_steps_trained: 3668000\n",
      "  num_steps_sampled: 3668000\n",
      "  num_steps_trained: 3668000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 917\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.935714285714276\n",
      "  ram_util_percent: 89.12142857142855\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07216418146463191\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08274543111773829\n",
      "  mean_inference_ms: 0.7923557254505031\n",
      "  mean_raw_obs_processing_ms: 0.0955123689775219\n",
      "time_since_restore: 6811.208724498749\n",
      "time_this_iter_s: 9.736479043960571\n",
      "time_total_s: 6811.208724498749\n",
      "timers:\n",
      "  learn_throughput: 1161.968\n",
      "  learn_time_ms: 3442.436\n",
      "  load_throughput: 18226198.805\n",
      "  load_time_ms: 0.219\n",
      "  sample_throughput: 467.856\n",
      "  sample_time_ms: 8549.643\n",
      "  update_time_ms: 2.381\n",
      "timestamp: 1658400775\n",
      "timesteps_since_restore: 3668000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3668000\n",
      "training_iteration: 917\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3672000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-53-04\n",
      "done: false\n",
      "episode_len_mean: 199.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.0\n",
      "episode_reward_min: 100.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19081\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24696409702301025\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003310121363028884\n",
      "        model: {}\n",
      "        policy_loss: 0.0005580231663770974\n",
      "        total_loss: 2.36950945854187\n",
      "        vf_explained_var: -0.13654297590255737\n",
      "        vf_loss: 2.3689515590667725\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3672000\n",
      "  num_agent_steps_trained: 3672000\n",
      "  num_steps_sampled: 3672000\n",
      "  num_steps_trained: 3672000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 918\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.775000000000006\n",
      "  ram_util_percent: 89.075\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07218109381468052\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08276451276227276\n",
      "  mean_inference_ms: 0.7925478976162939\n",
      "  mean_raw_obs_processing_ms: 0.09553378444245095\n",
      "time_since_restore: 6819.840029716492\n",
      "time_this_iter_s: 8.63130521774292\n",
      "time_total_s: 6819.840029716492\n",
      "timers:\n",
      "  learn_throughput: 1172.048\n",
      "  learn_time_ms: 3412.83\n",
      "  load_throughput: 19128053.814\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 461.597\n",
      "  sample_time_ms: 8665.574\n",
      "  update_time_ms: 2.33\n",
      "timestamp: 1658400784\n",
      "timesteps_since_restore: 3672000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3672000\n",
      "training_iteration: 918\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3676000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-53-12\n",
      "done: false\n",
      "episode_len_mean: 199.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.0\n",
      "episode_reward_min: 100.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19101\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2414988875389099\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038130786269903183\n",
      "        model: {}\n",
      "        policy_loss: 0.00013726763427257538\n",
      "        total_loss: 2.369089126586914\n",
      "        vf_explained_var: -0.14142358303070068\n",
      "        vf_loss: 2.3689517974853516\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3676000\n",
      "  num_agent_steps_trained: 3676000\n",
      "  num_steps_sampled: 3676000\n",
      "  num_steps_trained: 3676000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 919\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.05833333333334\n",
      "  ram_util_percent: 88.675\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07219965105784376\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08278537796493607\n",
      "  mean_inference_ms: 0.7927562051447543\n",
      "  mean_raw_obs_processing_ms: 0.09555765500652576\n",
      "time_since_restore: 6828.477735280991\n",
      "time_this_iter_s: 8.637705564498901\n",
      "time_total_s: 6828.477735280991\n",
      "timers:\n",
      "  learn_throughput: 1180.294\n",
      "  learn_time_ms: 3388.987\n",
      "  load_throughput: 19023943.758\n",
      "  load_time_ms: 0.21\n",
      "  sample_throughput: 460.805\n",
      "  sample_time_ms: 8680.466\n",
      "  update_time_ms: 2.29\n",
      "timestamp: 1658400792\n",
      "timesteps_since_restore: 3676000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3676000\n",
      "training_iteration: 919\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3680000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-53-21\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19121\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22946462035179138\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033332081511616707\n",
      "        model: {}\n",
      "        policy_loss: 7.910792191978544e-05\n",
      "        total_loss: 2.3690342903137207\n",
      "        vf_explained_var: 0.0002529023040551692\n",
      "        vf_loss: 2.368955373764038\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3680000\n",
      "  num_agent_steps_trained: 3680000\n",
      "  num_steps_sampled: 3680000\n",
      "  num_steps_trained: 3680000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 920\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.333333333333336\n",
      "  ram_util_percent: 88.37499999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07221913591527054\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08280721208635779\n",
      "  mean_inference_ms: 0.7929737817142006\n",
      "  mean_raw_obs_processing_ms: 0.09558206199611967\n",
      "time_since_restore: 6837.0225875377655\n",
      "time_this_iter_s: 8.544852256774902\n",
      "time_total_s: 6837.0225875377655\n",
      "timers:\n",
      "  learn_throughput: 1166.117\n",
      "  learn_time_ms: 3430.186\n",
      "  load_throughput: 19093224.081\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 464.07\n",
      "  sample_time_ms: 8619.382\n",
      "  update_time_ms: 2.319\n",
      "timestamp: 1658400801\n",
      "timesteps_since_restore: 3680000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3680000\n",
      "training_iteration: 920\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3684000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-53-29\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19141\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24519246816635132\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032567987218499184\n",
      "        model: {}\n",
      "        policy_loss: 0.0003105343785136938\n",
      "        total_loss: 2.3692626953125\n",
      "        vf_explained_var: 0.002867315895855427\n",
      "        vf_loss: 2.3689520359039307\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3684000\n",
      "  num_agent_steps_trained: 3684000\n",
      "  num_steps_sampled: 3684000\n",
      "  num_steps_trained: 3684000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 921\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.22307692307691\n",
      "  ram_util_percent: 88.52307692307691\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07223971822780494\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08282996780082287\n",
      "  mean_inference_ms: 0.7932033448238114\n",
      "  mean_raw_obs_processing_ms: 0.09560757801236575\n",
      "time_since_restore: 6845.549406290054\n",
      "time_this_iter_s: 8.526818752288818\n",
      "time_total_s: 6845.549406290054\n",
      "timers:\n",
      "  learn_throughput: 1158.171\n",
      "  learn_time_ms: 3453.721\n",
      "  load_throughput: 19067184.907\n",
      "  load_time_ms: 0.21\n",
      "  sample_throughput: 463.02\n",
      "  sample_time_ms: 8638.93\n",
      "  update_time_ms: 2.373\n",
      "timestamp: 1658400809\n",
      "timesteps_since_restore: 3684000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3684000\n",
      "training_iteration: 921\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3688000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-53-38\n",
      "done: false\n",
      "episode_len_mean: 199.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.78\n",
      "episode_reward_min: 178.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19161\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.237173393368721\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031364215537905693\n",
      "        model: {}\n",
      "        policy_loss: 0.0005866511492058635\n",
      "        total_loss: 1.981433391571045\n",
      "        vf_explained_var: -0.19030454754829407\n",
      "        vf_loss: 1.9808467626571655\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3688000\n",
      "  num_agent_steps_trained: 3688000\n",
      "  num_steps_sampled: 3688000\n",
      "  num_steps_trained: 3688000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 922\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.218181818181826\n",
      "  ram_util_percent: 88.37272727272729\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0722562669440772\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08284848170768765\n",
      "  mean_inference_ms: 0.793378913389079\n",
      "  mean_raw_obs_processing_ms: 0.09562753722437846\n",
      "time_since_restore: 6853.774790048599\n",
      "time_this_iter_s: 8.225383758544922\n",
      "time_total_s: 6853.774790048599\n",
      "timers:\n",
      "  learn_throughput: 1161.876\n",
      "  learn_time_ms: 3442.707\n",
      "  load_throughput: 19165199.909\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 462.966\n",
      "  sample_time_ms: 8639.945\n",
      "  update_time_ms: 2.373\n",
      "timestamp: 1658400818\n",
      "timesteps_since_restore: 3688000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3688000\n",
      "training_iteration: 922\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3692000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-53-46\n",
      "done: false\n",
      "episode_len_mean: 199.78\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.78\n",
      "episode_reward_min: 178.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19181\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22606344521045685\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003564487909898162\n",
      "        model: {}\n",
      "        policy_loss: 3.218586789444089e-05\n",
      "        total_loss: 1.2601128816604614\n",
      "        vf_explained_var: -0.19838112592697144\n",
      "        vf_loss: 1.2600806951522827\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3692000\n",
      "  num_agent_steps_trained: 3692000\n",
      "  num_steps_sampled: 3692000\n",
      "  num_steps_trained: 3692000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 923\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.96666666666667\n",
      "  ram_util_percent: 88.48333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07227027296329622\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08286403275833827\n",
      "  mean_inference_ms: 0.7935227710025583\n",
      "  mean_raw_obs_processing_ms: 0.0956443510105736\n",
      "time_since_restore: 6862.079029560089\n",
      "time_this_iter_s: 8.304239511489868\n",
      "time_total_s: 6862.079029560089\n",
      "timers:\n",
      "  learn_throughput: 1152.128\n",
      "  learn_time_ms: 3471.836\n",
      "  load_throughput: 18178801.604\n",
      "  load_time_ms: 0.22\n",
      "  sample_throughput: 469.341\n",
      "  sample_time_ms: 8522.594\n",
      "  update_time_ms: 2.327\n",
      "timestamp: 1658400826\n",
      "timesteps_since_restore: 3692000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3692000\n",
      "training_iteration: 923\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3696000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-53-58\n",
      "done: false\n",
      "episode_len_mean: 199.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.09\n",
      "episode_reward_min: 131.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 19202\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2402864247560501\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003961916547268629\n",
      "        model: {}\n",
      "        policy_loss: 0.0010770538356155157\n",
      "        total_loss: 2.911872625350952\n",
      "        vf_explained_var: -0.16129036247730255\n",
      "        vf_loss: 2.9107956886291504\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3696000\n",
      "  num_agent_steps_trained: 3696000\n",
      "  num_steps_sampled: 3696000\n",
      "  num_steps_trained: 3696000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 924\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 66.34444444444445\n",
      "  ram_util_percent: 89.02222222222223\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07229627282816581\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08289353364633642\n",
      "  mean_inference_ms: 0.7938033552503841\n",
      "  mean_raw_obs_processing_ms: 0.09567560589435745\n",
      "time_since_restore: 6874.444625377655\n",
      "time_this_iter_s: 12.365595817565918\n",
      "time_total_s: 6874.444625377655\n",
      "timers:\n",
      "  learn_throughput: 1136.795\n",
      "  learn_time_ms: 3518.665\n",
      "  load_throughput: 17643512.462\n",
      "  load_time_ms: 0.227\n",
      "  sample_throughput: 449.616\n",
      "  sample_time_ms: 8896.487\n",
      "  update_time_ms: 2.342\n",
      "timestamp: 1658400838\n",
      "timesteps_since_restore: 3696000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3696000\n",
      "training_iteration: 924\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3700000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-54-07\n",
      "done: false\n",
      "episode_len_mean: 199.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.09\n",
      "episode_reward_min: 131.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19222\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22313983738422394\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00235368893481791\n",
      "        model: {}\n",
      "        policy_loss: 0.008617491461336613\n",
      "        total_loss: 7.87152099609375\n",
      "        vf_explained_var: -1.7227665694008465e-07\n",
      "        vf_loss: 7.862903118133545\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3700000\n",
      "  num_agent_steps_trained: 3700000\n",
      "  num_steps_sampled: 3700000\n",
      "  num_steps_trained: 3700000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 925\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.47692307692307\n",
      "  ram_util_percent: 88.9\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07232059595356599\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08292114858471869\n",
      "  mean_inference_ms: 0.7940632947958015\n",
      "  mean_raw_obs_processing_ms: 0.09570478015149952\n",
      "time_since_restore: 6883.371706008911\n",
      "time_this_iter_s: 8.927080631256104\n",
      "time_total_s: 6883.371706008911\n",
      "timers:\n",
      "  learn_throughput: 1114.094\n",
      "  learn_time_ms: 3590.362\n",
      "  load_throughput: 17556735.036\n",
      "  load_time_ms: 0.228\n",
      "  sample_throughput: 446.908\n",
      "  sample_time_ms: 8950.379\n",
      "  update_time_ms: 2.343\n",
      "timestamp: 1658400847\n",
      "timesteps_since_restore: 3700000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3700000\n",
      "training_iteration: 925\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3704000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-54-19\n",
      "done: false\n",
      "episode_len_mean: 198.2\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.2\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19242\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22078043222427368\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003541494719684124\n",
      "        model: {}\n",
      "        policy_loss: 0.0020090860780328512\n",
      "        total_loss: 4.724791049957275\n",
      "        vf_explained_var: -0.03225795924663544\n",
      "        vf_loss: 4.722782135009766\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3704000\n",
      "  num_agent_steps_trained: 3704000\n",
      "  num_steps_sampled: 3704000\n",
      "  num_steps_trained: 3704000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 926\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 60.61875\n",
      "  ram_util_percent: 89.19375\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07235132785715336\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08295653191497926\n",
      "  mean_inference_ms: 0.7943974397270672\n",
      "  mean_raw_obs_processing_ms: 0.09574211570566467\n",
      "time_since_restore: 6894.961355209351\n",
      "time_this_iter_s: 11.589649200439453\n",
      "time_total_s: 6894.961355209351\n",
      "timers:\n",
      "  learn_throughput: 1072.578\n",
      "  learn_time_ms: 3729.332\n",
      "  load_throughput: 18428400.703\n",
      "  load_time_ms: 0.217\n",
      "  sample_throughput: 433.152\n",
      "  sample_time_ms: 9234.624\n",
      "  update_time_ms: 2.367\n",
      "timestamp: 1658400859\n",
      "timesteps_since_restore: 3704000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3704000\n",
      "training_iteration: 926\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3708000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-54-29\n",
      "done: false\n",
      "episode_len_mean: 198.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.42\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19262\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22199945151805878\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028889491222798824\n",
      "        model: {}\n",
      "        policy_loss: 0.002153923502191901\n",
      "        total_loss: 3.3791704177856445\n",
      "        vf_explained_var: -0.032258082181215286\n",
      "        vf_loss: 3.377016067504883\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3708000\n",
      "  num_agent_steps_trained: 3708000\n",
      "  num_steps_sampled: 3708000\n",
      "  num_steps_trained: 3708000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 927\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 58.28666666666666\n",
      "  ram_util_percent: 89.61333333333332\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07238597039619823\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08299637489079631\n",
      "  mean_inference_ms: 0.7947820116624302\n",
      "  mean_raw_obs_processing_ms: 0.09578478557975544\n",
      "time_since_restore: 6904.995318174362\n",
      "time_this_iter_s: 10.033962965011597\n",
      "time_total_s: 6904.995318174362\n",
      "timers:\n",
      "  learn_throughput: 1062.744\n",
      "  learn_time_ms: 3763.842\n",
      "  load_throughput: 18942323.586\n",
      "  load_time_ms: 0.211\n",
      "  sample_throughput: 426.956\n",
      "  sample_time_ms: 9368.641\n",
      "  update_time_ms: 2.389\n",
      "timestamp: 1658400869\n",
      "timesteps_since_restore: 3708000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3708000\n",
      "training_iteration: 927\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3712000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-54-38\n",
      "done: false\n",
      "episode_len_mean: 198.42\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.42\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19282\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20593538880348206\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003525923704728484\n",
      "        model: {}\n",
      "        policy_loss: 0.0018736241618171334\n",
      "        total_loss: 3.378890037536621\n",
      "        vf_explained_var: -0.03225810080766678\n",
      "        vf_loss: 3.377016067504883\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3712000\n",
      "  num_agent_steps_trained: 3712000\n",
      "  num_steps_sampled: 3712000\n",
      "  num_steps_trained: 3712000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 928\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 47.838461538461544\n",
      "  ram_util_percent: 89.86153846153844\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07242447306319023\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08303989558205961\n",
      "  mean_inference_ms: 0.7952063531027704\n",
      "  mean_raw_obs_processing_ms: 0.09583160656743846\n",
      "time_since_restore: 6914.119490623474\n",
      "time_this_iter_s: 9.124172449111938\n",
      "time_total_s: 6914.119490623474\n",
      "timers:\n",
      "  learn_throughput: 1060.637\n",
      "  learn_time_ms: 3771.32\n",
      "  load_throughput: 18961591.32\n",
      "  load_time_ms: 0.211\n",
      "  sample_throughput: 423.458\n",
      "  sample_time_ms: 9446.047\n",
      "  update_time_ms: 2.386\n",
      "timestamp: 1658400878\n",
      "timesteps_since_restore: 3712000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3712000\n",
      "training_iteration: 928\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3716000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-54-47\n",
      "done: false\n",
      "episode_len_mean: 199.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.11\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19302\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22587576508522034\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028149476274847984\n",
      "        model: {}\n",
      "        policy_loss: 0.002529434859752655\n",
      "        total_loss: 3.3795456886291504\n",
      "        vf_explained_var: -0.032258015125989914\n",
      "        vf_loss: 3.377016305923462\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3716000\n",
      "  num_agent_steps_trained: 3716000\n",
      "  num_steps_sampled: 3716000\n",
      "  num_steps_trained: 3716000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 929\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 50.51538461538462\n",
      "  ram_util_percent: 89.11538461538461\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07245061105520292\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08306927050509959\n",
      "  mean_inference_ms: 0.7954959586288518\n",
      "  mean_raw_obs_processing_ms: 0.09586355703689087\n",
      "time_since_restore: 6923.3925104141235\n",
      "time_this_iter_s: 9.273019790649414\n",
      "time_total_s: 6923.3925104141235\n",
      "timers:\n",
      "  learn_throughput: 1030.815\n",
      "  learn_time_ms: 3880.425\n",
      "  load_throughput: 18216304.017\n",
      "  load_time_ms: 0.22\n",
      "  sample_throughput: 425.172\n",
      "  sample_time_ms: 9407.947\n",
      "  update_time_ms: 2.323\n",
      "timestamp: 1658400887\n",
      "timesteps_since_restore: 3716000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3716000\n",
      "training_iteration: 929\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3720000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-54-59\n",
      "done: false\n",
      "episode_len_mean: 199.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.11\n",
      "episode_reward_min: 111.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19322\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.220014750957489\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002434313064441085\n",
      "        model: {}\n",
      "        policy_loss: 0.0018855406669899821\n",
      "        total_loss: 3.3789021968841553\n",
      "        vf_explained_var: -0.000546038500033319\n",
      "        vf_loss: 3.377016544342041\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3720000\n",
      "  num_agent_steps_trained: 3720000\n",
      "  num_steps_sampled: 3720000\n",
      "  num_steps_trained: 3720000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 930\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 60.59375\n",
      "  ram_util_percent: 89.46875\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07248170649947162\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08310394440372755\n",
      "  mean_inference_ms: 0.7958404729982352\n",
      "  mean_raw_obs_processing_ms: 0.09590192673586374\n",
      "time_since_restore: 6934.806563138962\n",
      "time_this_iter_s: 11.414052724838257\n",
      "time_total_s: 6934.806563138962\n",
      "timers:\n",
      "  learn_throughput: 988.6\n",
      "  learn_time_ms: 4046.126\n",
      "  load_throughput: 17850001.064\n",
      "  load_time_ms: 0.224\n",
      "  sample_throughput: 415.028\n",
      "  sample_time_ms: 9637.895\n",
      "  update_time_ms: 2.356\n",
      "timestamp: 1658400899\n",
      "timesteps_since_restore: 3720000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3720000\n",
      "training_iteration: 930\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3724000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-55-06\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19342\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21107709407806396\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004073051735758781\n",
      "        model: {}\n",
      "        policy_loss: 0.0008424980915151536\n",
      "        total_loss: 3.377858877182007\n",
      "        vf_explained_var: -0.032258160412311554\n",
      "        vf_loss: 3.377016067504883\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3724000\n",
      "  num_agent_steps_trained: 3724000\n",
      "  num_steps_sampled: 3724000\n",
      "  num_steps_trained: 3724000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 931\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.27272727272727\n",
      "  ram_util_percent: 89.25454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07250400566748044\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08312834618853912\n",
      "  mean_inference_ms: 0.7960854062479066\n",
      "  mean_raw_obs_processing_ms: 0.09592933758094897\n",
      "time_since_restore: 6942.339020013809\n",
      "time_this_iter_s: 7.532456874847412\n",
      "time_total_s: 6942.339020013809\n",
      "timers:\n",
      "  learn_throughput: 998.449\n",
      "  learn_time_ms: 4006.215\n",
      "  load_throughput: 18104258.12\n",
      "  load_time_ms: 0.221\n",
      "  sample_throughput: 410.492\n",
      "  sample_time_ms: 9744.407\n",
      "  update_time_ms: 2.33\n",
      "timestamp: 1658400906\n",
      "timesteps_since_restore: 3724000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3724000\n",
      "training_iteration: 931\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3728000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-55-15\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19362\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2172907292842865\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0020679645240306854\n",
      "        model: {}\n",
      "        policy_loss: 0.0023309143725782633\n",
      "        total_loss: 3.379347324371338\n",
      "        vf_explained_var: -0.032099511474370956\n",
      "        vf_loss: 3.377016305923462\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3728000\n",
      "  num_agent_steps_trained: 3728000\n",
      "  num_steps_sampled: 3728000\n",
      "  num_steps_trained: 3728000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 932\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.208333333333336\n",
      "  ram_util_percent: 88.65000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07252125628507852\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08314694397565013\n",
      "  mean_inference_ms: 0.7962694330372091\n",
      "  mean_raw_obs_processing_ms: 0.09595020443219218\n",
      "time_since_restore: 6950.65261721611\n",
      "time_this_iter_s: 8.313597202301025\n",
      "time_total_s: 6950.65261721611\n",
      "timers:\n",
      "  learn_throughput: 989.801\n",
      "  learn_time_ms: 4041.215\n",
      "  load_throughput: 17050016.26\n",
      "  load_time_ms: 0.235\n",
      "  sample_throughput: 413.3\n",
      "  sample_time_ms: 9678.197\n",
      "  update_time_ms: 2.342\n",
      "timestamp: 1658400915\n",
      "timesteps_since_restore: 3728000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3728000\n",
      "training_iteration: 932\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3732000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-55-23\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19382\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23668253421783447\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004385893698781729\n",
      "        model: {}\n",
      "        policy_loss: -0.0001635452063055709\n",
      "        total_loss: 3.3768537044525146\n",
      "        vf_explained_var: -0.00015289238945115358\n",
      "        vf_loss: 3.377017021179199\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3732000\n",
      "  num_agent_steps_trained: 3732000\n",
      "  num_steps_sampled: 3732000\n",
      "  num_steps_trained: 3732000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 933\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.218181818181826\n",
      "  ram_util_percent: 88.43636363636362\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07253439574636372\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0831613592742512\n",
      "  mean_inference_ms: 0.7964093665867861\n",
      "  mean_raw_obs_processing_ms: 0.09596621071031358\n",
      "time_since_restore: 6958.574360847473\n",
      "time_this_iter_s: 7.921743631362915\n",
      "time_total_s: 6958.574360847473\n",
      "timers:\n",
      "  learn_throughput: 1001.544\n",
      "  learn_time_ms: 3993.832\n",
      "  load_throughput: 17970454.156\n",
      "  load_time_ms: 0.223\n",
      "  sample_throughput: 411.408\n",
      "  sample_time_ms: 9722.713\n",
      "  update_time_ms: 2.339\n",
      "timestamp: 1658400923\n",
      "timesteps_since_restore: 3732000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3732000\n",
      "training_iteration: 933\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3736000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-55-31\n",
      "done: false\n",
      "episode_len_mean: 199.18\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.18\n",
      "episode_reward_min: 118.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 19403\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21057480573654175\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004084716085344553\n",
      "        model: {}\n",
      "        policy_loss: -0.006982614751905203\n",
      "        total_loss: 8.680023193359375\n",
      "        vf_explained_var: -7.41533057180277e-08\n",
      "        vf_loss: 8.687005043029785\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3736000\n",
      "  num_agent_steps_trained: 3736000\n",
      "  num_steps_sampled: 3736000\n",
      "  num_steps_trained: 3736000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 934\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.44545454545454\n",
      "  ram_util_percent: 88.40909090909089\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07254659211335182\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08317438315841784\n",
      "  mean_inference_ms: 0.796533069024285\n",
      "  mean_raw_obs_processing_ms: 0.09598076221439836\n",
      "time_since_restore: 6966.364017486572\n",
      "time_this_iter_s: 7.789656639099121\n",
      "time_total_s: 6966.364017486572\n",
      "timers:\n",
      "  learn_throughput: 1018.729\n",
      "  learn_time_ms: 3926.462\n",
      "  load_throughput: 18424353.174\n",
      "  load_time_ms: 0.217\n",
      "  sample_throughput: 430.823\n",
      "  sample_time_ms: 9284.562\n",
      "  update_time_ms: 2.309\n",
      "timestamp: 1658400931\n",
      "timesteps_since_restore: 3736000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3736000\n",
      "training_iteration: 934\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3740000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-55-40\n",
      "done: false\n",
      "episode_len_mean: 198.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.11\n",
      "episode_reward_min: 93.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19423\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20184896886348724\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003793765092268586\n",
      "        model: {}\n",
      "        policy_loss: 0.0018575014546513557\n",
      "        total_loss: 4.742280960083008\n",
      "        vf_explained_var: 1.0690381202493882e-07\n",
      "        vf_loss: 4.740423202514648\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3740000\n",
      "  num_agent_steps_trained: 3740000\n",
      "  num_steps_sampled: 3740000\n",
      "  num_steps_trained: 3740000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 935\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.142857142857146\n",
      "  ram_util_percent: 88.69285714285716\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07255614512819619\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08318460544397305\n",
      "  mean_inference_ms: 0.7966288178722885\n",
      "  mean_raw_obs_processing_ms: 0.09599216275195481\n",
      "time_since_restore: 6975.909818410873\n",
      "time_this_iter_s: 9.545800924301147\n",
      "time_total_s: 6975.909818410873\n",
      "timers:\n",
      "  learn_throughput: 1021.894\n",
      "  learn_time_ms: 3914.301\n",
      "  load_throughput: 18069161.012\n",
      "  load_time_ms: 0.221\n",
      "  sample_throughput: 430.486\n",
      "  sample_time_ms: 9291.826\n",
      "  update_time_ms: 2.243\n",
      "timestamp: 1658400940\n",
      "timesteps_since_restore: 3740000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3740000\n",
      "training_iteration: 935\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3744000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-55-48\n",
      "done: false\n",
      "episode_len_mean: 198.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.11\n",
      "episode_reward_min: 93.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19443\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22665667533874512\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002614776836708188\n",
      "        model: {}\n",
      "        policy_loss: 0.002246805466711521\n",
      "        total_loss: 3.9336986541748047\n",
      "        vf_explained_var: -7.408921476326213e-08\n",
      "        vf_loss: 3.9314515590667725\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3744000\n",
      "  num_agent_steps_trained: 3744000\n",
      "  num_steps_sampled: 3744000\n",
      "  num_steps_trained: 3744000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 936\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.03333333333334\n",
      "  ram_util_percent: 88.69166666666668\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07256740108654991\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08319681810312783\n",
      "  mean_inference_ms: 0.7967419888072459\n",
      "  mean_raw_obs_processing_ms: 0.09600558847966699\n",
      "time_since_restore: 6984.091328620911\n",
      "time_this_iter_s: 8.181510210037231\n",
      "time_total_s: 6984.091328620911\n",
      "timers:\n",
      "  learn_throughput: 1060.825\n",
      "  learn_time_ms: 3770.649\n",
      "  load_throughput: 18454753.052\n",
      "  load_time_ms: 0.217\n",
      "  sample_throughput: 440.414\n",
      "  sample_time_ms: 9082.353\n",
      "  update_time_ms: 2.203\n",
      "timestamp: 1658400948\n",
      "timesteps_since_restore: 3744000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3744000\n",
      "training_iteration: 936\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3748000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-55-58\n",
      "done: false\n",
      "episode_len_mean: 198.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.11\n",
      "episode_reward_min: 93.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19463\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21250860393047333\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0046166060492396355\n",
      "        model: {}\n",
      "        policy_loss: 0.0007968657882884145\n",
      "        total_loss: 3.932248592376709\n",
      "        vf_explained_var: 8.697151088199462e-08\n",
      "        vf_loss: 3.9314515590667725\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3748000\n",
      "  num_agent_steps_trained: 3748000\n",
      "  num_steps_sampled: 3748000\n",
      "  num_steps_trained: 3748000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 937\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.707692307692305\n",
      "  ram_util_percent: 88.66153846153846\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07258303101709541\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08321381155830407\n",
      "  mean_inference_ms: 0.7969055298249614\n",
      "  mean_raw_obs_processing_ms: 0.09602454894536784\n",
      "time_since_restore: 6993.538809776306\n",
      "time_this_iter_s: 9.447481155395508\n",
      "time_total_s: 6993.538809776306\n",
      "timers:\n",
      "  learn_throughput: 1071.159\n",
      "  learn_time_ms: 3734.274\n",
      "  load_throughput: 18610333.888\n",
      "  load_time_ms: 0.215\n",
      "  sample_throughput: 448.627\n",
      "  sample_time_ms: 8916.083\n",
      "  update_time_ms: 2.194\n",
      "timestamp: 1658400958\n",
      "timesteps_since_restore: 3748000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3748000\n",
      "training_iteration: 937\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3752000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-56-06\n",
      "done: false\n",
      "episode_len_mean: 198.11\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.11\n",
      "episode_reward_min: 93.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19483\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21308790147304535\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025305694434791803\n",
      "        model: {}\n",
      "        policy_loss: 0.002857112791389227\n",
      "        total_loss: 3.9343087673187256\n",
      "        vf_explained_var: 2.775141005884052e-08\n",
      "        vf_loss: 3.9314517974853516\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3752000\n",
      "  num_agent_steps_trained: 3752000\n",
      "  num_steps_sampled: 3752000\n",
      "  num_steps_trained: 3752000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 938\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.445454545454545\n",
      "  ram_util_percent: 88.55454545454546\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07259821988895668\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08323017324041353\n",
      "  mean_inference_ms: 0.7970635156387641\n",
      "  mean_raw_obs_processing_ms: 0.09604313977528815\n",
      "time_since_restore: 7001.374201059341\n",
      "time_this_iter_s: 7.835391283035278\n",
      "time_total_s: 7001.374201059341\n",
      "timers:\n",
      "  learn_throughput: 1073.51\n",
      "  learn_time_ms: 3726.096\n",
      "  load_throughput: 18804321.901\n",
      "  load_time_ms: 0.213\n",
      "  sample_throughput: 456.741\n",
      "  sample_time_ms: 8757.696\n",
      "  update_time_ms: 2.254\n",
      "timestamp: 1658400966\n",
      "timesteps_since_restore: 3752000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3752000\n",
      "training_iteration: 938\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3756000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-56-14\n",
      "done: false\n",
      "episode_len_mean: 198.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.93\n",
      "episode_reward_min: 93.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19503\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23081789910793304\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028769385535269976\n",
      "        model: {}\n",
      "        policy_loss: 0.0012630870332941413\n",
      "        total_loss: 3.9327151775360107\n",
      "        vf_explained_var: 3.4352783728763825e-08\n",
      "        vf_loss: 3.9314517974853516\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3756000\n",
      "  num_agent_steps_trained: 3756000\n",
      "  num_steps_sampled: 3756000\n",
      "  num_steps_trained: 3756000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 939\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.550000000000004\n",
      "  ram_util_percent: 88.49166666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07261340193082975\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08324678084509066\n",
      "  mean_inference_ms: 0.7972334741366112\n",
      "  mean_raw_obs_processing_ms: 0.09606188926839121\n",
      "time_since_restore: 7009.494928359985\n",
      "time_this_iter_s: 8.120727300643921\n",
      "time_total_s: 7009.494928359985\n",
      "timers:\n",
      "  learn_throughput: 1101.732\n",
      "  learn_time_ms: 3630.649\n",
      "  load_throughput: 19726297.472\n",
      "  load_time_ms: 0.203\n",
      "  sample_throughput: 458.181\n",
      "  sample_time_ms: 8730.176\n",
      "  update_time_ms: 2.226\n",
      "timestamp: 1658400974\n",
      "timesteps_since_restore: 3756000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3756000\n",
      "training_iteration: 939\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3760000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-56-22\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19523\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23177386820316315\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037943620700389147\n",
      "        model: {}\n",
      "        policy_loss: 0.0027797601651400328\n",
      "        total_loss: 3.934231996536255\n",
      "        vf_explained_var: -1.076729105875529e-08\n",
      "        vf_loss: 3.9314517974853516\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3760000\n",
      "  num_agent_steps_trained: 3760000\n",
      "  num_steps_sampled: 3760000\n",
      "  num_steps_trained: 3760000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 940\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.05\n",
      "  ram_util_percent: 88.58333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07262632387471307\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08326167557724386\n",
      "  mean_inference_ms: 0.7973759340701367\n",
      "  mean_raw_obs_processing_ms: 0.09607766401373877\n",
      "time_since_restore: 7017.765591144562\n",
      "time_this_iter_s: 8.270662784576416\n",
      "time_total_s: 7017.765591144562\n",
      "timers:\n",
      "  learn_throughput: 1161.426\n",
      "  learn_time_ms: 3444.042\n",
      "  load_throughput: 20131048.716\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 470.216\n",
      "  sample_time_ms: 8506.731\n",
      "  update_time_ms: 2.194\n",
      "timestamp: 1658400982\n",
      "timesteps_since_restore: 3760000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3760000\n",
      "training_iteration: 940\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3764000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-56-30\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19543\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23328709602355957\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0013005000073462725\n",
      "        model: {}\n",
      "        policy_loss: 0.004354457836598158\n",
      "        total_loss: 3.9358065128326416\n",
      "        vf_explained_var: 6.588556544784296e-08\n",
      "        vf_loss: 3.9314520359039307\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3764000\n",
      "  num_agent_steps_trained: 3764000\n",
      "  num_steps_sampled: 3764000\n",
      "  num_steps_trained: 3764000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 941\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.590909090909086\n",
      "  ram_util_percent: 88.53636363636363\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07263796722635311\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08327547102988078\n",
      "  mean_inference_ms: 0.7975038334853569\n",
      "  mean_raw_obs_processing_ms: 0.09609207191895709\n",
      "time_since_restore: 7025.285028219223\n",
      "time_this_iter_s: 7.519437074661255\n",
      "time_total_s: 7025.285028219223\n",
      "timers:\n",
      "  learn_throughput: 1166.042\n",
      "  learn_time_ms: 3430.408\n",
      "  load_throughput: 20152812.012\n",
      "  load_time_ms: 0.198\n",
      "  sample_throughput: 480.093\n",
      "  sample_time_ms: 8331.727\n",
      "  update_time_ms: 2.245\n",
      "timestamp: 1658400990\n",
      "timesteps_since_restore: 3764000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3764000\n",
      "training_iteration: 941\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3768000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-56-37\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19563\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20351795852184296\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001684857881627977\n",
      "        model: {}\n",
      "        policy_loss: 0.004135265480726957\n",
      "        total_loss: 3.935586929321289\n",
      "        vf_explained_var: 1.8009576052691045e-08\n",
      "        vf_loss: 3.9314515590667725\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3768000\n",
      "  num_agent_steps_trained: 3768000\n",
      "  num_steps_sampled: 3768000\n",
      "  num_steps_trained: 3768000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 942\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.279999999999994\n",
      "  ram_util_percent: 88.49000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0726438113196479\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08328274094571432\n",
      "  mean_inference_ms: 0.7975670536116113\n",
      "  mean_raw_obs_processing_ms: 0.09609967227457306\n",
      "time_since_restore: 7032.7968809604645\n",
      "time_this_iter_s: 7.511852741241455\n",
      "time_total_s: 7032.7968809604645\n",
      "timers:\n",
      "  learn_throughput: 1181.798\n",
      "  learn_time_ms: 3384.673\n",
      "  load_throughput: 21210134.008\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 482.899\n",
      "  sample_time_ms: 8283.299\n",
      "  update_time_ms: 2.216\n",
      "timestamp: 1658400997\n",
      "timesteps_since_restore: 3768000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3768000\n",
      "training_iteration: 942\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3772000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-56-45\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19583\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.204193577170372\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0036930092610418797\n",
      "        model: {}\n",
      "        policy_loss: 0.00240718643181026\n",
      "        total_loss: 3.9338598251342773\n",
      "        vf_explained_var: 1.6535482316726302e-08\n",
      "        vf_loss: 3.931452989578247\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3772000\n",
      "  num_agent_steps_trained: 3772000\n",
      "  num_steps_sampled: 3772000\n",
      "  num_steps_trained: 3772000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 943\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.4\n",
      "  ram_util_percent: 88.4090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07264907225034625\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08328940509019019\n",
      "  mean_inference_ms: 0.7976268277853745\n",
      "  mean_raw_obs_processing_ms: 0.0961068999834569\n",
      "time_since_restore: 7040.444894790649\n",
      "time_this_iter_s: 7.6480138301849365\n",
      "time_total_s: 7040.444894790649\n",
      "timers:\n",
      "  learn_throughput: 1183.196\n",
      "  learn_time_ms: 3380.675\n",
      "  load_throughput: 21079552.708\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 486.987\n",
      "  sample_time_ms: 8213.763\n",
      "  update_time_ms: 2.245\n",
      "timestamp: 1658401005\n",
      "timesteps_since_restore: 3772000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3772000\n",
      "training_iteration: 943\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3776000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-56-53\n",
      "done: false\n",
      "episode_len_mean: 197.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.25\n",
      "episode_reward_min: 18.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 19604\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21228957176208496\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0019028064562007785\n",
      "        model: {}\n",
      "        policy_loss: -7.045884558465332e-05\n",
      "        total_loss: 1.406179666519165\n",
      "        vf_explained_var: -0.22060415148735046\n",
      "        vf_loss: 1.40625\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3776000\n",
      "  num_agent_steps_trained: 3776000\n",
      "  num_steps_sampled: 3776000\n",
      "  num_steps_trained: 3776000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 944\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.199999999999996\n",
      "  ram_util_percent: 88.50909090909092\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07265425028152904\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08329599846866666\n",
      "  mean_inference_ms: 0.7976752254573165\n",
      "  mean_raw_obs_processing_ms: 0.09611414827757335\n",
      "time_since_restore: 7048.233274459839\n",
      "time_this_iter_s: 7.788379669189453\n",
      "time_total_s: 7048.233274459839\n",
      "timers:\n",
      "  learn_throughput: 1182.629\n",
      "  learn_time_ms: 3382.295\n",
      "  load_throughput: 21116697.294\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 487.342\n",
      "  sample_time_ms: 8207.787\n",
      "  update_time_ms: 2.257\n",
      "timestamp: 1658401013\n",
      "timesteps_since_restore: 3776000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3776000\n",
      "training_iteration: 944\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3780000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-57-00\n",
      "done: false\n",
      "episode_len_mean: 197.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.25\n",
      "episode_reward_min: 18.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19624\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22980056703090668\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.006618740037083626\n",
      "        model: {}\n",
      "        policy_loss: -0.0036682819481939077\n",
      "        total_loss: 0.14754143357276917\n",
      "        vf_explained_var: -0.3477781414985657\n",
      "        vf_loss: 0.15120969712734222\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3780000\n",
      "  num_agent_steps_trained: 3780000\n",
      "  num_steps_sampled: 3780000\n",
      "  num_steps_trained: 3780000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 945\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.82727272727272\n",
      "  ram_util_percent: 88.60909090909091\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0726572688410425\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08329928476346232\n",
      "  mean_inference_ms: 0.79770200619163\n",
      "  mean_raw_obs_processing_ms: 0.09611881147085027\n",
      "time_since_restore: 7055.746908187866\n",
      "time_this_iter_s: 7.513633728027344\n",
      "time_total_s: 7055.746908187866\n",
      "timers:\n",
      "  learn_throughput: 1213.498\n",
      "  learn_time_ms: 3296.256\n",
      "  load_throughput: 21732145.078\n",
      "  load_time_ms: 0.184\n",
      "  sample_throughput: 494.339\n",
      "  sample_time_ms: 8091.62\n",
      "  update_time_ms: 2.242\n",
      "timestamp: 1658401020\n",
      "timesteps_since_restore: 3780000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3780000\n",
      "training_iteration: 945\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3784000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-57-08\n",
      "done: false\n",
      "episode_len_mean: 197.25\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.25\n",
      "episode_reward_min: 18.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19644\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2735034227371216\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.013073901645839214\n",
      "        model: {}\n",
      "        policy_loss: -0.0036433578934520483\n",
      "        total_loss: 0.14756643772125244\n",
      "        vf_explained_var: -0.3065122067928314\n",
      "        vf_loss: 0.1512097716331482\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3784000\n",
      "  num_agent_steps_trained: 3784000\n",
      "  num_steps_sampled: 3784000\n",
      "  num_steps_trained: 3784000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 946\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.016666666666666\n",
      "  ram_util_percent: 88.51666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07266168022325104\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08330422738797308\n",
      "  mean_inference_ms: 0.7977465272959889\n",
      "  mean_raw_obs_processing_ms: 0.09612566012412209\n",
      "time_since_restore: 7063.765430212021\n",
      "time_this_iter_s: 8.018522024154663\n",
      "time_total_s: 7063.765430212021\n",
      "timers:\n",
      "  learn_throughput: 1223.081\n",
      "  learn_time_ms: 3270.429\n",
      "  load_throughput: 21882373.81\n",
      "  load_time_ms: 0.183\n",
      "  sample_throughput: 499.061\n",
      "  sample_time_ms: 8015.055\n",
      "  update_time_ms: 2.213\n",
      "timestamp: 1658401028\n",
      "timesteps_since_restore: 3784000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3784000\n",
      "training_iteration: 946\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3788000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-57-16\n",
      "done: false\n",
      "episode_len_mean: 178.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 178.99\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 30\n",
      "episodes_total: 19674\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.3018663227558136\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.007425736635923386\n",
      "        model: {}\n",
      "        policy_loss: -0.006506600882858038\n",
      "        total_loss: 6.883627414703369\n",
      "        vf_explained_var: 3.3056223855965072e-06\n",
      "        vf_loss: 6.890133380889893\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3788000\n",
      "  num_agent_steps_trained: 3788000\n",
      "  num_steps_sampled: 3788000\n",
      "  num_steps_trained: 3788000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 947\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.54\n",
      "  ram_util_percent: 88.44000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07266751987477227\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08331151489870685\n",
      "  mean_inference_ms: 0.7978044147213571\n",
      "  mean_raw_obs_processing_ms: 0.09613596696315785\n",
      "time_since_restore: 7071.236419439316\n",
      "time_this_iter_s: 7.470989227294922\n",
      "time_total_s: 7071.236419439316\n",
      "timers:\n",
      "  learn_throughput: 1236.607\n",
      "  learn_time_ms: 3234.658\n",
      "  load_throughput: 20830911.348\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 511.048\n",
      "  sample_time_ms: 7827.054\n",
      "  update_time_ms: 2.234\n",
      "timestamp: 1658401036\n",
      "timesteps_since_restore: 3788000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3788000\n",
      "training_iteration: 947\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3792000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-57-24\n",
      "done: false\n",
      "episode_len_mean: 180.07\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 180.07\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19694\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.250060111284256\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004019164480268955\n",
      "        model: {}\n",
      "        policy_loss: 0.0028411655221134424\n",
      "        total_loss: 5.552239894866943\n",
      "        vf_explained_var: -3.1789462809683755e-05\n",
      "        vf_loss: 5.549398422241211\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3792000\n",
      "  num_agent_steps_trained: 3792000\n",
      "  num_steps_sampled: 3792000\n",
      "  num_steps_trained: 3792000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 948\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.55833333333333\n",
      "  ram_util_percent: 88.41666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07267165715963288\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08331674727217403\n",
      "  mean_inference_ms: 0.7978460845792505\n",
      "  mean_raw_obs_processing_ms: 0.09614276716621813\n",
      "time_since_restore: 7079.164899349213\n",
      "time_this_iter_s: 7.928479909896851\n",
      "time_total_s: 7079.164899349213\n",
      "timers:\n",
      "  learn_throughput: 1231.668\n",
      "  learn_time_ms: 3247.629\n",
      "  load_throughput: 20661596.059\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 513.655\n",
      "  sample_time_ms: 7787.333\n",
      "  update_time_ms: 2.202\n",
      "timestamp: 1658401044\n",
      "timesteps_since_restore: 3792000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3792000\n",
      "training_iteration: 948\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3796000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-57-31\n",
      "done: false\n",
      "episode_len_mean: 180.35\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 180.35\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19714\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24782271683216095\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004405174404382706\n",
      "        model: {}\n",
      "        policy_loss: -0.00046391665819101036\n",
      "        total_loss: 1.9148585796356201\n",
      "        vf_explained_var: -0.20768670737743378\n",
      "        vf_loss: 1.9153225421905518\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3796000\n",
      "  num_agent_steps_trained: 3796000\n",
      "  num_steps_sampled: 3796000\n",
      "  num_steps_trained: 3796000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 949\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.97272727272727\n",
      "  ram_util_percent: 88.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07267598925022843\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0833222790292077\n",
      "  mean_inference_ms: 0.7978908581494847\n",
      "  mean_raw_obs_processing_ms: 0.09614963736053486\n",
      "time_since_restore: 7086.73126077652\n",
      "time_this_iter_s: 7.566361427307129\n",
      "time_total_s: 7086.73126077652\n",
      "timers:\n",
      "  learn_throughput: 1245.172\n",
      "  learn_time_ms: 3212.408\n",
      "  load_throughput: 20715169.774\n",
      "  load_time_ms: 0.193\n",
      "  sample_throughput: 514.1\n",
      "  sample_time_ms: 7780.591\n",
      "  update_time_ms: 2.198\n",
      "timestamp: 1658401051\n",
      "timesteps_since_restore: 3796000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3796000\n",
      "training_iteration: 949\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3800000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-57-39\n",
      "done: false\n",
      "episode_len_mean: 179.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 179.8\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 19735\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2524776756763458\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003831766080111265\n",
      "        model: {}\n",
      "        policy_loss: -0.008067806251347065\n",
      "        total_loss: 5.88911771774292\n",
      "        vf_explained_var: -0.0906408354640007\n",
      "        vf_loss: 5.897185802459717\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3800000\n",
      "  num_agent_steps_trained: 3800000\n",
      "  num_steps_sampled: 3800000\n",
      "  num_steps_trained: 3800000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 950\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.58\n",
      "  ram_util_percent: 88.45\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07267969544032944\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08332690530680148\n",
      "  mean_inference_ms: 0.7979285339623291\n",
      "  mean_raw_obs_processing_ms: 0.09615547060999882\n",
      "time_since_restore: 7094.269381523132\n",
      "time_this_iter_s: 7.538120746612549\n",
      "time_total_s: 7094.269381523132\n",
      "timers:\n",
      "  learn_throughput: 1254.2\n",
      "  learn_time_ms: 3189.284\n",
      "  load_throughput: 20787035.064\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 519.721\n",
      "  sample_time_ms: 7696.434\n",
      "  update_time_ms: 2.201\n",
      "timestamp: 1658401059\n",
      "timesteps_since_restore: 3800000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3800000\n",
      "training_iteration: 950\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3804000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-57-48\n",
      "done: false\n",
      "episode_len_mean: 187.43\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 187.43\n",
      "episode_reward_min: 10.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 19756\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23414300382137299\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0035663279704749584\n",
      "        model: {}\n",
      "        policy_loss: 0.0034820041619241238\n",
      "        total_loss: 6.3946123123168945\n",
      "        vf_explained_var: -0.09677399694919586\n",
      "        vf_loss: 6.391129493713379\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3804000\n",
      "  num_agent_steps_trained: 3804000\n",
      "  num_steps_sampled: 3804000\n",
      "  num_steps_trained: 3804000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 951\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 45.04615384615384\n",
      "  ram_util_percent: 88.5769230769231\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07268668932786852\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0833346487717091\n",
      "  mean_inference_ms: 0.7979978743446674\n",
      "  mean_raw_obs_processing_ms: 0.0961640344702718\n",
      "time_since_restore: 7102.911732673645\n",
      "time_this_iter_s: 8.642351150512695\n",
      "time_total_s: 7102.911732673645\n",
      "timers:\n",
      "  learn_throughput: 1246.569\n",
      "  learn_time_ms: 3208.808\n",
      "  load_throughput: 20588067.248\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 515.046\n",
      "  sample_time_ms: 7766.292\n",
      "  update_time_ms: 2.16\n",
      "timestamp: 1658401068\n",
      "timesteps_since_restore: 3804000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3804000\n",
      "training_iteration: 951\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3808000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-57-56\n",
      "done: false\n",
      "episode_len_mean: 195.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.51\n",
      "episode_reward_min: 35.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19776\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2278008759021759\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003703234950080514\n",
      "        model: {}\n",
      "        policy_loss: 0.00605991343036294\n",
      "        total_loss: 6.457673072814941\n",
      "        vf_explained_var: 3.0507322890116484e-08\n",
      "        vf_loss: 6.451612949371338\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3808000\n",
      "  num_agent_steps_trained: 3808000\n",
      "  num_steps_sampled: 3808000\n",
      "  num_steps_trained: 3808000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 952\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.31818181818182\n",
      "  ram_util_percent: 88.51818181818182\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07269526758371782\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08334485611986471\n",
      "  mean_inference_ms: 0.7980851718255363\n",
      "  mean_raw_obs_processing_ms: 0.0961744064390874\n",
      "time_since_restore: 7111.10561132431\n",
      "time_this_iter_s: 8.193878650665283\n",
      "time_total_s: 7111.10561132431\n",
      "timers:\n",
      "  learn_throughput: 1239.559\n",
      "  learn_time_ms: 3226.953\n",
      "  load_throughput: 21317936.468\n",
      "  load_time_ms: 0.188\n",
      "  sample_throughput: 510.463\n",
      "  sample_time_ms: 7836.023\n",
      "  update_time_ms: 2.256\n",
      "timestamp: 1658401076\n",
      "timesteps_since_restore: 3808000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3808000\n",
      "training_iteration: 952\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3812000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-58-04\n",
      "done: false\n",
      "episode_len_mean: 195.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.94\n",
      "episode_reward_min: 35.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19796\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22921232879161835\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00376589666120708\n",
      "        model: {}\n",
      "        policy_loss: 0.0017611575312912464\n",
      "        total_loss: 4.759828567504883\n",
      "        vf_explained_var: -0.09677410125732422\n",
      "        vf_loss: 4.7580671310424805\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3812000\n",
      "  num_agent_steps_trained: 3812000\n",
      "  num_steps_sampled: 3812000\n",
      "  num_steps_trained: 3812000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 953\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.016666666666666\n",
      "  ram_util_percent: 88.48333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07270458834857227\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08335589561951007\n",
      "  mean_inference_ms: 0.7981788550130651\n",
      "  mean_raw_obs_processing_ms: 0.09618573621636387\n",
      "time_since_restore: 7119.060390949249\n",
      "time_this_iter_s: 7.954779624938965\n",
      "time_total_s: 7119.060390949249\n",
      "timers:\n",
      "  learn_throughput: 1236.108\n",
      "  learn_time_ms: 3235.964\n",
      "  load_throughput: 21476210.958\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 507.852\n",
      "  sample_time_ms: 7876.303\n",
      "  update_time_ms: 2.189\n",
      "timestamp: 1658401084\n",
      "timesteps_since_restore: 3812000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3812000\n",
      "training_iteration: 953\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3816000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-58-11\n",
      "done: false\n",
      "episode_len_mean: 195.94\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.94\n",
      "episode_reward_min: 35.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19816\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21747487783432007\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0025571309961378574\n",
      "        model: {}\n",
      "        policy_loss: 0.001087097218260169\n",
      "        total_loss: 1.613990306854248\n",
      "        vf_explained_var: -0.22211477160453796\n",
      "        vf_loss: 1.6129032373428345\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3816000\n",
      "  num_agent_steps_trained: 3816000\n",
      "  num_steps_sampled: 3816000\n",
      "  num_steps_trained: 3816000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 954\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.33\n",
      "  ram_util_percent: 88.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07271354112265527\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08336661206639974\n",
      "  mean_inference_ms: 0.7982682968627784\n",
      "  mean_raw_obs_processing_ms: 0.09619670445872018\n",
      "time_since_restore: 7126.524720191956\n",
      "time_this_iter_s: 7.464329242706299\n",
      "time_total_s: 7126.524720191956\n",
      "timers:\n",
      "  learn_throughput: 1246.391\n",
      "  learn_time_ms: 3209.267\n",
      "  load_throughput: 21581188.577\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 507.643\n",
      "  sample_time_ms: 7879.553\n",
      "  update_time_ms: 2.213\n",
      "timestamp: 1658401091\n",
      "timesteps_since_restore: 3816000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3816000\n",
      "training_iteration: 954\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3820000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-58-19\n",
      "done: false\n",
      "episode_len_mean: 195.64\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.64\n",
      "episode_reward_min: 35.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 19837\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2320578396320343\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00295250047929585\n",
      "        model: {}\n",
      "        policy_loss: 0.0010042574722319841\n",
      "        total_loss: 3.3528189659118652\n",
      "        vf_explained_var: -0.13344700634479523\n",
      "        vf_loss: 3.3518145084381104\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3820000\n",
      "  num_agent_steps_trained: 3820000\n",
      "  num_steps_sampled: 3820000\n",
      "  num_steps_trained: 3820000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 955\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.1\n",
      "  ram_util_percent: 88.58333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07272386330387094\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0833789881431947\n",
      "  mean_inference_ms: 0.7983716820831668\n",
      "  mean_raw_obs_processing_ms: 0.09620933722419857\n",
      "time_since_restore: 7134.604357004166\n",
      "time_this_iter_s: 8.079636812210083\n",
      "time_total_s: 7134.604357004166\n",
      "timers:\n",
      "  learn_throughput: 1238.012\n",
      "  learn_time_ms: 3230.985\n",
      "  load_throughput: 21631273.853\n",
      "  load_time_ms: 0.185\n",
      "  sample_throughput: 507.134\n",
      "  sample_time_ms: 7887.464\n",
      "  update_time_ms: 2.349\n",
      "timestamp: 1658401099\n",
      "timesteps_since_restore: 3820000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3820000\n",
      "training_iteration: 955\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3824000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-58-27\n",
      "done: false\n",
      "episode_len_mean: 198.19\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.19\n",
      "episode_reward_min: 104.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19857\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23717162013053894\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003161410102620721\n",
      "        model: {}\n",
      "        policy_loss: 0.006843743845820427\n",
      "        total_loss: 7.416118144989014\n",
      "        vf_explained_var: -1.4497388178824622e-07\n",
      "        vf_loss: 7.409274101257324\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3824000\n",
      "  num_agent_steps_trained: 3824000\n",
      "  num_steps_sampled: 3824000\n",
      "  num_steps_trained: 3824000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 956\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.58181818181819\n",
      "  ram_util_percent: 88.37272727272726\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0727313348835818\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08338822329537188\n",
      "  mean_inference_ms: 0.7984480737808459\n",
      "  mean_raw_obs_processing_ms: 0.09621860445233921\n",
      "time_since_restore: 7142.556975364685\n",
      "time_this_iter_s: 7.952618360519409\n",
      "time_total_s: 7142.556975364685\n",
      "timers:\n",
      "  learn_throughput: 1235.192\n",
      "  learn_time_ms: 3238.364\n",
      "  load_throughput: 21451497.251\n",
      "  load_time_ms: 0.186\n",
      "  sample_throughput: 506.597\n",
      "  sample_time_ms: 7895.828\n",
      "  update_time_ms: 2.465\n",
      "timestamp: 1658401107\n",
      "timesteps_since_restore: 3824000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3824000\n",
      "training_iteration: 956\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3828000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-58-36\n",
      "done: false\n",
      "episode_len_mean: 197.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.09\n",
      "episode_reward_min: 90.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19877\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2312266081571579\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00302902446128428\n",
      "        model: {}\n",
      "        policy_loss: 0.0013265074230730534\n",
      "        total_loss: 2.420682191848755\n",
      "        vf_explained_var: 0.005433230195194483\n",
      "        vf_loss: 2.419355630874634\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3828000\n",
      "  num_agent_steps_trained: 3828000\n",
      "  num_steps_sampled: 3828000\n",
      "  num_steps_trained: 3828000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 957\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.85833333333333\n",
      "  ram_util_percent: 88.5\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07273928504222296\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08339635629496213\n",
      "  mean_inference_ms: 0.7985196407705292\n",
      "  mean_raw_obs_processing_ms: 0.09622705281380288\n",
      "time_since_restore: 7150.855282306671\n",
      "time_this_iter_s: 8.298306941986084\n",
      "time_total_s: 7150.855282306671\n",
      "timers:\n",
      "  learn_throughput: 1219.438\n",
      "  learn_time_ms: 3280.2\n",
      "  load_throughput: 22739517.484\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 503.527\n",
      "  sample_time_ms: 7943.964\n",
      "  update_time_ms: 2.445\n",
      "timestamp: 1658401116\n",
      "timesteps_since_restore: 3828000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3828000\n",
      "training_iteration: 957\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3832000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-58-44\n",
      "done: false\n",
      "episode_len_mean: 197.99\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.99\n",
      "episode_reward_min: 90.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19897\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22758641839027405\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0029693730175495148\n",
      "        model: {}\n",
      "        policy_loss: -0.0009831226198002696\n",
      "        total_loss: 1.7429684400558472\n",
      "        vf_explained_var: -0.22759538888931274\n",
      "        vf_loss: 1.7439515590667725\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3832000\n",
      "  num_agent_steps_trained: 3832000\n",
      "  num_steps_sampled: 3832000\n",
      "  num_steps_trained: 3832000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 958\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.9\n",
      "  ram_util_percent: 88.41666666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07274644301529017\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0834036342894721\n",
      "  mean_inference_ms: 0.7985850080256511\n",
      "  mean_raw_obs_processing_ms: 0.09623479320863697\n",
      "time_since_restore: 7158.803423881531\n",
      "time_this_iter_s: 7.948141574859619\n",
      "time_total_s: 7158.803423881531\n",
      "timers:\n",
      "  learn_throughput: 1218.188\n",
      "  learn_time_ms: 3283.566\n",
      "  load_throughput: 23045626.374\n",
      "  load_time_ms: 0.174\n",
      "  sample_throughput: 500.951\n",
      "  sample_time_ms: 7984.817\n",
      "  update_time_ms: 2.46\n",
      "timestamp: 1658401124\n",
      "timesteps_since_restore: 3832000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3832000\n",
      "training_iteration: 958\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3836000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-58-51\n",
      "done: false\n",
      "episode_len_mean: 194.96\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 194.96\n",
      "episode_reward_min: 64.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 19919\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22431042790412903\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004097501281648874\n",
      "        model: {}\n",
      "        policy_loss: 0.002714048605412245\n",
      "        total_loss: 5.877213001251221\n",
      "        vf_explained_var: 0.0008072873461060226\n",
      "        vf_loss: 5.874499320983887\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3836000\n",
      "  num_agent_steps_trained: 3836000\n",
      "  num_steps_sampled: 3836000\n",
      "  num_steps_trained: 3836000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 959\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.89090909090909\n",
      "  ram_util_percent: 88.91818181818182\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07275491626219402\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08341217308144473\n",
      "  mean_inference_ms: 0.7986638613889983\n",
      "  mean_raw_obs_processing_ms: 0.09624400058624895\n",
      "time_since_restore: 7166.584300518036\n",
      "time_this_iter_s: 7.780876636505127\n",
      "time_total_s: 7166.584300518036\n",
      "timers:\n",
      "  learn_throughput: 1214.388\n",
      "  learn_time_ms: 3293.841\n",
      "  load_throughput: 22823039.042\n",
      "  load_time_ms: 0.175\n",
      "  sample_throughput: 500.111\n",
      "  sample_time_ms: 7998.227\n",
      "  update_time_ms: 2.774\n",
      "timestamp: 1658401131\n",
      "timesteps_since_restore: 3836000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3836000\n",
      "training_iteration: 959\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3840000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-58-59\n",
      "done: false\n",
      "episode_len_mean: 195.81\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.81\n",
      "episode_reward_min: 64.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19939\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23210462927818298\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023156541865319014\n",
      "        model: {}\n",
      "        policy_loss: 0.005920413415879011\n",
      "        total_loss: 6.457533359527588\n",
      "        vf_explained_var: -2.9481868057956717e-09\n",
      "        vf_loss: 6.451612949371338\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3840000\n",
      "  num_agent_steps_trained: 3840000\n",
      "  num_steps_sampled: 3840000\n",
      "  num_steps_trained: 3840000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 960\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.01818181818182\n",
      "  ram_util_percent: 88.8090909090909\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0727619787397927\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08341973108270528\n",
      "  mean_inference_ms: 0.7987307902428918\n",
      "  mean_raw_obs_processing_ms: 0.09625160981652027\n",
      "time_since_restore: 7174.363203763962\n",
      "time_this_iter_s: 7.778903245925903\n",
      "time_total_s: 7174.363203763962\n",
      "timers:\n",
      "  learn_throughput: 1212.546\n",
      "  learn_time_ms: 3298.844\n",
      "  load_throughput: 22779655.126\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 498.346\n",
      "  sample_time_ms: 8026.546\n",
      "  update_time_ms: 2.807\n",
      "timestamp: 1658401139\n",
      "timesteps_since_restore: 3840000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3840000\n",
      "training_iteration: 960\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3844000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-59-07\n",
      "done: false\n",
      "episode_len_mean: 195.81\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.81\n",
      "episode_reward_min: 64.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 19959\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20963196456432343\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032973713241517544\n",
      "        model: {}\n",
      "        policy_loss: 0.004605639725923538\n",
      "        total_loss: 6.456219673156738\n",
      "        vf_explained_var: 3.0571413844882045e-08\n",
      "        vf_loss: 6.451613426208496\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3844000\n",
      "  num_agent_steps_trained: 3844000\n",
      "  num_steps_sampled: 3844000\n",
      "  num_steps_trained: 3844000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 961\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.22727272727273\n",
      "  ram_util_percent: 88.68181818181819\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07276858946302424\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08342689974265341\n",
      "  mean_inference_ms: 0.7987941106314501\n",
      "  mean_raw_obs_processing_ms: 0.09625895415171364\n",
      "time_since_restore: 7182.18737578392\n",
      "time_this_iter_s: 7.824172019958496\n",
      "time_total_s: 7182.18737578392\n",
      "timers:\n",
      "  learn_throughput: 1216.265\n",
      "  learn_time_ms: 3288.757\n",
      "  load_throughput: 22711812.644\n",
      "  load_time_ms: 0.176\n",
      "  sample_throughput: 502.518\n",
      "  sample_time_ms: 7959.919\n",
      "  update_time_ms: 2.823\n",
      "timestamp: 1658401147\n",
      "timesteps_since_restore: 3844000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3844000\n",
      "training_iteration: 961\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3848000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-59-15\n",
      "done: false\n",
      "episode_len_mean: 193.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.51\n",
      "episode_reward_min: 61.0\n",
      "episodes_this_iter: 22\n",
      "episodes_total: 19981\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24026937782764435\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027846884913742542\n",
      "        model: {}\n",
      "        policy_loss: -0.00994010828435421\n",
      "        total_loss: 5.534420967102051\n",
      "        vf_explained_var: -0.05130455270409584\n",
      "        vf_loss: 5.544361114501953\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3848000\n",
      "  num_agent_steps_trained: 3848000\n",
      "  num_steps_sampled: 3848000\n",
      "  num_steps_trained: 3848000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 962\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.00909090909091\n",
      "  ram_util_percent: 88.64545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07277363435455103\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08343298261280657\n",
      "  mean_inference_ms: 0.7988514598216008\n",
      "  mean_raw_obs_processing_ms: 0.09626524150195014\n",
      "time_since_restore: 7189.857125282288\n",
      "time_this_iter_s: 7.66974949836731\n",
      "time_total_s: 7189.857125282288\n",
      "timers:\n",
      "  learn_throughput: 1219.566\n",
      "  learn_time_ms: 3279.856\n",
      "  load_throughput: 22650487.377\n",
      "  load_time_ms: 0.177\n",
      "  sample_throughput: 505.9\n",
      "  sample_time_ms: 7906.703\n",
      "  update_time_ms: 2.754\n",
      "timestamp: 1658401155\n",
      "timesteps_since_restore: 3848000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3848000\n",
      "training_iteration: 962\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3852000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-59-22\n",
      "done: false\n",
      "episode_len_mean: 191.97\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.97\n",
      "episode_reward_min: 12.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 20002\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22575050592422485\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003696955507621169\n",
      "        model: {}\n",
      "        policy_loss: 0.008245990611612797\n",
      "        total_loss: 9.705826759338379\n",
      "        vf_explained_var: 1.8746622743037733e-07\n",
      "        vf_loss: 9.697580337524414\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3852000\n",
      "  num_agent_steps_trained: 3852000\n",
      "  num_steps_sampled: 3852000\n",
      "  num_steps_trained: 3852000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 963\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.83636363636363\n",
      "  ram_util_percent: 88.58181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07277764833956347\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08343801960300244\n",
      "  mean_inference_ms: 0.7988972154776414\n",
      "  mean_raw_obs_processing_ms: 0.09626944222206682\n",
      "time_since_restore: 7197.393537282944\n",
      "time_this_iter_s: 7.536412000656128\n",
      "time_total_s: 7197.393537282944\n",
      "timers:\n",
      "  learn_throughput: 1220.773\n",
      "  learn_time_ms: 3276.613\n",
      "  load_throughput: 22516730.64\n",
      "  load_time_ms: 0.178\n",
      "  sample_throughput: 508.98\n",
      "  sample_time_ms: 7858.862\n",
      "  update_time_ms: 2.878\n",
      "timestamp: 1658401162\n",
      "timesteps_since_restore: 3852000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3852000\n",
      "training_iteration: 963\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3856000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-59-30\n",
      "done: false\n",
      "episode_len_mean: 193.51\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.51\n",
      "episode_reward_min: 12.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20022\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.25108885765075684\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00339952833019197\n",
      "        model: {}\n",
      "        policy_loss: 0.0007862152997404337\n",
      "        total_loss: 4.37074613571167\n",
      "        vf_explained_var: 1.3882113591989764e-07\n",
      "        vf_loss: 4.369959831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3856000\n",
      "  num_agent_steps_trained: 3856000\n",
      "  num_steps_sampled: 3856000\n",
      "  num_steps_trained: 3856000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 964\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 36.62\n",
      "  ram_util_percent: 88.63000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07278062624913238\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0834416863307898\n",
      "  mean_inference_ms: 0.7989320480794266\n",
      "  mean_raw_obs_processing_ms: 0.09627263478216058\n",
      "time_since_restore: 7204.845963478088\n",
      "time_this_iter_s: 7.452426195144653\n",
      "time_total_s: 7204.845963478088\n",
      "timers:\n",
      "  learn_throughput: 1220.017\n",
      "  learn_time_ms: 3278.643\n",
      "  load_throughput: 22307161.282\n",
      "  load_time_ms: 0.179\n",
      "  sample_throughput: 509.356\n",
      "  sample_time_ms: 7853.054\n",
      "  update_time_ms: 2.885\n",
      "timestamp: 1658401170\n",
      "timesteps_since_restore: 3856000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3856000\n",
      "training_iteration: 964\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3860000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-59-38\n",
      "done: false\n",
      "episode_len_mean: 191.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.79\n",
      "episode_reward_min: 12.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 20043\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22518077492713928\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004053469747304916\n",
      "        model: {}\n",
      "        policy_loss: 0.000677714473567903\n",
      "        total_loss: 3.962372303009033\n",
      "        vf_explained_var: -0.004405357409268618\n",
      "        vf_loss: 3.9616947174072266\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3860000\n",
      "  num_agent_steps_trained: 3860000\n",
      "  num_steps_sampled: 3860000\n",
      "  num_steps_trained: 3860000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 965\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.449999999999996\n",
      "  ram_util_percent: 88.67500000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07278381525660298\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08344513062540106\n",
      "  mean_inference_ms: 0.7989696315988973\n",
      "  mean_raw_obs_processing_ms: 0.09627623680512798\n",
      "time_since_restore: 7212.658312082291\n",
      "time_this_iter_s: 7.8123486042022705\n",
      "time_total_s: 7212.658312082291\n",
      "timers:\n",
      "  learn_throughput: 1226.197\n",
      "  learn_time_ms: 3262.118\n",
      "  load_throughput: 22168625.793\n",
      "  load_time_ms: 0.18\n",
      "  sample_throughput: 509.831\n",
      "  sample_time_ms: 7845.737\n",
      "  update_time_ms: 2.731\n",
      "timestamp: 1658401178\n",
      "timesteps_since_restore: 3860000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3860000\n",
      "training_iteration: 965\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3864000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-59-45\n",
      "done: false\n",
      "episode_len_mean: 191.79\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 191.79\n",
      "episode_reward_min: 12.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20063\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.1996259093284607\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031439068261533976\n",
      "        model: {}\n",
      "        policy_loss: 0.004541975446045399\n",
      "        total_loss: 5.39768648147583\n",
      "        vf_explained_var: 2.7302773375481593e-08\n",
      "        vf_loss: 5.3931450843811035\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3864000\n",
      "  num_agent_steps_trained: 3864000\n",
      "  num_steps_sampled: 3864000\n",
      "  num_steps_trained: 3864000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 966\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.627272727272725\n",
      "  ram_util_percent: 88.79999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07278658825285428\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08344789404547244\n",
      "  mean_inference_ms: 0.7989993158136989\n",
      "  mean_raw_obs_processing_ms: 0.09627899253755313\n",
      "time_since_restore: 7220.242804527283\n",
      "time_this_iter_s: 7.584492444992065\n",
      "time_total_s: 7220.242804527283\n",
      "timers:\n",
      "  learn_throughput: 1230.339\n",
      "  learn_time_ms: 3251.137\n",
      "  load_throughput: 21965456.926\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 512.63\n",
      "  sample_time_ms: 7802.897\n",
      "  update_time_ms: 2.63\n",
      "timestamp: 1658401185\n",
      "timesteps_since_restore: 3864000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3864000\n",
      "training_iteration: 966\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3868000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_12-59-53\n",
      "done: false\n",
      "episode_len_mean: 193.92\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 193.92\n",
      "episode_reward_min: 12.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 20084\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22104816138744354\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0044800820760428905\n",
      "        model: {}\n",
      "        policy_loss: -0.007004806771874428\n",
      "        total_loss: 5.597834587097168\n",
      "        vf_explained_var: 2.486090409092867e-07\n",
      "        vf_loss: 5.604839324951172\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3868000\n",
      "  num_agent_steps_trained: 3868000\n",
      "  num_steps_sampled: 3868000\n",
      "  num_steps_trained: 3868000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 967\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.45454545454545\n",
      "  ram_util_percent: 88.7181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07279112921527668\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08345279564858363\n",
      "  mean_inference_ms: 0.799044768179945\n",
      "  mean_raw_obs_processing_ms: 0.09628401078657063\n",
      "time_since_restore: 7228.469249486923\n",
      "time_this_iter_s: 8.226444959640503\n",
      "time_total_s: 7228.469249486923\n",
      "timers:\n",
      "  learn_throughput: 1234.797\n",
      "  learn_time_ms: 3239.399\n",
      "  load_throughput: 21979845.408\n",
      "  load_time_ms: 0.182\n",
      "  sample_throughput: 513.044\n",
      "  sample_time_ms: 7796.599\n",
      "  update_time_ms: 2.634\n",
      "timestamp: 1658401193\n",
      "timesteps_since_restore: 3868000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3868000\n",
      "training_iteration: 967\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3872000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-00-01\n",
      "done: false\n",
      "episode_len_mean: 196.24\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.24\n",
      "episode_reward_min: 52.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20104\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20930883288383484\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031918007880449295\n",
      "        model: {}\n",
      "        policy_loss: -0.002143952762708068\n",
      "        total_loss: 9.040194511413574\n",
      "        vf_explained_var: 2.37905851463438e-07\n",
      "        vf_loss: 9.042338371276855\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3872000\n",
      "  num_agent_steps_trained: 3872000\n",
      "  num_steps_sampled: 3872000\n",
      "  num_steps_trained: 3872000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 968\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.76363636363636\n",
      "  ram_util_percent: 88.8\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07279608979200508\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08345800124599351\n",
      "  mean_inference_ms: 0.79909411604253\n",
      "  mean_raw_obs_processing_ms: 0.09629003052526539\n",
      "time_since_restore: 7236.313356399536\n",
      "time_this_iter_s: 7.844106912612915\n",
      "time_total_s: 7236.313356399536\n",
      "timers:\n",
      "  learn_throughput: 1236.818\n",
      "  learn_time_ms: 3234.106\n",
      "  load_throughput: 21151306.102\n",
      "  load_time_ms: 0.189\n",
      "  sample_throughput: 514.178\n",
      "  sample_time_ms: 7779.404\n",
      "  update_time_ms: 2.6\n",
      "timestamp: 1658401201\n",
      "timesteps_since_restore: 3872000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3872000\n",
      "training_iteration: 968\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3876000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-00-09\n",
      "done: false\n",
      "episode_len_mean: 196.71\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.71\n",
      "episode_reward_min: 52.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20124\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2010078877210617\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00338508072309196\n",
      "        model: {}\n",
      "        policy_loss: 0.006640249397605658\n",
      "        total_loss: 8.928013801574707\n",
      "        vf_explained_var: 1.5631798078175052e-07\n",
      "        vf_loss: 8.92137336730957\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3876000\n",
      "  num_agent_steps_trained: 3876000\n",
      "  num_steps_sampled: 3876000\n",
      "  num_steps_trained: 3876000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 969\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 42.75\n",
      "  ram_util_percent: 89.00833333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07280263554603386\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08346556623858255\n",
      "  mean_inference_ms: 0.7991592181720241\n",
      "  mean_raw_obs_processing_ms: 0.096297569359375\n",
      "time_since_restore: 7244.291775465012\n",
      "time_this_iter_s: 7.978419065475464\n",
      "time_total_s: 7244.291775465012\n",
      "timers:\n",
      "  learn_throughput: 1236.878\n",
      "  learn_time_ms: 3233.948\n",
      "  load_throughput: 21074257.003\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 513.154\n",
      "  sample_time_ms: 7794.937\n",
      "  update_time_ms: 2.315\n",
      "timestamp: 1658401209\n",
      "timesteps_since_restore: 3876000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3876000\n",
      "training_iteration: 969\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3880000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-00-17\n",
      "done: false\n",
      "episode_len_mean: 198.43\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.43\n",
      "episode_reward_min: 123.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20144\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19302251935005188\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024495134130120277\n",
      "        model: {}\n",
      "        policy_loss: 0.008198905736207962\n",
      "        total_loss: 7.568682670593262\n",
      "        vf_explained_var: 1.3125840325756144e-07\n",
      "        vf_loss: 7.560483932495117\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3880000\n",
      "  num_agent_steps_trained: 3880000\n",
      "  num_steps_sampled: 3880000\n",
      "  num_steps_trained: 3880000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 970\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 38.4\n",
      "  ram_util_percent: 88.8181818181818\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07280856714922093\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08347240378008201\n",
      "  mean_inference_ms: 0.799216680134403\n",
      "  mean_raw_obs_processing_ms: 0.09630438986458348\n",
      "time_since_restore: 7251.848469734192\n",
      "time_this_iter_s: 7.556694269180298\n",
      "time_total_s: 7251.848469734192\n",
      "timers:\n",
      "  learn_throughput: 1238.727\n",
      "  learn_time_ms: 3229.122\n",
      "  load_throughput: 20789610.905\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 514.331\n",
      "  sample_time_ms: 7777.091\n",
      "  update_time_ms: 2.252\n",
      "timestamp: 1658401217\n",
      "timesteps_since_restore: 3880000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3880000\n",
      "training_iteration: 970\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3884000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-00-24\n",
      "done: false\n",
      "episode_len_mean: 195.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 195.8\n",
      "episode_reward_min: 19.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 20165\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19669900834560394\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0032593400683254004\n",
      "        model: {}\n",
      "        policy_loss: 0.004224651958793402\n",
      "        total_loss: 6.3096723556518555\n",
      "        vf_explained_var: -0.0012249156134203076\n",
      "        vf_loss: 6.305447578430176\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3884000\n",
      "  num_agent_steps_trained: 3884000\n",
      "  num_steps_sampled: 3884000\n",
      "  num_steps_trained: 3884000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 971\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.85454545454546\n",
      "  ram_util_percent: 88.85454545454544\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0728139166559015\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08347875887952784\n",
      "  mean_inference_ms: 0.7992707754412678\n",
      "  mean_raw_obs_processing_ms: 0.09631098068257973\n",
      "time_since_restore: 7259.42217874527\n",
      "time_this_iter_s: 7.573709011077881\n",
      "time_total_s: 7259.42217874527\n",
      "timers:\n",
      "  learn_throughput: 1237.216\n",
      "  learn_time_ms: 3233.064\n",
      "  load_throughput: 21024080.201\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 516.608\n",
      "  sample_time_ms: 7742.811\n",
      "  update_time_ms: 2.223\n",
      "timestamp: 1658401224\n",
      "timesteps_since_restore: 3884000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3884000\n",
      "training_iteration: 971\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3888000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-00-32\n",
      "done: false\n",
      "episode_len_mean: 197.07\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.07\n",
      "episode_reward_min: 19.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20185\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19958053529262543\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.001718732062727213\n",
      "        model: {}\n",
      "        policy_loss: 0.004071240313351154\n",
      "        total_loss: 4.3891520500183105\n",
      "        vf_explained_var: -2.4867313541676594e-08\n",
      "        vf_loss: 4.385080814361572\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3888000\n",
      "  num_agent_steps_trained: 3888000\n",
      "  num_steps_sampled: 3888000\n",
      "  num_steps_trained: 3888000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 972\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.08\n",
      "  ram_util_percent: 88.63\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07281749673181309\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08348286224101276\n",
      "  mean_inference_ms: 0.7993069178033971\n",
      "  mean_raw_obs_processing_ms: 0.0963154234401023\n",
      "time_since_restore: 7266.944865465164\n",
      "time_this_iter_s: 7.522686719894409\n",
      "time_total_s: 7266.944865465164\n",
      "timers:\n",
      "  learn_throughput: 1239.535\n",
      "  learn_time_ms: 3227.018\n",
      "  load_throughput: 21058385.842\n",
      "  load_time_ms: 0.19\n",
      "  sample_throughput: 516.969\n",
      "  sample_time_ms: 7737.409\n",
      "  update_time_ms: 2.274\n",
      "timestamp: 1658401232\n",
      "timesteps_since_restore: 3888000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3888000\n",
      "training_iteration: 972\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3892000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-00-41\n",
      "done: false\n",
      "episode_len_mean: 197.07\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.07\n",
      "episode_reward_min: 19.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20205\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19443289935588837\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0034009397495537996\n",
      "        model: {}\n",
      "        policy_loss: 0.002625047927722335\n",
      "        total_loss: 4.3877058029174805\n",
      "        vf_explained_var: 7.312785044177872e-08\n",
      "        vf_loss: 4.385080814361572\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3892000\n",
      "  num_agent_steps_trained: 3892000\n",
      "  num_steps_sampled: 3892000\n",
      "  num_steps_trained: 3892000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 973\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 43.44615384615385\n",
      "  ram_util_percent: 88.68461538461537\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07282314381172775\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08348943055668945\n",
      "  mean_inference_ms: 0.7993667083397105\n",
      "  mean_raw_obs_processing_ms: 0.09632246230069025\n",
      "time_since_restore: 7275.582076311111\n",
      "time_this_iter_s: 8.637210845947266\n",
      "time_total_s: 7275.582076311111\n",
      "timers:\n",
      "  learn_throughput: 1227.225\n",
      "  learn_time_ms: 3259.387\n",
      "  load_throughput: 20643799.68\n",
      "  load_time_ms: 0.194\n",
      "  sample_throughput: 512.249\n",
      "  sample_time_ms: 7808.704\n",
      "  update_time_ms: 2.196\n",
      "timestamp: 1658401241\n",
      "timesteps_since_restore: 3892000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3892000\n",
      "training_iteration: 973\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3896000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-00-49\n",
      "done: false\n",
      "episode_len_mean: 197.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.03\n",
      "episode_reward_min: 19.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20225\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2091720700263977\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003285657148808241\n",
      "        model: {}\n",
      "        policy_loss: 0.001478730351664126\n",
      "        total_loss: 3.272648334503174\n",
      "        vf_explained_var: -0.08927854895591736\n",
      "        vf_loss: 3.271169424057007\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3896000\n",
      "  num_agent_steps_trained: 3896000\n",
      "  num_steps_sampled: 3896000\n",
      "  num_steps_trained: 3896000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 974\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.0\n",
      "  ram_util_percent: 88.75833333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07283083417615992\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08349750938462862\n",
      "  mean_inference_ms: 0.7994514765534458\n",
      "  mean_raw_obs_processing_ms: 0.09633215527601138\n",
      "time_since_restore: 7284.147660732269\n",
      "time_this_iter_s: 8.565584421157837\n",
      "time_total_s: 7284.147660732269\n",
      "timers:\n",
      "  learn_throughput: 1224.524\n",
      "  learn_time_ms: 3266.574\n",
      "  load_throughput: 20787035.064\n",
      "  load_time_ms: 0.192\n",
      "  sample_throughput: 503.411\n",
      "  sample_time_ms: 7945.794\n",
      "  update_time_ms: 2.158\n",
      "timestamp: 1658401249\n",
      "timesteps_since_restore: 3896000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3896000\n",
      "training_iteration: 974\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3900000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-00-59\n",
      "done: false\n",
      "episode_len_mean: 197.03\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.03\n",
      "episode_reward_min: 19.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20245\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19314320385456085\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023352166172116995\n",
      "        model: {}\n",
      "        policy_loss: 0.0016036865999922156\n",
      "        total_loss: 2.6729750633239746\n",
      "        vf_explained_var: -0.09835965186357498\n",
      "        vf_loss: 2.6713714599609375\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3900000\n",
      "  num_agent_steps_trained: 3900000\n",
      "  num_steps_sampled: 3900000\n",
      "  num_steps_trained: 3900000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 975\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.08571428571429\n",
      "  ram_util_percent: 89.01428571428572\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07284296584731718\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08351052368219189\n",
      "  mean_inference_ms: 0.7995818245784138\n",
      "  mean_raw_obs_processing_ms: 0.09634714682839052\n",
      "time_since_restore: 7293.914916753769\n",
      "time_this_iter_s: 9.767256021499634\n",
      "time_total_s: 7293.914916753769\n",
      "timers:\n",
      "  learn_throughput: 1188.879\n",
      "  learn_time_ms: 3364.514\n",
      "  load_throughput: 19147701.438\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 496.934\n",
      "  sample_time_ms: 8049.351\n",
      "  update_time_ms: 2.307\n",
      "timestamp: 1658401259\n",
      "timesteps_since_restore: 3900000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3900000\n",
      "training_iteration: 975\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3904000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-01-09\n",
      "done: false\n",
      "episode_len_mean: 199.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.66\n",
      "episode_reward_min: 166.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20265\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19322584569454193\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002438152441754937\n",
      "        model: {}\n",
      "        policy_loss: 0.0018481049919500947\n",
      "        total_loss: 2.6732192039489746\n",
      "        vf_explained_var: -0.09406014531850815\n",
      "        vf_loss: 2.6713709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3904000\n",
      "  num_agent_steps_trained: 3904000\n",
      "  num_steps_sampled: 3904000\n",
      "  num_steps_trained: 3904000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 976\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 49.37692307692308\n",
      "  ram_util_percent: 89.28461538461536\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0728608697650554\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08352960510916355\n",
      "  mean_inference_ms: 0.79977126849302\n",
      "  mean_raw_obs_processing_ms: 0.09636880801640445\n",
      "time_since_restore: 7303.3311467170715\n",
      "time_this_iter_s: 9.416229963302612\n",
      "time_total_s: 7303.3311467170715\n",
      "timers:\n",
      "  learn_throughput: 1174.268\n",
      "  learn_time_ms: 3406.378\n",
      "  load_throughput: 17591712.278\n",
      "  load_time_ms: 0.227\n",
      "  sample_throughput: 482.451\n",
      "  sample_time_ms: 8290.992\n",
      "  update_time_ms: 2.315\n",
      "timestamp: 1658401269\n",
      "timesteps_since_restore: 3904000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3904000\n",
      "training_iteration: 976\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3908000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-01-18\n",
      "done: false\n",
      "episode_len_mean: 199.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.66\n",
      "episode_reward_min: 166.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20285\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19882425665855408\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026799472980201244\n",
      "        model: {}\n",
      "        policy_loss: 0.0007085474790073931\n",
      "        total_loss: 2.6720802783966064\n",
      "        vf_explained_var: -0.00353609980084002\n",
      "        vf_loss: 2.6713714599609375\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3908000\n",
      "  num_agent_steps_trained: 3908000\n",
      "  num_steps_sampled: 3908000\n",
      "  num_steps_trained: 3908000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 977\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.057142857142864\n",
      "  ram_util_percent: 89.2\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07288310440600392\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08355308696941748\n",
      "  mean_inference_ms: 0.8000053156459765\n",
      "  mean_raw_obs_processing_ms: 0.09639535261526073\n",
      "time_since_restore: 7313.056893825531\n",
      "time_this_iter_s: 9.725747108459473\n",
      "time_total_s: 7313.056893825531\n",
      "timers:\n",
      "  learn_throughput: 1147.598\n",
      "  learn_time_ms: 3485.542\n",
      "  load_throughput: 16342505.357\n",
      "  load_time_ms: 0.245\n",
      "  sample_throughput: 475.941\n",
      "  sample_time_ms: 8404.408\n",
      "  update_time_ms: 2.292\n",
      "timestamp: 1658401278\n",
      "timesteps_since_restore: 3908000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3908000\n",
      "training_iteration: 977\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3912000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-01-29\n",
      "done: false\n",
      "episode_len_mean: 199.66\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.66\n",
      "episode_reward_min: 166.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20305\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20407167077064514\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002053509233519435\n",
      "        model: {}\n",
      "        policy_loss: 0.002396180760115385\n",
      "        total_loss: 2.673767328262329\n",
      "        vf_explained_var: -0.12180081754922867\n",
      "        vf_loss: 2.6713709831237793\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3912000\n",
      "  num_agent_steps_trained: 3912000\n",
      "  num_steps_sampled: 3912000\n",
      "  num_steps_trained: 3912000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 978\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.18\n",
      "  ram_util_percent: 89.44666666666669\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07290779769569705\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08357918618034509\n",
      "  mean_inference_ms: 0.8002683691515312\n",
      "  mean_raw_obs_processing_ms: 0.09642486629401184\n",
      "time_since_restore: 7323.667373895645\n",
      "time_this_iter_s: 10.610480070114136\n",
      "time_total_s: 7323.667373895645\n",
      "timers:\n",
      "  learn_throughput: 1103.169\n",
      "  learn_time_ms: 3625.918\n",
      "  load_throughput: 15826069.239\n",
      "  load_time_ms: 0.253\n",
      "  sample_throughput: 464.023\n",
      "  sample_time_ms: 8620.254\n",
      "  update_time_ms: 2.287\n",
      "timestamp: 1658401289\n",
      "timesteps_since_restore: 3912000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3912000\n",
      "training_iteration: 978\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3916000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-01-37\n",
      "done: false\n",
      "episode_len_mean: 200.0\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 200.0\n",
      "episode_reward_min: 200.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20325\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21487443149089813\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026293692644685507\n",
      "        model: {}\n",
      "        policy_loss: 0.0012000076239928603\n",
      "        total_loss: 2.6725716590881348\n",
      "        vf_explained_var: -0.12023356556892395\n",
      "        vf_loss: 2.6713714599609375\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3916000\n",
      "  num_agent_steps_trained: 3916000\n",
      "  num_steps_sampled: 3916000\n",
      "  num_steps_trained: 3916000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 979\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.31666666666667\n",
      "  ram_util_percent: 89.58333333333333\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07292977915392758\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0836024779371752\n",
      "  mean_inference_ms: 0.8004974247155282\n",
      "  mean_raw_obs_processing_ms: 0.09645121513120569\n",
      "time_since_restore: 7331.512891054153\n",
      "time_this_iter_s: 7.845517158508301\n",
      "time_total_s: 7331.512891054153\n",
      "timers:\n",
      "  learn_throughput: 1100.121\n",
      "  learn_time_ms: 3635.964\n",
      "  load_throughput: 15884506.722\n",
      "  load_time_ms: 0.252\n",
      "  sample_throughput: 457.797\n",
      "  sample_time_ms: 8737.49\n",
      "  update_time_ms: 2.262\n",
      "timestamp: 1658401297\n",
      "timesteps_since_restore: 3916000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3916000\n",
      "training_iteration: 979\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3920000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-01-45\n",
      "done: false\n",
      "episode_len_mean: 199.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.83\n",
      "episode_reward_min: 183.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20345\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19860006868839264\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00426282174885273\n",
      "        model: {}\n",
      "        policy_loss: -0.001096456777304411\n",
      "        total_loss: 1.9419478178024292\n",
      "        vf_explained_var: -0.1906428039073944\n",
      "        vf_loss: 1.9430443048477173\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3920000\n",
      "  num_agent_steps_trained: 3920000\n",
      "  num_steps_sampled: 3920000\n",
      "  num_steps_trained: 3920000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 980\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.96363636363637\n",
      "  ram_util_percent: 89.14545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07294858254524113\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08362230171943393\n",
      "  mean_inference_ms: 0.800693697571598\n",
      "  mean_raw_obs_processing_ms: 0.09647353562325878\n",
      "time_since_restore: 7339.547686338425\n",
      "time_this_iter_s: 8.03479528427124\n",
      "time_total_s: 7339.547686338425\n",
      "timers:\n",
      "  learn_throughput: 1095.785\n",
      "  learn_time_ms: 3650.353\n",
      "  load_throughput: 15841012.18\n",
      "  load_time_ms: 0.253\n",
      "  sample_throughput: 455.539\n",
      "  sample_time_ms: 8780.806\n",
      "  update_time_ms: 2.27\n",
      "timestamp: 1658401305\n",
      "timesteps_since_restore: 3920000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3920000\n",
      "training_iteration: 980\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3924000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-01-52\n",
      "done: false\n",
      "episode_len_mean: 199.83\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.83\n",
      "episode_reward_min: 183.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20365\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20504610240459442\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.003090755082666874\n",
      "        model: {}\n",
      "        policy_loss: -0.0007185592548921704\n",
      "        total_loss: 1.8137977123260498\n",
      "        vf_explained_var: -0.15688619017601013\n",
      "        vf_loss: 1.8145161867141724\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3924000\n",
      "  num_agent_steps_trained: 3924000\n",
      "  num_steps_sampled: 3924000\n",
      "  num_steps_trained: 3924000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 981\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.20909090909091\n",
      "  ram_util_percent: 88.95454545454545\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0729616567272493\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08363604476303894\n",
      "  mean_inference_ms: 0.8008315870533486\n",
      "  mean_raw_obs_processing_ms: 0.09648893159644757\n",
      "time_since_restore: 7347.0711081027985\n",
      "time_this_iter_s: 7.523421764373779\n",
      "time_total_s: 7347.0711081027985\n",
      "timers:\n",
      "  learn_throughput: 1097.818\n",
      "  learn_time_ms: 3643.593\n",
      "  load_throughput: 15849991.497\n",
      "  load_time_ms: 0.252\n",
      "  sample_throughput: 454.726\n",
      "  sample_time_ms: 8796.504\n",
      "  update_time_ms: 2.346\n",
      "timestamp: 1658401312\n",
      "timesteps_since_restore: 3924000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3924000\n",
      "training_iteration: 981\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3928000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-02-00\n",
      "done: false\n",
      "episode_len_mean: 199.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.44\n",
      "episode_reward_min: 161.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 20386\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.19225147366523743\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0022638305090367794\n",
      "        model: {}\n",
      "        policy_loss: -0.015591990202665329\n",
      "        total_loss: 9.435075759887695\n",
      "        vf_explained_var: 4.671594240335253e-07\n",
      "        vf_loss: 9.450667381286621\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3928000\n",
      "  num_agent_steps_trained: 3928000\n",
      "  num_steps_sampled: 3928000\n",
      "  num_steps_trained: 3928000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 982\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 37.19090909090909\n",
      "  ram_util_percent: 88.74545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07297058289646484\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08364579571211701\n",
      "  mean_inference_ms: 0.800928026318176\n",
      "  mean_raw_obs_processing_ms: 0.09649967809886972\n",
      "time_since_restore: 7354.568530797958\n",
      "time_this_iter_s: 7.497422695159912\n",
      "time_total_s: 7354.568530797958\n",
      "timers:\n",
      "  learn_throughput: 1099.896\n",
      "  learn_time_ms: 3636.707\n",
      "  load_throughput: 15895041.213\n",
      "  load_time_ms: 0.252\n",
      "  sample_throughput: 454.856\n",
      "  sample_time_ms: 8793.992\n",
      "  update_time_ms: 2.268\n",
      "timestamp: 1658401320\n",
      "timesteps_since_restore: 3928000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3928000\n",
      "training_iteration: 982\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3932000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-02-10\n",
      "done: false\n",
      "episode_len_mean: 199.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.44\n",
      "episode_reward_min: 161.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20406\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21069596707820892\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0027786274440586567\n",
      "        model: {}\n",
      "        policy_loss: -0.015485505573451519\n",
      "        total_loss: 9.840864181518555\n",
      "        vf_explained_var: 2.586713492291892e-07\n",
      "        vf_loss: 9.856350898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3932000\n",
      "  num_agent_steps_trained: 3932000\n",
      "  num_steps_sampled: 3932000\n",
      "  num_steps_trained: 3932000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 983\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.9857142857143\n",
      "  ram_util_percent: 89.09999999999998\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07297945276245285\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08365558261624556\n",
      "  mean_inference_ms: 0.8010189515817464\n",
      "  mean_raw_obs_processing_ms: 0.09651017986728029\n",
      "time_since_restore: 7364.557639360428\n",
      "time_this_iter_s: 9.989108562469482\n",
      "time_total_s: 7364.557639360428\n",
      "timers:\n",
      "  learn_throughput: 1080.31\n",
      "  learn_time_ms: 3702.642\n",
      "  load_throughput: 15267281.827\n",
      "  load_time_ms: 0.262\n",
      "  sample_throughput: 451.651\n",
      "  sample_time_ms: 8856.388\n",
      "  update_time_ms: 2.263\n",
      "timestamp: 1658401330\n",
      "timesteps_since_restore: 3932000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3932000\n",
      "training_iteration: 983\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3936000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-02-21\n",
      "done: false\n",
      "episode_len_mean: 199.44\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.44\n",
      "episode_reward_min: 161.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20426\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21810820698738098\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023731368128210306\n",
      "        model: {}\n",
      "        policy_loss: -0.015320670790970325\n",
      "        total_loss: 9.84103012084961\n",
      "        vf_explained_var: 6.229646487554419e-08\n",
      "        vf_loss: 9.856350898742676\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3936000\n",
      "  num_agent_steps_trained: 3936000\n",
      "  num_steps_sampled: 3936000\n",
      "  num_steps_trained: 3936000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 984\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 59.8125\n",
      "  ram_util_percent: 89.28125\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0729962176128311\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.0836741965594377\n",
      "  mean_inference_ms: 0.8012012122375342\n",
      "  mean_raw_obs_processing_ms: 0.09653007321411934\n",
      "time_since_restore: 7375.898081064224\n",
      "time_this_iter_s: 11.340441703796387\n",
      "time_total_s: 7375.898081064224\n",
      "timers:\n",
      "  learn_throughput: 1044.914\n",
      "  learn_time_ms: 3828.066\n",
      "  load_throughput: 15162418.437\n",
      "  load_time_ms: 0.264\n",
      "  sample_throughput: 440.857\n",
      "  sample_time_ms: 9073.246\n",
      "  update_time_ms: 2.315\n",
      "timestamp: 1658401341\n",
      "timesteps_since_restore: 3936000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3936000\n",
      "training_iteration: 984\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3940000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-02-32\n",
      "done: false\n",
      "episode_len_mean: 199.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.48\n",
      "episode_reward_min: 161.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20446\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21688812971115112\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0028008322697132826\n",
      "        model: {}\n",
      "        policy_loss: -0.005594450514763594\n",
      "        total_loss: 9.228276252746582\n",
      "        vf_explained_var: 4.839512826038117e-07\n",
      "        vf_loss: 9.233870506286621\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3940000\n",
      "  num_agent_steps_trained: 3940000\n",
      "  num_steps_sampled: 3940000\n",
      "  num_steps_trained: 3940000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 985\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.48125\n",
      "  ram_util_percent: 89.32499999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07302154600712918\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08370236284320978\n",
      "  mean_inference_ms: 0.801475725251901\n",
      "  mean_raw_obs_processing_ms: 0.09655966555490593\n",
      "time_since_restore: 7386.944304466248\n",
      "time_this_iter_s: 11.046223402023315\n",
      "time_total_s: 7386.944304466248\n",
      "timers:\n",
      "  learn_throughput: 1051.64\n",
      "  learn_time_ms: 3803.582\n",
      "  load_throughput: 16068591.131\n",
      "  load_time_ms: 0.249\n",
      "  sample_throughput: 427.709\n",
      "  sample_time_ms: 9352.142\n",
      "  update_time_ms: 2.257\n",
      "timestamp: 1658401352\n",
      "timesteps_since_restore: 3940000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3940000\n",
      "training_iteration: 985\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3944000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-02-41\n",
      "done: false\n",
      "episode_len_mean: 199.48\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.48\n",
      "episode_reward_min: 161.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20466\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.20272909104824066\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0024759825319051743\n",
      "        model: {}\n",
      "        policy_loss: -0.003842889331281185\n",
      "        total_loss: 9.230029106140137\n",
      "        vf_explained_var: -2.7559137194543837e-08\n",
      "        vf_loss: 9.233870506286621\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3944000\n",
      "  num_agent_steps_trained: 3944000\n",
      "  num_steps_sampled: 3944000\n",
      "  num_steps_trained: 3944000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 986\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.35833333333333\n",
      "  ram_util_percent: 89.31666666666666\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07304997938962661\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08373484788543444\n",
      "  mean_inference_ms: 0.8017829664230064\n",
      "  mean_raw_obs_processing_ms: 0.09659296209608056\n",
      "time_since_restore: 7395.433693647385\n",
      "time_this_iter_s: 8.489389181137085\n",
      "time_total_s: 7395.433693647385\n",
      "timers:\n",
      "  learn_throughput: 1060.071\n",
      "  learn_time_ms: 3773.333\n",
      "  load_throughput: 17394728.875\n",
      "  load_time_ms: 0.23\n",
      "  sample_throughput: 431.771\n",
      "  sample_time_ms: 9264.169\n",
      "  update_time_ms: 2.266\n",
      "timestamp: 1658401361\n",
      "timesteps_since_restore: 3944000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3944000\n",
      "training_iteration: 986\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3948000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-02-49\n",
      "done: false\n",
      "episode_len_mean: 199.24\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.24\n",
      "episode_reward_min: 137.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20486\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23947317898273468\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031249995809048414\n",
      "        model: {}\n",
      "        policy_loss: 0.00595914525911212\n",
      "        total_loss: 6.898604869842529\n",
      "        vf_explained_var: 2.499549509593635e-07\n",
      "        vf_loss: 6.892645359039307\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3948000\n",
      "  num_agent_steps_trained: 3948000\n",
      "  num_steps_sampled: 3948000\n",
      "  num_steps_trained: 3948000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 987\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.71666666666666\n",
      "  ram_util_percent: 89.10833333333335\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07308124010520506\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08377045459426782\n",
      "  mean_inference_ms: 0.8021196353208446\n",
      "  mean_raw_obs_processing_ms: 0.09662934214772666\n",
      "time_since_restore: 7403.767915248871\n",
      "time_this_iter_s: 8.334221601486206\n",
      "time_total_s: 7403.767915248871\n",
      "timers:\n",
      "  learn_throughput: 1090.428\n",
      "  learn_time_ms: 3668.283\n",
      "  load_throughput: 18916694.103\n",
      "  load_time_ms: 0.211\n",
      "  sample_throughput: 434.814\n",
      "  sample_time_ms: 9199.338\n",
      "  update_time_ms: 2.29\n",
      "timestamp: 1658401369\n",
      "timesteps_since_restore: 3948000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3948000\n",
      "training_iteration: 987\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3952000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-02-58\n",
      "done: false\n",
      "episode_len_mean: 197.74\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.74\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 20507\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.216241255402565\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031801708973944187\n",
      "        model: {}\n",
      "        policy_loss: 0.003222257364541292\n",
      "        total_loss: 7.606549263000488\n",
      "        vf_explained_var: -4.608143910900253e-08\n",
      "        vf_loss: 7.60332727432251\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3952000\n",
      "  num_agent_steps_trained: 3952000\n",
      "  num_steps_sampled: 3952000\n",
      "  num_steps_trained: 3952000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 988\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 50.03076923076923\n",
      "  ram_util_percent: 89.14615384615385\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07310884202923576\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08380183113063115\n",
      "  mean_inference_ms: 0.8024169592372836\n",
      "  mean_raw_obs_processing_ms: 0.09666130113877887\n",
      "time_since_restore: 7412.866738319397\n",
      "time_this_iter_s: 9.098823070526123\n",
      "time_total_s: 7412.866738319397\n",
      "timers:\n",
      "  learn_throughput: 1096.536\n",
      "  learn_time_ms: 3647.85\n",
      "  load_throughput: 20106922.339\n",
      "  load_time_ms: 0.199\n",
      "  sample_throughput: 446.282\n",
      "  sample_time_ms: 8962.939\n",
      "  update_time_ms: 2.406\n",
      "timestamp: 1658401378\n",
      "timesteps_since_restore: 3952000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3952000\n",
      "training_iteration: 988\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3956000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-03-09\n",
      "done: false\n",
      "episode_len_mean: 196.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.46\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20527\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2387794554233551\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0037613671738654375\n",
      "        model: {}\n",
      "        policy_loss: 0.0040453397668898106\n",
      "        total_loss: 6.84630012512207\n",
      "        vf_explained_var: -0.09677398204803467\n",
      "        vf_loss: 6.842254638671875\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3956000\n",
      "  num_agent_steps_trained: 3956000\n",
      "  num_steps_sampled: 3956000\n",
      "  num_steps_trained: 3956000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 989\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 52.978571428571435\n",
      "  ram_util_percent: 89.60000000000001\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07313198031488213\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08382816694047932\n",
      "  mean_inference_ms: 0.8026615864624066\n",
      "  mean_raw_obs_processing_ms: 0.09668756440808142\n",
      "time_since_restore: 7423.032532691956\n",
      "time_this_iter_s: 10.165794372558594\n",
      "time_total_s: 7423.032532691956\n",
      "timers:\n",
      "  learn_throughput: 1069.702\n",
      "  learn_time_ms: 3739.36\n",
      "  load_throughput: 19620180.096\n",
      "  load_time_ms: 0.204\n",
      "  sample_throughput: 440.399\n",
      "  sample_time_ms: 9082.677\n",
      "  update_time_ms: 2.432\n",
      "timestamp: 1658401389\n",
      "timesteps_since_restore: 3956000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3956000\n",
      "training_iteration: 989\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3960000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-03-20\n",
      "done: false\n",
      "episode_len_mean: 196.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.46\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20547\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.24000374972820282\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0038113039918243885\n",
      "        model: {}\n",
      "        policy_loss: -0.0002470239414833486\n",
      "        total_loss: 1.5118497610092163\n",
      "        vf_explained_var: -0.25806450843811035\n",
      "        vf_loss: 1.5120967626571655\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3960000\n",
      "  num_agent_steps_trained: 3960000\n",
      "  num_steps_sampled: 3960000\n",
      "  num_steps_trained: 3960000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 990\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 58.10625\n",
      "  ram_util_percent: 89.60624999999999\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07315336335705251\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08385317197626954\n",
      "  mean_inference_ms: 0.8028877350889374\n",
      "  mean_raw_obs_processing_ms: 0.09671242188092798\n",
      "time_since_restore: 7434.011266946793\n",
      "time_this_iter_s: 10.978734254837036\n",
      "time_total_s: 7434.011266946793\n",
      "timers:\n",
      "  learn_throughput: 1039.229\n",
      "  learn_time_ms: 3849.005\n",
      "  load_throughput: 19288590.481\n",
      "  load_time_ms: 0.207\n",
      "  sample_throughput: 427.358\n",
      "  sample_time_ms: 9359.831\n",
      "  update_time_ms: 2.514\n",
      "timestamp: 1658401400\n",
      "timesteps_since_restore: 3960000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3960000\n",
      "training_iteration: 990\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3964000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-03-29\n",
      "done: false\n",
      "episode_len_mean: 196.46\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 196.46\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20567\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21143285930156708\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.00355827366001904\n",
      "        model: {}\n",
      "        policy_loss: -0.001143640256486833\n",
      "        total_loss: 1.5109530687332153\n",
      "        vf_explained_var: -0.25806450843811035\n",
      "        vf_loss: 1.5120967626571655\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3964000\n",
      "  num_agent_steps_trained: 3964000\n",
      "  num_steps_sampled: 3964000\n",
      "  num_steps_trained: 3964000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 991\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 50.838461538461544\n",
      "  ram_util_percent: 89.82307692307691\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07317614538809313\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08387904344196384\n",
      "  mean_inference_ms: 0.8031325951084974\n",
      "  mean_raw_obs_processing_ms: 0.09674038923407383\n",
      "time_since_restore: 7443.245176315308\n",
      "time_this_iter_s: 9.233909368515015\n",
      "time_total_s: 7443.245176315308\n",
      "timers:\n",
      "  learn_throughput: 1030.217\n",
      "  learn_time_ms: 3882.677\n",
      "  load_throughput: 19228900.86\n",
      "  load_time_ms: 0.208\n",
      "  sample_throughput: 416.3\n",
      "  sample_time_ms: 9608.449\n",
      "  update_time_ms: 2.501\n",
      "timestamp: 1658401409\n",
      "timesteps_since_restore: 3964000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3964000\n",
      "training_iteration: 991\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3968000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-03-40\n",
      "done: false\n",
      "episode_len_mean: 197.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.09\n",
      "episode_reward_min: 50.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20587\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2575795352458954\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0042329509742558\n",
      "        model: {}\n",
      "        policy_loss: -0.0016339359572157264\n",
      "        total_loss: 1.5104628801345825\n",
      "        vf_explained_var: -0.1948610246181488\n",
      "        vf_loss: 1.5120967626571655\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3968000\n",
      "  num_agent_steps_trained: 3968000\n",
      "  num_steps_sampled: 3968000\n",
      "  num_steps_trained: 3968000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 992\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 59.025000000000006\n",
      "  ram_util_percent: 89.56875\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07320674918844268\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08391312594965315\n",
      "  mean_inference_ms: 0.803464423455795\n",
      "  mean_raw_obs_processing_ms: 0.09677662496286407\n",
      "time_since_restore: 7454.395988941193\n",
      "time_this_iter_s: 11.15081262588501\n",
      "time_total_s: 7454.395988941193\n",
      "timers:\n",
      "  learn_throughput: 1012.762\n",
      "  learn_time_ms: 3949.597\n",
      "  load_throughput: 18910297.565\n",
      "  load_time_ms: 0.212\n",
      "  sample_throughput: 402.421\n",
      "  sample_time_ms: 9939.847\n",
      "  update_time_ms: 2.736\n",
      "timestamp: 1658401420\n",
      "timesteps_since_restore: 3968000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3968000\n",
      "training_iteration: 992\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3972000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-03-48\n",
      "done: false\n",
      "episode_len_mean: 197.39\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 197.39\n",
      "episode_reward_min: 59.0\n",
      "episodes_this_iter: 21\n",
      "episodes_total: 20608\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23838724195957184\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0030764949042350054\n",
      "        model: {}\n",
      "        policy_loss: 0.0036831265315413475\n",
      "        total_loss: 4.943200588226318\n",
      "        vf_explained_var: -0.005018253810703754\n",
      "        vf_loss: 4.939517498016357\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3972000\n",
      "  num_agent_steps_trained: 3972000\n",
      "  num_steps_sampled: 3972000\n",
      "  num_steps_trained: 3972000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 993\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.724999999999994\n",
      "  ram_util_percent: 89.65000000000002\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07324009855356499\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08395025622110136\n",
      "  mean_inference_ms: 0.803824584447814\n",
      "  mean_raw_obs_processing_ms: 0.09681596055319204\n",
      "time_since_restore: 7462.730614185333\n",
      "time_this_iter_s: 8.334625244140625\n",
      "time_total_s: 7462.730614185333\n",
      "timers:\n",
      "  learn_throughput: 1032.754\n",
      "  learn_time_ms: 3873.138\n",
      "  load_throughput: 18927364.621\n",
      "  load_time_ms: 0.211\n",
      "  sample_throughput: 403.16\n",
      "  sample_time_ms: 9921.628\n",
      "  update_time_ms: 2.68\n",
      "timestamp: 1658401428\n",
      "timesteps_since_restore: 3972000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3972000\n",
      "training_iteration: 993\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3976000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-03-56\n",
      "done: false\n",
      "episode_len_mean: 198.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.8\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20628\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.21699543297290802\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0026252411771565676\n",
      "        model: {}\n",
      "        policy_loss: 0.0055387006141245365\n",
      "        total_loss: 5.549893856048584\n",
      "        vf_explained_var: -4.717098889273075e-08\n",
      "        vf_loss: 5.5443549156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3976000\n",
      "  num_agent_steps_trained: 3976000\n",
      "  num_steps_sampled: 3976000\n",
      "  num_steps_trained: 3976000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 994\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 41.25\n",
      "  ram_util_percent: 89.18333333333332\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07326727873405249\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08398059641051477\n",
      "  mean_inference_ms: 0.8041202417888266\n",
      "  mean_raw_obs_processing_ms: 0.09684878064079423\n",
      "time_since_restore: 7470.6765105724335\n",
      "time_this_iter_s: 7.94589638710022\n",
      "time_total_s: 7470.6765105724335\n",
      "timers:\n",
      "  learn_throughput: 1067.582\n",
      "  learn_time_ms: 3746.784\n",
      "  load_throughput: 19045539.789\n",
      "  load_time_ms: 0.21\n",
      "  sample_throughput: 415.284\n",
      "  sample_time_ms: 9631.974\n",
      "  update_time_ms: 2.661\n",
      "timestamp: 1658401436\n",
      "timesteps_since_restore: 3976000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3976000\n",
      "training_iteration: 994\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3980000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-04-04\n",
      "done: false\n",
      "episode_len_mean: 198.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.8\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20648\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.22890809178352356\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002513078274205327\n",
      "        model: {}\n",
      "        policy_loss: 0.005496256984770298\n",
      "        total_loss: 5.54985237121582\n",
      "        vf_explained_var: -8.665105610816681e-08\n",
      "        vf_loss: 5.544355869293213\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3980000\n",
      "  num_agent_steps_trained: 3980000\n",
      "  num_steps_sampled: 3980000\n",
      "  num_steps_trained: 3980000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 995\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 40.190909090909095\n",
      "  ram_util_percent: 89.24545454545454\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07328695506504644\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08400186409268416\n",
      "  mean_inference_ms: 0.8043355891400915\n",
      "  mean_raw_obs_processing_ms: 0.09687247748569977\n",
      "time_since_restore: 7478.438145875931\n",
      "time_this_iter_s: 7.7616353034973145\n",
      "time_total_s: 7478.438145875931\n",
      "timers:\n",
      "  learn_throughput: 1084.891\n",
      "  learn_time_ms: 3687.006\n",
      "  load_throughput: 19143331.812\n",
      "  load_time_ms: 0.209\n",
      "  sample_throughput: 433.054\n",
      "  sample_time_ms: 9236.721\n",
      "  update_time_ms: 2.618\n",
      "timestamp: 1658401444\n",
      "timesteps_since_restore: 3980000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3980000\n",
      "training_iteration: 995\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3984000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-04-14\n",
      "done: false\n",
      "episode_len_mean: 198.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.8\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20668\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2512425482273102\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.002878488041460514\n",
      "        model: {}\n",
      "        policy_loss: 0.00449902331456542\n",
      "        total_loss: 5.548854351043701\n",
      "        vf_explained_var: -1.3664204345786857e-07\n",
      "        vf_loss: 5.5443549156188965\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3984000\n",
      "  num_agent_steps_trained: 3984000\n",
      "  num_steps_sampled: 3984000\n",
      "  num_steps_trained: 3984000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 996\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 51.607142857142854\n",
      "  ram_util_percent: 89.37142857142858\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07330592805372936\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08402246224335391\n",
      "  mean_inference_ms: 0.8045395828151928\n",
      "  mean_raw_obs_processing_ms: 0.09689386002086377\n",
      "time_since_restore: 7488.151511669159\n",
      "time_this_iter_s: 9.71336579322815\n",
      "time_total_s: 7488.151511669159\n",
      "timers:\n",
      "  learn_throughput: 1057.738\n",
      "  learn_time_ms: 3781.656\n",
      "  load_throughput: 19257594.123\n",
      "  load_time_ms: 0.208\n",
      "  sample_throughput: 434.644\n",
      "  sample_time_ms: 9202.932\n",
      "  update_time_ms: 2.708\n",
      "timestamp: 1658401454\n",
      "timesteps_since_restore: 3984000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3984000\n",
      "training_iteration: 996\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3988000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-04-23\n",
      "done: false\n",
      "episode_len_mean: 198.8\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 198.8\n",
      "episode_reward_min: 80.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20688\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.23213931918144226\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0033668887335807085\n",
      "        model: {}\n",
      "        policy_loss: 0.0034887632355093956\n",
      "        total_loss: 5.547844409942627\n",
      "        vf_explained_var: 1.9996397426780277e-08\n",
      "        vf_loss: 5.544355392456055\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3988000\n",
      "  num_agent_steps_trained: 3988000\n",
      "  num_steps_sampled: 3988000\n",
      "  num_steps_trained: 3988000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 997\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 48.06923076923077\n",
      "  ram_util_percent: 89.58461538461538\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.073319835052033\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08403805308637485\n",
      "  mean_inference_ms: 0.80468164538411\n",
      "  mean_raw_obs_processing_ms: 0.09691035188463827\n",
      "time_since_restore: 7497.512959480286\n",
      "time_this_iter_s: 9.361447811126709\n",
      "time_total_s: 7497.512959480286\n",
      "timers:\n",
      "  learn_throughput: 1044.946\n",
      "  learn_time_ms: 3827.951\n",
      "  load_throughput: 17819666.49\n",
      "  load_time_ms: 0.224\n",
      "  sample_throughput: 427.599\n",
      "  sample_time_ms: 9354.549\n",
      "  update_time_ms: 2.704\n",
      "timestamp: 1658401463\n",
      "timesteps_since_restore: 3988000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3988000\n",
      "training_iteration: 997\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3992000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-04-32\n",
      "done: false\n",
      "episode_len_mean: 199.87\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.87\n",
      "episode_reward_min: 187.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20708\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2376507818698883\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.004566690418869257\n",
      "        model: {}\n",
      "        policy_loss: 0.0028684029821306467\n",
      "        total_loss: 5.285126686096191\n",
      "        vf_explained_var: 1.0837791108997408e-07\n",
      "        vf_loss: 5.2822585105896\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3992000\n",
      "  num_agent_steps_trained: 3992000\n",
      "  num_steps_sampled: 3992000\n",
      "  num_steps_trained: 3992000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 998\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 46.82307692307692\n",
      "  ram_util_percent: 89.7076923076923\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07333472217400122\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08405479777725162\n",
      "  mean_inference_ms: 0.804838771175969\n",
      "  mean_raw_obs_processing_ms: 0.09692791724849621\n",
      "time_since_restore: 7506.390383243561\n",
      "time_this_iter_s: 8.877423763275146\n",
      "time_total_s: 7506.390383243561\n",
      "timers:\n",
      "  learn_throughput: 1071.024\n",
      "  learn_time_ms: 3734.743\n",
      "  load_throughput: 17991652.547\n",
      "  load_time_ms: 0.222\n",
      "  sample_throughput: 422.289\n",
      "  sample_time_ms: 9472.18\n",
      "  update_time_ms: 2.573\n",
      "timestamp: 1658401472\n",
      "timesteps_since_restore: 3992000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3992000\n",
      "training_iteration: 998\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 3996000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-04-41\n",
      "done: false\n",
      "episode_len_mean: 199.87\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.87\n",
      "episode_reward_min: 187.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20728\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2267226129770279\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0023106252774596214\n",
      "        model: {}\n",
      "        policy_loss: 0.0045090047642588615\n",
      "        total_loss: 4.893621921539307\n",
      "        vf_explained_var: -7.473012431091774e-08\n",
      "        vf_loss: 4.889112949371338\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 3996000\n",
      "  num_agent_steps_trained: 3996000\n",
      "  num_steps_sampled: 3996000\n",
      "  num_steps_trained: 3996000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 999\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 44.26666666666666\n",
      "  ram_util_percent: 89.39166666666667\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07335150862237236\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08407352240378053\n",
      "  mean_inference_ms: 0.8050173023435093\n",
      "  mean_raw_obs_processing_ms: 0.09694734547687382\n",
      "time_since_restore: 7514.987002372742\n",
      "time_this_iter_s: 8.596619129180908\n",
      "time_total_s: 7514.987002372742\n",
      "timers:\n",
      "  learn_throughput: 1098.636\n",
      "  learn_time_ms: 3640.88\n",
      "  load_throughput: 17719915.505\n",
      "  load_time_ms: 0.226\n",
      "  sample_throughput: 429.396\n",
      "  sample_time_ms: 9315.42\n",
      "  update_time_ms: 2.642\n",
      "timestamp: 1658401481\n",
      "timesteps_since_restore: 3996000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 3996000\n",
      "training_iteration: 999\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n",
      "agent_timesteps_total: 4000000\n",
      "custom_metrics: {}\n",
      "date: 2022-07-21_13-04-49\n",
      "done: false\n",
      "episode_len_mean: 199.87\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 199.87\n",
      "episode_reward_min: 187.0\n",
      "episodes_this_iter: 20\n",
      "episodes_total: 20748\n",
      "experiment_id: 97ba0de45d524ff5b52346614f969764\n",
      "hostname: dufek-XPS-13\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_kl_coeff: 0.0\n",
      "        cur_lr: 4.999999873689376e-05\n",
      "        entropy: 0.2217981219291687\n",
      "        entropy_coeff: 0.0\n",
      "        kl: 0.0031868380028754473\n",
      "        model: {}\n",
      "        policy_loss: 0.0037718445528298616\n",
      "        total_loss: 4.892885684967041\n",
      "        vf_explained_var: -6.396283680487613e-08\n",
      "        vf_loss: 4.889113903045654\n",
      "      num_agent_steps_trained: 128.0\n",
      "  num_agent_steps_sampled: 4000000\n",
      "  num_agent_steps_trained: 4000000\n",
      "  num_steps_sampled: 4000000\n",
      "  num_steps_trained: 4000000\n",
      "  num_steps_trained_this_iter: 4000\n",
      "iterations_since_restore: 1000\n",
      "node_ip: 192.168.70.28\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 39.63636363636363\n",
      "  ram_util_percent: 89.64545454545456\n",
      "pid: 539417\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07336890081094619\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.08409288443653075\n",
      "  mean_inference_ms: 0.8052012235377071\n",
      "  mean_raw_obs_processing_ms: 0.09696733829529773\n",
      "time_since_restore: 7522.9491720199585\n",
      "time_this_iter_s: 7.962169647216797\n",
      "time_total_s: 7522.9491720199585\n",
      "timers:\n",
      "  learn_throughput: 1129.999\n",
      "  learn_time_ms: 3539.828\n",
      "  load_throughput: 17600939.992\n",
      "  load_time_ms: 0.227\n",
      "  sample_throughput: 443.425\n",
      "  sample_time_ms: 9020.682\n",
      "  update_time_ms: 2.837\n",
      "timestamp: 1658401489\n",
      "timesteps_since_restore: 4000000\n",
      "timesteps_this_iter: 4000\n",
      "timesteps_total: 4000000\n",
      "training_iteration: 1000\n",
      "trial_id: default\n",
      "warmup_time: 5.1087517738342285\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = ppo.PPOTrainer(config=config, env='CartPole-v0')\n",
    "for i in range(1000):\n",
    "    result = trainer.train()\n",
    "    print(pretty_print(result))\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        checkpoint = trainer.save()\n",
    "        print(f'checkpoint save at {checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Mulit-Input and Custom Model in RLlib\n",
    "import tensorflow as tf\n",
    "from ray.rllib.models.modelv2 import restore_original_dimensions\n",
    "from ray.rllib.models.tf.misc import normc_initializer\n",
    "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "from ray.rllib.utils.typing import ModelConfigDict\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasQModel(TFModelV2):\n",
    "    \"DQN\"\n",
    "    def __init__(self, obs_space: gym.spaces.Space, action_space: gym.spaces.Space, num_outputs: int, model_config: ModelConfigDict, name: str):\n",
    "        super(KerasQModel, self).__init__(obs_space, action_space, num_outputs, model_config, name)\n",
    "        original_space = obs_space.original_space if hasattr(obs_space, \"original_space\") else obs_space\n",
    "        self.cart = tf.keras.layers.Input(shape=original_space['cart'].shape, name='cart')\n",
    "        self.pole = tf.keras.layers.Input(shape=original_space['pole'].shape, name='pole')\n",
    "\n",
    "        # Concatenating the inputs\n",
    "        concatenated = tf.keras.layers.Concatenate()([self.cart, self.pole])\n",
    "\n",
    "        # Building the dense (fully-connected) layers\n",
    "        x = concatenated\n",
    "        neuron_lst = [ 64, 32, 16, 8, num_outputs]\n",
    "        for layer_id, nr_neurons in enumerate(neuron_lst):\n",
    "            x = tf.keras.layers.Dense(nr_neurons, name='dense_layer_' + str(layer_id), activation = tf.nn.relu,\n",
    "                                    kernel_initializer=normc_initializer(1.0))(x)\n",
    "                            \n",
    "        layer_out = x \n",
    "        self.model = tf.keras.Model([self.cart, self.pole], layer_out)\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        \"Custom coreforward method\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from ray.rllib.models.modelv2 import restore_original_dimensions\n",
    "from ray.rllib.models.tf.misc import normc_initializer\n",
    "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
    "from ray.rllib.policy.sample_batch import SampleBatch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_20/concat:0' shape=(?, 4) dtype=float32>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_space = {\n",
    "    'cart': np.array([-4.8, 0]),\n",
    "    'pole': np.array([-0.418, 0])\n",
    "}\n",
    "\n",
    "#print(obs_space['cart'].shape)\n",
    "#print(obs_space['pole'].shape)\n",
    "\n",
    "cart = tf.keras.layers.Input(shape=obs_space['cart'].shape, name='cart')\n",
    "pole = tf.keras.layers.Input(shape=obs_space['pole'].shape, name='pole')\n",
    "radek = tf.keras.layers.Input(shape=(0,), name='radek')\n",
    "zadek = tf.keras.layers.Input(shape=(1,), name='zadek')\n",
    "\n",
    "concatenated = tf.keras.layers.Concatenate()([cart, pole])\n",
    "concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " cart (InputLayer)              [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " pole (InputLayer)              [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 4)            0           ['cart[0][0]',                   \n",
      "                                                                  'pole[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_layer_0 (Dense)          (None, 64)           320         ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " dense_layer_1 (Dense)          (None, 32)           2080        ['dense_layer_0[0][0]']          \n",
      "                                                                                                  \n",
      " dense_layer_2 (Dense)          (None, 16)           528         ['dense_layer_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_layer_3 (Dense)          (None, 8)            136         ['dense_layer_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_layer_4 (Dense)          (None, 8)            72          ['dense_layer_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,136\n",
      "Trainable params: 3,136\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model was constructed with shape (?, 2) for input Tensor(\"cart_24:0\", shape=(?, 2), dtype=float32), but it was called on an input with incompatible shape (2,).\n",
      "WARNING:tensorflow:Model was constructed with shape (?, 2) for input Tensor(\"pole_23:0\", shape=(?, 2), dtype=float32), but it was called on an input with incompatible shape (2,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"dense_layer_0\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (Dimension(4),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dufek/Documents/finrl/rllib_example.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000009?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000009?line=12'>13</a>\u001b[0m inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000009?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcart\u001b[39m\u001b[39m'\u001b[39m: obs_space[\u001b[39m'\u001b[39m\u001b[39mcart\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000009?line=14'>15</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mpole\u001b[39m\u001b[39m'\u001b[39m: obs_space[\u001b[39m'\u001b[39m\u001b[39mpole\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000009?line=15'>16</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000009?line=17'>18</a>\u001b[0m model(inputs)\n",
      "File \u001b[0;32m~/.virtualenvs/rayrl/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.virtualenvs/rayrl/lib/python3.8/site-packages/keras/engine/input_spec.py:228\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    226\u001b[0m   ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    227\u001b[0m   \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    230\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    231\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    232\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"dense_layer_0\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (Dimension(4),)"
     ]
    }
   ],
   "source": [
    "x = concatenated\n",
    "num_outputs = 8\n",
    "neuron_lst = [64, 32, 16, 8, num_outputs]\n",
    "for layer_id, nr_neurons in enumerate(neuron_lst):\n",
    "    #print(layer_id, nr_neurons)\n",
    "    x = tf.keras.layers.Dense(nr_neurons, name='dense_layer_'+str(layer_id), activation=tf.nn.relu, \n",
    "                                kernel_initializer=normc_initializer(1.0))(x)\n",
    "\n",
    "layer_out = x\n",
    "model = tf.keras.Model([cart, pole], layer_out)\n",
    "print(model.summary())\n",
    "\n",
    "inputs = {\n",
    "    'cart': obs_space['cart'],\n",
    "    'pole': obs_space['pole']\n",
    "}\n",
    "\n",
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obs'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Customize Training Procedure -- callback actions\n",
    "# https://stackoverflow.com/questions/58777068/how-do-we-print-action-distributions-in-rllib-during-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1, layer2: (torch.Size([1000, 100]), torch.Size([100, 10]))\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "99 666.9195556640625\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "199 8.539146423339844\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "299 0.18283146619796753\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "399 0.004631791729480028\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "h: torch.Size([64, 100])\n",
      "clamped h: torch.Size([64, 100])\n",
      "layer2 out: torch.Size([64, 10])\n",
      "499 0.0003046269412152469\n"
     ]
    }
   ],
   "source": [
    "# Computational Graph\n",
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device('cpu')\n",
    "\n",
    "batch_size, inputs, hidden, outputs = 64, 1000, 100, 10\n",
    "x = torch.randn(batch_size, inputs, device=device, dtype=dtype)\n",
    "y = torch.randn(batch_size, outputs, device=device, dtype=dtype)\n",
    "\n",
    "layer1 = torch.randn(inputs, hidden, device=device, dtype=dtype)\n",
    "layer2 = torch.randn(hidden, outputs, device=device, dtype=dtype)\n",
    "print(f'layer1, layer2: {layer1.shape, layer2.shape}')\n",
    "learning_rate = 1e-6\n",
    "\n",
    "for t in range(500):\n",
    "    h = x.mm(layer1)\n",
    "    print(f'h: {h.shape}')\n",
    "    h_relu = h.clamp(min=0)\n",
    "    print(f'clamped h: {h_relu.shape}')\n",
    "    y_pred = h_relu.mm(layer2)\n",
    "    print(f'layer2 out: {y_pred.shape}')\n",
    "\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_layer2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(layer2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    \n",
    "    grad_h[h<0] = 0\n",
    "    grad_layer1 = x.t().mm(grad_h)\n",
    "\n",
    "    layer1 -= learning_rate * grad_layer1\n",
    "    layer2 -= learning_rate * grad_layer2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 641.9111938476562\n",
      "100 2.742946147918701\n",
      "200 0.06663484871387482\n",
      "300 0.002461441792547703\n",
      "400 0.00012200658966321498\n"
     ]
    }
   ],
   "source": [
    "# Torch to DL Graph\n",
    "import torch\n",
    "\n",
    "batch_size, inputs, hidden, outputs = 64, 1000, 100, 10\n",
    "\n",
    "x = torch.randn(batch_size, inputs)\n",
    "y = torch.randn(batch_size, outputs)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputs, hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden, outputs)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-4\n",
    "\n",
    "for t in range(500):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DQN using Torch\n",
    "import math, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import trange\n",
    "\n",
    "env_id = \"CartPole-v0\"\n",
    "#env_id = 'LunarLander-v2'\n",
    "\n",
    "env = gym.make(env_id)\n",
    "epsilon_start = 1.0\n",
    "\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 1000\n",
    "eps_by_episode = lambda epoch: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * epoch / epsilon_decay)\n",
    "\n",
    "plt.plot([eps_by_episode(i) for i in range(10000)])\n",
    "plt.show\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Agent Training: 14 Avg Reward 0.9285714285714286:   0%|          | 0/10001 [00:00<?, ?it/s]/tmp/ipykernel_452925/2002858631.py:38: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  state = autograd.Variable(torch.FloatTensor(state).unsqueeze(0),\n",
      "Agent Training: 33 Avg Reward 0.9696969696969697:   0%|          | 0/10001 [00:00<?, ?it/s]/tmp/ipykernel_452925/2002858631.py:69: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  state = autograd.Variable(torch.FloatTensor(np.float32(state)), volatile=True)\n",
      "/tmp/ipykernel_452925/2002858631.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  next_state = autograd.Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
      "/tmp/ipykernel_452925/2002858631.py:71: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  action = autograd.Variable(torch.LongTensor(reward))\n",
      "Agent Training: 10001 Avg Reward 0.9999000099990001: 100%|| 10001/10001 [02:16<00:00, 73.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from asyncore import readwrite\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(DQN, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(env.observation_space.shape[0], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, env.action_space.n)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state = autograd.Variable(torch.FloatTensor(state).unsqueeze(0),\n",
    "            volatile=True)\n",
    "            q_value = self.forward(state)\n",
    "            action = q_value.max(1)[1].item() # index of the maximul value(s)\n",
    "        else:\n",
    "            action = random.randrange(env.action_space.n)\n",
    "            q_value = None\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "model = DQN(env.observation_space.shape[0], env.action_space.n)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "replay_buffer = ReplayBuffer(capacity=1000)\n",
    "\n",
    "episodes = 10000\n",
    "batch_size = 32\n",
    "gamma = 0.99\n",
    "buffer_size = 3000 # DQN will not start training the model until the replay buffer is full\n",
    "neurons = 192\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()\n",
    "tot_reward = 0\n",
    "tr = trange(episodes+1, desc='Agent Training', leave=True)\n",
    "\n",
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done  = replay_buffer.sample(batch_size)\n",
    "    state = autograd.Variable(torch.FloatTensor(np.float32(state)), volatile=True)\n",
    "    next_state = autograd.Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
    "    action = autograd.Variable(torch.LongTensor(reward))\n",
    "    reward = autograd.Variable(torch.FloatTensor(reward))\n",
    "    done = autograd.Variable(torch.FloatTensor(done))\n",
    "\n",
    "    q_values = model(state)\n",
    "    next_q_values = model(next_state)\n",
    "    q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    next_q_value = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "\n",
    "    loss = (q_value - autograd.Variable(expected_q_value.data)).pow(2).mean()\n",
    "    \n",
    "    optimizer.zero_grad() # reset gradients\n",
    "    loss.backward() # push the loss backwards\n",
    "    optimizer.step() # make up weights (perform training)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def play_game():\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    while not done:\n",
    "        action = model.act(state, epsilon_final)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        state = next_state\n",
    "\n",
    "for episode in tr:\n",
    "\n",
    "    tr.set_description(f\"Agent Training: {episode+1} Avg Reward {tot_reward/(episode+1)}\")\n",
    "    tr.refresh()\n",
    "    epsilon = eps_by_episode(episode)\n",
    "\n",
    "    action = model.act(state, epsilon)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    tot_reward += reward\n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "\n",
    "    if done:\n",
    "        if episode > buffer_size:\n",
    "            play_game()\n",
    "            state = env.reset()\n",
    "            all_rewards.append(episode_reward)\n",
    "            episode_reward = 0\n",
    "\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "\n",
    "    if len(replay_buffer) > batch_size:\n",
    "        loss = compute_td_loss(batch_size)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    #if episode % 2000 == 0:\n",
    "        #plot(episode, all_rewards, losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# action = q_value.max(1)[1].item() # returns only scalar value\n",
    "q_value = torch.FloatTensor(np.array([[1., -2., 0.], [3., 5., 10.], [3., 5., 0.]]))\n",
    "#q_value.max(1)[1].item()\n",
    "q_value.max(1)[1] # returns indexes of maximas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ReplayBuffer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dufek/Documents/finrl/rllib_example.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000017?line=64'>65</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000017?line=66'>67</a>\u001b[0m replay_start \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000017?line=67'>68</a>\u001b[0m replay_buffer \u001b[39m=\u001b[39m ReplayBuffer(\u001b[39m100000\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000017?line=69'>70</a>\u001b[0m episodes \u001b[39m=\u001b[39m \u001b[39m1400000\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000017?line=71'>72</a>\u001b[0m \u001b[39mif\u001b[39;00m episode \u001b[39m%\u001b[39m \u001b[39m200000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ReplayBuffer' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DDQN -- Double (Dueling) DQN\n",
    "import wrappers\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "env_id = 'PongNoFrameskip-v4'\n",
    "env = wrappers.make_atari(env_id)\n",
    "env = wrappers.wrap_deepmind(env)\n",
    "env = wrappers.wrap_pytorch(env)\n",
    "\n",
    "epsilon_start = 1.\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 30000\n",
    "\n",
    "epsilon_by_episode = lambda episode: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * episode / epsilon_decay)\n",
    "\n",
    "plt.plot([epsilon_by_episode(i) for i in range(1000000)])\n",
    "plt.show\n",
    "\n",
    "class CnnDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(CnnDQN, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size(), 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
    "\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state = autograd.Variable(torch.FloatTensor(np.float32(state).unsqueeze(0), volatile=True))\n",
    "            q_value = self.forward(state)\n",
    "            action = q_value.max(1)[1].data[0]\n",
    "        else:\n",
    "            action = random.randrange(env.action_space.n)\n",
    "        return action\n",
    "\n",
    "\n",
    "model = CnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "replay_start = 10000\n",
    "replay_buffer = ReplayBuffer(100000)\n",
    "\n",
    "episodes = 1400000\n",
    "\n",
    "if episode % 200000 == 0:\n",
    "    plot(episode, all_rewards, losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dufek/Documents/finrl/rllib_example.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39m# DDQN\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000020?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m rand\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000020?line=4'>5</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDDQN\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000020?line=5'>6</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, num_inputs, num_outputs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000020?line=6'>7</a>\u001b[0m         \u001b[39msuper\u001b[39m(DDQN, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# DDQN\n",
    "from torch import rand\n",
    "\n",
    "\n",
    "class DDQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(DDQN, self).__init__()\n",
    "\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.advantage = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_outputs)\n",
    "        )\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.feature(x)\n",
    "            advantage = self.advantage(x)\n",
    "            value = self.value(x)\n",
    "            return value + advantage - advantage.mean()\n",
    "\n",
    "        def act(self, state, epsilon):\n",
    "            if random.random() > epsilon:\n",
    "                state = autograd.Variable(torch.FloatTensor(state).unsqueeze(0), volatile=True)\n",
    "                q_value = self.forward(state)\n",
    "                action = q_value.max(1)[1].item()\n",
    "            else:\n",
    "                action = random.randrange(env.action_space.n)\n",
    "            return action\n",
    "\n",
    "current_model = DDQN(env.observation_space.shape[0], env.action_space.n)\n",
    "target_model = DDQN(env.observation_space.shape[0], env.action_space.n)\n",
    "\n",
    "q_values = current_model(state)\n",
    "next_q_values = target_model(next_state)\n",
    "\n",
    "q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "next_q_value = next_q_values.max(1)[0]\n",
    "expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "\n",
    "loss = (q_value - expected_q_value.detach()).pow(2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1047347126.py, line 75)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [10]\u001b[0;36m\u001b[0m\n\u001b[0;31m    done = autograd.\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Replay Buffer with Prioritized Experience\n",
    "from random import sample\n",
    "\n",
    "from numpy import indices\n",
    "\n",
    "\n",
    "class NaivePrioritizedBudder(object):\n",
    "    def __init__(self, capacity, prob_alpha=0.6):\n",
    "        self.prob_alpha = prob_alpha\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.pos = 0\n",
    "        self.priorities = np.zeros((capacity), dtype=np.float32)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        assert state.ndim == next_state.ndim\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "        max_prio = self.priorities.max() if self.buffer else 1.0\n",
    "\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append((state, action, reward, next_state, done))\n",
    "        else:\n",
    "            self.buffer[self.pos] = (state, action, reward, next_state, done)\n",
    "\n",
    "        self.priorities[self.pos] = max_prio\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        if len(self.buffer) == self.capacity:\n",
    "            prios = self.priorities\n",
    "        else:\n",
    "            prios = self.priorities[:self.pos]\n",
    "\n",
    "        probs = prios ** self.prob_alpha\n",
    "        probs /= probs.sum()\n",
    "\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [ self.buffer[idx] for idx in indices ]\n",
    "\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()\n",
    "        weights = np.array(weights, dtype=np.float32)\n",
    "\n",
    "        batch = list(zip(*samples))\n",
    "        states = np.concatenate(batch[0])\n",
    "        actions = batch[1]\n",
    "        rewards = batch[2]\n",
    "        next_states = np.concatenate(batch[3])\n",
    "        dones = batch[4]\n",
    "\n",
    "        return states, actions, rewards, next_states, dones, indices, weights\n",
    "\n",
    "    def update_priorities(self, batch_indices, batch_priorities):\n",
    "        for idx, prio in zip(list(batch_indices), [batch_priorities]):\n",
    "            self.priorities[idx] = prio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "beta_start = 0.4\n",
    "beta_episodes = episodes / 10\n",
    "beta_by_episode = lambda episode: min(1., beta_start + episode * (1. - beta_start) / beta_episodes)\n",
    "\n",
    "plt.plot([beta_by_episode(i) for i in range(episodes)])\n",
    "\n",
    "def compute_td_loss(batch_size, beta):\n",
    "    state, action, reward, next_state, done, indices, weights = replay_buffer.sample(batch_size, beta)\n",
    "\n",
    "    state = autograd.Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = autograd.Variable(torch.FloatTensor(np.float32(next_state)))\n",
    "    action = autograd.Variable(torch.LongTensor(action))\n",
    "    reward = autograd.Variable(torch.FloatTensor(reward))\n",
    "    done = autograd.Variable(torch.FloatTensor(done))\n",
    "    weights = autograd.Variable(torch.FloatTensor(weights))\n",
    "\n",
    "    q_values = current_model(state)\n",
    "    next_q_values = target_model(next_state)\n",
    "\n",
    "    q_value = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "\n",
    "    loss = (q_value - expected_q_value.detach()).pow(2).mean()\n",
    "    prios = loss + 1e-5\n",
    "    loss = loss.mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    replay_buffer.update_priorities(indices, prios.data.cpu().numpy())\n",
    "    optimizer.step()\n",
    "\n",
    "if done:\n",
    "    if episode > buffer_size and avg_reward > min_play_reward:\n",
    "        play_game()\n",
    "    state = env.reset()\n",
    "    all_rewards.append(episode_reward)\n",
    "    episode_reward = 0\n",
    "\n",
    "if len(replay_buffer) > batch_size:\n",
    "    beta = beta_by_episode(episode)\n",
    "    loss = compute_td_loss(batch_size, beta)\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 84)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POLICY GRADIENT METHODS\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# sampling out action space from continuous probability back to discrete action value\n",
    "from torch.distributions import Categorical \n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionL 2\n",
      "Log Prob: -1.459815502166748\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2035449743270874\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4747905731201172\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.4127229452133179\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2032055854797363\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4678841829299927\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.497996211051941\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.4036810398101807\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2036086320877075\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.4006272554397583\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.205574870109558\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.5200520753860474\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.204581379890442\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3931373357772827\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3924733400344849\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3907074928283691\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3884668350219727\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2079715728759766\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2077945470809937\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4459980726242065\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.551629900932312\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3734307289123535\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4501683712005615\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.200600504875183\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.452732801437378\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3629833459854126\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.194732904434204\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.5730259418487549\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4635006189346313\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.1899724006652832\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4665615558624268\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.5862854719161987\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3466953039169312\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4745404720306396\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.5924705266952515\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4786194562911987\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.177839756011963\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3368213176727295\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.5963490009307861\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.1768180131912231\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3309893608093262\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.1767326593399048\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.176817536354065\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4962685108184814\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.1772407293319702\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.1786621809005737\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.499182939529419\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.6027252674102783\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3117766380310059\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3088922500610352\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5108932256698608\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.1852086782455444\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3007336854934692\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2978742122650146\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.1937083005905151\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2923070192337036\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.1998940706253052\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2022483348846436\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.526666522026062\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.5831236839294434\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5298184156417847\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.578173041343689\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2105485200881958\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2139272689819336\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2178232669830322\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5363644361495972\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.563428521156311\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2260777950286865\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2675559520721436\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5454312562942505\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2364009618759155\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2401076555252075\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.537367343902588\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.259307861328125\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.552184820175171\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2548630237579346\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2546314001083374\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2537490129470825\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5597730875015259\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.248090386390686\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2725903987884521\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.276246190071106\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.280142903327942\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.497623324394226\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2859382629394531\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4858009815216064\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2403957843780518\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2401388883590698\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.301594614982605\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.455759882926941\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4511616230010986\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2458690404891968\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5850292444229126\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4280370473861694\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5902760028839111\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2537802457809448\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.3213329315185547\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.390319585800171\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.3280818462371826\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.3333412408828735\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.3396414518356323\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2507309913635254\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5255768299102783\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2767051458358765\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2764277458190918\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.5063265562057495\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5196083784103394\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2794029712677002\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.514702558517456\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2689307928085327\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5084089040756226\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.5133846998214722\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.2738028764724731\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5049275159835815\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2849597930908203\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4958735704421997\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2885456085205078\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5031499862670898\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4807974100112915\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4771935939788818\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5018080472946167\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.2996346950531006\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4584534168243408\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3055256605148315\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5048240423202515\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3098435401916504\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.3159866333007812\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.4192376136779785\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5029629468917847\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3181713819503784\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.3288015127182007\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3213896751403809\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3240947723388672\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5037930011749268\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.5010117292404175\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3322889804840088\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4972206354141235\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.3466556072235107\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.371415376663208\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.3626796007156372\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3498021364212036\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.356317162513733\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4869552850723267\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.344900369644165\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4810069799423218\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.364639163017273\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3672189712524414\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.372357726097107\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.313665747642517\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4766117334365845\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.3098583221435547\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3886998891830444\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.3965027332305908\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.2807788848876953\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.280231237411499\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.3931266069412231\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.4234733581542969\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.4012372493743896\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.2444103956222534\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.241163730621338\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.410935401916504\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 0\n",
      "Log Prob: -1.417309284210205\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.2163727283477783\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4563108682632446\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.464690089225769\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 3\n",
      "Log Prob: -1.4569488763809204\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 2\n",
      "Log Prob: -1.1845041513442993\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "actionL 1\n",
      "Log Prob: -1.4403364658355713\n",
      "actionL 2\n",
      "Log Prob: -1.3084418773651123\n",
      "From train_net: <class 'numpy.float64'>, <class 'torch.Tensor'>\n",
      "From train_net: <class 'int'>, <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/torch/autograd/__init__.py:173: UserWarning: Error detected in MvBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_592361/2101006532.py\", line 67, in <cell line: 64>\n",
      "    prob = pi.act(torch.from_numpy(s).float())\n",
      "  File \"/tmp/ipykernel_592361/2101006532.py\", line 23, in act\n",
      "    x = F.softmax(self.fc2(x.clone()), dim=0)\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/dufek/.virtualenvs/rayrl/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [4, 128]], which is output 0 of AsStridedBackward0, is at version 169; expected version 168 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/dufek/Documents/finrl/rllib_example.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 64>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=78'>79</a>\u001b[0m         play_game()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=79'>80</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=80'>81</a>\u001b[0m pi\u001b[39m.\u001b[39;49mtrain_net()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=81'>82</a>\u001b[0m \u001b[39mif\u001b[39;00m iteration\u001b[39m%\u001b[39mprint_interval\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m iteration\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=82'>83</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m# of episode :\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, avg score : \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(iteration, score\u001b[39m/\u001b[39mprint_interval))\n",
      "\u001b[1;32m/home/dufek/Documents/finrl/rllib_example.ipynb Cell 11\u001b[0m in \u001b[0;36mREINFORCE.train_net\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=36'>37</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mlog_prob \u001b[39m*\u001b[39m R\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=37'>38</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=38'>39</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=39'>40</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dufek/Documents/finrl/rllib_example.ipynb#ch0000010?line=40'>41</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.virtualenvs/rayrl/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.virtualenvs/rayrl/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [4, 128]], which is output 0 of AsStridedBackward0, is at version 169; expected version 168 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "#Hyperparameters\n",
    "\n",
    "learning_rate = 0.0002\n",
    "gamma = 0.98\n",
    "\n",
    "class REINFORCE(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(REINFORCE, self).__init__()\n",
    "        \n",
    "        self.data = []\n",
    "        self.fc1 = nn.Linear(input_shape, 128)\n",
    "        self.fc2 = nn.Linear(128, num_actions)\n",
    "        self.optimizer = optim.Adam(self.parameters(),\n",
    "        lr=learning_rate)\n",
    "\n",
    "    def act(self, x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x.clone()), dim=0)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def put_data(self, item):\n",
    "        self.data.append(item)\n",
    "        \n",
    "    def train_net(self):\n",
    "\n",
    "        R = 0\n",
    "        for r, log_prob in self.data[::-1]:\n",
    "            print(f'From train_net: {type(r)}, {type(log_prob)}')\n",
    "            R = r + gamma * R\n",
    "            loss = -log_prob * R\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        self.data = []\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "pi = REINFORCE(env.observation_space.shape[0], env.action_space.n)\n",
    "score = 0.0\n",
    "print_interval = 100\n",
    "iterations = 10000\n",
    "min_play_reward = 20\n",
    "\n",
    "def play_game():\n",
    "\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    its = 500\n",
    "    while(not done and its > 0):\n",
    "        its -= 1\n",
    "        prob = pi.act(torch.from_numpy(state).float())\n",
    "        m = Categorical(prob)\n",
    "        action = m.sample()\n",
    "        next_state, reward, done, _ = env.step(action.item())\n",
    "        env.render()\n",
    "        state = next_state\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    s = env.reset()\n",
    "    for t in range(101):\n",
    "        prob = pi.act(torch.from_numpy(s).float())\n",
    "        m = Categorical(prob)\n",
    "        action = m.sample()\n",
    "        print(f'actionL {action}')\n",
    "        s_prime, r, done, info = env.step(action.item())\n",
    "        log_prob = torch.log(prob[action])\n",
    "        pi.put_data((r, log_prob))\n",
    "        print(f'Log Prob: {torch.log(prob[action])}')\n",
    "        s = s_prime\n",
    "        score += r\n",
    "        if done:\n",
    "            if score/print_interval > min_play_reward:\n",
    "                play_game()\n",
    "            break\n",
    "        pi.train_net()\n",
    "        if iteration%print_interval==0 and iteration!=0:\n",
    "            print(\"# of episode :{}, avg score : {}\".format(iteration, score/print_interval))\n",
    "        score = 0.0\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('rayrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58fc6565d1668f3a8f15489726c1f6002b6628ee77d2c1b5ccf40e4dc6d2dd90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
